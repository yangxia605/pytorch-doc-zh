{"./":{"url":"./","title":"PyTorch 1.4 教程&文档","keywords":"","body":"PyTorch 1.4 中文文档 & 教程 PyTorch 是一个针对深度学习, 并且使用 GPU 和 CPU 来优化的 tensor library (张量库) 正在校验: 1.4 中文版本 最新 英文教程 最新 英文文档 1.0 中文版本 1.2 中文版本 0.4 中文版本 0.3 中文版本 0.2 中文版本 欢迎任何人参与和完善：一个人可以走的很快，但是一群人却可以走的更远。 在线阅读 ApacheCN 学习资源 PyTorch 中文翻译组 | ApacheCN 713436582 目录结构 PyTorch 1.4 教程&文档 入门 使用 PyTorch 进行深度学习：60 分钟的闪电战 编写自定义数据集，数据加载器和转换 使用 TensorBoard 可视化模型，数据和训练 图片 TorchVision 对象检测微调教程 转移学习的计算机视觉教程 空间变压器网络教程 使用 PyTorch 进行神经传递 对抗示例生成 DCGAN 教程 音频 torchaudio 教程 文本 NLP From Scratch: 使用char-RNN对姓氏进行分类 NLP From Scratch: 生成名称与字符级RNN NLP From Scratch: 基于注意力机制的 seq2seq 神经网络翻译 使用 TorchText 进行文本分类 使用 TorchText 进行语言翻译 使用 nn.Transformer 和 TorchText 进行序列到序列建模 命名为 Tensor(实验性） (实验性）PyTorch 中的命名张量简介 强化学习 强化学习(DQN）教程 在生产中部署 PyTorch 模型 通过带有 Flask 的 REST API 在 Python 中部署 PyTorch TorchScript 简介 在 C ++中加载 TorchScript 模型 (可选）将模型从 PyTorch 导出到 ONNX 并使用 ONNX Runtime 运行 并行和分布式训练 单机模型并行最佳实践 分布式数据并行入门 用 PyTorch 编写分布式应用程序 分布式 RPC 框架入门 (高级）带有 Amazon AWS 的 PyTorch 1.0 分布式训练师 扩展 PyTorch 使用自定义 C ++运算符扩展 TorchScript 使用自定义 C ++类扩展 TorchScript 使用 numpy 和 scipy 创建扩展 自定义 C ++和 CUDA 扩展 模型优化 LSTM Word 语言模型上的(实验）动态量化 (实验性）在 PyTorch 中使用 Eager 模式进行静态量化 (实验性）计算机视觉教程的量化转移学习 (实验）BERT 上的动态量化 修剪教程 PyTorch 用其他语言 使用 PyTorch C ++前端 PyTorch 基础知识 通过示例学习 PyTorch torch.nn 到底是什么？ 文件 笔记 自动毕业力学 广播语义 CPU 线程和 TorchScript 推断 CUDA 语义 分布式 Autograd 设计 扩展 PyTorch 经常问的问题 大规模部署的功能 并行处理最佳实践 重现性 远程参考协议 序列化语义 Windows 常见问题 XLA 设备上的 PyTorch 语言绑定 PyTorch C ++ API PyTorch Java API Python API torch torch.nn torch功能 torch张量 张量属性 自动差分包-Torch.Autograd torch.cuda 分布式通讯包-Torch.Distributed 概率分布-torch分布 torch.hub torch脚本 torch.nn.init torch.onnx torch.optim 量化 分布式 RPC 框架 torch随机 torch稀疏 torch存储 torch.utils.bottleneck torch.utils.checkpoint torch.utils.cpp_extension torch.utils.data torch.utils.dlpack torch.utils.model_zoo torch.utils.tensorboard 类型信息 命名张量 命名为 Tensors 操作员范围 糟糕！ torchvision参考 torchvision 音频参考 torchaudio torchtext参考 torchtext 社区 PyTorch 贡献指南 PyTorch 治理 PyTorch 治理| 感兴趣的人 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 15:24:18 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"4.html":{"url":"4.html","title":"使用 PyTorch 进行深度学习：60 分钟的闪电战","keywords":"","body":"使用 PyTorch 进行深度学习：60 分钟的闪电战 原文： https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html 作者： Soumith Chintala 本教程的目标： 全面了解 PyTorch 的 Tensor 库和神经网络。 训练一个小型神经网络对图像进行分类 本教程假定您对 numpy 有基本的了解。 注意 确保已安装torch和torch软件包。 什么是 PyTorch？ Autograd：自动分化 神经网络 训练分类器 可选：数据并行 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-23 10:16:42 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"blitz/tensor_tutorial.html":{"url":"blitz/tensor_tutorial.html","title":"什么是PyTorch？","keywords":"","body":"什么是PyTorch？ 原文： https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html 译者：bat67 校验者：FontTian 作者： Soumith Chintala PyTorch是一个基于python的科学计算包，主要针对两类人群： 作为NumPy的替代品，可以利用GPU的性能进行计算 作为一个高灵活性、速度快的深度学习平台 入门 张量 Tensor(张量）类似于NumPy的ndarray，但还可以在GPU上使用来加速计算。 from __future__ import print_function import torch 创建一个没有初始化的5*3矩阵： x = torch.empty(5, 3) print(x) 输出： tensor([[2.2391e-19, 4.5869e-41, 1.4191e-17], [4.5869e-41, 0.0000e+00, 0.0000e+00], [0.0000e+00, 0.0000e+00, 0.0000e+00], [0.0000e+00, 0.0000e+00, 0.0000e+00], [0.0000e+00, 0.0000e+00, 0.0000e+00]]) 创建一个随机初始化矩阵： x = torch.rand(5, 3) print(x) 输出： tensor([[0.5307, 0.9752, 0.5376], [0.2789, 0.7219, 0.1254], [0.6700, 0.6100, 0.3484], [0.0922, 0.0779, 0.2446], [0.2967, 0.9481, 0.1311]]) 构造一个填满0且数据类型为long的矩阵: x = torch.zeros(5, 3, dtype=torch.long) print(x) 输出： tensor([[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]) 直接从数据构造张量： x = torch.tensor([5.5, 3]) print(x) 输出： tensor([5.5000, 3.0000]) 或者根据已有的tensor建立新的tensor。除非用户提供新的值，否则这些方法将重用输入张量的属性，例如dtype等： x = x.new_ones(5, 3, dtype=torch.double) # new_* methods take in sizes print(x) x = torch.randn_like(x, dtype=torch.float) # 重载 dtype! print(x) # 结果size一致 输出： tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) tensor([[ 1.6040, -0.6769, 0.0555], [ 0.6273, 0.7683, -0.2838], [-0.7159, -0.5566, -0.2020], [ 0.6266, 0.3566, 1.4497], [-0.8092, -0.6741, 0.0406]]) 获取张量的形状： print(x.size()) 输出： torch.Size([5, 3]) 注意： torch.Size本质上还是tuple，所以支持tuple的一切操作。 运算 一种运算有多种语法。在下面的示例中，我们将研究加法运算。 加法：形式一 y = torch.rand(5, 3) print(x + y) 输出： tensor([[ 2.5541, 0.0943, 0.9835], [ 1.4911, 1.3117, 0.5220], [-0.0078, -0.1161, 0.6687], [ 0.8176, 1.1179, 1.9194], [-0.3251, -0.2236, 0.7653]]) 加法：形式二 print(torch.add(x, y)) 输出： tensor([[ 2.5541, 0.0943, 0.9835], [ 1.4911, 1.3117, 0.5220], [-0.0078, -0.1161, 0.6687], [ 0.8176, 1.1179, 1.9194], [-0.3251, -0.2236, 0.7653]]) 加法：给定一个输出张量作为参数 result = torch.empty(5, 3) torch.add(x, y, out=result) print(result) 输出： tensor([[ 2.5541, 0.0943, 0.9835], [ 1.4911, 1.3117, 0.5220], [-0.0078, -0.1161, 0.6687], [ 0.8176, 1.1179, 1.9194], [-0.3251, -0.2236, 0.7653]]) 加法：原位/原地操作(in-place） # adds x to y y.add_(x) print(y) 输出： tensor([[ 2.5541, 0.0943, 0.9835], [ 1.4911, 1.3117, 0.5220], [-0.0078, -0.1161, 0.6687], [ 0.8176, 1.1179, 1.9194], [-0.3251, -0.2236, 0.7653]]) 注意： 任何一个in-place改变张量的操作后面都固定一个_。例如x.copy_(y)、x.t_()将更改x 也可以使用像标准的NumPy一样的各种索引操作： print(x[:, 1]) 输出： tensor([-0.6769, 0.7683, -0.5566, 0.3566, -0.6741]) 改变形状：如果想改变形状，可以使用torch.view x = torch.randn(4, 4) y = x.view(16) z = x.view(-1, 8) # the size -1 is inferred from other dimensions print(x.size(), y.size(), z.size()) 输出： torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8]) 如果是仅包含一个元素的tensor，可以使用.item()来得到对应的python数值 x = torch.randn(1) print(x) print(x.item()) 输出： tensor([0.0445]) 0.0445479191839695 后续阅读： 超过100种tensor的运算操作，包括转置，索引，切片，数学运算， 线性代数，随机数等，具体访问这里 桥接 NumPy 将一个Torch张量转换为一个NumPy数组是轻而易举的事情，反之亦然。 Torch张量和NumPy数组将共享它们的底层内存位置，因此当一个改变时,另外也会改变。 将torch的Tensor转化为NumPy数组 输入： a = torch.ones(5) print(a) 输出： tensor([1., 1., 1., 1., 1.]) 输入： b = a.numpy() print(b) 输出： [1. 1. 1. 1. 1.] 看NumPy数组是如何改变里面的值的： a.add_(1) print(a) print(b) 输出： tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.] 将NumPy数组转化为Torch张量 看改变NumPy数组是如何自动改变Torch张量的： import numpy as np a = np.ones(5) b = torch.from_numpy(a) np.add(a, 1, out=a) print(a) print(b) 输出： [2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64) CPU上的所有张量(CharTensor除外)都支持与Numpy的相互转换。 CUDA上的张量 张量可以使用.to方法移动到任何设备(device）上： # 当GPU可用时,我们可以运行以下代码 # 我们将使用`torch.device`来将tensor移入和移出GPU if torch.cuda.is_available(): device = torch.device(\"cuda\") # a CUDA device object y = torch.ones_like(x, device=device) # 直接在GPU上创建tensor x = x.to(device) # 或者使用`.to(\"cuda\")`方法 z = x + y print(z) print(z.to(\"cpu\", torch.double)) # `.to`也能在移动时改变dtype 输出： tensor([1.0445], device='cuda:0') tensor([1.0445], dtype=torch.float64) 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-23 10:17:10 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"blitz/autograd_tutorial.html":{"url":"blitz/autograd_tutorial.html","title":"Autograd：自动求导","keywords":"","body":"Autograd：自动求导 原文： https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html 译者：bat67 校验者：FontTian PyTorch中，所有神经网络的核心是 autograd 包。先简单介绍一下这个包，然后训练我们的第一个的神经网络。 autograd 包为张量上的所有操作提供了自动求导机制。它是一个在运行时定义(define-by-run）的框架，这意味着反向传播是根据代码如何运行来决定的，并且每次迭代可以是不同的. 让我们用一些简单的例子来看看吧。 张量 torch.Tensor 是这个包的核心类。如果设置它的属性 .requires_grad 为 True，那么它将会追踪对于该张量的所有操作。当完成计算后可以通过调用 .backward()，来自动计算所有的梯度。这个张量的所有梯度将会自动累加到.grad属性. 要阻止一个张量被跟踪历史，可以调用 .detach() 方法将其与计算历史分离，并阻止它未来的计算记录被跟踪。 为了防止跟踪历史记录(和使用内存），可以将代码块包装在 with torch.no_grad(): 中。在评估模型时特别有用，因为模型可能具有 requires_grad = True 的可训练的参数，但是我们不需要在此过程中对他们进行梯度计算。 还有一个类对于autograd的实现非常重要：Function。 Tensor 和 Function 互相连接生成了一个无圈图(acyclic graph)，它编码了完整的计算历史。每个张量都有一个 .grad_fn 属性，该属性引用了创建 Tensor 自身的Function(除非这个张量是用户手动创建的，即这个张量的 grad_fn 是 None )。 如果需要计算导数，可以在 Tensor 上调用 .backward()。如果 Tensor 是一个标量(即它包含一个元素的数据），则不需要为 backward() 指定任何参数，但是如果它有更多的元素，则需要指定一个 gradient 参数，该参数是形状匹配的张量。 import torch 创建一个张量并设置requires_grad=True用来追踪其计算历史 x = torch.ones(2, 2, requires_grad=True) print(x) 输出： tensor([[1., 1.], [1., 1.]], requires_grad=True) 对这个张量做一次运算： y = x + 2 print(y) 输出： tensor([[3., 3.], [3., 3.]], grad_fn=) y是计算的结果，所以它有grad_fn属性。 print(y.grad_fn) 输出： 对y进行更多操作 z = y * y * 3 out = z.mean() print(z, out) 输出： tensor([[27., 27.], [27., 27.]], grad_fn=) tensor(27., grad_fn=) .requires_grad_(...) 原地改变了现有张量的 requires_grad 标志。如果没有指定的话，默认输入的这个标志是 False。 a = torch.randn(2, 2) a = ((a * 3) / (a - 1)) print(a.requires_grad) a.requires_grad_(True) print(a.requires_grad) b = (a * a).sum() print(b.grad_fn) 输出： False True 梯度 现在开始进行反向传播，因为 out 是一个标量，因此 out.backward() 和 out.backward(torch.tensor(1.)) 等价。 out.backward() 输出导数 d(out)/dx print(x.grad) 输出： tensor([[4.5000, 4.5000], [4.5000, 4.5000]]) 我们的得到的是一个数取值全部为4.5的矩阵。 让我们来调用 out 张量 “o”。 就可以得到 o = \\frac{1}{4}\\sum_i z_i，z_i = 3(x_i+2)^2 和 z_i\\bigr\\rvert_{x_i=1} = 27 因此, \\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)，因而 \\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5。 数学上，若有向量值函数 \\vec{y}=f(\\vec{x})，那么 \\vec{y} 相对于 \\vec{x} 的梯度是一个雅可比矩阵： J=\\left(\\begin{array}{ccc} \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\ \\vdots & \\ddots & \\vdots\\\\ \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}} \\end{array}\\right) 通常来说，torch.autograd 是计算雅可比向量积的一个“引擎”。也就是说，给定任意向量 v=\\left(\\begin{array}{cccc} v_{1} & v_{2} & \\cdots & v_{m}\\end{array}\\right)^{T}，计算乘积 v^{T}\\cdot J。如果 v 恰好是一个标量函数 l=g\\left(\\vec{y}\\right) 的导数，即 v=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T}，那么根据链式法则，雅可比向量积应该是 l 对 \\vec{x} 的导数： J^{T}\\cdot v=\\left(\\begin{array}{ccc} \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\ \\vdots & \\ddots & \\vdots\\\\ \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}} \\end{array}\\right)\\left(\\begin{array}{c} \\frac{\\partial l}{\\partial y_{1}}\\\\ \\vdots\\\\ \\frac{\\partial l}{\\partial y_{m}} \\end{array}\\right)=\\left(\\begin{array}{c} \\frac{\\partial l}{\\partial x_{1}}\\\\ \\vdots\\\\ \\frac{\\partial l}{\\partial x_{n}} \\end{array}\\right) (注意：行向量的 v^{T}\\cdot J也可以被视作列向量的J^{T}\\cdot v) 雅可比向量积的这一特性使得将外部梯度输入到具有非标量输出的模型中变得非常方便。 现在我们来看一个雅可比向量积的例子: x = torch.randn(3, requires_grad=True) y = x * 2 while y.data.norm() 输出： tensor([-278.6740, 935.4016, 439.6572], grad_fn=) 在这种情况下，y 不再是标量。torch.autograd 不能直接计算完整的雅可比矩阵，但是如果我们只想要雅可比向量积，只需将这个向量作为参数传给 backward： v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float) y.backward(v) print(x.grad) 输出： tensor([4.0960e+02, 4.0960e+03, 4.0960e-01]) 也可以通过将代码块包装在 with torch.no_grad(): 中，来阻止autograd跟踪设置了 .requires_grad=True 的张量的历史记录。 print(x.requires_grad) print((x ** 2).requires_grad) with torch.no_grad(): print((x ** 2).requires_grad) 输出： True True False 后续阅读： autograd 和 Function 的文档见：https://pytorch.org/docs/autograd 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-23 10:15:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"blitz/neural_networks_tutorial.html":{"url":"blitz/neural_networks_tutorial.html","title":"神经网络","keywords":"","body":"神经网络 原文： https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html 译者：bat67 校验者：FontTian 可以使用torch.nn包来构建神经网络. 我们已经介绍了autograd，nn包则依赖于autograd包来定义模型并对它们求导。一个nn.Module包含各个层和一个forward(input)方法，该方法返回output。 例如，下面这个神经网络可以对数字进行分类： 这是一个简单的前馈神经网络(feed-forward network）。它接受一个输入，然后将它送入下一层，一层接一层的传递，最后给出输出。 一个神经网络的典型训练过程如下： 定义包含一些可学习参数(或者叫权重）的神经网络 在输入数据集上迭代 通过网络处理输入 计算损失(输出和正确答案的距离） 将梯度反向传播给网络的参数 更新网络的权重，一般使用一个简单的规则：weight = weight - learning_rate * gradient 定义网络 让我们定义这样一个网络： import torch import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() # 输入图像channel：1；输出channel：6；5x5卷积核 self.conv1 = nn.Conv2d(1, 6, 5) self.conv2 = nn.Conv2d(6, 16, 5) # an affine operation: y = Wx + b self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): # 2x2 Max pooling x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # 如果是方阵,则可以只使用一个数字进行定义 x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = x.view(-1, self.num_flat_features(x)) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x def num_flat_features(self, x): size = x.size()[1:] # 除去批处理维度的其他所有维度 num_features = 1 for s in size: num_features *= s return num_features net = Net() print(net) 输出： Net( (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True) ) 我们只需要定义 forward 函数，backward函数会在使用autograd时自动定义，backward函数用来计算导数。可以在 forward 函数中使用任何针对张量的操作和计算。 一个模型的可学习参数可以通过net.parameters()返回 params = list(net.parameters()) print(len(params)) print(params[0].size()) # conv1's .weight 输出： 10 torch.Size([6, 1, 5, 5]) 让我们尝试一个随机的32x32的输入。注意:这个网络(LeNet）的期待输入是32x32。如果使用MNIST数据集来训练这个网络，要把图片大小重新调整到32x32。 input = torch.randn(1, 1, 32, 32) out = net(input) print(out) 输出： tensor([[ 0.0399, -0.0856, 0.0668, 0.0915, 0.0453, -0.0680, -0.1024, 0.0493, -0.1043, -0.1267]], grad_fn=) 清零所有参数的梯度缓存，然后进行随机梯度的反向传播： net.zero_grad() out.backward(torch.randn(1, 10)) 注意： torch.nn只支持小批量处理(mini-batches）。整个torch.nn包只支持小批量样本的输入，不支持单个样本。 比如，nn.Conv2d 接受一个4维的张量，即nSamples x nChannels x Height x Width 如果是一个单独的样本，只需要使用input.unsqueeze(0)来添加一个“假的”批大小维度。 在继续之前，让我们回顾一下到目前为止看到的所有类。 复习： torch.Tensor - 一个多维数组，支持诸如backward()等的自动求导操作，同时也保存了张量的梯度。 nn.Module - 神经网络模块。是一种方便封装参数的方式，具有将参数移动到GPU、导出、加载等功能。 nn.Parameter - 张量的一种，当它作为一个属性分配给一个Module时，它会被自动注册为一个参数。 autograd.Function - 实现了自动求导前向和反向传播的定义，每个Tensor至少创建一个Function节点，该节点连接到创建Tensor的函数并对其历史进行编码。 目前为止，我们讨论了： 定义一个神经网络 处理输入调用backward 还剩下： 计算损失 更新网络权重 损失函数 一个损失函数接受一对(output, target)作为输入，计算一个值来估计网络的输出和目标值相差多少。 nn包中有很多不同的损失函数。nn.MSELoss是比较简单的一种，它计算输出和目标的均方误差(mean-squared error）。 例如： output = net(input) target = torch.randn(10) # 本例子中使用模拟数据 target = target.view(1, -1) # 使目标值与数据值形状一致 criterion = nn.MSELoss() loss = criterion(output, target) print(loss) 输出： tensor(1.0263, grad_fn=) 现在，如果使用loss的.grad_fn属性跟踪反向传播过程，会看到计算图如下： input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d -> view -> linear -> relu -> linear -> relu -> linear -> MSELoss -> loss 所以，当我们调用loss.backward()，整张图开始关于loss微分，图中所有设置了requires_grad=True的张量的.grad属性累积着梯度张量。 为了说明这一点，让我们向后跟踪几步： print(loss.grad_fn) # MSELoss print(loss.grad_fn.next_functions[0][0]) # Linear print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) # ReLU 输出： 反向传播 我们只需要调用loss.backward()来反向传播权重。我们需要清零现有的梯度，否则梯度将会与已有的梯度累加。 现在，我们将调用loss.backward()，并查看conv1层的偏置(bias）在反向传播前后的梯度。 net.zero_grad() # 清零所有参数(parameter）的梯度缓存 print('conv1.bias.grad before backward') print(net.conv1.bias.grad) loss.backward() print('conv1.bias.grad after backward') print(net.conv1.bias.grad) 输出： conv1.bias.grad before backward tensor([0., 0., 0., 0., 0., 0.]) conv1.bias.grad after backward tensor([ 0.0084, 0.0019, -0.0179, -0.0212, 0.0067, -0.0096]) 现在，我们已经见到了如何使用损失函数。 稍后阅读 神经网络包包含了各种模块和损失函数，这些模块和损失函数构成了深度神经网络的构建模块。完整的文档列表见这里。 现在唯一要学习的是： 更新网络的权重 更新权重 最简单的更新规则是随机梯度下降法(SGD）: weight = weight - learning_rate * gradient 我们可以使用简单的python代码来实现: learning_rate = 0.01 for f in net.parameters(): f.data.sub_(f.grad.data * learning_rate) 然而，在使用神经网络时，可能希望使用各种不同的更新规则，如SGD、Nesterov-SGD、Adam、RMSProp等。为此，我们构建了一个较小的包torch.optim，它实现了所有的这些方法。使用它很简单： import torch.optim as optim # 创建优化器(optimizer） optimizer = optim.SGD(net.parameters(), lr=0.01) # 在训练的迭代中： optimizer.zero_grad() # 清零梯度缓存 output = net(input) loss = criterion(output, target) loss.backward() optimizer.step() # 更新参数 注意： 观察梯度缓存区是如何使用optimizer.zero_grad()手动清零的。这是因为梯度是累加的，正如前面反向传播章节叙述的那样。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-23 10:15:54 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"blitz/cifar10_tutorial.html":{"url":"blitz/cifar10_tutorial.html","title":"训练分类器","keywords":"","body":"训练分类器 原文： https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html 译者：bat67 校验者：FontTian 目前为止，我们以及看到了如何定义网络，计算损失，并更新网络的权重。所以你现在可能会想, 数据应该怎么办呢？ 通常来说，当必须处理图像、文本、音频或视频数据时，可以使用python标准库将数据加载到numpy数组里。然后将这个数组转化成torch.*Tensor。 对于图片，有Pillow，OpenCV等包可以使用 对于音频，有scipy和librosa等包可以使用 对于文本，不管是原生python的或者是基于Cython的文本，可以使用NLTK和SpaCy 特别对于视觉方面，我们创建了一个包，名字叫torchvision，其中包含了针对Imagenet、CIFAR10、MNIST等常用数据集的数据加载器(data loaders），还有对图片数据变形的操作，即torchvision.datasets和torch.utils.data.DataLoader。 这提供了极大的便利，可以避免编写样板代码。 在这个教程中，我们将使用CIFAR10数据集，它有如下的分类：“飞机”，“汽车”，“鸟”，“猫”，“鹿”，“狗”，“青蛙”，“马”，“船”，“卡车”等。在CIFAR-10里面的图片数据大小是3x32x32，即三通道彩色图，图片大小是32x32像素。 训练一个图片分类器 我们将按顺序做以下步骤： 通过torchvision加载CIFAR10里面的训练和测试数据集，并对数据进行标准化 定义卷积神经网络 定义损失函数 利用训练数据训练网络 利用测试数据测试网络 1.加载并标准化CIFAR10 使用torchvision加载CIFAR10超级简单。 import torch import torchvision import torchvision.transforms as transforms torchvision数据集加载完后的输出是范围在[0, 1]之间的PILImage。我们将其标准化为范围在[-1, 1]之间的张量。 transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2) testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2) classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') 输出： Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz Files already downloaded and verified 乐趣所致，现在让我们可视化部分训练数据。 import matplotlib.pyplot as plt import numpy as np # 输出图像的函数 def imshow(img): img = img / 2 + 0.5 # unnormalize npimg = img.numpy() plt.imshow(np.transpose(npimg, (1, 2, 0))) plt.show() # 随机获取训练图片 dataiter = iter(trainloader) images, labels = dataiter.next() # 显示图片 imshow(torchvision.utils.make_grid(images)) # 打印图片标签 print(' '.join('%5s' % classes[labels[j]] for j in range(4))) 输出： horse horse horse car 2.定义卷积神经网络 将之前神经网络章节定义的神经网络拿过来，并将其修改成输入为3通道图像(替代原来定义的单通道图像）。 import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() 3.定义损失函数和优化器 我们使用分类的交叉熵损失和随机梯度下降(使用momentum）。 import torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) 4.训练网络 事情开始变得有趣了。我们只需要遍历我们的数据迭代器，并将输入“喂”给网络和优化函数。 for epoch in range(2): # loop over the dataset multiple times running_loss = 0.0 for i, data in enumerate(trainloader, 0): # get the inputs inputs, labels = data # zero the parameter gradients optimizer.zero_grad() # forward + backward + optimize outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() # print statistics running_loss += loss.item() if i % 2000 == 1999: # print every 2000 mini-batches print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000)) running_loss = 0.0 print('Finished Training') 输出： [1, 2000] loss: 2.182 [1, 4000] loss: 1.819 [1, 6000] loss: 1.648 [1, 8000] loss: 1.569 [1, 10000] loss: 1.511 [1, 12000] loss: 1.473 [2, 2000] loss: 1.414 [2, 4000] loss: 1.365 [2, 6000] loss: 1.358 [2, 8000] loss: 1.322 [2, 10000] loss: 1.298 [2, 12000] loss: 1.282 Finished Training 5.使用测试数据测试网络 我们已经在训练集上训练了2遍网络。但是我们需要检查网络是否学到了一些东西。 我们将通过预测神经网络输出的标签来检查这个问题，并和正确样本进行(ground-truth）对比。如果预测是正确的，我们将样本添加到正确预测的列表中。 ok，第一步。让我们显示测试集中的图像来熟悉一下。 dataiter = iter(testloader) images, labels = dataiter.next() # 输出图片 imshow(torchvision.utils.make_grid(images)) print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4))) GroundTruth: cat ship ship plane ok，现在让我们看看神经网络认为上面的例子是: outputs = net(images) 输出是10个类别的量值。一个类的值越高，网络就越认为这个图像属于这个特定的类。让我们得到最高量值的下标/索引； _, predicted = torch.max(outputs, 1) print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4))) 输出： Predicted: dog ship ship plane 结果还不错。 让我们看看网络在整个数据集上表现的怎么样。 correct = 0 total = 0 with torch.no_grad(): for data in testloader: images, labels = data outputs = net(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total)) 输出： Accuracy of the network on the 10000 test images: 55 % 这比随机选取(即从10个类中随机选择一个类，正确率是10%）要好很多。看来网络确实学到了一些东西。 那么哪些是表现好的类呢？哪些是表现的差的类呢？ class_correct = list(0. for i in range(10)) class_total = list(0. for i in range(10)) with torch.no_grad(): for data in testloader: images, labels = data outputs = net(images) _, predicted = torch.max(outputs, 1) c = (predicted == labels).squeeze() for i in range(4): label = labels[i] class_correct[label] += c[i].item() class_total[label] += 1 for i in range(10): print('Accuracy of %5s : %2d %%' % ( classes[i], 100 * class_correct[i] / class_total[i])) 输出： Accuracy of plane : 70 % Accuracy of car : 70 % Accuracy of bird : 28 % Accuracy of cat : 25 % Accuracy of deer : 37 % Accuracy of dog : 60 % Accuracy of frog : 66 % Accuracy of horse : 62 % Accuracy of ship : 69 % Accuracy of truck : 61 % ok，接下来呢？ 怎么在GPU上运行神经网络呢？ 在GPU上训练 与将一个张量传递给GPU一样，可以这样将神经网络转移到GPU上。 如果我们有cuda可用的话，让我们首先定义第一个设备为可见cuda设备： device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Assuming that we are on a CUDA machine, this should print a CUDA device: print(device) 输出： cuda:0 本节的其余部分假设device是CUDA。 然后这些方法将递归遍历所有模块，并将它们的参数和缓冲区转换为CUDA张量： net.to(device) 请记住，我们不得不将输入和目标在每一步都送入GPU： inputs, labels = inputs.to(device), labels.to(device) 为什么我们感受不到与CPU相比的巨大加速？因为我们的网络实在是太小了。 尝试一下：加宽你的网络(注意第一个nn.Conv2d的第二个参数和第二个nn.Conv2d的第一个参数要相同），看看能获得多少加速。 已实现的目标： 在更高层次上理解PyTorch的Tensor库和神经网络 训练一个小的神经网络做图片分类 在多GPU上训练 如果希望使用您所有GPU获得更大的加速，请查看Optional: Data Parallelism。 接下来要做什么？ Train neural nets to play video games Train a state-of-the-art ResNet network on imagenet Train a face generator using Generative Adversarial Networks Train a word-level language model using Recurrent LSTM networks More examples More tutorials Discuss PyTorch on the Forums Chat with other users on Slack 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-23 10:14:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"blitz/data_parallel_tutorial.html":{"url":"blitz/data_parallel_tutorial.html","title":"可选：数据并行","keywords":"","body":"可选: 数据并行处理 原文： https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html 作者: Sung Kim Jenny Kang 译者: bat67 校验者: FontTian 片刻 在这个教程里，我们将学习如何使用数据并行(DataParallel）来使用多GPU。 PyTorch非常容易的就可以使用GPU，可以用如下方式把一个模型放到GPU上: device = torch.device(\"cuda: 0\") model.to(device) 然后可以复制所有的张量到GPU上: mytensor = my_tensor.to(device) 请注意，调用my_tensor.to(device)返回一个GPU上的my_tensor副本，而不是重写my_tensor。我们需要把它赋值给一个新的张量并在GPU上使用这个张量。 在多GPU上执行前向和反向传播是自然而然的事。然而，PyTorch默认将只是用一个GPU。你可以使用DataParallel让模型并行运行来轻易的让你的操作在多个GPU上运行。 model = nn.DataParallel(model) 这是这篇教程背后的核心，我们接下来将更详细的介绍它。 导入和参数 导入PyTorch模块和定义参数。 import torch import torch.nn as nn from torch.utils.data import Dataset, DataLoader # Parameters 和 DataLoaders input_size = 5 output_size = 2 batch_size = 30 data_size = 100 设备(Device）: device = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\") 虚拟数据集 要制作一个虚拟(随机）数据集，只需实现__getitem__。 class RandomDataset(Dataset): def __init__(self, size, length): self.len = length self.data = torch.randn(length, size) def __getitem__(self, index): return self.data[index] def __len__(self): return self.len rand_loader = DataLoader(dataset=RandomDataset(input_size, data_size), batch_size=batch_size, shuffle=True) 简单模型 作为演示，我们的模型只接受一个输入，执行一个线性操作，然后得到结果。然而，你能在任何模型(CNN，RNN，Capsule Net等）上使用DataParallel。 我们在模型内部放置了一条打印语句来检测输入和输出向量的大小。请注意批等级为0时打印的内容。 class Model(nn.Module): # Our model def __init__(self, input_size, output_size): super(Model, self).__init__() self.fc = nn.Linear(input_size, output_size) def forward(self, input): output = self.fc(input) print(\"\\tIn Model: input size\", input.size(), \"output size\", output.size()) return output 创建一个模型和数据并行 这是本教程的核心部分。首先，我们需要创建一个模型实例和检测我们是否有多个GPU。如果我们有多个GPU，我们使用nn.DataParallel来包装我们的模型。然后通过model.to(device)把模型放到GPU上。 model = Model(input_size, output_size) if torch.cuda.device_count() > 1: print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\") # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs model = nn.DataParallel(model) model.to(device) 输出: Let's use 2 GPUs! 运行模型 现在我们可以看输入和输出张量的大小。 for data in rand_loader: input = data.to(device) output = model(input) print(\"Outside: input size\", input.size(), \"output_size\", output.size()) 输出: In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2]) In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2]) 结果 当我们对30个输入和输出进行批处理时，我们和期望的一样得到30个输入和30个输出，但是若有多个GPU，会得到如下的结果。 2个GPU 若有2个GPU，将看到: Let's use 2 GPUs! In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2]) In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2]) 3个GPU 若有3个GPU，将看到: Let's use 3 GPUs! In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2]) 8个GPU 若有8个GPU，将看到: Let's use 8 GPUs! In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2]) 总结 DataParallel自动的划分数据，并将作业发送到多个GPU上的多个模型。DataParallel会在每个模型完成作业后，收集与合并结果然后返回给你。 更多信息，请参考: https://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-23 10:21:15 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"5.html":{"url":"5.html","title":"编写自定义数据集，数据加载器和转换","keywords":"","body":"编写自定义数据集，数据加载器和转换 原文： https://pytorch.org/tutorials/beginner/data_loading_tutorial.html 注意 单击此处的下载完整的示例代码 作者： Sasank Chilamkurthy 解决任何机器学习问题都需要花费大量精力来准备数据。 PyTorch 提供了许多工具来简化数据加载过程，并有望使代码更具可读性。 在本教程中，我们将了解如何从非平凡的数据集中加载和预处理/增强数据。 要运行本教程，请确保已安装以下软件包： scikit-image：用于图像 io 和变换 pandas：用于更轻松的 csv 解析 from __future__ import print_function, division import os import torch import pandas as pd from skimage import io, transform import numpy as np import matplotlib.pyplot as plt from torch.utils.data import Dataset, DataLoader from torchvision import transforms, utils # Ignore warnings import warnings warnings.filterwarnings(\"ignore\") plt.ion() # interactive mode 我们要处理的数据集是面部姿势数据集。 这意味着将对面部进行如下注释： 总体上，每个面孔都标注了 68 个不同的界标点。 Note 从此处下载数据集，以使图像位于名为“ data / faces /”的目录中。 该数据集实际上是通过对来自标记为“面部”的 imagenet 上的一些图像应用出色的 dlib 姿态估计生成的。 数据集带有一个带注释的 csv 文件，如下所示： image_name,part_0_x,part_0_y,part_1_x,part_1_y,part_2_x, ... ,part_67_x,part_67_y 0805personali01.jpg,27,83,27,98, ... 84,134 1084239450_e76e00b7e7.jpg,70,236,71,257, ... ,128,312 让我们快速阅读 CSV 并获取(N，2）数组中的注释，其中 N 是地标数。 landmarks_frame = pd.read_csv('data/faces/face_landmarks.csv') n = 65 img_name = landmarks_frame.iloc[n, 0] landmarks = landmarks_frame.iloc[n, 1:] landmarks = np.asarray(landmarks) landmarks = landmarks.astype('float').reshape(-1, 2) print('Image name: {}'.format(img_name)) print('Landmarks shape: {}'.format(landmarks.shape)) print('First 4 Landmarks: {}'.format(landmarks[:4])) 出： Image name: person-7.jpg Landmarks shape: (68, 2) First 4 Landmarks: [[32\\. 65.] [33\\. 76.] [34\\. 86.] [34\\. 97.]] 让我们编写一个简单的辅助函数来显示图像及其地标，并使用它来显示示例。 def show_landmarks(image, landmarks): \"\"\"Show image with landmarks\"\"\" plt.imshow(image) plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='r') plt.pause(0.001) # pause a bit so that plots are updated plt.figure() show_landmarks(io.imread(os.path.join('data/faces/', img_name)), landmarks) plt.show() 数据集类 torch.utils.data.Dataset是代表数据集的抽象类。 您的自定义数据集应继承Dataset并覆盖以下方法： __len__，以便len(dataset)返回数据集的大小。 __getitem__支持索引，以便可以使用dataset[i]获取第个样本 让我们为面部轮廓数据集创建一个数据集类。 我们将在__init__中读取 csv，但将图像读取留给__getitem__。 由于所有图像不会立即存储在内存中，而是根据需要读取，因此可以提高存储效率。 我们的数据集样本将是 dict {'image': image, 'landmarks': landmarks}。 我们的数据集将使用可选参数transform，以便可以将任何所需的处理应用于样本。 我们将在下一部分中看到transform的有用性。 class FaceLandmarksDataset(Dataset): \"\"\"Face Landmarks dataset.\"\"\" def __init__(self, csv_file, root_dir, transform=None): \"\"\" Args: csv_file (string): Path to the csv file with annotations. root_dir (string): Directory with all the images. transform (callable, optional): Optional transform to be applied on a sample. \"\"\" self.landmarks_frame = pd.read_csv(csv_file) self.root_dir = root_dir self.transform = transform def __len__(self): return len(self.landmarks_frame) def __getitem__(self, idx): if torch.is_tensor(idx): idx = idx.tolist() img_name = os.path.join(self.root_dir, self.landmarks_frame.iloc[idx, 0]) image = io.imread(img_name) landmarks = self.landmarks_frame.iloc[idx, 1:] landmarks = np.array([landmarks]) landmarks = landmarks.astype('float').reshape(-1, 2) sample = {'image': image, 'landmarks': landmarks} if self.transform: sample = self.transform(sample) return sample 让我们实例化该类并遍历数据样本。 我们将打印前 4 个样本的大小并显示其地标。 face_dataset = FaceLandmarksDataset(csv_file='data/faces/face_landmarks.csv', root_dir='data/faces/') fig = plt.figure() for i in range(len(face_dataset)): sample = face_dataset[i] print(i, sample['image'].shape, sample['landmarks'].shape) ax = plt.subplot(1, 4, i + 1) plt.tight_layout() ax.set_title('Sample #{}'.format(i)) ax.axis('off') show_landmarks(**sample) if i == 3: plt.show() break Out: 0 (324, 215, 3) (68, 2) 1 (500, 333, 3) (68, 2) 2 (250, 258, 3) (68, 2) 3 (434, 290, 3) (68, 2) 变身 从上面可以看到的一个问题是样本的大小不同。 大多数神经网络期望图像的大小固定。 因此，我们将需要编写一些前置代码。 让我们创建三个转换： Rescale：缩放图像 RandomCrop：从图像中随机裁剪。 这是数据扩充。 ToTensor：将 numpy 图像转换为torch图像(我们需要交换轴）。 我们会将它们编写为可调用的类，而不是简单的函数，这样就不必每次调用转换时都传递其参数。 为此，我们只需要实现__call__方法，如果需要，可以实现__init__方法。 然后我们可以使用这样的变换： tsfm = Transform(params) transformed_sample = tsfm(sample) 在下面观察如何将这些变换同时应用于图像和地标。 class Rescale(object): \"\"\"Rescale the image in a sample to a given size. Args: output_size (tuple or int): Desired output size. If tuple, output is matched to output_size. If int, smaller of image edges is matched to output_size keeping aspect ratio the same. \"\"\" def __init__(self, output_size): assert isinstance(output_size, (int, tuple)) self.output_size = output_size def __call__(self, sample): image, landmarks = sample['image'], sample['landmarks'] h, w = image.shape[:2] if isinstance(self.output_size, int): if h > w: new_h, new_w = self.output_size * h / w, self.output_size else: new_h, new_w = self.output_size, self.output_size * w / h else: new_h, new_w = self.output_size new_h, new_w = int(new_h), int(new_w) img = transform.resize(image, (new_h, new_w)) # h and w are swapped for landmarks because for images, # x and y axes are axis 1 and 0 respectively landmarks = landmarks * [new_w / w, new_h / h] return {'image': img, 'landmarks': landmarks} class RandomCrop(object): \"\"\"Crop randomly the image in a sample. Args: output_size (tuple or int): Desired output size. If int, square crop is made. \"\"\" def __init__(self, output_size): assert isinstance(output_size, (int, tuple)) if isinstance(output_size, int): self.output_size = (output_size, output_size) else: assert len(output_size) == 2 self.output_size = output_size def __call__(self, sample): image, landmarks = sample['image'], sample['landmarks'] h, w = image.shape[:2] new_h, new_w = self.output_size top = np.random.randint(0, h - new_h) left = np.random.randint(0, w - new_w) image = image[top: top + new_h, left: left + new_w] landmarks = landmarks - [left, top] return {'image': image, 'landmarks': landmarks} class ToTensor(object): \"\"\"Convert ndarrays in sample to Tensors.\"\"\" def __call__(self, sample): image, landmarks = sample['image'], sample['landmarks'] # swap color axis because # numpy image: H x W x C # torch image: C X H X W image = image.transpose((2, 0, 1)) return {'image': torch.from_numpy(image), 'landmarks': torch.from_numpy(landmarks)} 撰写变换 现在，我们将转换应用于样本。 假设我们要将图片的较短边重新缩放为 256，然后从中随机裁剪一个尺寸为 224 的正方形。 也就是说，我们要组成Rescale和RandomCrop转换。 torchvision.transforms.Compose是一个简单的可调用类，它使我们可以执行此操作。 scale = Rescale(256) crop = RandomCrop(128) composed = transforms.Compose([Rescale(256), RandomCrop(224)]) # Apply each of the above transforms on sample. fig = plt.figure() sample = face_dataset[65] for i, tsfrm in enumerate([scale, crop, composed]): transformed_sample = tsfrm(sample) ax = plt.subplot(1, 3, i + 1) plt.tight_layout() ax.set_title(type(tsfrm).__name__) show_landmarks(**transformed_sample) plt.show() 遍历数据集 让我们将所有这些放在一起，以创建具有组合转换的数据集。 总而言之，每次采样此数据集时： 从文件中即时读取图像 转换应用于读取的图像 由于其中一种转换是随机的，因此在采样时会增加数据 我们可以像以前一样使用for i in range循环遍历创建的数据集。 transformed_dataset = FaceLandmarksDataset(csv_file='data/faces/face_landmarks.csv', root_dir='data/faces/', transform=transforms.Compose([ Rescale(256), RandomCrop(224), ToTensor() ])) for i in range(len(transformed_dataset)): sample = transformed_dataset[i] print(i, sample['image'].size(), sample['landmarks'].size()) if i == 3: break Out: 0 torch.Size([3, 224, 224]) torch.Size([68, 2]) 1 torch.Size([3, 224, 224]) torch.Size([68, 2]) 2 torch.Size([3, 224, 224]) torch.Size([68, 2]) 3 torch.Size([3, 224, 224]) torch.Size([68, 2]) 但是，通过使用简单的for循环迭代数据，我们失去了很多功能。 特别是，我们错过了： 批量处理数据 整理数据 使用multiprocessing工作程序并行加载数据。 torch.utils.data.DataLoader是提供所有这些功能的迭代器。 下面使用的参数应该清楚。 感兴趣的一个参数是collate_fn。 您可以使用collate_fn指定需要精确分批的样品。 但是，默认排序规则在大多数情况下都可以正常工作。 dataloader = DataLoader(transformed_dataset, batch_size=4, shuffle=True, num_workers=4) # Helper function to show a batch def show_landmarks_batch(sample_batched): \"\"\"Show image with landmarks for a batch of samples.\"\"\" images_batch, landmarks_batch = \\ sample_batched['image'], sample_batched['landmarks'] batch_size = len(images_batch) im_size = images_batch.size(2) grid_border_size = 2 grid = utils.make_grid(images_batch) plt.imshow(grid.numpy().transpose((1, 2, 0))) for i in range(batch_size): plt.scatter(landmarks_batch[i, :, 0].numpy() + i * im_size + (i + 1) * grid_border_size, landmarks_batch[i, :, 1].numpy() + grid_border_size, s=10, marker='.', c='r') plt.title('Batch from dataloader') for i_batch, sample_batched in enumerate(dataloader): print(i_batch, sample_batched['image'].size(), sample_batched['landmarks'].size()) # observe 4th batch and stop. if i_batch == 3: plt.figure() show_landmarks_batch(sample_batched) plt.axis('off') plt.ioff() plt.show() break Out: 0 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2]) 1 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2]) 2 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2]) 3 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2]) 后记：torchvision 在本教程中，我们已经看到了如何编写和使用数据集，转换和数据加载器。 torchvision包提供了一些常见的数据集和转换。 您甚至不必编写自定义类。 Torchvision 中可用的更通用的数据集之一是ImageFolder。 假定图像的组织方式如下： root/ants/xxx.png root/ants/xxy.jpeg root/ants/xxz.png . . . root/bees/123.jpg root/bees/nsdf3.png root/bees/asd932_.png 其中“蚂蚁”，“蜜蜂”等是类别标签。 同样也可以使用对PIL.Image，Scale等PIL.Image进行操作的通用转换。 您可以使用以下代码编写数据加载器，如下所示： import torch from torchvision import transforms, datasets data_transform = transforms.Compose([ transforms.RandomSizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ]) hymenoptera_dataset = datasets.ImageFolder(root='hymenoptera_data/train', transform=data_transform) dataset_loader = torch.utils.data.DataLoader(hymenoptera_dataset, batch_size=4, shuffle=True, num_workers=4) 有关训练代码的示例，请参见计算机视觉转移学习教程。 脚本的总运行时间：(0 分钟 58.611 秒） Download Python source code: data_loading_tutorial.py Download Jupyter notebook: data_loading_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"6.html":{"url":"6.html","title":"使用 TensorBoard 可视化模型，数据和训练","keywords":"","body":"使用 TensorBoard 可视化模型，数据和训练 原文： https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html 在 60 分钟闪电战中，我们向您展示了如何加载数据，如何通过定义为nn.Module子类的模型提供数据，如何在训练数据上训练该模型，以及在测试数据上对其进行测试。 为了了解发生的情况，我们在模型训练期间打印一些统计信息，以了解训练是否在进行中。 但是，我们可以做得更好：PyTorch 与 TensorBoard 集成，该工具旨在可视化神经网络训练运行的结果。 本教程使用 Fashion-MNIST 数据集说明了其某些功能，可以使用 torchvision.datasets 将其读取到 PyTorch 中。 在本教程中，我们将学习如何： 读取数据并进行适当的转换(与先前的教程几乎相同）。 设置 TensorBoard。 编写 TensorBoard。 使用 TensorBoard 检查模型架构。 使用 TensorBoard 来创建我们在上一个教程中创建的可视化的替代版本，并使用替代的代码 具体来说，在第 5 点，我们将看到： 有两种检查训练数据的方法 在训练模型时如何追踪其性能 在训练后如何评估模型的性能。 我们将从 CIFAR-10 教程中类似的样板代码开始： # imports import matplotlib.pyplot as plt import numpy as np import torch import torchvision import torchvision.transforms as transforms import torch.nn as nn import torch.nn.functional as F import torch.optim as optim # transforms transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) # datasets trainset = torchvision.datasets.FashionMNIST('./data', download=True, train=True, transform=transform) testset = torchvision.datasets.FashionMNIST('./data', download=True, train=False, transform=transform) # dataloaders trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2) testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2) # constant for classes classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot') # helper function to show an image # (used in the `plot_classes_preds` function below) def matplotlib_imshow(img, one_channel=False): if one_channel: img = img.mean(dim=0) img = img / 2 + 0.5 # unnormalize npimg = img.numpy() if one_channel: plt.imshow(npimg, cmap=\"Greys\") else: plt.imshow(np.transpose(npimg, (1, 2, 0))) 我们将在该教程中定义一个类似的模型架构，仅需进行少量修改即可说明以下事实：图像现在是一个通道而不是三个通道，而图像是 28x28 而不是 32x32： class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(1, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 4 * 4, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16 * 4 * 4) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() 我们将在之前定义相同的optimizer和criterion： criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) 1. TensorBoard 设置 现在，我们将设置 TensorBoard，从torch.utils导入tensorboard并定义SummaryWriter，这是将信息写入 TensorBoard 的关键对象。 from torch.utils.tensorboard import SummaryWriter # default `log_dir` is \"runs\" - we'll be more specific here writer = SummaryWriter('runs/fashion_mnist_experiment_1') 请注意，仅此行会创建一个runs/fashion_mnist_experiment_1文件夹。 2.写入 TensorBoard 现在，使用 make_grid 将图像写入到 TensorBoard 中，具体来说就是网格。 # get some random training images dataiter = iter(trainloader) images, labels = dataiter.next() # create grid of images img_grid = torchvision.utils.make_grid(images) # show images matplotlib_imshow(img_grid, one_channel=True) # write to tensorboard writer.add_image('four_fashion_mnist_images', img_grid) 正在运行 tensorboard --logdir=runs 从命令行，然后导航到 https：// localhost：6006 应该显示以下内容。 现在您知道如何使用 TensorBoard 了！ 但是，此示例可以在 Jupyter Notebook 中完成-TensorBoard 真正擅长的地方是创建交互式可视化。 接下来，我们将介绍其中之一，并在本教程结束时介绍更多内容。 3.使用 TensorBoard 检查模型 TensorBoard 的优势之一是其可视化复杂模型结构的能力。 让我们可视化我们构建的模型。 writer.add_graph(net, images) writer.close() 现在刷新 TensorBoard 后，您应该会看到一个“ Graphs”标签，如下所示： 继续并双击“ Net”以展开它，查看组成模型的各个操作的详细视图。 TensorBoard 具有非常方便的功能，可在低维空间中可视化高维数据，例如图像数据； 接下来我们将介绍。 4.在 TensorBoard 中添加一个“投影仪” 我们可以通过 add_embedding 方法可视化高维数据的低维表示 # helper function def select_n_random(data, labels, n=100): ''' Selects n random datapoints and their corresponding labels from a dataset ''' assert len(data) == len(labels) perm = torch.randperm(len(data)) return data[perm][:n], labels[perm][:n] # select random images and their target indices images, labels = select_n_random(trainset.data, trainset.targets) # get the class labels for each image class_labels = [classes[lab] for lab in labels] # log embeddings features = images.view(-1, 28 * 28) writer.add_embedding(features, metadata=class_labels, label_img=images.unsqueeze(1)) writer.close() 现在，在 TensorBoard 的“投影仪”选项卡中，您可以看到这 100 张图像-每个图像 784 维-向下投影到三维空间中。 此外，这是交互式的：您可以单击并拖动以旋转三维投影。 最后，有两个技巧可以使可视化效果更容易看到：在左上方选择“颜色：标签”，并启用“夜间模式”，这将使图像更容易看到，因为它们的背景是白色的： 现在我们已经彻底检查了我们的数据，让我们展示了 TensorBoard 如何从训练开始就可以使跟踪模型的训练和评估更加清晰。 5.使用 TensorBoard 跟踪模型训练 在前面的示例中，我们仅每 2000 次迭代打印该模型的运行损失。 现在，我们将运行损失记录到 TensorBoard 中，并通过plot_classes_preds函数查看模型所做的预测。 # helper functions def images_to_probs(net, images): ''' Generates predictions and corresponding probabilities from a trained network and a list of images ''' output = net(images) # convert output probabilities to predicted class _, preds_tensor = torch.max(output, 1) preds = np.squeeze(preds_tensor.numpy()) return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)] def plot_classes_preds(net, images, labels): ''' Generates matplotlib Figure using a trained network, along with images and labels from a batch, that shows the network's top prediction along with its probability, alongside the actual label, coloring this information based on whether the prediction was correct or not. Uses the \"images_to_probs\" function. ''' preds, probs = images_to_probs(net, images) # plot the images in the batch, along with predicted and true labels fig = plt.figure(figsize=(12, 48)) for idx in np.arange(4): ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[]) matplotlib_imshow(images[idx], one_channel=True) ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format( classes[preds[idx]], probs[idx] * 100.0, classes[labels[idx]]), color=(\"green\" if preds[idx]==labels[idx].item() else \"red\")) return fig 最后，让我们使用与之前教程相同的模型训练代码来训练模型，但是每 1000 批将结果写入 TensorBoard，而不是打印到控制台。 这是通过 add_scalar 函数完成的。 此外，在训练过程中，我们将生成一幅图像，显示该批次中包含的四幅图像的模型预测与实际结果。 running_loss = 0.0 for epoch in range(1): # loop over the dataset multiple times for i, data in enumerate(trainloader, 0): # get the inputs; data is a list of [inputs, labels] inputs, labels = data # zero the parameter gradients optimizer.zero_grad() # forward + backward + optimize outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() running_loss += loss.item() if i % 1000 == 999: # every 1000 mini-batches... # ...log the running loss writer.add_scalar('training loss', running_loss / 1000, epoch * len(trainloader) + i) # ...log a Matplotlib Figure showing the model's predictions on a # random mini-batch writer.add_figure('predictions vs. actuals', plot_classes_preds(net, inputs, labels), global_step=epoch * len(trainloader) + i) running_loss = 0.0 print('Finished Training') 现在，您可以查看“标量”选项卡，以查看在 15,000 次训练迭代中绘制的运行损失： 此外，我们可以查看整个学习过程中模型在任意批次上所做的预测。 查看“图像”选项卡，然后在“预测与实际”可视化条件下向下滚动以查看此内容； 这向我们表明，例如，仅经过 3000 次训练迭代，该模型就能够区分出视觉上截然不同的类，例如衬衫，运动鞋和外套，尽管它并没有像后来的训练那样有信心： 在之前的教程中，我们研究了模型训练后的每类准确性； 在这里，我们将使用 TensorBoard 绘制每个类的精确调用曲线(很好的解释在这里）。 6.使用 TensorBoard 评估经过训练的模型 # 1\\. gets the probability predictions in a test_size x num_classes Tensor # 2\\. gets the preds in a test_size Tensor # takes ~10 seconds to run class_probs = [] class_preds = [] with torch.no_grad(): for data in testloader: images, labels = data output = net(images) class_probs_batch = [F.softmax(el, dim=0) for el in output] _, class_preds_batch = torch.max(output, 1) class_probs.append(class_probs_batch) class_preds.append(class_preds_batch) test_probs = torch.cat([torch.stack(batch) for batch in class_probs]) test_preds = torch.cat(class_preds) # helper function def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0): ''' Takes in a \"class_index\" from 0 to 9 and plots the corresponding precision-recall curve ''' tensorboard_preds = test_preds == class_index tensorboard_probs = test_probs[:, class_index] writer.add_pr_curve(classes[class_index], tensorboard_preds, tensorboard_probs, global_step=global_step) writer.close() # plot all the pr curves for i in range(len(classes)): add_pr_curve_tensorboard(i, test_probs, test_preds) 现在，您将看到一个“ PR Curves”选项卡，其中包含每个类别的精确调用曲线。 继续戳一下； 您会发现在某些类别中，模型的“曲线下面积”接近 100％，而在另一些类别中，该面积更低： 这是 TensorBoard 和 PyTorch 与之集成的介绍。 当然，您可以在 Jupyter Notebook 中完成 TensorBoard 所做的所有操作，但是使用 TensorBoard，您可以获得默认情况下是交互式的视觉效果。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"8.html":{"url":"8.html","title":"TorchVision 对象检测微调教程","keywords":"","body":"TorchVision 对象检测微调教程 原文： https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html 小费 为了充分利用本教程，我们建议使用此 Colab 版本。 这将使您可以尝试以下信息。 在本教程中，我们将在 Penn-Fudan 数据库中对行人检测和分割进行预训练的遮罩 R-CNN 模型进行微调。 它包含 170 个图像，其中包含 345 个行人实例，我们将用它来说明如何在 torchvision 中使用新功能，以便在自定义数据集上训练实例细分模型。 定义数据集 用于训练对象检测，实例细分和人员关键点检测的参考脚本可轻松支持添加新的自定义数据集。 数据集应继承自标准torch.utils.data.Dataset类，并实现__len__和__getitem__。 我们唯一需要的特异性是数据集__getitem__应该返回： 图像：大小为(H, W)的 PIL 图像 目标：包含以下字段的字典 boxes (FloatTensor[N, 4])：[x0, y0, x1, y1]格式的N边界框的坐标，范围从0至W，从0至H labels (Int64Tensor[N])：每个边界框的标签 image_id (Int64Tensor[1])：图像标识符。 它在数据集中的所有图像之间应该是唯一的，并在评估过程中使用 area (Tensor[N])：边界框的区域。 在使用 COCO 度量进行评估时，可使用此值来区分小盒子，中盒子和大盒子之间的度量得分。 iscrowd (UInt8Tensor[N])：iscrowd = True 的实例在评估期间将被忽略。 (可选）masks (UInt8Tensor[N, H, W])：每个对象的分割蒙版 (可选）keypoints (FloatTensor[N, K, 3])：对于 N 个对象中的每个对象，它包含[x, y, visibility]格式的 K 个关键点，以定义对象。 可见性= 0 表示关键点不可见。 请注意，对于数据扩充，翻转关键点的概念取决于数据表示形式，您可能应该将references/detection/transforms.py修改为新的关键点表示形式 如果您的模型返回上述方法，则它们将使其适用于训练和评估，并将使用pycocotools中的评估脚本。 此外，如果要在训练过程中使用长宽比分组(以便每个批次仅包含具有相似长宽比的图像），则建议您还实施get_height_and_width方法，该方法返回图像的高度和宽度。 如果未提供此方法，我们将通过__getitem__查询数据集的所有元素，这会将图像加载到内存中，并且比提供自定义方法慢。 为 PennFudan 编写自定义数据集 让我们为 PennFudan 数据集编写一个数据集。 在下载并解压缩 zip 文件之后，我们具有以下文件夹结构： PennFudanPed/ PedMasks/ FudanPed00001_mask.png FudanPed00002_mask.png FudanPed00003_mask.png FudanPed00004_mask.png ... PNGImages/ FudanPed00001.png FudanPed00002.png FudanPed00003.png FudanPed00004.png 这是一对图像和分割蒙版的一个示例 因此，每个图像都有一个对应的分割蒙版，其中每个颜色对应一个不同的实例。 让我们为此数据集编写一个torch.utils.data.Dataset类。 import os import numpy as np import torch from PIL import Image class PennFudanDataset(object): def __init__(self, root, transforms): self.root = root self.transforms = transforms # load all image files, sorting them to # ensure that they are aligned self.imgs = list(sorted(os.listdir(os.path.join(root, \"PNGImages\")))) self.masks = list(sorted(os.listdir(os.path.join(root, \"PedMasks\")))) def __getitem__(self, idx): # load images ad masks img_path = os.path.join(self.root, \"PNGImages\", self.imgs[idx]) mask_path = os.path.join(self.root, \"PedMasks\", self.masks[idx]) img = Image.open(img_path).convert(\"RGB\") # note that we haven't converted the mask to RGB, # because each color corresponds to a different instance # with 0 being background mask = Image.open(mask_path) # convert the PIL Image into a numpy array mask = np.array(mask) # instances are encoded as different colors obj_ids = np.unique(mask) # first id is the background, so remove it obj_ids = obj_ids[1:] # split the color-encoded mask into a set # of binary masks masks = mask == obj_ids[:, None, None] # get bounding box coordinates for each mask num_objs = len(obj_ids) boxes = [] for i in range(num_objs): pos = np.where(masks[i]) xmin = np.min(pos[1]) xmax = np.max(pos[1]) ymin = np.min(pos[0]) ymax = np.max(pos[0]) boxes.append([xmin, ymin, xmax, ymax]) # convert everything into a torch.Tensor boxes = torch.as_tensor(boxes, dtype=torch.float32) # there is only one class labels = torch.ones((num_objs,), dtype=torch.int64) masks = torch.as_tensor(masks, dtype=torch.uint8) image_id = torch.tensor([idx]) area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0]) # suppose all instances are not crowd iscrowd = torch.zeros((num_objs,), dtype=torch.int64) target = {} target[\"boxes\"] = boxes target[\"labels\"] = labels target[\"masks\"] = masks target[\"image_id\"] = image_id target[\"area\"] = area target[\"iscrowd\"] = iscrowd if self.transforms is not None: img, target = self.transforms(img, target) return img, target def __len__(self): return len(self.imgs) 这就是数据集的全部内容。 现在，让我们定义一个可以对该数据集进行预测的模型。 定义模型 在本教程中，我们将基于 Faster R-CNN 使用 Mask R-CNN 。 更快的 R-CNN 是可预测图像中潜在对象的边界框和类分数的模型。 Mask R-CNN 在 Faster R-CNN 中增加了一个分支，该分支还可以预测每个实例的分割掩码。 在两种常见情况下，可能要修改 Torchvision modelzoo 中的可用模型之一。 首先是当我们想从预先训练的模型开始，然后微调最后一层时。 另一个是当我们要用另一个模型替换主干时(例如，为了更快的预测）。 在以下各节中，让我们看看如何做一个或另一个。 1-通过预训练模型进行微调 假设您想从在 COCO 上经过预训练的模型开始，并希望针对您的特定班级对其进行微调。 这是一种可行的方法： import torchvision from torchvision.models.detection.faster_rcnn import FastRCNNPredictor # load a model pre-trained pre-trained on COCO model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True) # replace the classifier with a new one, that has # num_classes which is user-defined num_classes = 2 # 1 class (person) + background # get number of input features for the classifier in_features = model.roi_heads.box_predictor.cls_score.in_features # replace the pre-trained head with a new one model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) 2-修改模型以添加其他主干 import torchvision from torchvision.models.detection import FasterRCNN from torchvision.models.detection.rpn import AnchorGenerator # load a pre-trained model for classification and return # only the features backbone = torchvision.models.mobilenet_v2(pretrained=True).features # FasterRCNN needs to know the number of # output channels in a backbone. For mobilenet_v2, it's 1280 # so we need to add it here backbone.out_channels = 1280 # let's make the RPN generate 5 x 3 anchors per spatial # location, with 5 different sizes and 3 different aspect # ratios. We have a Tuple[Tuple[int]] because each feature # map could potentially have different sizes and # aspect ratios anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),), aspect_ratios=((0.5, 1.0, 2.0),)) # let's define what are the feature maps that we will # use to perform the region of interest cropping, as well as # the size of the crop after rescaling. # if your backbone returns a Tensor, featmap_names is expected to # be [0]. More generally, the backbone should return an # OrderedDict[Tensor], and in featmap_names you can choose which # feature maps to use. roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0], output_size=7, sampling_ratio=2) # put the pieces together inside a FasterRCNN model model = FasterRCNN(backbone, num_classes=2, rpn_anchor_generator=anchor_generator, box_roi_pool=roi_pooler) PennFudan 数据集的实例细分模型 在我们的例子中，由于我们的数据集非常小，我们希望从预训练的模型中进行微调，因此我们将遵循方法 1。 这里我们还想计算实例分割掩码，因此我们将使用 Mask R-CNN： import torchvision from torchvision.models.detection.faster_rcnn import FastRCNNPredictor from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor def get_model_instance_segmentation(num_classes): # load an instance segmentation model pre-trained pre-trained on COCO model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True) # get number of input features for the classifier in_features = model.roi_heads.box_predictor.cls_score.in_features # replace the pre-trained head with a new one model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) # now get the number of input features for the mask classifier in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels hidden_layer = 256 # and replace the mask predictor with a new one model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes) return model 就是这样，这将使model随时可以在您的自定义数据集上进行训练和评估。 放在一起 在references/detection/中，我们提供了许多帮助程序功能来简化训练和评估检测模型。 在这里，我们将使用references/detection/engine.py，references/detection/utils.py和references/detection/transforms.py。 只需将它们复制到您的文件夹中并在此处使用它们即可。 让我们写一些辅助函数来进行数据扩充/转换： import transforms as T def get_transform(train): transforms = [] transforms.append(T.ToTensor()) if train: transforms.append(T.RandomHorizontalFlip(0.5)) return T.Compose(transforms) 测试forward()方法(可选） 遍历数据集之前，最好先查看模型在训练过程中的期望值以及对样本数据的推断时间。 model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True) dataset = PennFudanDataset('PennFudanPed', get_transform(train=True)) data_loader = torch.utils.data.DataLoader( dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=utils.collate_fn) # For Training images,targets = next(iter(data_loader)) images = list(image for image in images) targets = [{k: v for k, v in t.items()} for t in targets] output = model(images,targets) # Returns losses and detections # For inference model.eval() x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)] predictions = model(x) # Returns predictions 现在让我们编写执行训练和验证的主要功能： from engine import train_one_epoch, evaluate import utils def main(): # train on the GPU or on the CPU, if a GPU is not available device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') # our dataset has two classes only - background and person num_classes = 2 # use our dataset and defined transformations dataset = PennFudanDataset('PennFudanPed', get_transform(train=True)) dataset_test = PennFudanDataset('PennFudanPed', get_transform(train=False)) # split the dataset in train and test set indices = torch.randperm(len(dataset)).tolist() dataset = torch.utils.data.Subset(dataset, indices[:-50]) dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:]) # define training and validation data loaders data_loader = torch.utils.data.DataLoader( dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=utils.collate_fn) data_loader_test = torch.utils.data.DataLoader( dataset_test, batch_size=1, shuffle=False, num_workers=4, collate_fn=utils.collate_fn) # get the model using our helper function model = get_model_instance_segmentation(num_classes) # move model to the right device model.to(device) # construct an optimizer params = [p for p in model.parameters() if p.requires_grad] optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005) # and a learning rate scheduler lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1) # let's train it for 10 epochs num_epochs = 10 for epoch in range(num_epochs): # train for one epoch, printing every 10 iterations train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10) # update the learning rate lr_scheduler.step() # evaluate on the test dataset evaluate(model, data_loader_test, device=device) print(\"That's it!\") 您应该获得第一个时期的输出： Epoch: [0] [ 0/60] eta: 0:01:18 lr: 0.000090 loss: 2.5213 (2.5213) loss_classifier: 0.8025 (0.8025) loss_box_reg: 0.2634 (0.2634) loss_mask: 1.4265 (1.4265) loss_objectness: 0.0190 (0.0190) loss_rpn_box_reg: 0.0099 (0.0099) time: 1.3121 data: 0.3024 max mem: 3485 Epoch: [0] [10/60] eta: 0:00:20 lr: 0.000936 loss: 1.3007 (1.5313) loss_classifier: 0.3979 (0.4719) loss_box_reg: 0.2454 (0.2272) loss_mask: 0.6089 (0.7953) loss_objectness: 0.0197 (0.0228) loss_rpn_box_reg: 0.0121 (0.0141) time: 0.4198 data: 0.0298 max mem: 5081 Epoch: [0] [20/60] eta: 0:00:15 lr: 0.001783 loss: 0.7567 (1.1056) loss_classifier: 0.2221 (0.3319) loss_box_reg: 0.2002 (0.2106) loss_mask: 0.2904 (0.5332) loss_objectness: 0.0146 (0.0176) loss_rpn_box_reg: 0.0094 (0.0123) time: 0.3293 data: 0.0035 max mem: 5081 Epoch: [0] [30/60] eta: 0:00:11 lr: 0.002629 loss: 0.4705 (0.8935) loss_classifier: 0.0991 (0.2517) loss_box_reg: 0.1578 (0.1957) loss_mask: 0.1970 (0.4204) loss_objectness: 0.0061 (0.0140) loss_rpn_box_reg: 0.0075 (0.0118) time: 0.3403 data: 0.0044 max mem: 5081 Epoch: [0] [40/60] eta: 0:00:07 lr: 0.003476 loss: 0.3901 (0.7568) loss_classifier: 0.0648 (0.2022) loss_box_reg: 0.1207 (0.1736) loss_mask: 0.1705 (0.3585) loss_objectness: 0.0018 (0.0113) loss_rpn_box_reg: 0.0075 (0.0112) time: 0.3407 data: 0.0044 max mem: 5081 Epoch: [0] [50/60] eta: 0:00:03 lr: 0.004323 loss: 0.3237 (0.6703) loss_classifier: 0.0474 (0.1731) loss_box_reg: 0.1109 (0.1561) loss_mask: 0.1658 (0.3201) loss_objectness: 0.0015 (0.0093) loss_rpn_box_reg: 0.0093 (0.0116) time: 0.3379 data: 0.0043 max mem: 5081 Epoch: [0] [59/60] eta: 0:00:00 lr: 0.005000 loss: 0.2540 (0.6082) loss_classifier: 0.0309 (0.1526) loss_box_reg: 0.0463 (0.1405) loss_mask: 0.1568 (0.2945) loss_objectness: 0.0012 (0.0083) loss_rpn_box_reg: 0.0093 (0.0123) time: 0.3489 data: 0.0042 max mem: 5081 Epoch: [0] Total time: 0:00:21 (0.3570 s / it) creating index... index created! Test: [ 0/50] eta: 0:00:19 model_time: 0.2152 (0.2152) evaluator_time: 0.0133 (0.0133) time: 0.4000 data: 0.1701 max mem: 5081 Test: [49/50] eta: 0:00:00 model_time: 0.0628 (0.0687) evaluator_time: 0.0039 (0.0064) time: 0.0735 data: 0.0022 max mem: 5081 Test: Total time: 0:00:04 (0.0828 s / it) Averaged stats: model_time: 0.0628 (0.0687) evaluator_time: 0.0039 (0.0064) Accumulating evaluation results... DONE (t=0.01s). Accumulating evaluation results... DONE (t=0.01s). IoU metric: bbox Average Precision (AP) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.606 Average Precision (AP) @[ IoU=0.50 | area= all | maxDets=100 ] = 0.984 Average Precision (AP) @[ IoU=0.75 | area= all | maxDets=100 ] = 0.780 Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.313 Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.582 Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.612 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 1 ] = 0.270 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 10 ] = 0.672 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.672 Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.650 Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.755 Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664 IoU metric: segm Average Precision (AP) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.704 Average Precision (AP) @[ IoU=0.50 | area= all | maxDets=100 ] = 0.979 Average Precision (AP) @[ IoU=0.75 | area= all | maxDets=100 ] = 0.871 Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325 Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.488 Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.727 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 1 ] = 0.316 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 10 ] = 0.748 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.749 Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.650 Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.673 Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758 因此，经过一个时期的训练，我们获得了 60.6 的 COCO 风格 mAP 和 70.4 的口罩 mAP。 经过 10 个时期的训练，我得到了以下指标 IoU metric: bbox Average Precision (AP) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.799 Average Precision (AP) @[ IoU=0.50 | area= all | maxDets=100 ] = 0.969 Average Precision (AP) @[ IoU=0.75 | area= all | maxDets=100 ] = 0.935 Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.349 Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592 Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.831 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 1 ] = 0.324 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 10 ] = 0.844 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.844 Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400 Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.777 Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.870 IoU metric: segm Average Precision (AP) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.761 Average Precision (AP) @[ IoU=0.50 | area= all | maxDets=100 ] = 0.969 Average Precision (AP) @[ IoU=0.75 | area= all | maxDets=100 ] = 0.919 Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.341 Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.464 Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 1 ] = 0.303 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 10 ] = 0.799 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.799 Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400 Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.769 Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.818 但是这些预测是什么样的？ 让我们在数据集中拍摄一张图像并进行验证 经过训练的模型会在此图片中预测 9 个人物实例，让我们看看其中的几个： 结果看起来还不错！ 包起来 在本教程中，您学习了如何在自定义数据集上为实例细分模型创建自己的训练管道。 为此，您编写了一个torch.utils.data.Dataset类，该类返回图像以及地面真相框和分段蒙版。 您还利用了在 COCO train2017 上预先训练的 Mask R-CNN 模型，以便对该新数据集执行转移学习。 对于更完整的示例(包括多机/多 GPU 训练），请检查在 Torchvision 存储库中存在的references/detection/train.py。 您可以在处下载本教程的完整源文件。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"9.html":{"url":"9.html","title":"转移学习的计算机视觉教程","keywords":"","body":"转移学习的计算机视觉教程 原文： https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html 注意 单击此处的下载完整的示例代码 作者： Sasank Chilamkurthy 在本教程中，您将学习如何使用转移学习训练卷积神经网络进行图像分类。 您可以在 cs231n 笔记上了解有关转移学习的更多信息。 引用这些注释， 实际上，很少有人从头开始训练整个卷积网络(使用随机初始化），因为拥有足够大小的数据集相对很少。 相反，通常在非常大的数据集上对 ConvNet 进行预训练(例如 ImageNet，其中包含 120 万个具有 1000 个类别的图像），然后将 ConvNet 用作初始化或固定特征提取器以完成感兴趣的任务。 这两个主要的转移学习方案如下所示： 对卷积网络进行微调：代替随机初始化，我们使用经过预训练的网络初始化网络，例如在 imagenet 1000 数据集上进行训练的网络。 其余的训练照常进行。 ConvNet 作为固定特征提取器：在这里，我们将冻结除最终完全连接层以外的所有网络的权重。 最后一个完全连接的层将替换为具有随机权重的新层，并且仅训练该层。 # License: BSD # Author: Sasank Chilamkurthy from __future__ import print_function, division import torch import torch.nn as nn import torch.optim as optim from torch.optim import lr_scheduler import numpy as np import torchvision from torchvision import datasets, models, transforms import matplotlib.pyplot as plt import time import os import copy plt.ion() # interactive mode 载入资料 我们将使用 torchvision 和 torch.utils.data 包来加载数据。 我们今天要解决的问题是训练一个模型来对蚂蚁和蜜蜂进行分类。 我们为蚂蚁和蜜蜂提供了大约 120 张训练图像。 每个类别有 75 个验证图像。 通常，如果从头开始训练的话，这是一个很小的数据集。 由于我们正在使用迁移学习，因此我们应该能够很好地概括。 该数据集是 imagenet 的很小一部分。 Note 从的下载数据，并将其提取到当前目录。 # Data augmentation and normalization for training # Just normalization for validation data_transforms = { 'train': transforms.Compose([ transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]), 'val': transforms.Compose([ transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]), } data_dir = 'data/hymenoptera_data' image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']} dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']} dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']} class_names = image_datasets['train'].classes device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") 可视化一些图像 让我们可视化一些训练图像，以了解数据扩充。 def imshow(inp, title=None): \"\"\"Imshow for Tensor.\"\"\" inp = inp.numpy().transpose((1, 2, 0)) mean = np.array([0.485, 0.456, 0.406]) std = np.array([0.229, 0.224, 0.225]) inp = std * inp + mean inp = np.clip(inp, 0, 1) plt.imshow(inp) if title is not None: plt.title(title) plt.pause(0.001) # pause a bit so that plots are updated # Get a batch of training data inputs, classes = next(iter(dataloaders['train'])) # Make a grid from batch out = torchvision.utils.make_grid(inputs) imshow(out, title=[class_names[x] for x in classes]) 训练模型 现在，让我们编写一个通用函数来训练模型。 在这里，我们将说明： 安排学习率 保存最佳模型 以下，参数scheduler是来自torch.optim.lr_scheduler的 LR 调度程序对象。 def train_model(model, criterion, optimizer, scheduler, num_epochs=25): since = time.time() best_model_wts = copy.deepcopy(model.state_dict()) best_acc = 0.0 for epoch in range(num_epochs): print('Epoch {}/{}'.format(epoch, num_epochs - 1)) print('-' * 10) # Each epoch has a training and validation phase for phase in ['train', 'val']: if phase == 'train': model.train() # Set model to training mode else: model.eval() # Set model to evaluate mode running_loss = 0.0 running_corrects = 0 # Iterate over data. for inputs, labels in dataloaders[phase]: inputs = inputs.to(device) labels = labels.to(device) # zero the parameter gradients optimizer.zero_grad() # forward # track history if only in train with torch.set_grad_enabled(phase == 'train'): outputs = model(inputs) _, preds = torch.max(outputs, 1) loss = criterion(outputs, labels) # backward + optimize only if in training phase if phase == 'train': loss.backward() optimizer.step() # statistics running_loss += loss.item() * inputs.size(0) running_corrects += torch.sum(preds == labels.data) if phase == 'train': scheduler.step() epoch_loss = running_loss / dataset_sizes[phase] epoch_acc = running_corrects.double() / dataset_sizes[phase] print('{} Loss: {:.4f} Acc: {:.4f}'.format( phase, epoch_loss, epoch_acc)) # deep copy the model if phase == 'val' and epoch_acc > best_acc: best_acc = epoch_acc best_model_wts = copy.deepcopy(model.state_dict()) print() time_elapsed = time.time() - since print('Training complete in {:.0f}m {:.0f}s'.format( time_elapsed // 60, time_elapsed % 60)) print('Best val Acc: {:4f}'.format(best_acc)) # load best model weights model.load_state_dict(best_model_wts) return model 可视化模型预测 通用功能可显示一些图像的预测 def visualize_model(model, num_images=6): was_training = model.training model.eval() images_so_far = 0 fig = plt.figure() with torch.no_grad(): for i, (inputs, labels) in enumerate(dataloaders['val']): inputs = inputs.to(device) labels = labels.to(device) outputs = model(inputs) _, preds = torch.max(outputs, 1) for j in range(inputs.size()[0]): images_so_far += 1 ax = plt.subplot(num_images//2, 2, images_so_far) ax.axis('off') ax.set_title('predicted: {}'.format(class_names[preds[j]])) imshow(inputs.cpu().data[j]) if images_so_far == num_images: model.train(mode=was_training) return model.train(mode=was_training) 微调 convnet 加载预训练的模型并重置最终的完全连接层。 model_ft = models.resnet18(pretrained=True) num_ftrs = model_ft.fc.in_features # Here the size of each output sample is set to 2. # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)). model_ft.fc = nn.Linear(num_ftrs, 2) model_ft = model_ft.to(device) criterion = nn.CrossEntropyLoss() # Observe that all parameters are being optimized optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9) # Decay LR by a factor of 0.1 every 7 epochs exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1) 训练和评估 在 CPU 上大约需要 15-25 分钟。 但是在 GPU 上，此过程不到一分钟。 model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25) 出： Epoch 0/24 ---------- train Loss: 0.5582 Acc: 0.6967 val Loss: 0.1987 Acc: 0.9216 Epoch 1/24 ---------- train Loss: 0.4663 Acc: 0.8238 val Loss: 0.2519 Acc: 0.8889 Epoch 2/24 ---------- train Loss: 0.5978 Acc: 0.7623 val Loss: 1.2933 Acc: 0.6601 Epoch 3/24 ---------- train Loss: 0.4471 Acc: 0.8320 val Loss: 0.2576 Acc: 0.8954 Epoch 4/24 ---------- train Loss: 0.3654 Acc: 0.8115 val Loss: 0.2977 Acc: 0.9150 Epoch 5/24 ---------- train Loss: 0.4404 Acc: 0.8197 val Loss: 0.3330 Acc: 0.8627 Epoch 6/24 ---------- train Loss: 0.6416 Acc: 0.7623 val Loss: 0.3174 Acc: 0.8693 Epoch 7/24 ---------- train Loss: 0.4058 Acc: 0.8361 val Loss: 0.2551 Acc: 0.9085 Epoch 8/24 ---------- train Loss: 0.2294 Acc: 0.9098 val Loss: 0.2603 Acc: 0.9085 Epoch 9/24 ---------- train Loss: 0.2805 Acc: 0.8730 val Loss: 0.2765 Acc: 0.8954 Epoch 10/24 ---------- train Loss: 0.3139 Acc: 0.8525 val Loss: 0.2639 Acc: 0.9020 Epoch 11/24 ---------- train Loss: 0.3198 Acc: 0.8648 val Loss: 0.2458 Acc: 0.9020 Epoch 12/24 ---------- train Loss: 0.2947 Acc: 0.8811 val Loss: 0.2835 Acc: 0.8889 Epoch 13/24 ---------- train Loss: 0.3097 Acc: 0.8730 val Loss: 0.2542 Acc: 0.9085 Epoch 14/24 ---------- train Loss: 0.1849 Acc: 0.9303 val Loss: 0.2710 Acc: 0.9085 Epoch 15/24 ---------- train Loss: 0.2764 Acc: 0.8934 val Loss: 0.2522 Acc: 0.9085 Epoch 16/24 ---------- train Loss: 0.2214 Acc: 0.9098 val Loss: 0.2620 Acc: 0.9085 Epoch 17/24 ---------- train Loss: 0.2949 Acc: 0.8525 val Loss: 0.2600 Acc: 0.9085 Epoch 18/24 ---------- train Loss: 0.2237 Acc: 0.9139 val Loss: 0.2666 Acc: 0.9020 Epoch 19/24 ---------- train Loss: 0.2456 Acc: 0.8852 val Loss: 0.2521 Acc: 0.9150 Epoch 20/24 ---------- train Loss: 0.2351 Acc: 0.8852 val Loss: 0.2781 Acc: 0.9085 Epoch 21/24 ---------- train Loss: 0.2654 Acc: 0.8730 val Loss: 0.2560 Acc: 0.9085 Epoch 22/24 ---------- train Loss: 0.1955 Acc: 0.9262 val Loss: 0.2605 Acc: 0.9020 Epoch 23/24 ---------- train Loss: 0.2285 Acc: 0.8893 val Loss: 0.2650 Acc: 0.9085 Epoch 24/24 ---------- train Loss: 0.2360 Acc: 0.9221 val Loss: 0.2690 Acc: 0.8954 Training complete in 1m 7s Best val Acc: 0.921569 visualize_model(model_ft) ConvNet 作为固定特征提取器 在这里，我们需要冻结除最后一层之外的所有网络。 我们需要设置requires_grad == False冻结参数，以便不在backward()中计算梯度。 您可以在的文档中阅读有关此内容的更多信息。 model_conv = torchvision.models.resnet18(pretrained=True) for param in model_conv.parameters(): param.requires_grad = False # Parameters of newly constructed modules have requires_grad=True by default num_ftrs = model_conv.fc.in_features model_conv.fc = nn.Linear(num_ftrs, 2) model_conv = model_conv.to(device) criterion = nn.CrossEntropyLoss() # Observe that only parameters of final layer are being optimized as # opposed to before. optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9) # Decay LR by a factor of 0.1 every 7 epochs exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1) Train and evaluate 与以前的方案相比，在 CPU 上将花费大约一半的时间。 这是可以预期的，因为不需要为大多数网络计算梯度。 但是，确实需要计算正向。 model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=25) Out: Epoch 0/24 ---------- train Loss: 0.5633 Acc: 0.7008 val Loss: 0.2159 Acc: 0.9412 Epoch 1/24 ---------- train Loss: 0.4394 Acc: 0.7623 val Loss: 0.2000 Acc: 0.9150 Epoch 2/24 ---------- train Loss: 0.5182 Acc: 0.7623 val Loss: 0.1897 Acc: 0.9346 Epoch 3/24 ---------- train Loss: 0.3993 Acc: 0.8074 val Loss: 0.3029 Acc: 0.8824 Epoch 4/24 ---------- train Loss: 0.4163 Acc: 0.8607 val Loss: 0.2190 Acc: 0.9412 Epoch 5/24 ---------- train Loss: 0.4741 Acc: 0.7951 val Loss: 0.1903 Acc: 0.9477 Epoch 6/24 ---------- train Loss: 0.4266 Acc: 0.8115 val Loss: 0.2178 Acc: 0.9281 Epoch 7/24 ---------- train Loss: 0.3623 Acc: 0.8238 val Loss: 0.2080 Acc: 0.9412 Epoch 8/24 ---------- train Loss: 0.3979 Acc: 0.8279 val Loss: 0.1796 Acc: 0.9412 Epoch 9/24 ---------- train Loss: 0.3534 Acc: 0.8648 val Loss: 0.2043 Acc: 0.9412 Epoch 10/24 ---------- train Loss: 0.3849 Acc: 0.8115 val Loss: 0.2012 Acc: 0.9346 Epoch 11/24 ---------- train Loss: 0.3814 Acc: 0.8361 val Loss: 0.2088 Acc: 0.9412 Epoch 12/24 ---------- train Loss: 0.3443 Acc: 0.8648 val Loss: 0.1823 Acc: 0.9477 Epoch 13/24 ---------- train Loss: 0.2931 Acc: 0.8525 val Loss: 0.1853 Acc: 0.9477 Epoch 14/24 ---------- train Loss: 0.2749 Acc: 0.8811 val Loss: 0.2068 Acc: 0.9412 Epoch 15/24 ---------- train Loss: 0.3387 Acc: 0.8566 val Loss: 0.2080 Acc: 0.9477 Epoch 16/24 ---------- train Loss: 0.2992 Acc: 0.8648 val Loss: 0.2096 Acc: 0.9346 Epoch 17/24 ---------- train Loss: 0.3396 Acc: 0.8648 val Loss: 0.1870 Acc: 0.9412 Epoch 18/24 ---------- train Loss: 0.3956 Acc: 0.8320 val Loss: 0.1858 Acc: 0.9412 Epoch 19/24 ---------- train Loss: 0.3379 Acc: 0.8402 val Loss: 0.1729 Acc: 0.9542 Epoch 20/24 ---------- train Loss: 0.2555 Acc: 0.8811 val Loss: 0.2186 Acc: 0.9281 Epoch 21/24 ---------- train Loss: 0.3764 Acc: 0.8484 val Loss: 0.1817 Acc: 0.9477 Epoch 22/24 ---------- train Loss: 0.2747 Acc: 0.8975 val Loss: 0.2042 Acc: 0.9412 Epoch 23/24 ---------- train Loss: 0.3072 Acc: 0.8689 val Loss: 0.1924 Acc: 0.9477 Epoch 24/24 ---------- train Loss: 0.3479 Acc: 0.8402 val Loss: 0.1835 Acc: 0.9477 Training complete in 0m 34s Best val Acc: 0.954248 visualize_model(model_conv) plt.ioff() plt.show() 进阶学习 如果您想了解有关迁移学习的更多信息，请查看我们的计算机视觉教程的量化迁移学习。 脚本的总运行时间：(1 分钟 53.551 秒） Download Python source code: transfer_learning_tutorial.py Download Jupyter notebook: transfer_learning_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"10.html":{"url":"10.html","title":"空间变压器网络教程","keywords":"","body":"空间变压器网络教程 原文： https://pytorch.org/tutorials/intermediate/spatial_transformer_tutorial.html 注意 单击此处的下载完整的示例代码 作者： Ghassen HAMROUNI 在本教程中，您将学习如何使用称为空间变换器网络的视觉注意力机制来扩充网络。 您可以在 DeepMind 论文中详细了解空间变压器网络。 空间变换器网络是对任何空间变换的可区别关注的概括。 空间变换器网络(简称 STN）允许神经网络学习如何对输入图像执行空间变换，以增强模型的几何不变性。 例如，它可以裁剪感兴趣的区域，缩放并校正图像的方向。 这可能是一个有用的机制，因为 CNN 不会对旋转和缩放以及更一般的仿射变换保持不变。 关于 STN 的最好的事情之一就是能够将它简单地插入到任何现有的 CNN 中。 # License: BSD # Author: Ghassen Hamrouni from __future__ import print_function import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim import torchvision from torchvision import datasets, transforms import matplotlib.pyplot as plt import numpy as np plt.ion() # interactive mode 加载数据 在本文中，我们将尝试使用经典的 MNIST 数据集。 使用标准卷积网络和空间变换器网络。 device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Training dataset train_loader = torch.utils.data.DataLoader( datasets.MNIST(root='.', train=True, download=True, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=64, shuffle=True, num_workers=4) # Test dataset test_loader = torch.utils.data.DataLoader( datasets.MNIST(root='.', train=False, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=64, shuffle=True, num_workers=4) 出： Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw Processing... Done! 描述空间变压器网络 空间变压器网络可归结为三个主要组成部分： 本地化网络是常规的 CNN，可以对转换参数进行回归。 永远不会从此数据集中显式学习变换，而是网络会自动学习增强全局精度的空间变换。 网格生成器在输入图像中生成与来自输出图像的每个像素相对应的坐标网格。 采样器使用转换的参数，并将其应用于输入图像。 Note 我们需要包含 affine_grid 和 grid_sample 模块的最新版本的 PyTorch。 class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(1, 10, kernel_size=5) self.conv2 = nn.Conv2d(10, 20, kernel_size=5) self.conv2_drop = nn.Dropout2d() self.fc1 = nn.Linear(320, 50) self.fc2 = nn.Linear(50, 10) # Spatial transformer localization-network self.localization = nn.Sequential( nn.Conv2d(1, 8, kernel_size=7), nn.MaxPool2d(2, stride=2), nn.ReLU(True), nn.Conv2d(8, 10, kernel_size=5), nn.MaxPool2d(2, stride=2), nn.ReLU(True) ) # Regressor for the 3 * 2 affine matrix self.fc_loc = nn.Sequential( nn.Linear(10 * 3 * 3, 32), nn.ReLU(True), nn.Linear(32, 3 * 2) ) # Initialize the weights/bias with identity transformation self.fc_loc[2].weight.data.zero_() self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float)) # Spatial transformer network forward function def stn(self, x): xs = self.localization(x) xs = xs.view(-1, 10 * 3 * 3) theta = self.fc_loc(xs) theta = theta.view(-1, 2, 3) grid = F.affine_grid(theta, x.size()) x = F.grid_sample(x, grid) return x def forward(self, x): # transform the input x = self.stn(x) # Perform the usual forward pass x = F.relu(F.max_pool2d(self.conv1(x), 2)) x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2)) x = x.view(-1, 320) x = F.relu(self.fc1(x)) x = F.dropout(x, training=self.training) x = self.fc2(x) return F.log_softmax(x, dim=1) model = Net().to(device) 训练模型 现在，让我们使用 SGD 算法训练模型。 网络正在以监督方式学习分类任务。 同时，该模型以端到端的方式自动学习 STN。 optimizer = optim.SGD(model.parameters(), lr=0.01) def train(epoch): model.train() for batch_idx, (data, target) in enumerate(train_loader): data, target = data.to(device), target.to(device) optimizer.zero_grad() output = model(data) loss = F.nll_loss(output, target) loss.backward() optimizer.step() if batch_idx % 500 == 0: print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format( epoch, batch_idx * len(data), len(train_loader.dataset), 100\\. * batch_idx / len(train_loader), loss.item())) # # A simple test procedure to measure STN the performances on MNIST. # def test(): with torch.no_grad(): model.eval() test_loss = 0 correct = 0 for data, target in test_loader: data, target = data.to(device), target.to(device) output = model(data) # sum up batch loss test_loss += F.nll_loss(output, target, size_average=False).item() # get the index of the max log-probability pred = output.max(1, keepdim=True)[1] correct += pred.eq(target.view_as(pred)).sum().item() test_loss /= len(test_loader.dataset) print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n' .format(test_loss, correct, len(test_loader.dataset), 100\\. * correct / len(test_loader.dataset))) 可视化 STN 结果 现在，我们将检查学习到的视觉注意力机制的结果。 我们定义了一个小的辅助函数，以便在训练时可视化转换。 def convert_image_np(inp): \"\"\"Convert a Tensor to numpy image.\"\"\" inp = inp.numpy().transpose((1, 2, 0)) mean = np.array([0.485, 0.456, 0.406]) std = np.array([0.229, 0.224, 0.225]) inp = std * inp + mean inp = np.clip(inp, 0, 1) return inp # We want to visualize the output of the spatial transformers layer # after the training, we visualize a batch of input images and # the corresponding transformed batch using STN. def visualize_stn(): with torch.no_grad(): # Get a batch of training data data = next(iter(test_loader))[0].to(device) input_tensor = data.cpu() transformed_input_tensor = model.stn(data).cpu() in_grid = convert_image_np( torchvision.utils.make_grid(input_tensor)) out_grid = convert_image_np( torchvision.utils.make_grid(transformed_input_tensor)) # Plot the results side-by-side f, axarr = plt.subplots(1, 2) axarr[0].imshow(in_grid) axarr[0].set_title('Dataset Images') axarr[1].imshow(out_grid) axarr[1].set_title('Transformed Images') for epoch in range(1, 20 + 1): train(epoch) test() # Visualize the STN transformation on some input batch visualize_stn() plt.ioff() plt.show() Out: Train Epoch: 1 [0/60000 (0%)] Loss: 2.312544 Train Epoch: 1 [32000/60000 (53%)] Loss: 0.865688 Test set: Average loss: 0.2105, Accuracy: 9426/10000 (94%) Train Epoch: 2 [0/60000 (0%)] Loss: 0.528199 Train Epoch: 2 [32000/60000 (53%)] Loss: 0.273284 Test set: Average loss: 0.1150, Accuracy: 9661/10000 (97%) Train Epoch: 3 [0/60000 (0%)] Loss: 0.312562 Train Epoch: 3 [32000/60000 (53%)] Loss: 0.496166 Test set: Average loss: 0.1130, Accuracy: 9661/10000 (97%) Train Epoch: 4 [0/60000 (0%)] Loss: 0.346181 Train Epoch: 4 [32000/60000 (53%)] Loss: 0.206084 Test set: Average loss: 0.0875, Accuracy: 9730/10000 (97%) Train Epoch: 5 [0/60000 (0%)] Loss: 0.351175 Train Epoch: 5 [32000/60000 (53%)] Loss: 0.388225 Test set: Average loss: 0.0659, Accuracy: 9802/10000 (98%) Train Epoch: 6 [0/60000 (0%)] Loss: 0.122667 Train Epoch: 6 [32000/60000 (53%)] Loss: 0.258372 Test set: Average loss: 0.0791, Accuracy: 9759/10000 (98%) Train Epoch: 7 [0/60000 (0%)] Loss: 0.190197 Train Epoch: 7 [32000/60000 (53%)] Loss: 0.154468 Test set: Average loss: 0.0647, Accuracy: 9791/10000 (98%) Train Epoch: 8 [0/60000 (0%)] Loss: 0.121149 Train Epoch: 8 [32000/60000 (53%)] Loss: 0.288490 Test set: Average loss: 0.0583, Accuracy: 9821/10000 (98%) Train Epoch: 9 [0/60000 (0%)] Loss: 0.244609 Train Epoch: 9 [32000/60000 (53%)] Loss: 0.023396 Test set: Average loss: 0.0685, Accuracy: 9778/10000 (98%) Train Epoch: 10 [0/60000 (0%)] Loss: 0.256878 Train Epoch: 10 [32000/60000 (53%)] Loss: 0.091626 Test set: Average loss: 0.0684, Accuracy: 9783/10000 (98%) Train Epoch: 11 [0/60000 (0%)] Loss: 0.181910 Train Epoch: 11 [32000/60000 (53%)] Loss: 0.113193 Test set: Average loss: 0.0492, Accuracy: 9856/10000 (99%) Train Epoch: 12 [0/60000 (0%)] Loss: 0.081072 Train Epoch: 12 [32000/60000 (53%)] Loss: 0.082513 Test set: Average loss: 0.0670, Accuracy: 9800/10000 (98%) Train Epoch: 13 [0/60000 (0%)] Loss: 0.180748 Train Epoch: 13 [32000/60000 (53%)] Loss: 0.194512 Test set: Average loss: 0.0439, Accuracy: 9874/10000 (99%) Train Epoch: 14 [0/60000 (0%)] Loss: 0.099560 Train Epoch: 14 [32000/60000 (53%)] Loss: 0.084377 Test set: Average loss: 0.0416, Accuracy: 9880/10000 (99%) Train Epoch: 15 [0/60000 (0%)] Loss: 0.070021 Train Epoch: 15 [32000/60000 (53%)] Loss: 0.241336 Test set: Average loss: 0.0588, Accuracy: 9820/10000 (98%) Train Epoch: 16 [0/60000 (0%)] Loss: 0.060536 Train Epoch: 16 [32000/60000 (53%)] Loss: 0.053016 Test set: Average loss: 0.0405, Accuracy: 9877/10000 (99%) Train Epoch: 17 [0/60000 (0%)] Loss: 0.207369 Train Epoch: 17 [32000/60000 (53%)] Loss: 0.069607 Test set: Average loss: 0.1006, Accuracy: 9685/10000 (97%) Train Epoch: 18 [0/60000 (0%)] Loss: 0.127503 Train Epoch: 18 [32000/60000 (53%)] Loss: 0.070724 Test set: Average loss: 0.0659, Accuracy: 9814/10000 (98%) Train Epoch: 19 [0/60000 (0%)] Loss: 0.176861 Train Epoch: 19 [32000/60000 (53%)] Loss: 0.116980 Test set: Average loss: 0.0413, Accuracy: 9871/10000 (99%) Train Epoch: 20 [0/60000 (0%)] Loss: 0.146933 Train Epoch: 20 [32000/60000 (53%)] Loss: 0.245741 Test set: Average loss: 0.0346, Accuracy: 9892/10000 (99%) 脚本的总运行时间：(2 分钟 3.339 秒） Download Python source code: spatial_transformer_tutorial.py Download Jupyter notebook: spatial_transformer_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"11.html":{"url":"11.html","title":"使用 PyTorch 进行神经传递","keywords":"","body":"使用 PyTorch 进行神经传递 原文： https://pytorch.org/tutorials/advanced/neural_style_tutorial.html 注意 单击此处的下载完整的示例代码 作者： Alexis Jacq 由编辑：温斯顿·鲱鱼 介绍 本教程说明了如何实现由 Leon A. Gatys，Alexander S. Ecker 和 Matthias Bethge 开发的神经样式算法。 神经风格(Neural-Style）或神经传递(Neural-Transfer）使您可以拍摄图像并以新的艺术风格对其进行再现。 该算法获取三个图像，即输入图像，内容图像和样式图像，然后更改输入以使其类似于内容图像的内容和样式图像的艺术风格。 基本原理 原理很简单：我们定义了两个距离，一个为内容(），一个为样式(）。 测量两个图像之间的内容有多大不同，而测量两个图像之间的样式有多大不同。 然后，我们获取第三个图像(输入），并将其转换为最小化与内容图像的内容距离和与样式图像的样式距离。 现在我们可以导入必要的程序包并开始神经传递。 导入软件包并选择设备 以下是实现神经传递所需的软件包列表。 torch，torch.nn，numpy(使用 PyTorch 的神经网络必不可少的软件包） torch.optim(有效梯度下降） PIL，PIL.Image，matplotlib.pyplot(加载并显示图像） torchvision.transforms(将 PIL 图像转换为张量） torchvision.models(训练或负载预训练模型） copy(用于深复制模型；系统软件包） from __future__ import print_function import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim from PIL import Image import matplotlib.pyplot as plt import torchvision.transforms as transforms import torchvision.models as models import copy 接下来，我们需要选择要在哪个设备上运行网络并导入内容和样式图像。 在大图像上运行神经传递算法需要更长的时间，并且在 GPU 上运行时会更快。 我们可以使用torch.cuda.is_available()来检测是否有 GPU。 接下来，我们设置torch.device以在整个教程中使用。 .to(device)方法也用于将张量或模块移动到所需的设备。 device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") 加载图像 现在，我们将导入样式和内容图像。 原始的 PIL 图像的值在 0 到 255 之间，但是当转换为torch张量时，其值将转换为 0 到 1 之间。图像也需要调整大小以具有相同的尺寸。 需要注意的一个重要细节是，使用从 0 到 1 的张量值对torch库中的神经网络进行训练。如果尝试为网络提供 0 到 255 张量图像，则激活的特征图将无法感知预期的内容 和风格。 但是，使用 0 到 255 张量图像对 Caffe 库中的预训练网络进行训练。 Note 以下是下载运行本教程所需的图像的链接： picasso.jpg 和 dance.jpg 。 下载这两个图像并将它们添加到当前工作目录中名称为images的目录中。 # desired size of the output image imsize = 512 if torch.cuda.is_available() else 128 # use small size if no gpu loader = transforms.Compose([ transforms.Resize(imsize), # scale imported image transforms.ToTensor()]) # transform it into a torch tensor def image_loader(image_name): image = Image.open(image_name) # fake batch dimension required to fit network's input dimensions image = loader(image).unsqueeze(0) return image.to(device, torch.float) style_img = image_loader(\"./daimg/neural-style/picasso.jpg\") content_img = image_loader(\"./daimg/neural-style/dancing.jpg\") assert style_img.size() == content_img.size(), \\ \"we need to import style and content images of the same size\" 现在，让我们创建一个显示图像的功能，方法是将图像的副本转换为 PIL 格式，然后使用plt.imshow显示该副本。 我们将尝试显示内容和样式图像，以确保正确导入它们。 unloader = transforms.ToPILImage() # reconvert into PIL image plt.ion() def imshow(tensor, title=None): image = tensor.cpu().clone() # we clone the tensor to not do changes on it image = image.squeeze(0) # remove the fake batch dimension image = unloader(image) plt.imshow(image) if title is not None: plt.title(title) plt.pause(0.001) # pause a bit so that plots are updated plt.figure() imshow(style_img, title='Style Image') plt.figure() imshow(content_img, title='Content Image') 损失函数 内容损失 内容损失是代表单个图层内容距离的加权版本的函数。 该功能获取网络处理输入中层的特征图，并返回图像和内容图像之间的加权内容距离。 为了计算内容距离，该功能必须知道内容图像的特征图(）。 我们将此功能实现为炬管模块，并使用以作为输入的构造函数。 距离是两组特征图之间的均方误差，可以使用nn.MSELoss进行计算。 我们将直接在用于计算内容距离的卷积层之后添加此内容丢失模块。 这样，每次向网络馈入输入图像时，都会在所需层上计算内容损失，并且由于自动渐变，将计算所有梯度。 现在，为了使内容丢失层透明，我们必须定义一种forward方法，该方法计算内容丢失，然后返回该层的输入。 计算出的损耗将保存为模块的参数。 class ContentLoss(nn.Module): def __init__(self, target,): super(ContentLoss, self).__init__() # we 'detach' the target content from the tree used # to dynamically compute the gradient: this is a stated value, # not a variable. Otherwise the forward method of the criterion # will throw an error. self.target = target.detach() def forward(self, input): self.loss = F.mse_loss(input, self.target) return input Note 重要细节：尽管此模块名为ContentLoss，但它不是真正的 PyTorch Loss 函数。 如果要将内容损失定义为 PyTorch 损失函数，则必须创建一个 PyTorch autograd 函数以使用backward方法手动重新计算/实现渐变。 风格损失 样式丢失模块的实现类似于内容丢失模块。 在网络中它将充当透明层，计算该层的样式损失。 为了计算样式损失，我们需要计算语法矩阵。 gram 矩阵是给定矩阵与其转置矩阵相乘的结果。 在此应用程序中，给定的矩阵是图层的特征图的重塑版本。 被重塑以形成， x 矩阵，其中是第层特征图的数量，是任何矢量化特征图的长度 ]。 例如，的第一行对应于第一矢量化特征图。 最后，必须通过将每个元素除以矩阵中元素的总数来对 gram 矩阵进行归一化。 此归一化是为了抵消尺寸较大的矩阵在 Gram 矩阵中产生较大值的事实。 这些较大的值将导致第一层(在合并池之前）在梯度下降期间具有较大的影响。 样式特征往往位于网络的更深层，因此此标准化步骤至关重要。 def gram_matrix(input): a, b, c, d = input.size() # a=batch size(=1) # b=number of feature maps # (c,d)=dimensions of a f. map (N=c*d) features = input.view(a * b, c * d) # resise F_XL into \\hat F_XL G = torch.mm(features, features.t()) # compute the gram product # we 'normalize' the values of the gram matrix # by dividing by the number of element in each feature maps. return G.div(a * b * c * d) 现在，样式丢失模块看起来几乎与内容丢失模块完全一样。 还使用和之间的均方误差来计算样式距离。 class StyleLoss(nn.Module): def __init__(self, target_feature): super(StyleLoss, self).__init__() self.target = gram_matrix(target_feature).detach() def forward(self, input): G = gram_matrix(input) self.loss = F.mse_loss(G, self.target) return input 导入模型 现在我们需要导入一个预训练的神经网络。 我们将使用 19 层 VGG 网络，就像本文中使用的那样。 PyTorch 的 VGG 实现是一个模块，分为两个子Sequential模块：features(包含卷积和池化层）和classifier(包含完全连接的层）。 我们将使用features模块，因为我们需要各个卷积层的输出来测量内容和样式损失。 某些层在训练期间的行为与评估不同，因此我们必须使用.eval()将网络设置为评估模式。 cnn = models.vgg19(pretrained=True).features.to(device).eval() 另外，在图像上训练 VGG 网络，每个通道的均值通过均值= [0.485，0.456，0.406]和 std = [0.229，0.224，0.225]归一化。 在将其发送到网络之前，我们将使用它们对图像进行规范化。 cnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device) cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device) # create a module to normalize input image so we can easily put it in a # nn.Sequential class Normalization(nn.Module): def __init__(self, mean, std): super(Normalization, self).__init__() # .view the mean and std to make them [C x 1 x 1] so that they can # directly work with image Tensor of shape [B x C x H x W]. # B is batch size. C is number of channels. H is height and W is width. self.mean = torch.tensor(mean).view(-1, 1, 1) self.std = torch.tensor(std).view(-1, 1, 1) def forward(self, img): # normalize img return (img - self.mean) / self.std Sequential模块包含子模块的有序列表。 例如，vgg19.features包含以正确的深度顺序排列的序列(Conv2d，ReLU，MaxPool2d，Conv2d，ReLU…）。 我们需要在检测到的卷积层之后立即添加内容丢失层和样式丢失层。 为此，我们必须创建一个新的Sequential模块，该模块具有正确插入的内容丢失和样式丢失模块。 # desired depth layers to compute style/content losses : content_layers_default = ['conv_4'] style_layers_default = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5'] def get_style_model_and_losses(cnn, normalization_mean, normalization_std, style_img, content_img, content_layers=content_layers_default, style_layers=style_layers_default): cnn = copy.deepcopy(cnn) # normalization module normalization = Normalization(normalization_mean, normalization_std).to(device) # just in order to have an iterable access to or list of content/syle # losses content_losses = [] style_losses = [] # assuming that cnn is a nn.Sequential, so we make a new nn.Sequential # to put in modules that are supposed to be activated sequentially model = nn.Sequential(normalization) i = 0 # increment every time we see a conv for layer in cnn.children(): if isinstance(layer, nn.Conv2d): i += 1 name = 'conv_{}'.format(i) elif isinstance(layer, nn.ReLU): name = 'relu_{}'.format(i) # The in-place version doesn't play very nicely with the ContentLoss # and StyleLoss we insert below. So we replace with out-of-place # ones here. layer = nn.ReLU(inplace=False) elif isinstance(layer, nn.MaxPool2d): name = 'pool_{}'.format(i) elif isinstance(layer, nn.BatchNorm2d): name = 'bn_{}'.format(i) else: raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__)) model.add_module(name, layer) if name in content_layers: # add content loss: target = model(content_img).detach() content_loss = ContentLoss(target) model.add_module(\"content_loss_{}\".format(i), content_loss) content_losses.append(content_loss) if name in style_layers: # add style loss: target_feature = model(style_img).detach() style_loss = StyleLoss(target_feature) model.add_module(\"style_loss_{}\".format(i), style_loss) style_losses.append(style_loss) # now we trim off the layers after the last content and style losses for i in range(len(model) - 1, -1, -1): if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss): break model = model[:(i + 1)] return model, style_losses, content_losses 接下来，我们选择输入图像。 您可以使用内容图像或白噪声的副本。 input_img = content_img.clone() # if you want to use white noise instead uncomment the below line: # input_img = torch.randn(content_img.data.size(), device=device) # add the original input image to the figure: plt.figure() imshow(input_img, title='Input Image') 梯度下降 正如算法作者 Leon Gatys 在此处建议一样，我们将使用 L-BFGS 算法来运行梯度下降。 与训练网络不同，我们希望训练输入图像，以最大程度地减少内容/样式损失。 我们将创建一个 PyTorch L-BFGS 优化器optim.LBFGS，并将图像作为张量传递给它进行优化。 def get_input_optimizer(input_img): # this line to show that input is a parameter that requires a gradient optimizer = optim.LBFGS([input_img.requires_grad_()]) return optimizer 最后，我们必须定义一个执行神经传递的函数。 对于网络的每次迭代，它都会被提供更新的输入并计算新的损耗。 我们将运行每个损失模块的backward方法来动态计算其梯度。 优化器需要“关闭”功能，该功能可以重新评估模数并返回损耗。 我们还有最后一个约束要解决。 网络可能会尝试使用超出图像的 0 到 1 张量范围的值来优化输入。 我们可以通过在每次网络运行时将输入值校正为 0 到 1 之间来解决此问题。 def run_style_transfer(cnn, normalization_mean, normalization_std, content_img, style_img, input_img, num_steps=300, style_weight=1000000, content_weight=1): \"\"\"Run the style transfer.\"\"\" print('Building the style transfer model..') model, style_losses, content_losses = get_style_model_and_losses(cnn, normalization_mean, normalization_std, style_img, content_img) optimizer = get_input_optimizer(input_img) print('Optimizing..') run = [0] while run[0] 最后，我们可以运行算法。 output = run_style_transfer(cnn, cnn_normalization_mean, cnn_normalization_std, content_img, style_img, input_img) plt.figure() imshow(output, title='Output Image') # sphinx_gallery_thumbnail_number = 4 plt.ioff() plt.show() 出： Building the style transfer model.. Optimizing.. run [50]: Style Loss : 4.169305 Content Loss: 4.235329 run [100]: Style Loss : 1.145476 Content Loss: 3.039176 run [150]: Style Loss : 0.716769 Content Loss: 2.663749 run [200]: Style Loss : 0.476047 Content Loss: 2.500893 run [250]: Style Loss : 0.347092 Content Loss: 2.410895 run [300]: Style Loss : 0.263698 Content Loss: 2.358449 脚本的总运行时间：(1 分钟 20.670 秒） Download Python source code: neural_style_tutorial.py Download Jupyter notebook: neural_style_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"12.html":{"url":"12.html","title":"对抗示例生成","keywords":"","body":"对抗示例生成 原文： https://pytorch.org/tutorials/beginner/fgsm_tutorial.html 注意 单击此处的下载完整的示例代码 作者： Nathan Inkawhich 如果您正在阅读本文，希望您能体会到某些机器学习模型的有效性。 研究不断推动 ML 模型更快，更准确和更高效。 但是，设计和训练模型的一个经常被忽略的方面是安全性和鲁棒性，尤其是在面对想要欺骗模型的对手的情况下。 本教程将提高您对 ML 模型的安全漏洞的认识，并深入了解对抗性机器学习的热门话题。 您可能会惊讶地发现，在图像上添加无法察觉的扰动会导致导致完全不同的模型性能。 鉴于这是一个教程，我们将通过图像分类器上的示例来探讨该主题。 具体来说，我们将使用第一种也是最流行的攻击方法之一，即快速梯度符号攻击(FGSM）来欺骗 MNIST 分类器。 威胁模型 就上下文而言，有多种类型的对抗性攻击，每种攻击者的目标和假设都不同。 但是，总的来说，总体目标是向输入数据添加最少的扰动，以引起所需的错误分类。 攻击者的知识有几种假设，其中两种是：白盒和黑盒。 白盒攻击假定攻击者具有完整的知识并可以访问模型，包括体系结构，输入，输出和权重。 黑盒攻击假定攻击者仅有权访问模型的输入和输出，并且对底层体系结构或权重一无所知。 目标也有几种类型，包括错误分类和源/目标错误分类。 错误分类的目标是，这意味着对手只希望输出分类错误，而不在乎新分类是什么。 源/目标错误分类意味着对手想要更改最初属于特定源类别的图像，以便将其分类为特定目标类别。 在这种情况下，FGSM 攻击是白盒攻击，目标是错误分类。 有了这些背景信息，我们现在就可以详细讨论攻击了。 快速梯度符号攻击 迄今为止，最早的也是最流行的对抗性攻击之一称为快速梯度符号攻击(FGSM），由 Goodfellow 等描述。 等 中的解释和利用对抗性示例。 攻击非常强大，而且直观。 它旨在利用神经网络的学习方式梯度来攻击神经网络。 这个想法很简单，不是通过基于反向传播的梯度来调整权重来使损失最小化，攻击会基于相同的反向传播的梯度来调整输入数据以使损失最大化。 换句话说，攻击使用损失了输入数据的梯度，然后调整输入数据以使损失最大化。 在进入代码之前，让我们看一下著名的 FGSM 熊猫示例，并提取一些符号。 从图中可以看出，是正确分类为“熊猫”的原始输入图像，是的地面真实标签，代表模型参数，是损失，即 用于训练网络。 攻击将梯度反向传播回输入数据以计算。 然后，它会在使损失最大化的方向(即）上以小步长(图片中的或）调整输入数据。 当目标网络仍然明显是“熊猫”时，目标网络将由此产生的扰动图像误分类为为“长臂猿”。 希望本教程的动机已经明确，所以让我们跳入实施过程。 from __future__ import print_function import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim from torchvision import datasets, transforms import numpy as np import matplotlib.pyplot as plt 实作 在本节中，我们将讨论本教程的输入参数，定义受攻击的模型，然后编写攻击代码并运行一些测试。 输入项 本教程只有三个输入，定义如下： epsilons -用于运行的 epsilon 值列表。 在列表中保留 0 很重要，因为它表示原始测试集上的模型性能。 同样，从直觉上讲，我们期望ε越大，扰动越明显，但是从降低模型准确性的角度来看，攻击越有效。 由于此处的数据范围是，因此 epsilon 值不得超过 1。 pretrained_model -使用 pytorch / examples / mnist 训练的预训练 MNIST 模型的路径。 为简单起见，请在此处下载预训练模型。 use_cuda -布尔标志，如果需要和可用，则使用 CUDA。 请注意，具有 CUDA 的 GPU 在本教程中并不重要，因为 CPU 不会花费很多时间。 epsilons = [0, .05, .1, .15, .2, .25, .3] pretrained_model = \"data/lenet_mnist_model.pth\" use_cuda=True 受到攻击的模型 如前所述，受到攻击的模型与 pytorch / examples / mnist 中的 MNIST 模型相同。 您可以训练并保存自己的 MNIST 模型，也可以下载并使用提供的模型。 这里的网络定义和测试数据加载器已从 MNIST 示例中复制而来。 本部分的目的是定义模型和数据加载器，然后初始化模型并加载预训练的权重。 # LeNet Model definition class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(1, 10, kernel_size=5) self.conv2 = nn.Conv2d(10, 20, kernel_size=5) self.conv2_drop = nn.Dropout2d() self.fc1 = nn.Linear(320, 50) self.fc2 = nn.Linear(50, 10) def forward(self, x): x = F.relu(F.max_pool2d(self.conv1(x), 2)) x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2)) x = x.view(-1, 320) x = F.relu(self.fc1(x)) x = F.dropout(x, training=self.training) x = self.fc2(x) return F.log_softmax(x, dim=1) # MNIST Test dataset and dataloader declaration test_loader = torch.utils.data.DataLoader( datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([ transforms.ToTensor(), ])), batch_size=1, shuffle=True) # Define what device we are using print(\"CUDA Available: \",torch.cuda.is_available()) device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\") # Initialize the network model = Net().to(device) # Load the pretrained model model.load_state_dict(torch.load(pretrained_model, map_location='cpu')) # Set the model in evaluation mode. In this case this is for the Dropout layers model.eval() 出： Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw Processing... Done! CUDA Available: True FGSM 攻击 现在，我们可以通过干扰原始输入来定义创建对抗示例的函数。 fgsm_attack函数接受三个输入，图像是原始的干净图像(）， epsilon 是像素级扰动量(），以及[HTG7 data_grad 是输入图像(）的损耗的梯度。 该函数然后创建扰动图像为 最后，为了维持数据的原始范围，将被摄动的图像裁剪为范围。 # FGSM attack code def fgsm_attack(image, epsilon, data_grad): # Collect the element-wise sign of the data gradient sign_data_grad = data_grad.sign() # Create the perturbed image by adjusting each pixel of the input image perturbed_image = image + epsilon*sign_data_grad # Adding clipping to maintain [0,1] range perturbed_image = torch.clamp(perturbed_image, 0, 1) # Return the perturbed image return perturbed_image 测试功能 最后，本教程的主要结果来自test函数。 每次调用此测试功能都会在 MNIST 测试集中执行完整的测试步骤，并报告最终精度。 但是，请注意，此功能还需要 epsilon 输入。 这是因为test函数报告了具有强度的对手所攻击的模型的准确性。 更具体地说，对于测试集中的每个样本，该函数都会计算输入数据(）的损耗梯度，使用fgsm_attack(）创建一个扰动图像，然后检查是否受到扰动 例子是对抗性的。 除了测试模型的准确性外，该功能还保存并返回了一些成功的对抗示例，以供以后可视化。 def test( model, device, test_loader, epsilon ): # Accuracy counter correct = 0 adv_examples = [] # Loop over all examples in test set for data, target in test_loader: # Send the data and label to the device data, target = data.to(device), target.to(device) # Set requires_grad attribute of tensor. Important for Attack data.requires_grad = True # Forward pass the data through the model output = model(data) init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability # If the initial prediction is wrong, dont bother attacking, just move on if init_pred.item() != target.item(): continue # Calculate the loss loss = F.nll_loss(output, target) # Zero all existing gradients model.zero_grad() # Calculate gradients of model in backward pass loss.backward() # Collect datagrad data_grad = data.grad.data # Call FGSM Attack perturbed_data = fgsm_attack(data, epsilon, data_grad) # Re-classify the perturbed image output = model(perturbed_data) # Check for success final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability if final_pred.item() == target.item(): correct += 1 # Special case for saving 0 epsilon examples if (epsilon == 0) and (len(adv_examples) 奔跑攻击 实现的最后一部分是实际运行攻击。 在这里，我们为 epsilons 输入中的每个 epsilon 值运行完整的测试步骤。 对于每个 epsilon，我们还将保存最终精度，并在接下来的部分中绘制一些成功的对抗示例。 请注意，随着ε值的增加，打印的精度如何降低。 另外，请注意的情况代表了原始的测试准确性，没有受到攻击。 accuracies = [] examples = [] # Run test for each epsilon for eps in epsilons: acc, ex = test(model, device, test_loader, eps) accuracies.append(acc) examples.append(ex) Out: Epsilon: 0 Test Accuracy = 9810 / 10000 = 0.981 Epsilon: 0.05 Test Accuracy = 9426 / 10000 = 0.9426 Epsilon: 0.1 Test Accuracy = 8510 / 10000 = 0.851 Epsilon: 0.15 Test Accuracy = 6826 / 10000 = 0.6826 Epsilon: 0.2 Test Accuracy = 4301 / 10000 = 0.4301 Epsilon: 0.25 Test Accuracy = 2082 / 10000 = 0.2082 Epsilon: 0.3 Test Accuracy = 869 / 10000 = 0.0869 结果 精度与 Epsilon 第一个结果是精度与ε曲线的关系。 如前所述，随着ε的增加，我们期望测试精度会降低。 这是因为较大的ε意味着我们朝着将损失最大化的方向迈出了更大的一步。 请注意，即使 epsilon 值是线性间隔的，曲线中的趋势也不是线性的。 例如，在处的精度仅比低约 4％，但在处的精度比低 25％。 另外，请注意，对于和之间的 10 类分类器，模型的准确性达到了随机准确性。 plt.figure(figsize=(5,5)) plt.plot(epsilons, accuracies, \"*-\") plt.yticks(np.arange(0, 1.1, step=0.1)) plt.xticks(np.arange(0, .35, step=0.05)) plt.title(\"Accuracy vs Epsilon\") plt.xlabel(\"Epsilon\") plt.ylabel(\"Accuracy\") plt.show() 对抗示例 还记得没有免费午餐的想法吗？ 在这种情况下，随着ε的增加，测试精度降低，但的扰动变得更容易察觉。 实际上，在攻击者必须考虑的准确性下降和可感知性之间要进行权衡。 在这里，我们展示了每个 epsilon 值的成功对抗示例。 绘图的每一行显示不同的ε值。 第一行是示例，代表原始的“干净”图像，没有干扰。 每张图像的标题均显示“原始分类->对抗分类”。 注意，扰动开始在变得明显，并且在变得非常明显。 然而，在所有情况下，尽管噪声增加，人类仍然能够识别正确的类别。 # Plot several examples of adversarial samples at each epsilon cnt = 0 plt.figure(figsize=(8,10)) for i in range(len(epsilons)): for j in range(len(examples[i])): cnt += 1 plt.subplot(len(epsilons),len(examples[0]),cnt) plt.xticks([], []) plt.yticks([], []) if j == 0: plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14) orig,adv,ex = examples[i][j] plt.title(\"{} -> {}\".format(orig, adv)) plt.imshow(ex, cmap=\"gray\") plt.tight_layout() plt.show() 接下来要去哪里？ 希望本教程对对抗性机器学习主题有所了解。 从这里可以找到许多潜在的方向。 这种攻击代表了对抗性攻击研究的最开始，并且由于随后有许多关于如何攻击和防御来自对手的 ML 模型的想法。 实际上，在 NIPS 2017 上有一个对抗性的攻击和防御竞赛，并且本文描述了该竞赛中使用的许多方法：对抗性的攻击与防御竞赛。 国防方面的工作还引发了使机器学习模型总体上更健壮健壮的想法，以适应自然扰动和对抗制造的输入。 另一个方向是不同领域的对抗性攻击和防御。 对抗性研究不仅限于图像领域，请查看对语音到文本模型的这种攻击。 但是，也许更多地了解对抗性机器学习的最好方法是弄脏您的手。 尝试实施与 NIPS 2017 竞赛不同的攻击，并查看其与 FGSM 的不同之处。 然后，尝试保护模型免受自己的攻击。 脚本的总运行时间：(3 分钟 14.922 秒） Download Python source code: fgsm_tutorial.py Download Jupyter notebook: fgsm_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:39:43 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"13.html":{"url":"13.html","title":"DCGAN 教程","keywords":"","body":"DCGAN 教程 原文： https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html 注意 单击此处的下载完整的示例代码 作者： Nathan Inkawhich 介绍 本教程将通过一个示例对 DCGAN 进行介绍。 在向其展示许多真实名人的照片后，我们将训练一个生成对抗网络(GAN）以产生新名人。 此处的大部分代码来自 pytorch / examples 中的 dcgan 实现，并且本文档将对该实现进行详尽的解释，并阐明此模型的工作方式和原因。 但是请放心，不需要 GAN 的先验知识，但这可能需要新手花一些时间来推理幕后实际发生的事情。 另外，为了节省时间，安装一两个 GPU 也将有所帮助。 让我们从头开始。 生成对抗网络 什么是 GAN？ GAN 是用于教授 DL 模型以捕获训练数据分布的框架，因此我们可以从同一分布中生成新数据。 GAN 由 Ian Goodfellow 于 2014 年发明，并首先在论文生成对抗网络中进行了描述。 它们由两个不同的模型组成：生成器和鉴别器。 生成器的工作是生成看起来像训练图像的“假”图像。 鉴别器的工作是查看图像并从生成器输出它是真实的训练图像还是伪图像。 在训练过程中，生成器不断尝试通过生成越来越好的伪造品而使鉴别器的性能超过智者，而鉴别器正在努力成为更好的侦探并正确地对真实和伪造图像进行分类。 博弈的平衡点是当生成器生成的伪造品看起来像直接来自训练数据时，而鉴别器则总是猜测生成器输出是真品还是伪造品的 50％置信度。 现在，让我们从判别器开始定义一些在整个教程中使用的符号。 令是表示图像的数据。 是鉴别器网络，其输出来自训练数据而非生成器的(标量）概率。 在这里，由于我们要处理图像，因此的输入是 CHW 大小为 3x64x64 的图像。 直观地讲，当来自训练数据时，应该为高，而当来自发生器时，则应为低。 也可以被视为传统的二进制分类器。 对于发生器的表示法，将设为从标准正态分布中采样的潜在空间矢量。 表示将潜在矢量映射到数据空间的生成器函数。 的目标是估计训练数据来自的分布(），以便它可以从该估计的分布(）中生成假样本。 因此，是发生器的输出是真实图像的概率(标量）。 如所述，Goodfellow 的论文，和玩一个 minimax 游戏，其中试图最大化其正确分类实物和假货(）的概率，而尝试 以最大程度地降低预测其输出为假的可能性(）。 从本文来看，GAN 损失函数为 从理论上讲，此 minimax 游戏的解决方案是，判别器会随机猜测输入是真实的还是假的。 但是，GAN 的收敛理论仍在积极研究中，实际上，模型并不总是能达到这一目的。 什么是 DCGAN？ DCGAN 是上述 GAN 的直接扩展，不同之处在于 DCGAN 分别在鉴别器和生成器中分别使用卷积和卷积转置层。 它最初是由 Radford 等人描述的。 等 深度卷积生成对抗网络中的无监督表示学习。 鉴别器由分层的卷积层，批处理规范层和 LeakyReLU 激活组成。 输入是 3x64x64 的输入图像，输出是输入来自真实数据分布的标量概率。 生成器由卷积转置层，批处理规范层和 ReLU 激活组成。 输入是从标准正态分布中提取的潜矢量，输出是 3x64x64 RGB 图像。 跨步的转置图层使潜矢量可以转换为与图像具有相同形状的体积。 在本文中，作者还提供了有关如何设置优化器，如何计算损失函数以及如何初始化模型权重的一些技巧，所有这些将在接下来的部分中进行解释。 from __future__ import print_function #%matplotlib inline import argparse import os import random import torch import torch.nn as nn import torch.nn.parallel import torch.backends.cudnn as cudnn import torch.optim as optim import torch.utils.data import torchvision.datasets as dset import torchvision.transforms as transforms import torchvision.utils as vutils import numpy as np import matplotlib.pyplot as plt import matplotlib.animation as animation from IPython.display import HTML # Set random seed for reproducibility manualSeed = 999 #manualSeed = random.randint(1, 10000) # use if you want new results print(\"Random Seed: \", manualSeed) random.seed(manualSeed) torch.manual_seed(manualSeed) 出： Random Seed: 999 输入项 让我们为跑步定义一些输入： dataroot -数据集文件夹根目录的路径。 我们将在下一节中进一步讨论数据集 worker -使用 DataLoader 加载数据的工作线程数 batch_size -训练中使用的批次大小。 DCGAN 纸使用的批处理大小为 128 image_size -用于训练的图像的空间大小。 此实现默认为 64x64。 如果需要其他尺寸，则必须更改 D 和 G 的结构。 有关更多详细信息，请参见此处的。 nc -输入图像中的颜色通道数。 对于彩色图像，这是 3 nz -潜矢量的长度 ngf -与通过生成器传送的特征图的深度有关 ndf -设置通过鉴别器传播的特征图的深度 num_epochs -要运行的训练时期数。 训练更长的时间可能会导致更好的结果，但也会花费更长的时间 lr -训练的学习率。 如 DCGAN 文件中所述，此数字应为 0.0002 beta1 -Adam 优化器的 beta1 超参数。 如论文所述，该数字应为 0.5 ngpu -可用的 GPU 数量。 如果为 0，代码将在 CPU 模式下运行。 如果此数字大于 0，它将在该数量的 GPU 上运行 # Root directory for dataset dataroot = \"data/celeba\" # Number of workers for dataloader workers = 2 # Batch size during training batch_size = 128 # Spatial size of training images. All images will be resized to this # size using a transformer. image_size = 64 # Number of channels in the training images. For color images this is 3 nc = 3 # Size of z latent vector (i.e. size of generator input) nz = 100 # Size of feature maps in generator ngf = 64 # Size of feature maps in discriminator ndf = 64 # Number of training epochs num_epochs = 5 # Learning rate for optimizers lr = 0.0002 # Beta1 hyperparam for Adam optimizers beta1 = 0.5 # Number of GPUs available. Use 0 for CPU mode. ngpu = 1 数据 在本教程中，我们将使用 Celeb-A Faces 数据集，该数据集可在链接的站点或 Google 云端硬盘中下载。 数据集将下载为名为 img_align_celeba.zip 的文件。 下载完成后，创建一个名为 celeba 的目录，并将 zip 文件解压缩到该目录中。 然后，将此笔记本的数据根输入设置为刚创建的 celeba 目录。 结果目录结构应为： /path/to/celeba -> img_align_celeba -> 188242.jpg -> 173822.jpg -> 284702.jpg -> 537394.jpg ... 这是重要的一步，因为我们将使用 ImageFolder 数据集类，该类要求数据集的根文件夹中有子目录。 现在，我们可以创建数据集，创建数据加载器，将设备设置为可以运行，最后可视化一些训练数据。 # We can use an image folder dataset the way we have it setup. # Create the dataset dataset = dset.ImageFolder(root=dataroot, transform=transforms.Compose([ transforms.Resize(image_size), transforms.CenterCrop(image_size), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), ])) # Create the dataloader dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=workers) # Decide which device we want to run on device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\") # Plot some training images real_batch = next(iter(dataloader)) plt.figure(figsize=(8,8)) plt.axis(\"off\") plt.title(\"Training Images\") plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0))) 实作 设置好输入参数并准备好数据集后，我们现在可以进入实现了。 我们将从 Weigth 初始化策略开始，然后详细讨论生成器，鉴别器，损失函数和训练循环。 重量初始化 从 DCGAN 论文中，作者指定所有模型权重均应从均值= 0，stdev = 0.02 的正态分布中随机初始化。 weights_init函数采用已初始化的模型作为输入，并重新初始化所有卷积，卷积转置和批处理归一化层，以满足该标准。 初始化后立即将此功能应用于模型。 # custom weights initialization called on netG and netD def weights_init(m): classname = m.__class__.__name__ if classname.find('Conv') != -1: nn.init.normal_(m.weight.data, 0.0, 0.02) elif classname.find('BatchNorm') != -1: nn.init.normal_(m.weight.data, 1.0, 0.02) nn.init.constant_(m.bias.data, 0) 发电机 生成器旨在将潜在空间矢量(）映射到数据空间。 由于我们的数据是图像，因此将转换为数据空间意味着最终创建与训练图像大小相同的 RGB 图像(即 3x64x64）。 在实践中，这是通过一系列跨步的二维卷积转置层来完成的，每个层都与 2d 批处理规范层和 relu 激活配对。 生成器的输出通过 tanh 函数进行馈送，以使其返回到的输入数据范围。 值得注意的是，在卷积转置层之后存在批处理规范函数，因为这是 DCGAN 论文的关键贡献。 这些层有助于训练过程中的梯度流动。 DCGAN 纸生成的图像如下所示。 注意，我们在输入部分中设置的输入 (nz ， ngf 和 nc )如何影响代码中的生成器体系结构。 nz 是 z 输入向量的长度， ngf 与通过生成器传播的特征图的大小有关， nc 是 输出图像中的通道(对于 RGB 图像设置为 3）。 下面是生成器的代码。 # Generator Code class Generator(nn.Module): def __init__(self, ngpu): super(Generator, self).__init__() self.ngpu = ngpu self.main = nn.Sequential( # input is Z, going into a convolution nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False), nn.BatchNorm2d(ngf * 8), nn.ReLU(True), # state size. (ngf*8) x 4 x 4 nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False), nn.BatchNorm2d(ngf * 4), nn.ReLU(True), # state size. (ngf*4) x 8 x 8 nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d(ngf * 2), nn.ReLU(True), # state size. (ngf*2) x 16 x 16 nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False), nn.BatchNorm2d(ngf), nn.ReLU(True), # state size. (ngf) x 32 x 32 nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False), nn.Tanh() # state size. (nc) x 64 x 64 ) def forward(self, input): return self.main(input) 现在，我们可以实例化生成器并应用weights_init函数。 签出打印的模型以查看生成器对象的结构。 # Create the generator netG = Generator(ngpu).to(device) # Handle multi-gpu if desired if (device.type == 'cuda') and (ngpu > 1): netG = nn.DataParallel(netG, list(range(ngpu))) # Apply the weights_init function to randomly initialize all weights # to mean=0, stdev=0.2. netG.apply(weights_init) # Print the model print(netG) Out: Generator( (main): Sequential( (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (5): ReLU(inplace=True) (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (8): ReLU(inplace=True) (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (11): ReLU(inplace=True) (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (13): Tanh() ) ) 鉴别器 如前所述，鉴别符是一个二进制分类网络，该二进制分类网络将图像作为输入并输出输入图像是真实的(与假的相对）的标量概率。 在这里，拍摄 3x64x64 的输入图像，通过一系列的 Conv2d，BatchNorm2d 和 LeakyReLU 层对其进行处理，然后通过 Sigmoid 激活函数输出最终概率。 如果需要解决此问题，可以用更多层扩展此体系结构，但是使用跨步卷积，BatchNorm 和 LeakyReLUs 具有重要意义。 DCGAN 论文提到，使用跨步卷积而不是合并以进行下采样是一个好习惯，因为它可以让网络学习自己的合并功能。 批处理规范和泄漏的 relu 函数还可以促进健康的梯度流，这对于和的学习过程都是至关重要的。 鉴别码 class Discriminator(nn.Module): def __init__(self, ngpu): super(Discriminator, self).__init__() self.ngpu = ngpu self.main = nn.Sequential( # input is (nc) x 64 x 64 nn.Conv2d(nc, ndf, 4, 2, 1, bias=False), nn.LeakyReLU(0.2, inplace=True), # state size. (ndf) x 32 x 32 nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d(ndf * 2), nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*2) x 16 x 16 nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False), nn.BatchNorm2d(ndf * 4), nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*4) x 8 x 8 nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False), nn.BatchNorm2d(ndf * 8), nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*8) x 4 x 4 nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False), nn.Sigmoid() ) def forward(self, input): return self.main(input) 现在，与生成器一样，我们可以创建鉴别器，应用weights_init函数，并打印模型的结构。 # Create the Discriminator netD = Discriminator(ngpu).to(device) # Handle multi-gpu if desired if (device.type == 'cuda') and (ngpu > 1): netD = nn.DataParallel(netD, list(range(ngpu))) # Apply the weights_init function to randomly initialize all weights # to mean=0, stdev=0.2. netD.apply(weights_init) # Print the model print(netD) Out: Discriminator( (main): Sequential( (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (1): LeakyReLU(negative_slope=0.2, inplace=True) (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (4): LeakyReLU(negative_slope=0.2, inplace=True) (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (7): LeakyReLU(negative_slope=0.2, inplace=True) (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (10): LeakyReLU(negative_slope=0.2, inplace=True) (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False) (12): Sigmoid() ) ) 损失函数和优化器 通过和设置，我们可以指定它们如何通过损失函数和优化器学习。 我们将使用在 PyTorch 中定义的二进制交叉熵损失 (BCELoss)函数： 请注意，此函数如何提供目标函数(即和）中两个日志分量的计算。 我们可以指定[CEG2]输入要使用 BCE 公式的哪一部分。 这是在即将到来的训练循环中完成的，但重要的是要了解我们如何仅通过更改(即 GT 标签）就可以选择想要计算的组件。 接下来，我们将实际标签定义为 1，将假标签定义为 0。这些标签将在计算和的损耗时使用，这也是 GAN 原始文件中使用的惯例。 最后，我们设置了两个单独的优化器，一个用于，一个用于。 如 DCGAN 论文中所述，这两个都是 Adam 优化器，学习率均为 0.0002，Beta1 = 0.5。 为了跟踪生成器的学习进度，我们将生成一批固定的潜在矢量，这些矢量是从高斯分布(即 fixed_noise）中提取的。 在训练循环中，我们将定期将此 fixed_noise 输入到中，并且在迭代过程中，我们将看到图像形成于噪声之外。 # Initialize BCELoss function criterion = nn.BCELoss() # Create batch of latent vectors that we will use to visualize # the progression of the generator fixed_noise = torch.randn(64, nz, 1, 1, device=device) # Establish convention for real and fake labels during training real_label = 1 fake_label = 0 # Setup Adam optimizers for both G and D optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999)) optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999)) 训练 最后，既然我们已经定义了 GAN 框架的所有部分，我们就可以对其进行训练。 请注意，训练 GAN 某种程度上是一种艺术形式，因为不正确的超参数设置会导致模式崩溃，而对失败的原因几乎没有解释。 在这里，我们将严格遵循 Goodfellow 论文中的算法 1，同时遵守 ganhacks 中显示的一些最佳做法。 即，我们将“为真实和伪造构建不同的小批量”图像，并调整 G 的目标函数以最大化。 训练分为两个主要部分。 第 1 部分更新了鉴别器，第 2 部分更新了生成器。 第 1 部分-训练鉴别器 回想一下，训练鉴别器的目的是最大程度地提高将给定输入正确分类为真实或伪造的可能性。 关于古德费罗，我们希望“通过提高随机梯度来更新鉴别器”。 实际上，我们要最大化。 由于 ganhacks 提出了单独的小批量建议，因此我们将分两步进行计算。 首先，我们将从训练集中构造一批真实样本，向前通过，计算损失(），然后在向后通过中计算梯度。 其次，我们将使用电流发生器构造一批假样本，将这批样本通过正向传递，计算损失(），然后向后传递累积梯度。 现在，利用从所有真实批次和所有伪批次累积的渐变，我们将其称为“鉴别器”优化器的一个步骤。 第 2 部分-训练发电机 如原始论文所述，我们希望通过最小化来训练 Generator，以产生更好的假货。 如前所述，Goodfellow 指出这不能提供足够的梯度，尤其是在学习过程的早期。 作为解决方法，我们改为希望最大化。 在代码中，我们通过以下步骤来实现此目的：将第 1 部分的 Generator 输出与 Discriminator 进行分类，使用实数标签 GT 计算 G 的损耗，反向计算 G 的梯度，最后使用优化器更新 G 的参数 步。 将真实标签用作损失函数的 GT 标签似乎违反直觉，但这使我们可以使用 BCELoss 的部分(而不是部分），这正是我们想要的。 最后，我们将进行一些统计报告，并在每个时期结束时，将我们的 fixed_noise 批次推入生成器，以直观地跟踪 G 的训练进度。 报告的训练统计数据是： Loss_D -鉴别器损失，计算为所有真实批次和所有假批次的损失总和(）。 Loss_G -发电机损耗计算为 D(x）-所有真实批次的鉴别器的平均输出(整个批次）。 这应该从接近 1 开始，然后在 G 变得更好时理论上收敛到 0.5。 想想这是为什么。 D(G(z））-所有假批次的平均鉴别器输出。 第一个数字在 D 更新之前，第二个数字在 D 更新之后。 这些数字应从 0 开始，并随着 G 的提高收敛到 0.5。 想想这是为什么。 注意：此步骤可能需要一段时间，具体取决于您运行了多少个时期以及是否从数据集中删除了一些数据。 # Training Loop # Lists to keep track of progress img_list = [] G_losses = [] D_losses = [] iters = 0 print(\"Starting Training Loop...\") # For each epoch for epoch in range(num_epochs): # For each batch in the dataloader for i, data in enumerate(dataloader, 0): ############################ # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z))) ########################### ## Train with all-real batch netD.zero_grad() # Format batch real_cpu = data[0].to(device) b_size = real_cpu.size(0) label = torch.full((b_size,), real_label, device=device) # Forward pass real batch through D output = netD(real_cpu).view(-1) # Calculate loss on all-real batch errD_real = criterion(output, label) # Calculate gradients for D in backward pass errD_real.backward() D_x = output.mean().item() ## Train with all-fake batch # Generate batch of latent vectors noise = torch.randn(b_size, nz, 1, 1, device=device) # Generate fake image batch with G fake = netG(noise) label.fill_(fake_label) # Classify all fake batch with D output = netD(fake.detach()).view(-1) # Calculate D's loss on the all-fake batch errD_fake = criterion(output, label) # Calculate the gradients for this batch errD_fake.backward() D_G_z1 = output.mean().item() # Add the gradients from the all-real and all-fake batches errD = errD_real + errD_fake # Update D optimizerD.step() ############################ # (2) Update G network: maximize log(D(G(z))) ########################### netG.zero_grad() label.fill_(real_label) # fake labels are real for generator cost # Since we just updated D, perform another forward pass of all-fake batch through D output = netD(fake).view(-1) # Calculate G's loss based on this output errG = criterion(output, label) # Calculate gradients for G errG.backward() D_G_z2 = output.mean().item() # Update G optimizerG.step() # Output training stats if i % 50 == 0: print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f' % (epoch, num_epochs, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2)) # Save Losses for plotting later G_losses.append(errG.item()) D_losses.append(errD.item()) # Check how the generator is doing by saving G's output on fixed_noise if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)): with torch.no_grad(): fake = netG(fixed_noise).detach().cpu() img_list.append(vutils.make_grid(fake, padding=2, normalize=True)) iters += 1 Out: Starting Training Loop... [0/5][0/1583] Loss_D: 2.0937 Loss_G: 5.2060 D(x): 0.5704 D(G(z)): 0.6680 / 0.0090 [0/5][50/1583] Loss_D: 0.2073 Loss_G: 12.9653 D(x): 0.9337 D(G(z)): 0.0000 / 0.0000 [0/5][100/1583] Loss_D: 0.0364 Loss_G: 34.5761 D(x): 0.9917 D(G(z)): 0.0000 / 0.0000 [0/5][150/1583] Loss_D: 0.0078 Loss_G: 39.3111 D(x): 0.9947 D(G(z)): 0.0000 / 0.0000 [0/5][200/1583] Loss_D: 0.0029 Loss_G: 38.7681 D(x): 0.9974 D(G(z)): 0.0000 / 0.0000 [0/5][250/1583] Loss_D: 1.2861 Loss_G: 13.3356 D(x): 0.8851 D(G(z)): 0.2970 / 0.0035 [0/5][300/1583] Loss_D: 1.2933 Loss_G: 6.7655 D(x): 0.8533 D(G(z)): 0.5591 / 0.0020 [0/5][350/1583] Loss_D: 0.7473 Loss_G: 3.2617 D(x): 0.5798 D(G(z)): 0.0514 / 0.0483 [0/5][400/1583] Loss_D: 0.5454 Loss_G: 4.0144 D(x): 0.8082 D(G(z)): 0.2346 / 0.0310 [0/5][450/1583] Loss_D: 1.1872 Loss_G: 3.2918 D(x): 0.4389 D(G(z)): 0.0360 / 0.0858 [0/5][500/1583] Loss_D: 0.7546 Loss_G: 4.7428 D(x): 0.9072 D(G(z)): 0.4049 / 0.0178 [0/5][550/1583] Loss_D: 0.3514 Loss_G: 3.7726 D(x): 0.8937 D(G(z)): 0.1709 / 0.0394 [0/5][600/1583] Loss_D: 0.4400 Loss_G: 4.1662 D(x): 0.7768 D(G(z)): 0.1069 / 0.0284 [0/5][650/1583] Loss_D: 0.3275 Loss_G: 4.3374 D(x): 0.8452 D(G(z)): 0.0852 / 0.0214 [0/5][700/1583] Loss_D: 0.7711 Loss_G: 5.0677 D(x): 0.9103 D(G(z)): 0.3848 / 0.0190 [0/5][750/1583] Loss_D: 0.5346 Loss_G: 5.7441 D(x): 0.8971 D(G(z)): 0.2969 / 0.0064 [0/5][800/1583] Loss_D: 0.5027 Loss_G: 2.5982 D(x): 0.6897 D(G(z)): 0.0431 / 0.1196 [0/5][850/1583] Loss_D: 0.4479 Loss_G: 4.8790 D(x): 0.7407 D(G(z)): 0.0456 / 0.0200 [0/5][900/1583] Loss_D: 0.9812 Loss_G: 5.8792 D(x): 0.8895 D(G(z)): 0.4801 / 0.0070 [0/5][950/1583] Loss_D: 0.5154 Loss_G: 3.4813 D(x): 0.7722 D(G(z)): 0.1549 / 0.0449 [0/5][1000/1583] Loss_D: 0.8468 Loss_G: 6.6179 D(x): 0.8914 D(G(z)): 0.4262 / 0.0030 [0/5][1050/1583] Loss_D: 0.4425 Loss_G: 3.9902 D(x): 0.8307 D(G(z)): 0.1872 / 0.0270 [0/5][1100/1583] Loss_D: 0.6800 Loss_G: 4.3945 D(x): 0.8244 D(G(z)): 0.3022 / 0.0223 [0/5][1150/1583] Loss_D: 0.7227 Loss_G: 2.2669 D(x): 0.6177 D(G(z)): 0.0625 / 0.1613 [0/5][1200/1583] Loss_D: 0.4061 Loss_G: 5.7088 D(x): 0.9269 D(G(z)): 0.2367 / 0.0071 [0/5][1250/1583] Loss_D: 0.8514 Loss_G: 3.8994 D(x): 0.7686 D(G(z)): 0.3573 / 0.0330 [0/5][1300/1583] Loss_D: 0.5323 Loss_G: 3.0046 D(x): 0.7102 D(G(z)): 0.0742 / 0.1138 [0/5][1350/1583] Loss_D: 0.5793 Loss_G: 4.6804 D(x): 0.8722 D(G(z)): 0.2877 / 0.0169 [0/5][1400/1583] Loss_D: 0.6849 Loss_G: 5.4391 D(x): 0.8974 D(G(z)): 0.3630 / 0.0100 [0/5][1450/1583] Loss_D: 1.1515 Loss_G: 6.0096 D(x): 0.8054 D(G(z)): 0.5186 / 0.0049 [0/5][1500/1583] Loss_D: 0.4771 Loss_G: 3.3768 D(x): 0.8590 D(G(z)): 0.2357 / 0.0541 [0/5][1550/1583] Loss_D: 0.6947 Loss_G: 5.9660 D(x): 0.8989 D(G(z)): 0.3671 / 0.0064 [1/5][0/1583] Loss_D: 0.5001 Loss_G: 3.9243 D(x): 0.8238 D(G(z)): 0.2077 / 0.0377 [1/5][50/1583] Loss_D: 0.4494 Loss_G: 4.4726 D(x): 0.8514 D(G(z)): 0.2159 / 0.0187 [1/5][100/1583] Loss_D: 0.4519 Loss_G: 2.6781 D(x): 0.7331 D(G(z)): 0.0688 / 0.0948 [1/5][150/1583] Loss_D: 0.3808 Loss_G: 3.6005 D(x): 0.8827 D(G(z)): 0.1908 / 0.0456 [1/5][200/1583] Loss_D: 0.4373 Loss_G: 4.0625 D(x): 0.8281 D(G(z)): 0.1719 / 0.0306 [1/5][250/1583] Loss_D: 0.5906 Loss_G: 3.1507 D(x): 0.7603 D(G(z)): 0.1952 / 0.0682 [1/5][300/1583] Loss_D: 1.4315 Loss_G: 6.2042 D(x): 0.9535 D(G(z)): 0.6480 / 0.0051 [1/5][350/1583] Loss_D: 0.8529 Loss_G: 1.2236 D(x): 0.5291 D(G(z)): 0.0552 / 0.3978 [1/5][400/1583] Loss_D: 0.8166 Loss_G: 5.3178 D(x): 0.8460 D(G(z)): 0.3872 / 0.0104 [1/5][450/1583] Loss_D: 0.6699 Loss_G: 2.4998 D(x): 0.6921 D(G(z)): 0.1719 / 0.1220 [1/5][500/1583] Loss_D: 0.4986 Loss_G: 4.3763 D(x): 0.8835 D(G(z)): 0.2643 / 0.0212 [1/5][550/1583] Loss_D: 0.9149 Loss_G: 5.6209 D(x): 0.9476 D(G(z)): 0.5069 / 0.0088 [1/5][600/1583] Loss_D: 0.5116 Loss_G: 3.4946 D(x): 0.8368 D(G(z)): 0.2444 / 0.0488 [1/5][650/1583] Loss_D: 0.4408 Loss_G: 2.8180 D(x): 0.7795 D(G(z)): 0.1262 / 0.0926 [1/5][700/1583] Loss_D: 0.3821 Loss_G: 3.5735 D(x): 0.8237 D(G(z)): 0.1387 / 0.0432 [1/5][750/1583] Loss_D: 0.5042 Loss_G: 2.4218 D(x): 0.6897 D(G(z)): 0.0541 / 0.1319 [1/5][800/1583] Loss_D: 1.3208 Loss_G: 4.7094 D(x): 0.9466 D(G(z)): 0.5988 / 0.0158 [1/5][850/1583] Loss_D: 0.3780 Loss_G: 2.9969 D(x): 0.8475 D(G(z)): 0.1662 / 0.0648 [1/5][900/1583] Loss_D: 0.4350 Loss_G: 3.2726 D(x): 0.8306 D(G(z)): 0.1925 / 0.0531 [1/5][950/1583] Loss_D: 0.4228 Loss_G: 2.5205 D(x): 0.7438 D(G(z)): 0.0493 / 0.1090 [1/5][1000/1583] Loss_D: 0.4680 Loss_G: 4.4448 D(x): 0.8652 D(G(z)): 0.2433 / 0.0190 [1/5][1050/1583] Loss_D: 0.4261 Loss_G: 2.7076 D(x): 0.7683 D(G(z)): 0.1049 / 0.0999 [1/5][1100/1583] Loss_D: 0.5115 Loss_G: 1.9458 D(x): 0.6730 D(G(z)): 0.0449 / 0.2070 [1/5][1150/1583] Loss_D: 0.6619 Loss_G: 2.0092 D(x): 0.6320 D(G(z)): 0.1115 / 0.1926 [1/5][1200/1583] Loss_D: 0.4824 Loss_G: 2.0529 D(x): 0.7735 D(G(z)): 0.1647 / 0.1758 [1/5][1250/1583] Loss_D: 0.4529 Loss_G: 4.3564 D(x): 0.9270 D(G(z)): 0.2881 / 0.0223 [1/5][1300/1583] Loss_D: 0.5469 Loss_G: 2.5909 D(x): 0.7217 D(G(z)): 0.1403 / 0.1101 [1/5][1350/1583] Loss_D: 0.4525 Loss_G: 1.4998 D(x): 0.7336 D(G(z)): 0.0904 / 0.2715 [1/5][1400/1583] Loss_D: 0.5267 Loss_G: 2.3458 D(x): 0.7594 D(G(z)): 0.1700 / 0.1311 [1/5][1450/1583] Loss_D: 0.4700 Loss_G: 3.7640 D(x): 0.9059 D(G(z)): 0.2852 / 0.0316 [1/5][1500/1583] Loss_D: 0.7703 Loss_G: 1.4253 D(x): 0.5655 D(G(z)): 0.0683 / 0.3071 [1/5][1550/1583] Loss_D: 0.5535 Loss_G: 2.4315 D(x): 0.6773 D(G(z)): 0.0834 / 0.1280 [2/5][0/1583] Loss_D: 0.7237 Loss_G: 3.4642 D(x): 0.8383 D(G(z)): 0.3687 / 0.0442 [2/5][50/1583] Loss_D: 0.4401 Loss_G: 2.4749 D(x): 0.7939 D(G(z)): 0.1526 / 0.1107 [2/5][100/1583] Loss_D: 0.7470 Loss_G: 1.8611 D(x): 0.5830 D(G(z)): 0.0871 / 0.2102 [2/5][150/1583] Loss_D: 0.7930 Loss_G: 1.3743 D(x): 0.5201 D(G(z)): 0.0343 / 0.3171 [2/5][200/1583] Loss_D: 0.5059 Loss_G: 2.9394 D(x): 0.8044 D(G(z)): 0.2128 / 0.0739 [2/5][250/1583] Loss_D: 0.5873 Loss_G: 1.6961 D(x): 0.6329 D(G(z)): 0.0561 / 0.2297 [2/5][300/1583] Loss_D: 0.5341 Loss_G: 1.9229 D(x): 0.7022 D(G(z)): 0.1145 / 0.1921 [2/5][350/1583] Loss_D: 0.7095 Loss_G: 1.3619 D(x): 0.5855 D(G(z)): 0.0707 / 0.3038 [2/5][400/1583] Loss_D: 0.5163 Loss_G: 3.0209 D(x): 0.8695 D(G(z)): 0.2828 / 0.0657 [2/5][450/1583] Loss_D: 0.5413 Loss_G: 3.5822 D(x): 0.8450 D(G(z)): 0.2748 / 0.0387 [2/5][500/1583] Loss_D: 0.4929 Loss_G: 2.1009 D(x): 0.7645 D(G(z)): 0.1692 / 0.1552 [2/5][550/1583] Loss_D: 0.5042 Loss_G: 2.5833 D(x): 0.7047 D(G(z)): 0.0888 / 0.1107 [2/5][600/1583] Loss_D: 0.4562 Loss_G: 2.5190 D(x): 0.8316 D(G(z)): 0.2151 / 0.0987 [2/5][650/1583] Loss_D: 0.9564 Loss_G: 2.5315 D(x): 0.7157 D(G(z)): 0.3861 / 0.1153 [2/5][700/1583] Loss_D: 0.6706 Loss_G: 3.0991 D(x): 0.7382 D(G(z)): 0.2497 / 0.0603 [2/5][750/1583] Loss_D: 0.5803 Loss_G: 2.9059 D(x): 0.7523 D(G(z)): 0.2092 / 0.0785 [2/5][800/1583] Loss_D: 0.8315 Loss_G: 3.7972 D(x): 0.9184 D(G(z)): 0.4829 / 0.0325 [2/5][850/1583] Loss_D: 0.6177 Loss_G: 2.2548 D(x): 0.7526 D(G(z)): 0.2470 / 0.1306 [2/5][900/1583] Loss_D: 0.7398 Loss_G: 3.2303 D(x): 0.8604 D(G(z)): 0.3999 / 0.0572 [2/5][950/1583] Loss_D: 0.7914 Loss_G: 1.5464 D(x): 0.6001 D(G(z)): 0.1507 / 0.2605 [2/5][1000/1583] Loss_D: 0.9693 Loss_G: 4.0590 D(x): 0.9251 D(G(z)): 0.5270 / 0.0275 [2/5][1050/1583] Loss_D: 0.5805 Loss_G: 2.1703 D(x): 0.6749 D(G(z)): 0.1185 / 0.1465 [2/5][1100/1583] Loss_D: 0.8626 Loss_G: 0.9626 D(x): 0.5259 D(G(z)): 0.0865 / 0.4571 [2/5][1150/1583] Loss_D: 0.7256 Loss_G: 4.0511 D(x): 0.9135 D(G(z)): 0.4172 / 0.0300 [2/5][1200/1583] Loss_D: 0.5937 Loss_G: 3.8598 D(x): 0.8982 D(G(z)): 0.3440 / 0.0320 [2/5][1250/1583] Loss_D: 0.6144 Loss_G: 1.8087 D(x): 0.6660 D(G(z)): 0.1424 / 0.2062 [2/5][1300/1583] Loss_D: 0.8017 Loss_G: 1.2032 D(x): 0.5450 D(G(z)): 0.0746 / 0.3562 [2/5][1350/1583] Loss_D: 0.7563 Loss_G: 1.6629 D(x): 0.6002 D(G(z)): 0.1437 / 0.2351 [2/5][1400/1583] Loss_D: 0.7457 Loss_G: 1.5831 D(x): 0.6069 D(G(z)): 0.1493 / 0.2511 [2/5][1450/1583] Loss_D: 0.6697 Loss_G: 2.8194 D(x): 0.7597 D(G(z)): 0.2677 / 0.0804 [2/5][1500/1583] Loss_D: 0.5681 Loss_G: 2.2054 D(x): 0.7171 D(G(z)): 0.1626 / 0.1358 [2/5][1550/1583] Loss_D: 0.6741 Loss_G: 2.9537 D(x): 0.8373 D(G(z)): 0.3492 / 0.0760 [3/5][0/1583] Loss_D: 1.0265 Loss_G: 1.1510 D(x): 0.4474 D(G(z)): 0.0685 / 0.3681 [3/5][50/1583] Loss_D: 0.6190 Loss_G: 1.9895 D(x): 0.7136 D(G(z)): 0.1900 / 0.1705 [3/5][100/1583] Loss_D: 0.7754 Loss_G: 3.2350 D(x): 0.8117 D(G(z)): 0.3782 / 0.0535 [3/5][150/1583] Loss_D: 1.8367 Loss_G: 5.1895 D(x): 0.9408 D(G(z)): 0.7750 / 0.0095 [3/5][200/1583] Loss_D: 0.6821 Loss_G: 2.4254 D(x): 0.7709 D(G(z)): 0.3020 / 0.1152 [3/5][250/1583] Loss_D: 1.1273 Loss_G: 4.2718 D(x): 0.9373 D(G(z)): 0.5970 / 0.0206 [3/5][300/1583] Loss_D: 0.5944 Loss_G: 2.2868 D(x): 0.7547 D(G(z)): 0.2306 / 0.1256 [3/5][350/1583] Loss_D: 0.7941 Loss_G: 3.4394 D(x): 0.7585 D(G(z)): 0.3472 / 0.0437 [3/5][400/1583] Loss_D: 0.7588 Loss_G: 3.7067 D(x): 0.8416 D(G(z)): 0.3981 / 0.0347 [3/5][450/1583] Loss_D: 0.7671 Loss_G: 2.7477 D(x): 0.7932 D(G(z)): 0.3686 / 0.0823 [3/5][500/1583] Loss_D: 1.0295 Loss_G: 1.6097 D(x): 0.6318 D(G(z)): 0.3568 / 0.2429 [3/5][550/1583] Loss_D: 0.5186 Loss_G: 2.1037 D(x): 0.7998 D(G(z)): 0.2266 / 0.1473 [3/5][600/1583] Loss_D: 0.5855 Loss_G: 1.9740 D(x): 0.6520 D(G(z)): 0.0972 / 0.1770 [3/5][650/1583] Loss_D: 0.5954 Loss_G: 2.2880 D(x): 0.7819 D(G(z)): 0.2611 / 0.1234 [3/5][700/1583] Loss_D: 1.0706 Loss_G: 1.1761 D(x): 0.4335 D(G(z)): 0.0681 / 0.3609 [3/5][750/1583] Loss_D: 0.7128 Loss_G: 1.5402 D(x): 0.5909 D(G(z)): 0.0993 / 0.2702 [3/5][800/1583] Loss_D: 0.8883 Loss_G: 2.4234 D(x): 0.8035 D(G(z)): 0.4176 / 0.1206 [3/5][850/1583] Loss_D: 0.7085 Loss_G: 2.7516 D(x): 0.7502 D(G(z)): 0.2918 / 0.0878 [3/5][900/1583] Loss_D: 0.8472 Loss_G: 3.5935 D(x): 0.8553 D(G(z)): 0.4403 / 0.0397 [3/5][950/1583] Loss_D: 0.4454 Loss_G: 2.3438 D(x): 0.7763 D(G(z)): 0.1519 / 0.1226 [3/5][1000/1583] Loss_D: 1.2425 Loss_G: 1.0600 D(x): 0.3930 D(G(z)): 0.0889 / 0.4122 [3/5][1050/1583] Loss_D: 1.0465 Loss_G: 1.4973 D(x): 0.4618 D(G(z)): 0.1165 / 0.2906 [3/5][1100/1583] Loss_D: 0.5885 Loss_G: 2.7760 D(x): 0.8852 D(G(z)): 0.3356 / 0.0854 [3/5][1150/1583] Loss_D: 0.5940 Loss_G: 2.5669 D(x): 0.7481 D(G(z)): 0.2109 / 0.1001 [3/5][1200/1583] Loss_D: 0.9074 Loss_G: 3.0569 D(x): 0.7762 D(G(z)): 0.4214 / 0.0644 [3/5][1250/1583] Loss_D: 0.7487 Loss_G: 3.0959 D(x): 0.8534 D(G(z)): 0.4052 / 0.0601 [3/5][1300/1583] Loss_D: 0.5956 Loss_G: 2.5807 D(x): 0.7263 D(G(z)): 0.1887 / 0.1039 [3/5][1350/1583] Loss_D: 1.7038 Loss_G: 0.6425 D(x): 0.2487 D(G(z)): 0.0507 / 0.5746 [3/5][1400/1583] Loss_D: 0.5863 Loss_G: 1.7754 D(x): 0.6609 D(G(z)): 0.1044 / 0.2069 [3/5][1450/1583] Loss_D: 0.4925 Loss_G: 2.7946 D(x): 0.7665 D(G(z)): 0.1660 / 0.0864 [3/5][1500/1583] Loss_D: 0.6616 Loss_G: 2.9829 D(x): 0.9091 D(G(z)): 0.3944 / 0.0654 [3/5][1550/1583] Loss_D: 1.2097 Loss_G: 1.0897 D(x): 0.4433 D(G(z)): 0.1887 / 0.3918 [4/5][0/1583] Loss_D: 0.5653 Loss_G: 2.1567 D(x): 0.6781 D(G(z)): 0.1105 / 0.1464 [4/5][50/1583] Loss_D: 0.7300 Loss_G: 1.7770 D(x): 0.7472 D(G(z)): 0.3011 / 0.2104 [4/5][100/1583] Loss_D: 0.5735 Loss_G: 1.7644 D(x): 0.6723 D(G(z)): 0.1219 / 0.2092 [4/5][150/1583] Loss_D: 1.0598 Loss_G: 0.6708 D(x): 0.4336 D(G(z)): 0.0800 / 0.5560 [4/5][200/1583] Loss_D: 0.6098 Loss_G: 2.0432 D(x): 0.6658 D(G(z)): 0.1378 / 0.1655 [4/5][250/1583] Loss_D: 0.7227 Loss_G: 1.6686 D(x): 0.5750 D(G(z)): 0.0759 / 0.2371 [4/5][300/1583] Loss_D: 0.8077 Loss_G: 2.7966 D(x): 0.7647 D(G(z)): 0.3703 / 0.0771 [4/5][350/1583] Loss_D: 0.7086 Loss_G: 1.3171 D(x): 0.5890 D(G(z)): 0.1103 / 0.3079 [4/5][400/1583] Loss_D: 0.6418 Loss_G: 2.3383 D(x): 0.6284 D(G(z)): 0.1060 / 0.1303 [4/5][450/1583] Loss_D: 0.7046 Loss_G: 3.6138 D(x): 0.8926 D(G(z)): 0.4057 / 0.0354 [4/5][500/1583] Loss_D: 1.7355 Loss_G: 2.1156 D(x): 0.5473 D(G(z)): 0.4802 / 0.2431 [4/5][550/1583] Loss_D: 0.6479 Loss_G: 2.5634 D(x): 0.7987 D(G(z)): 0.3139 / 0.0956 [4/5][600/1583] Loss_D: 0.5650 Loss_G: 1.9429 D(x): 0.6772 D(G(z)): 0.1203 / 0.1713 [4/5][650/1583] Loss_D: 0.9440 Loss_G: 3.2048 D(x): 0.7789 D(G(z)): 0.4225 / 0.0533 [4/5][700/1583] Loss_D: 0.5745 Loss_G: 2.5296 D(x): 0.7004 D(G(z)): 0.1496 / 0.1075 [4/5][750/1583] Loss_D: 0.7448 Loss_G: 1.5417 D(x): 0.5864 D(G(z)): 0.1132 / 0.2617 [4/5][800/1583] Loss_D: 0.5315 Loss_G: 2.4287 D(x): 0.7047 D(G(z)): 0.1254 / 0.1159 [4/5][850/1583] Loss_D: 1.1006 Loss_G: 0.9708 D(x): 0.4101 D(G(z)): 0.0549 / 0.4226 [4/5][900/1583] Loss_D: 0.8635 Loss_G: 1.1581 D(x): 0.5057 D(G(z)): 0.0711 / 0.3618 [4/5][950/1583] Loss_D: 0.5915 Loss_G: 2.8714 D(x): 0.8364 D(G(z)): 0.3005 / 0.0727 [4/5][1000/1583] Loss_D: 1.5283 Loss_G: 0.4922 D(x): 0.2847 D(G(z)): 0.0228 / 0.6394 [4/5][1050/1583] Loss_D: 0.7626 Loss_G: 1.7556 D(x): 0.5865 D(G(z)): 0.1282 / 0.2159 [4/5][1100/1583] Loss_D: 0.6571 Loss_G: 1.7024 D(x): 0.6470 D(G(z)): 0.1505 / 0.2243 [4/5][1150/1583] Loss_D: 0.7735 Loss_G: 1.2737 D(x): 0.5851 D(G(z)): 0.1427 / 0.3350 [4/5][1200/1583] Loss_D: 0.4104 Loss_G: 3.2208 D(x): 0.8835 D(G(z)): 0.2290 / 0.0520 [4/5][1250/1583] Loss_D: 0.4898 Loss_G: 2.1841 D(x): 0.7873 D(G(z)): 0.1912 / 0.1451 [4/5][1300/1583] Loss_D: 0.6657 Loss_G: 2.5232 D(x): 0.6504 D(G(z)): 0.1283 / 0.1273 [4/5][1350/1583] Loss_D: 1.0126 Loss_G: 4.9254 D(x): 0.9131 D(G(z)): 0.5439 / 0.0115 [4/5][1400/1583] Loss_D: 1.2293 Loss_G: 5.6073 D(x): 0.9281 D(G(z)): 0.6209 / 0.0062 [4/5][1450/1583] Loss_D: 0.3908 Loss_G: 2.4251 D(x): 0.7873 D(G(z)): 0.1181 / 0.1124 [4/5][1500/1583] Loss_D: 1.1000 Loss_G: 0.9861 D(x): 0.4594 D(G(z)): 0.1542 / 0.4324 [4/5][1550/1583] Loss_D: 0.9504 Loss_G: 3.8109 D(x): 0.9275 D(G(z)): 0.5386 / 0.0277 结果 最后，让我们看看我们是如何做到的。 在这里，我们将看三个不同的结果。 首先，我们将了解 D 和 G 的损失在训练过程中如何变化。 其次，我们将在每个时期将 G 的输出显示为 fixed_noise 批次。 第三，我们将查看一批真实数据和来自 G 的一批伪数据。 损失与训练迭代 下面是 D & G 的损失与训练迭代的关系图。 plt.figure(figsize=(10,5)) plt.title(\"Generator and Discriminator Loss During Training\") plt.plot(G_losses,label=\"G\") plt.plot(D_losses,label=\"D\") plt.xlabel(\"iterations\") plt.ylabel(\"Loss\") plt.legend() plt.show() 可视化 G 的进度 请记住，在每次训练之后，我们如何将生成器的输出保存为 fixed_noise 批次。 现在，我们可以用动画形象化 G 的训练进度。 按下播放按钮开始动画。 #%%capture fig = plt.figure(figsize=(8,8)) plt.axis(\"off\") ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list] ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True) HTML(ani.to_jshtml()) 实像与假像 最后，让我们并排查看一些真实图像和伪图像。 # Grab a batch of real images from the dataloader real_batch = next(iter(dataloader)) # Plot the real images plt.figure(figsize=(15,15)) plt.subplot(1,2,1) plt.axis(\"off\") plt.title(\"Real Images\") plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0))) # Plot the fake images from the last epoch plt.subplot(1,2,2) plt.axis(\"off\") plt.title(\"Fake Images\") plt.imshow(np.transpose(img_list[-1],(1,2,0))) plt.show() 下一步去哪里 我们已经走到了旅程的尽头，但是您可以从这里到达几个地方。 你可以： 训练更长的时间，看看效果如何 修改此模型以采用其他数据集，并可能更改图像的大小和模型架构 在处查看其他一些不错的 GAN 项目 创建可生成音乐的 GAN 脚本的总运行时间：(28 分钟 39.288 秒） Download Python source code: dcgan_faces_tutorial.py Download Jupyter notebook: dcgan_faces_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"15.html":{"url":"15.html","title":"torchaudio 教程","keywords":"","body":"torchaudio 教程 标题： https://pytorch.org/tutorials/beginner/audio_preprocessing_tutorial.html 注意 单击此处的下载完整的示例代码 PyTorch 是一个开源深度学习平台，提供了从研究原型到具有 GPU 支持的生产部署的无缝路径。 解决机器学习问题的巨大努力在于数据准备。 torchaudio充分利用了 PyTorch 的 GPU 支持，并提供了许多工具来简化数据加载并使其更具可读性。 在本教程中，我们将看到如何从简单的数据集中加载和预处理数据。 对于本教程，请确保已安装matplotlib软件包，以便于查看。 import torch import torchaudio import matplotlib.pyplot as plt 开启档案 torchaudio还支持以 wav 和 mp3 格式加载声音文件。 我们将波形称为原始音频信号。 filename = \"../_static/img/steam-train-whistle-daniel_simon-converted-from-mp3.wav\" waveform, sample_rate = torchaudio.load(filename) print(\"Shape of waveform: {}\".format(waveform.size())) print(\"Sample rate of waveform: {}\".format(sample_rate)) plt.figure() plt.plot(waveform.t().numpy()) 出： Shape of waveform: torch.Size([2, 276858]) Sample rate of waveform: 44100 在torchaudio中加载文件时，可以选择指定后端以通过torchaudio.set_audio_backend使用 SoX 或 SoundFile 。 这些后端在需要时会延迟加载。 torchaudio还使 JIT 编译对于功能是可选的，并在可能的情况下使用nn.Module。 转变 torchaudio支持不断增长的转换列表。 重采样：将波形重采样为其他采样率。 频谱图：从波形创建频谱图。 GriffinLim ：使用 Griffin-Lim 转换从线性比例幅度谱图计算波形。 ComputeDeltas ：计算张量(通常是声谱图）的增量系数。 ComplexNorm ：计算复数张量的范数。 MelScale ：使用转换矩阵将正常 STFT 转换为 Mel 频率 STFT。 AmplitudeToDB ：这将频谱图从功率/振幅标度变为分贝标度。 MFCC ：根据波形创建梅尔频率倒谱系数。 MelSpectrogram ：使用 PyTorch 中的 STFT 功能从波形创建 MEL 频谱图。 MuLawEncoding ：基于 mu-law 压扩对波形进行编码。 MuLawDecoding ：解码 mu-law 编码波形。 TimeStretch ：在不更改给定速率的音高的情况下，及时拉伸频谱图。 FrequencyMasking ：在频域中对频谱图应用屏蔽。 TimeMasking ：在时域中对频谱图应用屏蔽。 每个变换都支持批处理：您可以对单个原始音频信号或频谱图或许多相同形状的信号执行变换。 由于所有变换都是nn.Modules或jit.ScriptModules，因此它们可以随时用作神经网络的一部分。 首先，我们可以以对数刻度查看频谱图的对数。 specgram = torchaudio.transforms.Spectrogram()(waveform) print(\"Shape of spectrogram: {}\".format(specgram.size())) plt.figure() plt.imshow(specgram.log2()[0,:,:].numpy(), cmap='gray') Out: Shape of spectrogram: torch.Size([2, 201, 1385]) 或者我们可以以对数刻度查看梅尔光谱图。 specgram = torchaudio.transforms.MelSpectrogram()(waveform) print(\"Shape of spectrogram: {}\".format(specgram.size())) plt.figure() p = plt.imshow(specgram.log2()[0,:,:].detach().numpy(), cmap='gray') Out: Shape of spectrogram: torch.Size([2, 128, 1385]) 我们可以一次对一个通道重新采样波形。 new_sample_rate = sample_rate/10 # Since Resample applies to a single channel, we resample first channel here channel = 0 transformed = torchaudio.transforms.Resample(sample_rate, new_sample_rate)(waveform[channel,:].view(1,-1)) print(\"Shape of transformed waveform: {}\".format(transformed.size())) plt.figure() plt.plot(transformed[0,:].numpy()) Out: Shape of transformed waveform: torch.Size([1, 27686]) 作为变换的另一个示例，我们可以基于 Mu-Law 编码对信号进行编码。 但是要做到这一点，我们需要信号在-1 和 1 之间。由于张量只是一个常规的 PyTorch 张量，因此我们可以在其上应用标准运算符。 # Let's check if the tensor is in the interval [-1,1] print(\"Min of waveform: {}\\nMax of waveform: {}\\nMean of waveform: {}\".format(waveform.min(), waveform.max(), waveform.mean())) Out: Min of waveform: -0.572845458984375 Max of waveform: 0.575958251953125 Mean of waveform: 9.293758921558037e-05 由于波形已经在-1 和 1 之间，因此我们不需要对其进行归一化。 def normalize(tensor): # Subtract the mean, and scale to the interval [-1,1] tensor_minusmean = tensor - tensor.mean() return tensor_minusmean/tensor_minusmean.abs().max() # Let's normalize to the full interval [-1,1] # waveform = normalize(waveform) 让我们对波形进行编码。 transformed = torchaudio.transforms.MuLawEncoding()(waveform) print(\"Shape of transformed waveform: {}\".format(transformed.size())) plt.figure() plt.plot(transformed[0,:].numpy()) Out: Shape of transformed waveform: torch.Size([2, 276858]) 现在解码。 reconstructed = torchaudio.transforms.MuLawDecoding()(transformed) print(\"Shape of recovered waveform: {}\".format(reconstructed.size())) plt.figure() plt.plot(reconstructed[0,:].numpy()) Out: Shape of recovered waveform: torch.Size([2, 276858]) 我们最终可以将原始波形与其重建版本进行比较。 # Compute median relative difference err = ((waveform-reconstructed).abs() / waveform.abs()).median() print(\"Median relative difference between original and MuLaw reconstucted signals: {:.2%}\".format(err)) Out: Median relative difference between original and MuLaw reconstucted signals: 1.28% 功能性 上面看到的转换依赖于较低级别的无状态函数进行计算。 这些功能在torchaudio.functional下可用。 完整列表位于，此处为，包括： istft ：短时傅立叶逆变换。 增益：对整个波形进行放大或衰减。 抖动：增加以特定位深度存储的音频的动态范围。 compute_deltas ：计算张量的增量系数。 equalizer_biquad ：设计双二阶峰均化器滤波器并执行滤波。 lowpass_biquad ：设计双二阶低通滤波器并执行滤波。 highpass_biquad ：设计双二阶高通滤波器并执行滤波。 例如，让我们尝试 mu_law_encoding 功能： mu_law_encoding_waveform = torchaudio.functional.mu_law_encoding(waveform, quantization_channels=256) print(\"Shape of transformed waveform: {}\".format(mu_law_encoding_waveform.size())) plt.figure() plt.plot(mu_law_encoding_waveform[0,:].numpy()) Out: Shape of transformed waveform: torch.Size([2, 276858]) 您可以看到从torchaudio.functional.mu_law_encoding的输出与从torchaudio.transforms.MuLawEncoding的输出相同。 现在，让我们尝试其他一些功能并将其输出可视化。 通过我们的频谱图，我们可以计算出其增量： computed = torchaudio.functional.compute_deltas(specgram, win_length=3) print(\"Shape of computed deltas: {}\".format(computed.shape)) plt.figure() plt.imshow(computed.log2()[0,:,:].detach().numpy(), cmap='gray') Out: Shape of computed deltas: torch.Size([2, 128, 1385]) 我们可以获取原始波形并对其应用不同的效果。 gain_waveform = torchaudio.functional.gain(waveform, gain_db=5.0) print(\"Min of gain_waveform: {}\\nMax of gain_waveform: {}\\nMean of gain_waveform: {}\".format(gain_waveform.min(), gain_waveform.max(), gain_waveform.mean())) dither_waveform = torchaudio.functional.dither(waveform) print(\"Min of dither_waveform: {}\\nMax of dither_waveform: {}\\nMean of dither_waveform: {}\".format(dither_waveform.min(), dither_waveform.max(), dither_waveform.mean())) Out: Min of gain_waveform: -1.0186792612075806 Max of gain_waveform: 1.024214744567871 Mean of gain_waveform: 0.00016526904073543847 Min of dither_waveform: -0.572784423828125 Max of dither_waveform: 0.575927734375 Mean of dither_waveform: 0.00010744280007202178 torchaudio.functional中功能的另一个示例是将滤波器应用于我们的波形。 将低通双二阶滤波器应用于我们的波形，将输出修改了频率信号的新波形。 lowpass_waveform = torchaudio.functional.lowpass_biquad(waveform, sample_rate, cutoff_freq=3000) print(\"Min of lowpass_waveform: {}\\nMax of lowpass_waveform: {}\\nMean of lowpass_waveform: {}\".format(lowpass_waveform.min(), lowpass_waveform.max(), lowpass_waveform.mean())) plt.figure() plt.plot(lowpass_waveform.t().numpy()) Out: Min of lowpass_waveform: -0.5595061182975769 Max of lowpass_waveform: 0.5595013499259949 Mean of lowpass_waveform: 9.293758921558037e-05 我们还可以使用高通双二阶滤波器可视化波形。 highpass_waveform = torchaudio.functional.highpass_biquad(waveform, sample_rate, cutoff_freq=2000) print(\"Min of highpass_waveform: {}\\nMax of highpass_waveform: {}\\nMean of highpass_waveform: {}\".format(highpass_waveform.min(), highpass_waveform.max(), highpass_waveform.mean())) plt.figure() plt.plot(highpass_waveform.t().numpy()) Out: Min of highpass_waveform: -0.11269105970859528 Max of highpass_waveform: 0.10451901704072952 Mean of highpass_waveform: -4.971002776077427e-12 从 Kaldi 迁移到 Torchaudio 用户可能熟悉 Kaldi (一种用于语音识别的工具包）。 torchaudio提供与torchaudio.kaldi_io中的兼容性。 实际上，它可以通过以下方式从 kaldi scp 或 ark 文件或流中读取： read_vec_int_ark read_vec_flt_scp read_vec_flt_arkfile / stream read_mat_scp read_mat_ark torchaudio为spectrogram，fbank，mfcc和提供 Kaldi 兼容的转换。 resample_waveform 受益于 GPU 支持，有关更多信息，请参见在此处。 n_fft = 400.0 frame_length = n_fft / sample_rate * 1000.0 frame_shift = frame_length / 2.0 params = { \"channel\": 0, \"dither\": 0.0, \"window_type\": \"hanning\", \"frame_length\": frame_length, \"frame_shift\": frame_shift, \"remove_dc_offset\": False, \"round_to_power_of_two\": False, \"sample_frequency\": sample_rate, } specgram = torchaudio.compliance.kaldi.spectrogram(waveform, **params) print(\"Shape of spectrogram: {}\".format(specgram.size())) plt.figure() plt.imshow(specgram.t().numpy(), cmap='gray') Out: Shape of spectrogram: torch.Size([1383, 201]) 我们还支持根据波形计算滤波器组功能，以匹配 Kaldi 的实现。 fbank = torchaudio.compliance.kaldi.fbank(waveform, **params) print(\"Shape of fbank: {}\".format(fbank.size())) plt.figure() plt.imshow(fbank.t().numpy(), cmap='gray') Out: Shape of fbank: torch.Size([1383, 23]) 您可以从原始音频信号创建梅尔频率倒谱系数，这与 Kaldi 的 compute-mfcc-feats 的输入/输出相匹配。 mfcc = torchaudio.compliance.kaldi.mfcc(waveform, **params) print(\"Shape of mfcc: {}\".format(mfcc.size())) plt.figure() plt.imshow(mfcc.t().numpy(), cmap='gray') Out: Shape of mfcc: torch.Size([1383, 13]) 可用数据集 如果您不想创建自己的数据集来训练模型，则torchaudio提供了统一的数据集界面。 该接口支持将文件延迟加载到内存，下载和提取函数以及数据集以构建模型。 当前支持的数据集torchaudio为： VCTK ：109 位以英语为母语的母语者发出的语音数据，带有各种重音(在此处详细了解）。 是或否：一个人在希伯来语中说是或否的 60 张录音； 每个记录长 8 个字(此处更多信息）。 通用语音：开源的多语言语音数据集，任何人都可以用来训练启用语音的应用程序(在此处了解更多）。 LibriSpeech ：阅读英语语音的大型语料库(1000 小时）(在此处详细了解）。 yesno_data = torchaudio.datasets.YESNO('./', download=True) # A data point in Yesno is a tuple (waveform, sample_rate, labels) where labels is a list of integers with 1 for yes and 0 for no. # Pick data point number 3 to see an example of the the yesno_data: n = 3 waveform, sample_rate, labels = yesno_data[n] print(\"Waveform: {}\\nSample rate: {}\\nLabels: {}\".format(waveform, sample_rate, labels)) plt.figure() plt.plot(waveform.t().numpy()) Out: Waveform: tensor([[3.0518e-05, 6.1035e-05, 3.0518e-05, ..., 5.8594e-03, 3.5400e-03, 3.3569e-04]]) Sample rate: 8000 Labels: [0, 1, 0, 0, 1, 0, 1, 0] 现在，每当您从数据集中请求声音文件时，仅当您请求声音文件时，它才会加载到内存中。 意思是，数据集仅加载您想要和使用的项目并将其保留在内存中，并保存在内存中。 结论 我们使用示例原始音频信号或波形来说明如何使用torchaudio打开音频文件，以及如何对该波形进行预处理，转换和应用功能。 我们还演示了如何使用熟悉的 Kaldi 函数以及如何使用内置数据集来构建模型。 鉴于torchaudio是基于 PyTorch 构建的，因此这些技术可在利用 GPU 的同时，用作更高级音频应用(例如语音识别）的构建块。 脚本的总运行时间：(0 分钟 39.004 秒） Download Python source code: audio_preprocessing_tutorial.py Download Jupyter notebook: audio_preprocessing_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"17.html":{"url":"17.html","title":"NLP From Scratch: 使用char-RNN对姓氏进行分类","keywords":"","body":"NLP From Scratch: 使用char-RNN对姓氏进行分类 原文： https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html 注意 单击此处的下载完整的示例代码 作者： Sean Robertson 我们将构建和训练基本的字符级 RNN 对单词进行分类。 本教程与以下两个教程一起，展示了如何“从头开始”进行 NLP 建模的预处理数据，特别是不使用 torchtext 的许多便利功能，因此您可以了解如何进行 NLP 建模的预处理 在低水平上工作。 字符级 RNN 将单词作为一系列字符读取-在每个步骤输出预测和“隐藏状态”，将其先前的隐藏状态输入到每个下一步。 我们将最终的预测作为输出，即单词属于哪个类别。 具体来说，我们将训练来自 18 种起源语言的数千种姓氏，并根据拼写方式预测名称的来源： $ python predict.py Hinton (-0.47) Scottish (-1.52) English (-3.57) Irish $ python predict.py Schmidhuber (-0.19) German (-2.48) Czech (-2.68) Dutch 推荐读物： 我假设您至少已经安装了 PyTorch，了解 Python 和了解 Tensors： https://pytorch.org/ 有关安装说明 使用 PyTorch 进行深度学习：60 分钟的闪电战通常开始使用 PyTorch 使用示例学习 PyTorch 进行广泛而深入的概述 PyTorch(以前的 Torch 用户）(如果您以前是 Lua Torch 用户） 了解 RNN 及其工作方式也将很有用： 循环神经网络的不合理效果显示了许多现实生活中的例子 了解 LSTM 网络特别是关于 LSTM 的，但总体上也关于 RNN 的 准备数据 Note 从的下载数据，并将其提取到当前目录。 data/names目录中包含 18 个文本文件，名为“ [Language] .txt”。 每个文件包含一堆名称，每行一个名称，大多数都是罗马化的(但我们仍然需要从 Unicode 转换为 ASCII）。 我们将得到一个字典，列出每种语言的名称列表{language: [names ...]}。 通用变量“类别”和“行”(在本例中为语言和名称）用于以后的扩展。 from __future__ import unicode_literals, print_function, division from io import open import glob import os def findFiles(path): return glob.glob(path) print(findFiles('data/names/*.txt')) import unicodedata import string all_letters = string.ascii_letters + \" .,;'\" n_letters = len(all_letters) # Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427 def unicodeToAscii(s): return ''.join( c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn' and c in all_letters ) print(unicodeToAscii('Ślusàrski')) # Build the category_lines dictionary, a list of names per language category_lines = {} all_categories = [] # Read a file and split into lines def readLines(filename): lines = open(filename, encoding='utf-8').read().strip().split('\\n') return [unicodeToAscii(line) for line in lines] for filename in findFiles('data/names/*.txt'): category = os.path.splitext(os.path.basename(filename))[0] all_categories.append(category) lines = readLines(filename) category_lines[category] = lines n_categories = len(all_categories) 出： ['data/names/French.txt', 'data/names/Czech.txt', 'data/names/Dutch.txt', 'data/names/Polish.txt', 'data/names/Scottish.txt', 'data/names/Chinese.txt', 'data/names/English.txt', 'data/names/Italian.txt', 'data/names/Portuguese.txt', 'data/names/Japanese.txt', 'data/names/German.txt', 'data/names/Russian.txt', 'data/names/Korean.txt', 'data/names/Arabic.txt', 'data/names/Greek.txt', 'data/names/Vietnamese.txt', 'data/names/Spanish.txt', 'data/names/Irish.txt'] Slusarski 现在我们有了category_lines，这是一个字典，将每个类别(语言）映射到行(名称）列表。 我们还跟踪了all_categories(只是语言列表）和n_categories，以供以后参考。 print(category_lines['Italian'][:5]) Out: ['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni'] 将名称转换为张量 现在我们已经组织了所有名称，我们需要将它们转换为张量以使用它们。 为了表示单个字母，我们使用大小为&lt;1 x n_letters&gt;的“ one-hot vector”。 一个热门向量用 0 填充，但当前字母的索引处的数字为 1，例如 \"b\" = &lt;0 1 0 0 0 ...&gt;。 为了制造一个单词，我们将其中的一些连接成 2D 矩阵&lt;line_length x 1 x n_letters&gt;。 额外的 1 维是因为 PyTorch 假设所有内容都是批量的-我们在这里只使用 1 的批量大小。 import torch # Find letter index from all_letters, e.g. \"a\" = 0 def letterToIndex(letter): return all_letters.find(letter) # Just for demonstration, turn a letter into a Tensor def letterToTensor(letter): tensor = torch.zeros(1, n_letters) tensor[0][letterToIndex(letter)] = 1 return tensor # Turn a line into a , # or an array of one-hot letter vectors def lineToTensor(line): tensor = torch.zeros(len(line), 1, n_letters) for li, letter in enumerate(line): tensor[li][0][letterToIndex(letter)] = 1 return tensor print(letterToTensor('J')) print(lineToTensor('Jones').size()) Out: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]) torch.Size([5, 1, 57]) 建立网络 在进行自动分级之前，在 Torch 中创建一个递归神经网络需要在多个时间步上克隆图层的参数。 图层保留了隐藏状态和渐变，这些图层现在完全由图形本身处理。 这意味着您可以以非常“纯粹”的方式实现 RNN，作为常规的前馈层。 这个 RNN 模块(主要从 PyTorch for Torch 用户教程的复制）仅是 2 个线性层，它们在输入和隐藏状态下运行，输出之后是 LogSoftmax 层。 import torch.nn as nn class RNN(nn.Module): def __init__(self, input_size, hidden_size, output_size): super(RNN, self).__init__() self.hidden_size = hidden_size self.i2h = nn.Linear(input_size + hidden_size, hidden_size) self.i2o = nn.Linear(input_size + hidden_size, output_size) self.softmax = nn.LogSoftmax(dim=1) def forward(self, input, hidden): combined = torch.cat((input, hidden), 1) hidden = self.i2h(combined) output = self.i2o(combined) output = self.softmax(output) return output, hidden def initHidden(self): return torch.zeros(1, self.hidden_size) n_hidden = 128 rnn = RNN(n_letters, n_hidden, n_categories) 要运行此网络的步骤，我们需要传递输入(在本例中为当前字母的张量）和先前的隐藏状态(首先将其初始化为零）。 我们将返回输出(每种语言的概率）和下一个隐藏状态(我们将其保留用于下一步）。 input = letterToTensor('A') hidden =torch.zeros(1, n_hidden) output, next_hidden = rnn(input, hidden) 为了提高效率，我们不想为每个步骤创建一个新的 Tensor，因此我们将使用lineToTensor而不是letterToTensor并使用切片。 这可以通过预先计算一批张量来进一步优化。 input = lineToTensor('Albert') hidden = torch.zeros(1, n_hidden) output, next_hidden = rnn(input[0], hidden) print(output) Out: tensor([[-2.9504, -2.8402, -2.9195, -2.9136, -2.9799, -2.8207, -2.8258, -2.8399, -2.9098, -2.8815, -2.8313, -2.8628, -3.0440, -2.8689, -2.9391, -2.8381, -2.9202, -2.8717]], grad_fn=) 如您所见，输出为&lt;1 x n_categories&gt;张量，其中每个项目都是该类别的可能性(更高的可能性更大）。 训练 准备训练 在接受训练之前，我们应该做一些辅助功能。 首先是解释网络的输出，我们知道这是每个类别的可能性。 我们可以使用Tensor.topk来获得最大值的索引： def categoryFromOutput(output): top_n, top_i = output.topk(1) category_i = top_i[0].item() return all_categories[category_i], category_i print(categoryFromOutput(output)) Out: ('Chinese', 5) 我们还将需要一种快速的方法来获取训练示例(名称及其语言）： import random def randomChoice(l): return l[random.randint(0, len(l) - 1)] def randomTrainingExample(): category = randomChoice(all_categories) line = randomChoice(category_lines[category]) category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long) line_tensor = lineToTensor(line) return category, line, category_tensor, line_tensor for i in range(10): category, line, category_tensor, line_tensor = randomTrainingExample() print('category =', category, '/ line =', line) Out: category = Italian / line = Pastore category = Arabic / line = Toma category = Irish / line = Tracey category = Portuguese / line = Lobo category = Arabic / line = Sleiman category = Polish / line = Sokolsky category = English / line = Farr category = Polish / line = Winogrodzki category = Russian / line = Adoratsky category = Dutch / line = Robert 训练网络 现在，训练该网络所需要做的就是向它展示大量示例，进行猜测，并告诉它是否错误。 对于损失函数，nn.NLLLoss是适当的，因为 RNN 的最后一层是nn.LogSoftmax。 criterion = nn.NLLLoss() 每个训练循环将： 创建输入和目标张量 创建归零的初始隐藏状态 阅读和中的每个字母 保持下一个字母的隐藏状态 比较最终输出与目标 反向传播 返回输出和损失 learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn def train(category_tensor, line_tensor): hidden = rnn.initHidden() rnn.zero_grad() for i in range(line_tensor.size()[0]): output, hidden = rnn(line_tensor[i], hidden) loss = criterion(output, category_tensor) loss.backward() # Add parameters' gradients to their values, multiplied by learning rate for p in rnn.parameters(): p.data.add_(-learning_rate, p.grad.data) return output, loss.item() 现在，我们只需要运行大量示例。 由于train函数同时返回输出和损失，因此我们可以打印其猜测并跟踪绘制损失。 因为有 1000 个示例，所以我们仅打印每个print_every示例，并对损失进行平均。 import time import math n_iters = 100000 print_every = 5000 plot_every = 1000 # Keep track of losses for plotting current_loss = 0 all_losses = [] def timeSince(since): now = time.time() s = now - since m = math.floor(s / 60) s -= m * 60 return '%dm %ds' % (m, s) start = time.time() for iter in range(1, n_iters + 1): category, line, category_tensor, line_tensor = randomTrainingExample() output, loss = train(category_tensor, line_tensor) current_loss += loss # Print iter number, loss, name and guess if iter % print_every == 0: guess, guess_i = categoryFromOutput(output) correct = '✓' if guess == category else '✗ (%s)' % category print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct)) # Add current loss avg to list of losses if iter % plot_every == 0: all_losses.append(current_loss / plot_every) current_loss = 0 Out: 5000 5% (0m 12s) 3.1806 Olguin / Irish ✗ (Spanish) 10000 10% (0m 21s) 2.1254 Dubnov / Russian ✓ 15000 15% (0m 29s) 3.1001 Quirke / Polish ✗ (Irish) 20000 20% (0m 38s) 0.9191 Jiang / Chinese ✓ 25000 25% (0m 46s) 2.3233 Marti / Italian ✗ (Spanish) 30000 30% (0m 54s) nan Amari / Russian ✗ (Arabic) 35000 35% (1m 3s) nan Gudojnik / Russian ✓ 40000 40% (1m 11s) nan Finn / Russian ✗ (Irish) 45000 45% (1m 20s) nan Napoliello / Russian ✗ (Italian) 50000 50% (1m 28s) nan Clark / Russian ✗ (Irish) 55000 55% (1m 37s) nan Roijakker / Russian ✗ (Dutch) 60000 60% (1m 46s) nan Kalb / Russian ✗ (Arabic) 65000 65% (1m 54s) nan Hanania / Russian ✗ (Arabic) 70000 70% (2m 3s) nan Theofilopoulos / Russian ✗ (Greek) 75000 75% (2m 11s) nan Pakulski / Russian ✗ (Polish) 80000 80% (2m 20s) nan Thistlethwaite / Russian ✗ (English) 85000 85% (2m 29s) nan Shadid / Russian ✗ (Arabic) 90000 90% (2m 37s) nan Finnegan / Russian ✗ (Irish) 95000 95% (2m 46s) nan Brannon / Russian ✗ (Irish) 100000 100% (2m 54s) nan Gomulka / Russian ✗ (Polish) 绘制结果 从all_losses绘制历史损失可显示网络学习情况： import matplotlib.pyplot as plt import matplotlib.ticker as ticker plt.figure() plt.plot(all_losses) 评估结果 为了查看网络在不同类别上的表现如何，我们将创建一个混淆矩阵，为每种实际语言(行）指示网络猜测(列）哪种语言。 为了计算混淆矩阵，使用evaluate()通过网络运行一堆样本，该样本等于train()减去反向传播器。 # Keep track of correct guesses in a confusion matrix confusion = torch.zeros(n_categories, n_categories) n_confusion = 10000 # Just return an output given a line def evaluate(line_tensor): hidden = rnn.initHidden() for i in range(line_tensor.size()[0]): output, hidden = rnn(line_tensor[i], hidden) return output # Go through a bunch of examples and record which are correctly guessed for i in range(n_confusion): category, line, category_tensor, line_tensor = randomTrainingExample() output = evaluate(line_tensor) guess, guess_i = categoryFromOutput(output) category_i = all_categories.index(category) confusion[category_i][guess_i] += 1 # Normalize by dividing every row by its sum for i in range(n_categories): confusion[i] = confusion[i] / confusion[i].sum() # Set up plot fig = plt.figure() ax = fig.add_subplot(111) cax = ax.matshow(confusion.numpy()) fig.colorbar(cax) # Set up axes ax.set_xticklabels([''] + all_categories, rotation=90) ax.set_yticklabels([''] + all_categories) # Force label at every tick ax.xaxis.set_major_locator(ticker.MultipleLocator(1)) ax.yaxis.set_major_locator(ticker.MultipleLocator(1)) # sphinx_gallery_thumbnail_number = 2 plt.show() 您可以从主轴上挑出一些亮点，以显示它猜错了哪些语言，例如 中文(朝鲜语）和西班牙语(意大利语）。 它似乎与希腊语搭配得很好，与英语搭配得很差(可能是因为与其他语言重叠）。 在用户输入上运行 def predict(input_line, n_predictions=3): print('\\n> %s' % input_line) with torch.no_grad(): output = evaluate(lineToTensor(input_line)) # Get top N categories topv, topi = output.topk(n_predictions, 1, True) predictions = [] for i in range(n_predictions): value = topv[0][i].item() category_index = topi[0][i].item() print('(%.2f) %s' % (value, all_categories[category_index])) predictions.append([value, all_categories[category_index]]) predict('Dovesky') predict('Jackson') predict('Satoshi') Out: > Dovesky (nan) Russian (nan) Arabic (nan) Korean > Jackson (nan) Russian (nan) Arabic (nan) Korean > Satoshi (nan) Russian (nan) Arabic (nan) Korean 实际 PyTorch 存储库中的脚本的最终版本将上述代码分成几个文件： data.py(加载文件） model.py(定义 RNN） train.py(进行训练） predict.py(使用命令行参数运行predict()） server.py(通过 bottle.py 将预测用作 JSON API） 运行train.py训练并保存网络。 使用名称运行predict.py以查看预测： $ python predict.py Hazaki (-0.42) Japanese (-1.39) Polish (-3.51) Czech 运行server.py并访问 http：// localhost：5533 /您的名字以获取预测的 JSON 输出。 练习题 尝试使用其他行->类别的数据集，例如： 任何字词->语言 名->性别 角色名称->作家 页面标题->博客或 subreddit 通过更大和/或形状更好的网络获得更好的结果 添加更多线性层 尝试nn.LSTM和nn.GRU层 将多个这些 RNN 合并为更高级别的网络 脚本的总运行时间：(3 分 4.326 秒） Download Python source code: char_rnn_classification_tutorial.py Download Jupyter notebook: char_rnn_classification_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:27:35 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"18.html":{"url":"18.html","title":"NLP From Scratch: 生成名称与字符级RNN","keywords":"","body":"NLP From Scratch: 生成名称与字符级RNN 原文： https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html 注意 单击此处的下载完整的示例代码 作者： Sean Robertson 这是我们关于“NLP From Scratch”的三个教程中的第二个。 在第一个教程 中，我们使用了 RNN 将名称分类为来源语言。 这次，我们将转过来并使用语言生成名称。 > python sample.py Russian RUS Rovakov Uantov Shavakov > python sample.py German GER Gerren Ereng Rosher > python sample.py Spanish SPA Salla Parer Allan > python sample.py Chinese CHI Chan Hang Iun 我们仍在手工制作带有一些线性层的小型 RNN。 最大的区别在于，我们无需输入名称中的所有字母即可预测类别，而是输入类别并一次输出一个字母。 反复预测字符以形成语言(这也可以用单词或其他高阶结构来完成）通常称为“语言模型”。 推荐读物： 我假设您至少已经安装了 PyTorch，了解 Python 和了解 Tensors： https://pytorch.org/ 有关安装说明 使用 PyTorch 进行深度学习：60 分钟的闪电战通常开始使用 PyTorch 使用示例学习 PyTorch 进行广泛而深入的概述 PyTorch(以前的 Torch 用户）(如果您以前是 Lua Torch 用户） 了解 RNN 及其工作方式也将很有用： 循环神经网络的不合理效果显示了许多现实生活中的例子 了解 LSTM 网络特别是关于 LSTM 的，但总体上也关于 RNN 的 我还建议上一个教程从头开始进行 NLP：使用字符级 RNN 对名称进行分类 准备数据 Note 从的下载数据，并将其提取到当前目录。 有关此过程的更多详细信息，请参见上一教程。 简而言之，有一堆纯文本文件data/names/[Language].txt，每行都有一个名称。 我们将行分割成一个数组，将 Unicode 转换为 ASCII，最后得到一个字典{language: [names ...]}。 from __future__ import unicode_literals, print_function, division from io import open import glob import os import unicodedata import string all_letters = string.ascii_letters + \" .,;'-\" n_letters = len(all_letters) + 1 # Plus EOS marker def findFiles(path): return glob.glob(path) # Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427 def unicodeToAscii(s): return ''.join( c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn' and c in all_letters ) # Read a file and split into lines def readLines(filename): lines = open(filename, encoding='utf-8').read().strip().split('\\n') return [unicodeToAscii(line) for line in lines] # Build the category_lines dictionary, a list of lines per category category_lines = {} all_categories = [] for filename in findFiles('data/names/*.txt'): category = os.path.splitext(os.path.basename(filename))[0] all_categories.append(category) lines = readLines(filename) category_lines[category] = lines n_categories = len(all_categories) if n_categories == 0: raise RuntimeError('Data not found. Make sure that you downloaded data ' 'from https://download.pytorch.org/tutorial/data.zip and extract it to ' 'the current directory.') print('# categories:', n_categories, all_categories) print(unicodeToAscii(\"O'Néàl\")) 出： # categories: 18 ['French', 'Czech', 'Dutch', 'Polish', 'Scottish', 'Chinese', 'English', 'Italian', 'Portuguese', 'Japanese', 'German', 'Russian', 'Korean', 'Arabic', 'Greek', 'Vietnamese', 'Spanish', 'Irish'] O'Neal 建立网络 该网络使用最后一个教程的 RNN 扩展了，并为类别张量附加了一个参数，该参数与其他张量串联在一起。 类别张量是一个热向量，就像字母输入一样。 我们将输出解释为下一个字母的概率。 采样时，最有可能的输出字母用作下一个输入字母。 我添加了第二个线性层o2o(将隐藏和输出结合在一起之后），以使它具有更多的肌肉可以使用。 还有一个辍学层，以给定的概率(此处为 0.1）将输入的部分随机归零，通常用于模糊输入以防止过拟合。 在这里，我们在网络的末端使用它来故意添加一些混乱并增加采样种类。 import torch import torch.nn as nn class RNN(nn.Module): def __init__(self, input_size, hidden_size, output_size): super(RNN, self).__init__() self.hidden_size = hidden_size self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size) self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size) self.o2o = nn.Linear(hidden_size + output_size, output_size) self.dropout = nn.Dropout(0.1) self.softmax = nn.LogSoftmax(dim=1) def forward(self, category, input, hidden): input_combined = torch.cat((category, input, hidden), 1) hidden = self.i2h(input_combined) output = self.i2o(input_combined) output_combined = torch.cat((hidden, output), 1) output = self.o2o(output_combined) output = self.dropout(output) output = self.softmax(output) return output, hidden def initHidden(self): return torch.zeros(1, self.hidden_size) 训练 准备训练 首先，helper 函数获取随机对(类别，行）： import random # Random item from a list def randomChoice(l): return l[random.randint(0, len(l) - 1)] # Get a random category and random line from that category def randomTrainingPair(): category = randomChoice(all_categories) line = randomChoice(category_lines[category]) return category, line 对于每个时间步(即，对于训练词中的每个字母），网络的输入将为(category, current letter, hidden state)，而输出将为(next letter, next hidden state)。 因此，对于每个训练集，我们都需要类别，一组输入字母和一组输出/目标字母。 由于我们正在预测每个时间步中当前字母的下一个字母，因此字母对是该行中连续字母的组-例如 对于\"ABCD&lt;EOS&gt;\"，我们将创建(“ A”，“ B”），(“ B”，“ C”），(“ C”，“ D”），(“ D”，“ EOS”）。 类别张量是大小为&lt;1 x n_categories&gt;的一热张量。 训练时，我们会随时随地将其馈送到网络中-这是一种设计选择，它可能已被包含为初始隐藏状态或某些其他策略的一部分。 # One-hot vector for category def categoryTensor(category): li = all_categories.index(category) tensor = torch.zeros(1, n_categories) tensor[0][li] = 1 return tensor # One-hot matrix of first to last letters (not including EOS) for input def inputTensor(line): tensor = torch.zeros(len(line), 1, n_letters) for li in range(len(line)): letter = line[li] tensor[li][0][all_letters.find(letter)] = 1 return tensor # LongTensor of second letter to end (EOS) for target def targetTensor(line): letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))] letter_indexes.append(n_letters - 1) # EOS return torch.LongTensor(letter_indexes) 为了方便训练，我们将使用randomTrainingExample函数来提取随机(类别，行）对，并将其转换为所需的(类别，输入，目标）张量。 # Make category, input, and target tensors from a random category, line pair def randomTrainingExample(): category, line = randomTrainingPair() category_tensor = categoryTensor(category) input_line_tensor = inputTensor(line) target_line_tensor = targetTensor(line) return category_tensor, input_line_tensor, target_line_tensor 训练网络 与仅使用最后一个输出的分类相反，我们在每个步骤进行预测，因此在每个步骤都计算损失。 autograd 的神奇之处在于，您可以简单地将每一步的损失相加，然后在末尾调用。 criterion = nn.NLLLoss() learning_rate = 0.0005 def train(category_tensor, input_line_tensor, target_line_tensor): target_line_tensor.unsqueeze_(-1) hidden = rnn.initHidden() rnn.zero_grad() loss = 0 for i in range(input_line_tensor.size(0)): output, hidden = rnn(category_tensor, input_line_tensor[i], hidden) l = criterion(output, target_line_tensor[i]) loss += l loss.backward() for p in rnn.parameters(): p.data.add_(-learning_rate, p.grad.data) return output, loss.item() / input_line_tensor.size(0) 为了跟踪训练需要多长时间，我添加了一个timeSince(timestamp)函数，该函数返回人类可读的字符串： import time import math def timeSince(since): now = time.time() s = now - since m = math.floor(s / 60) s -= m * 60 return '%dm %ds' % (m, s) 训练照常进行-召集训练多次，等待几分钟，每print_every个示例打印当前时间和损失，并在all_losses中将每个plot_every实例的平均损失存储下来，以便以后进行绘图。 rnn = RNN(n_letters, 128, n_letters) n_iters = 100000 print_every = 5000 plot_every = 500 all_losses = [] total_loss = 0 # Reset every plot_every iters start = time.time() for iter in range(1, n_iters + 1): output, loss = train(*randomTrainingExample()) total_loss += loss if iter % print_every == 0: print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss)) if iter % plot_every == 0: all_losses.append(total_loss / plot_every) total_loss = 0 Out: 0m 21s (5000 5%) 2.7607 0m 41s (10000 10%) 2.8047 1m 0s (15000 15%) 3.8541 1m 19s (20000 20%) 2.1222 1m 39s (25000 25%) 3.7181 1m 58s (30000 30%) 2.6274 2m 17s (35000 35%) 2.4538 2m 37s (40000 40%) 1.3385 2m 56s (45000 45%) 2.1603 3m 15s (50000 50%) 2.2497 3m 35s (55000 55%) 2.7588 3m 54s (60000 60%) 2.3754 4m 13s (65000 65%) 2.2863 4m 33s (70000 70%) 2.3610 4m 52s (75000 75%) 3.1793 5m 11s (80000 80%) 2.3203 5m 31s (85000 85%) 2.5548 5m 50s (90000 90%) 2.7351 6m 9s (95000 95%) 2.7740 6m 29s (100000 100%) 2.9683 绘制损失 绘制 all_losses 的历史损失可显示网络学习情况： import matplotlib.pyplot as plt import matplotlib.ticker as ticker plt.figure() plt.plot(all_losses) 网络采样 为了示例，我们给网络一个字母，询问下一个字母是什么，将其作为下一个字母输入，并重复直到 EOS 令牌。 为输入类别，起始字母和空隐藏状态创建张量 用起始字母创建一个字符串output_name 直到最大输出长度， 将当前信件输入网络 从最高输出中获取下一个字母，以及下一个隐藏状态 如果字母是 EOS，请在此处停止 如果是普通字母，请添加到output_name并继续 返回姓氏 Note 不必给它起一个开始字母，另一种策略是在训练中包括一个“字符串开始”令牌，并让网络选择自己的开始字母。 max_length = 20 # Sample from a category and starting letter def sample(category, start_letter='A'): with torch.no_grad(): # no need to track history in sampling category_tensor = categoryTensor(category) input = inputTensor(start_letter) hidden = rnn.initHidden() output_name = start_letter for i in range(max_length): output, hidden = rnn(category_tensor, input[0], hidden) topv, topi = output.topk(1) topi = topi[0][0] if topi == n_letters - 1: break else: letter = all_letters[topi] output_name += letter input = inputTensor(letter) return output_name # Get multiple samples from one category and multiple starting letters def samples(category, start_letters='ABC'): for start_letter in start_letters: print(sample(category, start_letter)) samples('Russian', 'RUS') samples('German', 'GER') samples('Spanish', 'SPA') samples('Chinese', 'CHI') Out: Rovakovak Uariki Sakilok Gare Eren Rour Salla Pare Alla Cha Honggg Iun 练习题 尝试使用其他类别的数据集->行，例如： 虚构系列->角色名称 词性->词 国家->城市 使用“句子开头”标记，以便可以在不选择开始字母的情况下进行采样 通过更大和/或形状更好的网络获得更好的结果 尝试 nn.LSTM 和 nn.GRU 层 将多个这些 RNN 合并为更高级别的网络 脚本的总运行时间：(6 分钟 29.292 秒） Download Python source code: char_rnn_generation_tutorial.py Download Jupyter notebook: char_rnn_generation_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:28:07 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"19.html":{"url":"19.html","title":"NLP From Scratch: 基于注意力机制的 seq2seq 神经网络翻译","keywords":"","body":"NLP From Scratch: 基于注意力机制的 seq2seq 神经网络翻译 原文： https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html 注意 单击此处的下载完整的示例代码 作者： Sean Robertson 这是关于“从头开始进行 NLP”的第三篇也是最后一篇教程，我们在其中编写自己的类和函数来预处理数据以完成 NLP 建模任务。 我们希望在完成本教程后，您将继续学习紧接着本教程的三本教程， torchtext 如何为您处理许多此类预处理。 在这个项目中，我们将教授将法语翻译成英语的神经网络。 [KEY: > input, = target, il est en train de peindre un tableau . = he is painting a picture . pourquoi ne pas essayer ce vin delicieux ? = why not try that delicious wine ? elle n est pas poete mais romanciere . = she is not a poet but a novelist . vous etes trop maigre . = you re too skinny . ……取得不同程度的成功。 通过序列到序列网络的简单但强大的构想，使这成为可能，在该网络中，两个循环神经网络协同工作，将一个序列转换为另一个序列。 编码器网络将输入序列压缩为一个向量，而解码器网络将该向量展开为一个新序列。 为了改进此模型，我们将使用注意机制，该机制可让解码器学习将注意力集中在输入序列的特定范围内。 推荐读物： 我假设您至少已经安装了 PyTorch，了解 Python 和了解 Tensors： https://pytorch.org/ 有关安装说明 使用 PyTorch 进行深度学习：60 分钟的闪电战通常开始使用 PyTorch 使用示例学习 PyTorch 进行广泛而深入的概述 PyTorch(以前的 Torch 用户）(如果您以前是 Lua Torch 用户） 了解序列到序列网络及其工作方式也将很有用： 使用 RNN 编解码器学习短语表示法以进行统计机器翻译 序列到神经网络的序列学习 通过共同学习对齐和翻译的神经机器翻译 神经对话模型 您还将找到先前的 NLP 从零开始：使用字符级 RNN 对名称进行分类的教程，以及 NLP 从零开始：使用字符级 RNN 生成名称的指南，因为这些概念是有用的 分别与编码器和解码器模型非常相似。 有关更多信息，请阅读介绍以下主题的论文： 使用 RNN 编解码器学习短语表示法以进行统计机器翻译 序列到神经网络的序列学习 通过共同学习对齐和翻译的神经机器翻译 神经对话模型 要求 from __future__ import unicode_literals, print_function, division from io import open import unicodedata import string import re import random import torch import torch.nn as nn from torch import optim import torch.nn.functional as F device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") 加载数据文件 该项目的数据是成千上万的英语到法语翻译对的集合。 开放数据堆栈交换上的这个问题使我指向开放翻译站点 https://tatoeba.org/ ，该站点可从 https://tatoeba.org/下载。 eng / downloads -更好的是，有人在这里做了额外的工作，将语言对拆分为单独的文本文件： https://www.manythings.org/anki/ 英文对法文对太大，无法包含在仓库中，因此请先下载到data/eng-fra.txt，然后再继续。 该文件是制表符分隔的翻译对列表： I am cold. J'ai froid. Note 从的下载数据，并将其提取到当前目录。 与字符级 RNN 教程中使用的字符编码类似，我们将一种语言中的每个单词表示为一个单向矢量，或者零外的一个巨大矢量(除了单个索引(在单词的索引处））。 与一种语言中可能存在的数十个字符相比，单词有很多，因此编码向量要大得多。 但是，我们将作弊并整理数据以使每种语言仅使用几千个单词。 我们需要每个单词一个唯一的索引，以便以后用作网络的输入和目标。 为了跟踪所有这些信息，我们将使用一个名为Lang的帮助程序类，该类具有单词→索引(word2index）和索引→单词(index2word）字典，以及每个要使用的单词word2count的计数 以便以后替换稀有词。 SOS_token = 0 EOS_token = 1 class Lang: def __init__(self, name): self.name = name self.word2index = {} self.word2count = {} self.index2word = {0: \"SOS\", 1: \"EOS\"} self.n_words = 2 # Count SOS and EOS def addSentence(self, sentence): for word in sentence.split(' '): self.addWord(word) def addWord(self, word): if word not in self.word2index: self.word2index[word] = self.n_words self.word2count[word] = 1 self.index2word[self.n_words] = word self.n_words += 1 else: self.word2count[word] += 1 这些文件全部为 Unicode，为简化起见，我们将 Unicode 字符转换为 ASCII，将所有内容都转换为小写，并修剪大多数标点符号。 # Turn a Unicode string to plain ASCII, thanks to # https://stackoverflow.com/a/518232/2809427 def unicodeToAscii(s): return ''.join( c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn' ) # Lowercase, trim, and remove non-letter characters def normalizeString(s): s = unicodeToAscii(s.lower().strip()) s = re.sub(r\"([.!?])\", r\" \\1\", s) s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s) return s 要读取数据文件，我们将文件分成几行，然后将行分成两对。 这些文件都是英语→其他语言的，因此，如果我们要从其他语言→英语进行翻译，我添加了reverse标志来反转对。 def readLangs(lang1, lang2, reverse=False): print(\"Reading lines...\") # Read the file and split into lines lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\ read().strip().split('\\n') # Split every line into pairs and normalize pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines] # Reverse pairs, make Lang instances if reverse: pairs = [list(reversed(p)) for p in pairs] input_lang = Lang(lang2) output_lang = Lang(lang1) else: input_lang = Lang(lang1) output_lang = Lang(lang2) return input_lang, output_lang, pairs 由于示例句子的数量很多，并且我们想快速训练一些东西，因此我们将数据集修剪为仅相对较短和简单的句子。 在这里，最大长度为 10 个字(包括结尾的标点符号），并且我们正在过滤翻译成“我是”或“他是”等形式的句子(考虑到前面已替换掉撇号的情况）。 MAX_LENGTH = 10 eng_prefixes = ( \"i am \", \"i m \", \"he is\", \"he s \", \"she is\", \"she s \", \"you are\", \"you re \", \"we are\", \"we re \", \"they are\", \"they re \" ) def filterPair(p): return len(p[0].split(' ')) 准备数据的完整过程是： 读取文本文件并拆分为行，将行拆分为成对 规范文本，按长度和内容过滤 成对建立句子中的单词列表 def prepareData(lang1, lang2, reverse=False): input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse) print(\"Read %s sentence pairs\" % len(pairs)) pairs = filterPairs(pairs) print(\"Trimmed to %s sentence pairs\" % len(pairs)) print(\"Counting words...\") for pair in pairs: input_lang.addSentence(pair[0]) output_lang.addSentence(pair[1]) print(\"Counted words:\") print(input_lang.name, input_lang.n_words) print(output_lang.name, output_lang.n_words) return input_lang, output_lang, pairs input_lang, output_lang, pairs = prepareData('eng', 'fra', True) print(random.choice(pairs)) 出： Reading lines... Read 135842 sentence pairs Trimmed to 10599 sentence pairs Counting words... Counted words: fra 4345 eng 2803 ['je ne suis pas grand .', 'i m not tall .'] Seq2Seq 模型 递归神经网络(RNN）是在序列上运行并将其自身的输出用作后续步骤的输入的网络。 序列到序列网络或 seq2seq 网络或编码器解码器网络是由两个称为编码器和解码器的 RNN 组成的模型。 编码器读取输入序列并输出单个向量，而解码器读取该向量以产生输出序列。 与使用单个 RNN 进行序列预测(每个输入对应一个输出）不同，seq2seq 模型使我们摆脱了序列长度和顺序的限制，这使其非常适合在两种语言之间进行翻译。 考虑一下句子“ Je ne suis pas le chat noir”→“我不是黑猫”。 输入句子中的大多数单词在输出句子中具有直接翻译，但是顺序略有不同，例如 “黑猫聊天”和“黑猫”。 由于采用“ ne / pas”结构，因此在输入句子中还有一个单词。 直接从输入单词的序列中产生正确的翻译将是困难的。 使用 seq2seq 模型，编码器创建单个矢量，在理想情况下，该矢量将输入序列的“含义”编码为单个矢量-句子的某些 N 维空间中的单个点。 编码器 seq2seq 网络的编码器是 RNN，它为输入句子中的每个单词输出一些值。 对于每个输入字，编码器输出一个向量和一个隐藏状态，并将隐藏状态用于下一个输入字。 class EncoderRNN(nn.Module): def __init__(self, input_size, hidden_size): super(EncoderRNN, self).__init__() self.hidden_size = hidden_size self.embedding = nn.Embedding(input_size, hidden_size) self.gru = nn.GRU(hidden_size, hidden_size) def forward(self, input, hidden): embedded = self.embedding(input).view(1, 1, -1) output = embedded output, hidden = self.gru(output, hidden) return output, hidden def initHidden(self): return torch.zeros(1, 1, self.hidden_size, device=device) 解码器 解码器是另一个 RNN，它采用编码器输出矢量并输出单词序列来创建翻译。 简单解码器 在最简单的 seq2seq 解码器中，我们仅使用编码器的最后一个输出。 最后的输出有时称为上下文向量，因为它对整个序列的上下文进行编码。 该上下文向量用作解码器的初始隐藏状态。 在解码的每个步骤中，为解码器提供输入令牌和隐藏状态。 初始输入令牌是字符串开始&lt;SOS&gt;令牌，第一个隐藏状态是上下文向量(编码器的最后一个隐藏状态）。 class DecoderRNN(nn.Module): def __init__(self, hidden_size, output_size): super(DecoderRNN, self).__init__() self.hidden_size = hidden_size self.embedding = nn.Embedding(output_size, hidden_size) self.gru = nn.GRU(hidden_size, hidden_size) self.out = nn.Linear(hidden_size, output_size) self.softmax = nn.LogSoftmax(dim=1) def forward(self, input, hidden): output = self.embedding(input).view(1, 1, -1) output = F.relu(output) output, hidden = self.gru(output, hidden) output = self.softmax(self.out(output[0])) return output, hidden def initHidden(self): return torch.zeros(1, 1, self.hidden_size, device=device) 我鼓励您训练并观察该模型的结果，但是为了节省空间，我们将直接努力，并引入注意机制。 注意解码器 如果仅上下文向量在编码器和解码器之间传递，则该单个向量承担对整个句子进行编码的负担。 注意使解码器网络可以针对解码器自身输出的每一步，“专注”于编码器输出的不同部分。 首先，我们计算一组注意权重。 将这些与编码器输出向量相乘以创建加权组合。 结果(在代码中称为attn_applied）应包含有关输入序列特定部分的信息，从而帮助解码器选择正确的输出字。 计算注意力权重的方法是使用另一个前馈层attn，并使用解码器的输入和隐藏状态作为输入。 由于训练数据中包含各种大小的句子，因此要实际创建和训练该层，我们必须选择可以应用的最大句子长度(输入长度​​，用于编码器输出）。 最大长度的句子将使用所有注意权重，而较短的句子将仅使用前几个。 class AttnDecoderRNN(nn.Module): def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH): super(AttnDecoderRNN, self).__init__() self.hidden_size = hidden_size self.output_size = output_size self.dropout_p = dropout_p self.max_length = max_length self.embedding = nn.Embedding(self.output_size, self.hidden_size) self.attn = nn.Linear(self.hidden_size * 2, self.max_length) self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size) self.dropout = nn.Dropout(self.dropout_p) self.gru = nn.GRU(self.hidden_size, self.hidden_size) self.out = nn.Linear(self.hidden_size, self.output_size) def forward(self, input, hidden, encoder_outputs): embedded = self.embedding(input).view(1, 1, -1) embedded = self.dropout(embedded) attn_weights = F.softmax( self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1) attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0)) output = torch.cat((embedded[0], attn_applied[0]), 1) output = self.attn_combine(output).unsqueeze(0) output = F.relu(output) output, hidden = self.gru(output, hidden) output = F.log_softmax(self.out(output[0]), dim=1) return output, hidden, attn_weights def initHidden(self): return torch.zeros(1, 1, self.hidden_size, device=device) Note 还有其他形式的注意力可以通过使用相对位置方法来解决长度限制问题。 阅读基于注意力的神经机器翻译的有效方法中的“本地注意力”信息。 训练 准备训练数据 为了训练，对于每一对，我们将需要一个输入张量(输入句子中单词的索引）和目标张量(目标句子中单词的索引）。 创建这些向量时，我们会将 EOS 令牌附加到两个序列上。 def indexesFromSentence(lang, sentence): return [lang.word2index[word] for word in sentence.split(' ')] def tensorFromSentence(lang, sentence): indexes = indexesFromSentence(lang, sentence) indexes.append(EOS_token) return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1) def tensorsFromPair(pair): input_tensor = tensorFromSentence(input_lang, pair[0]) target_tensor = tensorFromSentence(output_lang, pair[1]) return (input_tensor, target_tensor) 训练模型 为了进行训练，我们通过编码器运行输入语句，并跟踪每个输出和最新的隐藏状态。 然后，为解码器提供&lt;SOS&gt;令牌作为其第一个输入，并将编码器的最后一个隐藏状态作为其第一个隐藏状态。 “教师强制”的概念是使用实际目标输出作为每个下一个输入，而不是使用解码器的猜测作为下一个输入。 使用教师强制会导致其收敛更快，但是当使用受过训练的网络时，可能会显示不稳定。 您可以观察到以教师为主导的网络的输出，这些输出阅读的是连贯的语法，但却偏离了正确的翻译-直观地，它学会了代表输出语法，并且一旦老师说了最初的几个单词就可以“理解”含义，但是 首先，它还没有正确地学习如何从翻译中创建句子。 由于 PyTorch 的 autograd 具有给我们的自由，我们可以通过简单的 if 语句随意选择是否使用教师强迫。 调高teacher_forcing_ratio以使用更多功能。 teacher_forcing_ratio = 0.5 def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH): encoder_hidden = encoder.initHidden() encoder_optimizer.zero_grad() decoder_optimizer.zero_grad() input_length = input_tensor.size(0) target_length = target_tensor.size(0) encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device) loss = 0 for ei in range(input_length): encoder_output, encoder_hidden = encoder( input_tensor[ei], encoder_hidden) encoder_outputs[ei] = encoder_output[0, 0] decoder_input = torch.tensor([[SOS_token]], device=device) decoder_hidden = encoder_hidden use_teacher_forcing = True if random.random() 这是一个帮助功能，用于在给定当前时间和进度％的情况下打印经过的时间和估计的剩余时间。 import time import math def asMinutes(s): m = math.floor(s / 60) s -= m * 60 return '%dm %ds' % (m, s) def timeSince(since, percent): now = time.time() s = now - since es = s / (percent) rs = es - s return '%s (- %s)' % (asMinutes(s), asMinutes(rs)) 整个训练过程如下所示： 启动计时器 初始化优化器和标准 创建一组训练对 启动空损耗阵列进行绘图 然后我们多次调用train，并偶尔打印进度(示例的百分比，到目前为止的时间，估计的时间）和平均损失。 def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01): start = time.time() plot_losses = [] print_loss_total = 0 # Reset every print_every plot_loss_total = 0 # Reset every plot_every encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate) decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate) training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)] criterion = nn.NLLLoss() for iter in range(1, n_iters + 1): training_pair = training_pairs[iter - 1] input_tensor = training_pair[0] target_tensor = training_pair[1] loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion) print_loss_total += loss plot_loss_total += loss if iter % print_every == 0: print_loss_avg = print_loss_total / print_every print_loss_total = 0 print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters), iter, iter / n_iters * 100, print_loss_avg)) if iter % plot_every == 0: plot_loss_avg = plot_loss_total / plot_every plot_losses.append(plot_loss_avg) plot_loss_total = 0 showPlot(plot_losses) 绘图结果 使用训练时保存的损失值数组plot_losses，使用 matplotlib 进行绘制。 import matplotlib.pyplot as plt plt.switch_backend('agg') import matplotlib.ticker as ticker import numpy as np def showPlot(points): plt.figure() fig, ax = plt.subplots() # this locator puts ticks at regular intervals loc = ticker.MultipleLocator(base=0.2) ax.yaxis.set_major_locator(loc) plt.plot(points) 评价 评估与训练基本相同，但是没有目标，因此我们只需将解码器的预测反馈给每一步。 每当它预测一个单词时，我们都会将其添加到输出字符串中，如果它预测到 EOS 令牌，我们将在此处停止。 我们还将存储解码器的注意输出，以供以后显示。 def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH): with torch.no_grad(): input_tensor = tensorFromSentence(input_lang, sentence) input_length = input_tensor.size()[0] encoder_hidden = encoder.initHidden() encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device) for ei in range(input_length): encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden) encoder_outputs[ei] += encoder_output[0, 0] decoder_input = torch.tensor([[SOS_token]], device=device) # SOS decoder_hidden = encoder_hidden decoded_words = [] decoder_attentions = torch.zeros(max_length, max_length) for di in range(max_length): decoder_output, decoder_hidden, decoder_attention = decoder( decoder_input, decoder_hidden, encoder_outputs) decoder_attentions[di] = decoder_attention.data topv, topi = decoder_output.data.topk(1) if topi.item() == EOS_token: decoded_words.append('') break else: decoded_words.append(output_lang.index2word[topi.item()]) decoder_input = topi.squeeze().detach() return decoded_words, decoder_attentions[:di + 1] 我们可以从训练集中评估随机句子，并打印出输入，目标和输出以做出一些主观的质量判断： def evaluateRandomly(encoder, decoder, n=10): for i in range(n): pair = random.choice(pairs) print('>', pair[0]) print('=', pair[1]) output_words, attentions = evaluate(encoder, decoder, pair[0]) output_sentence = ' '.join(output_words) print('训练与评估 有了所有这些帮助器功能(看起来像是额外的工作，但它使运行多个实验更加容易），我们实际上可以初始化网络并开始训练。 请记住，输入句子已被严格过滤。 对于这个小的数据集，我们可以使用具有 256 个隐藏节点和单个 GRU 层的相对较小的网络。 在 MacBook CPU 上运行约 40 分钟后，我们将获得一些合理的结果。 Note 如果运行此笔记本，则可以进行训练，中断内核，评估并在以后继续进行训练。 注释掉编码器和解码器已初始化的行，然后再次运行trainIters。 hidden_size = 256 encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device) attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device) trainIters(encoder1, attn_decoder1, 75000, print_every=5000) Out: 1m 54s (- 26m 42s) (5000 6%) 2.8452 3m 44s (- 24m 19s) (10000 13%) 2.2926 5m 34s (- 22m 17s) (15000 20%) 1.9628 7m 24s (- 20m 23s) (20000 26%) 1.7224 9m 15s (- 18m 31s) (25000 33%) 1.4997 11m 7s (- 16m 41s) (30000 40%) 1.3610 12m 58s (- 14m 49s) (35000 46%) 1.2299 14m 48s (- 12m 57s) (40000 53%) 1.0881 16m 38s (- 11m 5s) (45000 60%) 0.9991 18m 29s (- 9m 14s) (50000 66%) 0.9053 20m 19s (- 7m 23s) (55000 73%) 0.8031 22m 8s (- 5m 32s) (60000 80%) 0.7141 23m 58s (- 3m 41s) (65000 86%) 0.6693 25m 48s (- 1m 50s) (70000 93%) 0.6342 27m 38s (- 0m 0s) (75000 100%) 0.5604 evaluateRandomly(encoder1, attn_decoder1) Out: > je suis tres serieux . = i m quite serious . > tu es creatif . = you re creative . > j attends de vos nouvelles . = i m looking forward to hearing from you . > tu es un de ces pauvres types ! = you re such a jerk . > je ne suis pas si preoccupe . = i m not that worried . > vous etes avides . = you re greedy . > ils ne sont pas satisfaits . = they re not happy . > nous avons tous peur . = we re all afraid . > nous sommes tous uniques . = we re all unique . > c est un tres chouette garcon . = he s a very nice boy . 可视化注意力 注意机制的一个有用特性是其高度可解释的输出。 因为它用于加权输入序列的特定编码器输出，所以我们可以想象一下在每个时间步长上网络最关注的位置。 您可以简单地运行plt.matshow(attentions)以将注意力输出显示为矩阵，其中列为输入步骤，行为输出步骤： output_words, attentions = evaluate( encoder1, attn_decoder1, \"je suis trop froid .\") plt.matshow(attentions.numpy()) 为了获得更好的观看体验，我们将做一些额外的工作来添加轴和标签： def showAttention(input_sentence, output_words, attentions): # Set up figure with colorbar fig = plt.figure() ax = fig.add_subplot(111) cax = ax.matshow(attentions.numpy(), cmap='bone') fig.colorbar(cax) # Set up axes ax.set_xticklabels([''] + input_sentence.split(' ') + [''], rotation=90) ax.set_yticklabels([''] + output_words) # Show label at every tick ax.xaxis.set_major_locator(ticker.MultipleLocator(1)) ax.yaxis.set_major_locator(ticker.MultipleLocator(1)) plt.show() def evaluateAndShowAttention(input_sentence): output_words, attentions = evaluate( encoder1, attn_decoder1, input_sentence) print('input =', input_sentence) print('output =', ' '.join(output_words)) showAttention(input_sentence, output_words, attentions) evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\") evaluateAndShowAttention(\"elle est trop petit .\") evaluateAndShowAttention(\"je ne crains pas de mourir .\") evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\") Out: input = elle a cinq ans de moins que moi . output = she is five years years years years . input = elle est trop petit . output = she is too short . input = je ne crains pas de mourir . output = i m not scared of dying . input = c est un jeune directeur plein de talent . output = he s a talented young director . 练习题 尝试使用其他数据集 另一对语言 人机→机器(例如 IOT 命令） 聊天→回复 问题→答案 用预先训练的单词嵌入(例如 word2vec 或 GloVe）替换嵌入 尝试使用更多层，更多隐藏单元和更多句子。 比较训练时间和结果。 如果您使用的翻原文件中，对具有两个相同的词组(I am test \\t I am test），则可以将其用作自动编码器。 尝试这个： 训练为自动编码器 仅保存编码器网络 从那里训练新的解码器进行翻译 脚本的总运行时间：(27 分钟 45.966 秒） Download Python source code: seq2seq_translation_tutorial.py Download Jupyter notebook: seq2seq_translation_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:28:57 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"20.html":{"url":"20.html","title":"使用 TorchText 进行文本分类","keywords":"","body":"使用 TorchText 进行文本分类 原文： https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html 注意 单击此处的下载完整的示例代码 本教程介绍了如何使用torchtext中的文本分类数据集，包括 - AG_NEWS, - SogouNews, - DBpedia, - YelpReviewPolarity, - YelpReviewFull, - YahooAnswers, - AmazonReviewPolarity, - AmazonReviewFull 本示例说明了如何使用这些TextClassification数据集之一训练用于分类的监督学习算法。 用 ngram 加载数据 一袋 ngrams 功能用于捕获有关本地单词顺序的一些部分信息。 在实践中，应用二元语法或三元语法作为单词组比仅仅一个单词提供更多的好处。 一个例子： \"load data with ngrams\" Bi-grams results: \"load data\", \"data with\", \"with ngrams\" Tri-grams results: \"load data with\", \"data with ngrams\" TextClassification数据集支持 ngrams 方法。 通过将 ngrams 设置为 2，数据集中的示例文本将是一个单字加 bi-grams 字符串的列表。 import torch import torchtext from torchtext.datasets import text_classification NGRAMS = 2 import os if not os.path.isdir('./.data'): os.mkdir('./.data') train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS']( root='./.data', ngrams=NGRAMS, vocab=None) BATCH_SIZE = 16 device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") 定义模型 该模型由 EmbeddingBag 层和线性层组成(请参见下图）。 nn.EmbeddingBag计算嵌入“袋”的平均值。 此处的文本条目具有不同的长度。 nn.EmbeddingBag此处不需要填充，因为文本长度以偏移量保存。 另外，由于nn.EmbeddingBag会动态累积嵌入中的平均值，因此nn.EmbeddingBag可以提高性能和存储效率，以处理张量序列。 import torch.nn as nn import torch.nn.functional as F class TextSentiment(nn.Module): def __init__(self, vocab_size, embed_dim, num_class): super().__init__() self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True) self.fc = nn.Linear(embed_dim, num_class) self.init_weights() def init_weights(self): initrange = 0.5 self.embedding.weight.data.uniform_(-initrange, initrange) self.fc.weight.data.uniform_(-initrange, initrange) self.fc.bias.data.zero_() def forward(self, text, offsets): embedded = self.embedding(text, offsets) return self.fc(embedded) 启动实例 AG_NEWS 数据集具有四个标签，因此类别数是四个。 1 : World 2 : Sports 3 : Business 4 : Sci/Tec 词汇的大小等于词汇的长度(包括单个单词和 ngram）。 类的数量等于标签的数量，在 AG_NEWS 情况下为 4。 VOCAB_SIZE = len(train_dataset.get_vocab()) EMBED_DIM = 32 NUN_CLASS = len(train_dataset.get_labels()) model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device) 用于生成批处理的函数 由于文本条目的长度不同，因此使用自定义函数 generate_batch(）生成数据批和偏移量。 该功能将传递到torch.utils.data.DataLoader中的collate_fn。 collate_fn的输入是张量为 list_batch_size 的张量列表，collate_fn函数将它们打包成一个小批量。 请注意此处，并确保将collate_fn声明为顶级 def。 这样可以确保该功能在每个工作程序中均可用。 原始数据批处理输入中的文本条目打包到一个列表中，并作为单个张量级联，作为nn.EmbeddingBag的输入。 偏移量是定界符的张量，表示文本张量中各个序列的起始索引。 Label 是一个张量，用于保存单个文本条目的标签。 def generate_batch(batch): label = torch.tensor([entry[0] for entry in batch]) text = [entry[1] for entry in batch] offsets = [0] + [len(entry) for entry in text] # torch.Tensor.cumsum returns the cumulative sum # of elements in the dimension dim. # torch.Tensor([1.0, 2.0, 3.0]).cumsum(dim=0) offsets = torch.tensor(offsets[:-1]).cumsum(dim=0) text = torch.cat(text) return text, offsets, label 定义功能以训练模型并评估结果。 建议 PyTorch 用户使用 torch.utils.data.DataLoader ，它可以轻松地并行加载数据(教程为，此处为）。 我们在此处使用DataLoader加载 AG_NEWS 数据集并将其发送到模型以进行训练/验证。 from torch.utils.data import DataLoader def train_func(sub_train_): # Train the model train_loss = 0 train_acc = 0 data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch) for i, (text, offsets, cls) in enumerate(data): optimizer.zero_grad() text, offsets, cls = text.to(device), offsets.to(device), cls.to(device) output = model(text, offsets) loss = criterion(output, cls) train_loss += loss.item() loss.backward() optimizer.step() train_acc += (output.argmax(1) == cls).sum().item() # Adjust the learning rate scheduler.step() return train_loss / len(sub_train_), train_acc / len(sub_train_) def test(data_): loss = 0 acc = 0 data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch) for text, offsets, cls in data: text, offsets, cls = text.to(device), offsets.to(device), cls.to(device) with torch.no_grad(): output = model(text, offsets) loss = criterion(output, cls) loss += loss.item() acc += (output.argmax(1) == cls).sum().item() return loss / len(data_), acc / len(data_) 分割数据集并运行模型 由于原始 AG_NEWS 没有有效的数据集，因此我们将训练数据集分为训练/有效集，其分割比率为 0.95(训练）和 0.05(有效）。 在这里，我们在 PyTorch 核心库中使用 torch.utils.data.dataset.random_split 函数。 CrossEntropyLoss 标准将 nn.LogSoftmax(）和 nn.NLLLoss(）合并到一个类中。 在训练带有 C 类的分类问题时很有用。 SGD 实现了随机梯度下降方法作为优化程序。 初始学习率设置为 4.0。 StepLR 在此处用于通过历时调整学习率。 import time from torch.utils.data.dataset import random_split N_EPOCHS = 5 min_valid_loss = float('inf') criterion = torch.nn.CrossEntropyLoss().to(device) optimizer = torch.optim.SGD(model.parameters(), lr=4.0) scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9) train_len = int(len(train_dataset) * 0.95) sub_train_, sub_valid_ = \\ random_split(train_dataset, [train_len, len(train_dataset) - train_len]) for epoch in range(N_EPOCHS): start_time = time.time() train_loss, train_acc = train_func(sub_train_) valid_loss, valid_acc = test(sub_valid_) secs = int(time.time() - start_time) mins = secs / 60 secs = secs % 60 print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs)) print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)') print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)') 出： Epoch: 1 | time in 0 minutes, 9 seconds Loss: 0.0263(train) | Acc: 84.6%(train) Loss: 0.0000(valid) | Acc: 90.1%(valid) Epoch: 2 | time in 0 minutes, 9 seconds Loss: 0.0120(train) | Acc: 93.6%(train) Loss: 0.0001(valid) | Acc: 91.4%(valid) Epoch: 3 | time in 0 minutes, 9 seconds Loss: 0.0070(train) | Acc: 96.4%(train) Loss: 0.0001(valid) | Acc: 91.7%(valid) Epoch: 4 | time in 0 minutes, 9 seconds Loss: 0.0039(train) | Acc: 98.0%(train) Loss: 0.0001(valid) | Acc: 91.4%(valid) Epoch: 5 | time in 0 minutes, 9 seconds Loss: 0.0023(train) | Acc: 99.0%(train) Loss: 0.0001(valid) | Acc: 91.7%(valid) 使用以下信息在 GPU 上运行模型： 纪元：1 | 时间在 0 分钟 11 秒 Loss: 0.0263(train) | Acc: 84.5%(train) Loss: 0.0001(valid) | Acc: 89.0%(valid) 纪元：2 | 时间在 0 分钟 10 秒内 Loss: 0.0119(train) | Acc: 93.6%(train) Loss: 0.0000(valid) | Acc: 89.6%(valid) 纪元：3 | 时间在 0 分钟 9 秒 Loss: 0.0069(train) | Acc: 96.4%(train) Loss: 0.0000(valid) | Acc: 90.5%(valid) 纪元：4 | 时间在 0 分钟 11 秒 Loss: 0.0038(train) | Acc: 98.2%(train) Loss: 0.0000(valid) | Acc: 90.4%(valid) 纪元：5 | 时间在 0 分钟 11 秒 Loss: 0.0022(train) | Acc: 99.0%(train) Loss: 0.0000(valid) | Acc: 91.0%(valid) 使用测试数据集评估模型 print('Checking the results of test dataset...') test_loss, test_acc = test(test_dataset) print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)') Out: Checking the results of test dataset... Loss: 0.0003(test) | Acc: 91.1%(test) 正在检查测试数据集的结果… Loss: 0.0237(test) | Acc: 90.5%(test) 测试随机新闻 使用到目前为止最好的模型并测试高尔夫新闻。 标签信息在可用。 import re from torchtext.data.utils import ngrams_iterator from torchtext.data.utils import get_tokenizer ag_news_label = {1 : \"World\", 2 : \"Sports\", 3 : \"Business\", 4 : \"Sci/Tec\"} def predict(text, model, vocab, ngrams): tokenizer = get_tokenizer(\"basic_english\") with torch.no_grad(): text = torch.tensor([vocab[token] for token in ngrams_iterator(tokenizer(text), ngrams)]) output = model(text, torch.tensor([0])) return output.argmax(1).item() + 1 ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\ enduring the season’s worst weather conditions on Sunday at The \\ Open on his way to a closing 75 at Royal Portrush, which \\ considering the wind and the rain was a respectable showing. \\ Thursday’s first round at the WGC-FedEx St. Jude Invitational \\ was another story. With temperatures in the mid-80s and hardly any \\ wind, the Spaniard was 13 strokes better in a flawless round. \\ Thanks to his best putting performance on the PGA Tour, Rahm \\ finished with an 8-under 62 for a three-stroke lead, which \\ was even more impressive considering he’d never played the \\ front nine at TPC Southwind.\" vocab = train_dataset.get_vocab() model = model.to(\"cpu\") print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, model, vocab, 2)]) Out: This is a Sports news 这是体育新闻 您可以在此处找到本说明中显示的代码示例。 脚本的总运行时间：(1 分钟 26.276 秒） Download Python source code: text_sentiment_ngrams_tutorial.py Download Jupyter notebook: text_sentiment_ngrams_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"21.html":{"url":"21.html","title":"使用 TorchText 进行语言翻译","keywords":"","body":"使用 TorchText 进行语言翻译 原文： https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html 注意 单击此处的下载完整的示例代码 本教程说明如何使用torchtext的几个便捷类来预处理包含英语和德语句子的著名数据集的数据，并使用它来训练序列到序列模型，并注意将德语句子翻译成英语 。 它基于 PyTorch 社区成员 Ben Trevett 的本教程，并由 Seth Weidman 在 Ben 的允许下创建。 在本教程结束时，您将能够： Preprocess sentences into a commonly-used format for NLP modeling using the following torchtext convenience classes: TranslationDataset 字段 BucketIterator 字段和 TranslationDataset torchtext具有用于创建数据集的实用程序，可以轻松地对其进行迭代，以创建语言翻译模型。 一个关键类是字段，它指定应该对每个句子进行预处理的方式，另一个关键类是 TranslationDataset ； torchtext有几个这样的数据集； 在本教程中，我们将使用 Multi30k 数据集，其中包含约 30,000 个英语和德语句子(平均长度约为 13 个单词）。 注意：本教程中的标记化需要 Spacy 我们使用 Spacy，因为它为英语以外的其他语言的标记化提供了强大的支持。 torchtext提供了basic_english标记器，并支持其他英语标记器(例如摩西），但对于语言翻译(需要多种语言），Spacy 是您的最佳选择。 要运行本教程，请先使用pip或conda安装spacy。 接下来，下载英语和德语 Spacy 分词器的原始数据： python -m spacy download en python -m spacy download de 安装 Spacy 后，以下代码将根据Field中定义的标记器，标记TranslationDataset中的每个句子。 from torchtext.datasets import Multi30k from torchtext.data import Field, BucketIterator SRC = Field(tokenize = \"spacy\", tokenizer_language=\"de\", init_token = '', eos_token = '', lower = True) TRG = Field(tokenize = \"spacy\", tokenizer_language=\"en\", init_token = '', eos_token = '', lower = True) train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), fields = (SRC, TRG)) 出： downloading training.tar.gz downloading validation.tar.gz downloading mmt_task1_test2016.tar.gz 现在我们已经定义了train_data，我们可以看到torchtext的Field的一个非常有用的功能：build_vocab方法现在允许我们创建与每种语言相关的词汇 SRC.build_vocab(train_data, min_freq = 2) TRG.build_vocab(train_data, min_freq = 2) 一旦运行了这些代码行，SRC.vocab.stoi将是一个词典，其词汇表中的标记作为键，而其对应的索引作为值； SRC.vocab.itos将是相同的字典，其中的键和值被交换。 在本教程中，我们不会广泛使用此事实，但这在您将遇到的其他 NLP 任务中可能很有用。 BucketIterator 我们将使用的最后torchtext个特定功能是BucketIterator，它很容易使用，因为它以TranslationDataset作为第一个参数。 具体来说，正如文档所说：定义一个迭代器，该迭代器将相似长度的示例批处理在一起。 在为每个新纪元生产新鲜改组的批次时，最大程度地减少所需的填充量。 有关使用的存储过程，请参阅池。 import torch device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') BATCH_SIZE = 128 train_iterator, valid_iterator, test_iterator = BucketIterator.splits( (train_data, valid_data, test_data), batch_size = BATCH_SIZE, device = device) 可以像DataLoader``s; below, in the ``train和evaluate函数一样调用这些迭代器，只需使用以下命令即可调用它们： for i, batch in enumerate(iterator): 每个batch然后具有src和trg属性： src = batch.src trg = batch.trg 定义我们的nn.Module和Optimizer 这大部分是从torchtext角度出发的：构建了数据集并定义了迭代器，本教程的其余部分仅将模型定义为nn.Module以及Optimizer，然后对其进行训练。 具体来说，我们的模型遵循在此处中描述的架构(您可以在此处找到更多注释的版本）。 注意：此模型只是可用于语言翻译的示例模型； 我们选择它是因为它是任务的标准模型，而不是因为它是用于翻译的推荐模型。 如您所知，目前最先进的模型基于“变形金刚”； 您可以在此处看到 PyTorch 的实现 Transformer 层的功能； 特别是，以下模型中使用的“注意”与变压器模型中存在的多头自我注意不同。 import random from typing import Tuple import torch.nn as nn import torch.optim as optim import torch.nn.functional as F from torch import Tensor class Encoder(nn.Module): def __init__(self, input_dim: int, emb_dim: int, enc_hid_dim: int, dec_hid_dim: int, dropout: float): super().__init__() self.input_dim = input_dim self.emb_dim = emb_dim self.enc_hid_dim = enc_hid_dim self.dec_hid_dim = dec_hid_dim self.dropout = dropout self.embedding = nn.Embedding(input_dim, emb_dim) self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True) self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim) self.dropout = nn.Dropout(dropout) def forward(self, src: Tensor) -> Tuple[Tensor]: embedded = self.dropout(self.embedding(src)) outputs, hidden = self.rnn(embedded) hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))) return outputs, hidden class Attention(nn.Module): def __init__(self, enc_hid_dim: int, dec_hid_dim: int, attn_dim: int): super().__init__() self.enc_hid_dim = enc_hid_dim self.dec_hid_dim = dec_hid_dim self.attn_in = (enc_hid_dim * 2) + dec_hid_dim self.attn = nn.Linear(self.attn_in, attn_dim) def forward(self, decoder_hidden: Tensor, encoder_outputs: Tensor) -> Tensor: src_len = encoder_outputs.shape[0] repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1) encoder_outputs = encoder_outputs.permute(1, 0, 2) energy = torch.tanh(self.attn(torch.cat(( repeated_decoder_hidden, encoder_outputs), dim = 2))) attention = torch.sum(energy, dim=2) return F.softmax(attention, dim=1) class Decoder(nn.Module): def __init__(self, output_dim: int, emb_dim: int, enc_hid_dim: int, dec_hid_dim: int, dropout: int, attention: nn.Module): super().__init__() self.emb_dim = emb_dim self.enc_hid_dim = enc_hid_dim self.dec_hid_dim = dec_hid_dim self.output_dim = output_dim self.dropout = dropout self.attention = attention self.embedding = nn.Embedding(output_dim, emb_dim) self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim) self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim) self.dropout = nn.Dropout(dropout) def _weighted_encoder_rep(self, decoder_hidden: Tensor, encoder_outputs: Tensor) -> Tensor: a = self.attention(decoder_hidden, encoder_outputs) a = a.unsqueeze(1) encoder_outputs = encoder_outputs.permute(1, 0, 2) weighted_encoder_rep = torch.bmm(a, encoder_outputs) weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2) return weighted_encoder_rep def forward(self, input: Tensor, decoder_hidden: Tensor, encoder_outputs: Tensor) -> Tuple[Tensor]: input = input.unsqueeze(0) embedded = self.dropout(self.embedding(input)) weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden, encoder_outputs) rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2) output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0)) embedded = embedded.squeeze(0) output = output.squeeze(0) weighted_encoder_rep = weighted_encoder_rep.squeeze(0) output = self.out(torch.cat((output, weighted_encoder_rep, embedded), dim = 1)) return output, decoder_hidden.squeeze(0) class Seq2Seq(nn.Module): def __init__(self, encoder: nn.Module, decoder: nn.Module, device: torch.device): super().__init__() self.encoder = encoder self.decoder = decoder self.device = device def forward(self, src: Tensor, trg: Tensor, teacher_forcing_ratio: float = 0.5) -> Tensor: batch_size = src.shape[1] max_len = trg.shape[0] trg_vocab_size = self.decoder.output_dim outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device) encoder_outputs, hidden = self.encoder(src) # first input to the decoder is the token output = trg[0,:] for t in range(1, max_len): output, hidden = self.decoder(output, hidden, encoder_outputs) outputs[t] = output teacher_force = random.random() Out: The model has 1,856,685 trainable parameters 注意：特别是在对语言翻译模型的性能进行评分时，我们必须告诉nn.CrossEntropyLoss函数忽略仅填充目标的索引。 PAD_IDX = TRG.vocab.stoi[''] criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX) 最后，我们可以训练和评估该模型： import math import time def train(model: nn.Module, iterator: BucketIterator, optimizer: optim.Optimizer, criterion: nn.Module, clip: float): model.train() epoch_loss = 0 for _, batch in enumerate(iterator): src = batch.src trg = batch.trg optimizer.zero_grad() output = model(src, trg) output = output[1:].view(-1, output.shape[-1]) trg = trg[1:].view(-1) loss = criterion(output, trg) loss.backward() torch.nn.utils.clip_grad_norm_(model.parameters(), clip) optimizer.step() epoch_loss += loss.item() return epoch_loss / len(iterator) def evaluate(model: nn.Module, iterator: BucketIterator, criterion: nn.Module): model.eval() epoch_loss = 0 with torch.no_grad(): for _, batch in enumerate(iterator): src = batch.src trg = batch.trg output = model(src, trg, 0) #turn off teacher forcing output = output[1:].view(-1, output.shape[-1]) trg = trg[1:].view(-1) loss = criterion(output, trg) epoch_loss += loss.item() return epoch_loss / len(iterator) def epoch_time(start_time: int, end_time: int): elapsed_time = end_time - start_time elapsed_mins = int(elapsed_time / 60) elapsed_secs = int(elapsed_time - (elapsed_mins * 60)) return elapsed_mins, elapsed_secs N_EPOCHS = 10 CLIP = 1 best_valid_loss = float('inf') for epoch in range(N_EPOCHS): start_time = time.time() train_loss = train(model, train_iterator, optimizer, criterion, CLIP) valid_loss = evaluate(model, valid_iterator, criterion) end_time = time.time() epoch_mins, epoch_secs = epoch_time(start_time, end_time) print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s') print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}') print(f'\\t Val. Loss: {valid_loss:.3f} | Val. PPL: {math.exp(valid_loss):7.3f}') test_loss = evaluate(model, test_iterator, criterion) print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |') Out: Epoch: 01 | Time: 0m 35s Train Loss: 5.667 | Train PPL: 289.080 Val. Loss: 5.201 | Val. PPL: 181.371 Epoch: 02 | Time: 0m 35s Train Loss: 4.968 | Train PPL: 143.728 Val. Loss: 5.096 | Val. PPL: 163.375 Epoch: 03 | Time: 0m 35s Train Loss: 4.720 | Train PPL: 112.221 Val. Loss: 4.989 | Val. PPL: 146.781 Epoch: 04 | Time: 0m 35s Train Loss: 4.586 | Train PPL: 98.094 Val. Loss: 4.841 | Val. PPL: 126.612 Epoch: 05 | Time: 0m 35s Train Loss: 4.430 | Train PPL: 83.897 Val. Loss: 4.809 | Val. PPL: 122.637 Epoch: 06 | Time: 0m 35s Train Loss: 4.331 | Train PPL: 75.997 Val. Loss: 4.797 | Val. PPL: 121.168 Epoch: 07 | Time: 0m 35s Train Loss: 4.240 | Train PPL: 69.434 Val. Loss: 4.694 | Val. PPL: 109.337 Epoch: 08 | Time: 0m 35s Train Loss: 4.116 | Train PPL: 61.326 Val. Loss: 4.714 | Val. PPL: 111.452 Epoch: 09 | Time: 0m 35s Train Loss: 4.004 | Train PPL: 54.815 Val. Loss: 4.563 | Val. PPL: 95.835 Epoch: 10 | Time: 0m 36s Train Loss: 3.922 | Train PPL: 50.519 Val. Loss: 4.452 | Val. PPL: 85.761 | Test Loss: 4.456 | Test PPL: 86.155 | 下一步 在上查看使用torchtext 的 Ben Trevett 其余教程。 敬请关注使用其他torchtext功能以及nn.Transformer通过下一个单词预测进行语言建模的教程！ 脚本的总运行时间：(6 分钟 10.266 秒） Download Python source code: torchtext_translation_tutorial.py Download Jupyter notebook: torchtext_translation_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"22.html":{"url":"22.html","title":"使用 nn.Transformer 和 TorchText 进行序列到序列建模","keywords":"","body":"使用 nn.Transformer 和 TorchText 进行序列到序列建模 原文： https://pytorch.org/tutorials/beginner/transformer_tutorial.html 注意 单击此处的下载完整的示例代码 这是一个有关如何训练使用 nn.Transformer 模块的序列到序列模型的教程。 PyTorch 1.2 版本包括一个基于纸张的标准变压器模块。 事实证明，该变压器模型在许多序列间问题上具有较高的质量，同时具有更高的可并行性。 nn.Transformer模块完全依赖于注意力机制(另一个最近实现为 nn.MultiheadAttention 的模块）来绘制输入和输出之间的全局依存关系。 nn.Transformer模块现在已高度模块化，因此可以轻松地修改/组成单个组件(例如本教程中的 nn.TransformerEncoder)。 定义模型 在本教程中，我们在语言建模任务上训练nn.TransformerEncoder模型。 语言建模任务是为给定单词(或单词序列）遵循单词序列的可能性分配概率。 令牌序列首先传递到嵌入层，然后传递到位置编码层以说明单词的顺序(有关更多详细信息，请参见下一段）。 nn.TransformerEncoder由多层 nn.TransformerEncoderLayer 组成。 与输入序列一起，还需要一个正方形的注意掩码，因为nn.TransformerEncoder中的自注意层只允许出现在该序列中的较早位置。 对于语言建模任务，应屏蔽将来头寸上的所有标记。 为了获得实际的单词，nn.TransformerEncoder模型的输出将发送到最终的 Linear 层，然后是 log-Softmax 函数。 import math import torch import torch.nn as nn import torch.nn.functional as F class TransformerModel(nn.Module): def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5): super(TransformerModel, self).__init__() from torch.nn import TransformerEncoder, TransformerEncoderLayer self.model_type = 'Transformer' self.src_mask = None self.pos_encoder = PositionalEncoding(ninp, dropout) encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout) self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers) self.encoder = nn.Embedding(ntoken, ninp) self.ninp = ninp self.decoder = nn.Linear(ninp, ntoken) self.init_weights() def _generate_square_subsequent_mask(self, sz): mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1) mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0)) return mask def init_weights(self): initrange = 0.1 self.encoder.weight.data.uniform_(-initrange, initrange) self.decoder.bias.data.zero_() self.decoder.weight.data.uniform_(-initrange, initrange) def forward(self, src): if self.src_mask is None or self.src_mask.size(0) != len(src): device = src.device mask = self._generate_square_subsequent_mask(len(src)).to(device) self.src_mask = mask src = self.encoder(src) * math.sqrt(self.ninp) src = self.pos_encoder(src) output = self.transformer_encoder(src, self.src_mask) output = self.decoder(output) return output PositionalEncoding模块注入一些有关令牌在序列中的相对或绝对位置的信息。 位置编码的尺寸与嵌入的尺寸相同，因此可以将两者相加。 在这里，我们使用不同频率的sine和cosine功能。 class PositionalEncoding(nn.Module): def __init__(self, d_model, dropout=0.1, max_len=5000): super(PositionalEncoding, self).__init__() self.dropout = nn.Dropout(p=dropout) pe = torch.zeros(max_len, d_model) position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1) div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) pe[:, 0::2] = torch.sin(position * div_term) pe[:, 1::2] = torch.cos(position * div_term) pe = pe.unsqueeze(0).transpose(0, 1) self.register_buffer('pe', pe) def forward(self, x): x = x + self.pe[:x.size(0), :] return self.dropout(x) 加载和批处理数据 训练过程使用torchtext中的 Wikitext-2 数据集。 vocab 对象是基于训练数据集构建的，用于将标记数字化为张量。 从顺序数据开始，batchify()函数将数据集排列为列，以修剪掉数据分成大小为batch_size的批次后剩余的所有令牌。 例如，以字母为序列(总长度为 26）并且批大小为 4，我们将字母分为 4 个长度为 6 的序列： 这些列被模型视为独立的，这意味着无法了解G和F的依赖性，但可以进行更有效的批处理。 import torchtext from torchtext.data.utils import get_tokenizer TEXT = torchtext.data.Field(tokenize=get_tokenizer(\"basic_english\"), init_token='', eos_token='', lower=True) train_txt, val_txt, test_txt = torchtext.datasets.WikiText2.splits(TEXT) TEXT.build_vocab(train_txt) device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") def batchify(data, bsz): data = TEXT.numericalize([data.examples[0].text]) # Divide the dataset into bsz parts. nbatch = data.size(0) // bsz # Trim off any extra elements that wouldn't cleanly fit (remainders). data = data.narrow(0, 0, nbatch * bsz) # Evenly divide the data across the bsz batches. data = data.view(bsz, -1).t().contiguous() return data.to(device) batch_size = 20 eval_batch_size = 10 train_data = batchify(train_txt, batch_size) val_data = batchify(val_txt, eval_batch_size) test_data = batchify(test_txt, eval_batch_size) 出： downloading wikitext-2-v1.zip extracting 产生输入和目标序列的功能 get_batch()功能为变压器模型生成输入和目标序列。 它将源数据细分为长度为bptt的块。 对于语言建模任务，模型需要以下单词作为Target。 例如，如果bptt值为 2，则i = 0 时，我们将获得以下两个变量： 应该注意的是，这些块沿维度 0，与 Transformer 模型中的S维度一致。 批次尺寸N沿尺寸 1。 bptt = 35 def get_batch(source, i): seq_len = min(bptt, len(source) - 1 - i) data = source[i:i+seq_len] target = source[i+1:i+1+seq_len].view(-1) return data, target 启动实例 使用下面的超参数建立模型。 vocab 的大小等于 vocab 对象的长度。 ntokens = len(TEXT.vocab.stoi) # the size of vocabulary emsize = 200 # embedding dimension nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder nhead = 2 # the number of heads in the multiheadattention models dropout = 0.2 # the dropout value model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device) 运行模型 CrossEntropyLoss 用于跟踪损失， SGD 实现随机梯度下降法作为优化器。 初始学习率设置为 5.0。 StepLR 用于通过历时调整学习速率。 在训练过程中，我们使用 nn.utils.clipgrad_norm 函数将所有梯度缩放在一起，以防止爆炸。 criterion = nn.CrossEntropyLoss() lr = 5.0 # learning rate optimizer = torch.optim.SGD(model.parameters(), lr=lr) scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95) import time def train(): model.train() # Turn on the train mode total_loss = 0. start_time = time.time() ntokens = len(TEXT.vocab.stoi) for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)): data, targets = get_batch(train_data, i) optimizer.zero_grad() output = model(data) loss = criterion(output.view(-1, ntokens), targets) loss.backward() torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) optimizer.step() total_loss += loss.item() log_interval = 200 if batch % log_interval == 0 and batch > 0: cur_loss = total_loss / log_interval elapsed = time.time() - start_time print('| epoch {:3d} | {:5d}/{:5d} batches | ' 'lr {:02.2f} | ms/batch {:5.2f} | ' 'loss {:5.2f} | ppl {:8.2f}'.format( epoch, batch, len(train_data) // bptt, scheduler.get_lr()[0], elapsed * 1000 / log_interval, cur_loss, math.exp(cur_loss))) total_loss = 0 start_time = time.time() def evaluate(eval_model, data_source): eval_model.eval() # Turn on the evaluation mode total_loss = 0. ntokens = len(TEXT.vocab.stoi) with torch.no_grad(): for i in range(0, data_source.size(0) - 1, bptt): data, targets = get_batch(data_source, i) output = eval_model(data) output_flat = output.view(-1, ntokens) total_loss += len(data) * criterion(output_flat, targets).item() return total_loss / (len(data_source) - 1) 循环遍历。 如果验证损失是迄今为止迄今为止最好的，请保存模型。 在每个时期之后调整学习率。 best_val_loss = float(\"inf\") epochs = 3 # The number of epochs best_model = None for epoch in range(1, epochs + 1): epoch_start_time = time.time() train() val_loss = evaluate(model, val_data) print('-' * 89) print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | ' 'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time), val_loss, math.exp(val_loss))) print('-' * 89) if val_loss Out: | epoch 1 | 200/ 2981 batches | lr 5.00 | ms/batch 29.47 | loss 8.04 | ppl 3112.50 | epoch 1 | 400/ 2981 batches | lr 5.00 | ms/batch 28.38 | loss 6.78 | ppl 882.16 | epoch 1 | 600/ 2981 batches | lr 5.00 | ms/batch 28.38 | loss 6.38 | ppl 589.27 | epoch 1 | 800/ 2981 batches | lr 5.00 | ms/batch 28.40 | loss 6.23 | ppl 508.15 | epoch 1 | 1000/ 2981 batches | lr 5.00 | ms/batch 28.41 | loss 6.12 | ppl 454.63 | epoch 1 | 1200/ 2981 batches | lr 5.00 | ms/batch 28.40 | loss 6.09 | ppl 441.65 | epoch 1 | 1400/ 2981 batches | lr 5.00 | ms/batch 28.42 | loss 6.04 | ppl 418.77 | epoch 1 | 1600/ 2981 batches | lr 5.00 | ms/batch 28.41 | loss 6.04 | ppl 421.53 | epoch 1 | 1800/ 2981 batches | lr 5.00 | ms/batch 28.40 | loss 5.96 | ppl 387.98 | epoch 1 | 2000/ 2981 batches | lr 5.00 | ms/batch 28.41 | loss 5.96 | ppl 386.42 | epoch 1 | 2200/ 2981 batches | lr 5.00 | ms/batch 28.42 | loss 5.85 | ppl 346.77 | epoch 1 | 2400/ 2981 batches | lr 5.00 | ms/batch 28.42 | loss 5.89 | ppl 362.54 | epoch 1 | 2600/ 2981 batches | lr 5.00 | ms/batch 28.42 | loss 5.90 | ppl 364.01 | epoch 1 | 2800/ 2981 batches | lr 5.00 | ms/batch 28.43 | loss 5.80 | ppl 329.20 ----------------------------------------------------------------------------------------- | end of epoch 1 | time: 88.26s | valid loss 5.73 | valid ppl 307.01 ----------------------------------------------------------------------------------------- | epoch 2 | 200/ 2981 batches | lr 4.51 | ms/batch 28.58 | loss 5.79 | ppl 328.13 | epoch 2 | 400/ 2981 batches | lr 4.51 | ms/batch 28.42 | loss 5.77 | ppl 319.25 | epoch 2 | 600/ 2981 batches | lr 4.51 | ms/batch 28.42 | loss 5.60 | ppl 270.79 | epoch 2 | 800/ 2981 batches | lr 4.51 | ms/batch 28.44 | loss 5.63 | ppl 279.91 | epoch 2 | 1000/ 2981 batches | lr 4.51 | ms/batch 28.44 | loss 5.58 | ppl 265.99 | epoch 2 | 1200/ 2981 batches | lr 4.51 | ms/batch 28.44 | loss 5.61 | ppl 273.55 | epoch 2 | 1400/ 2981 batches | lr 4.51 | ms/batch 28.42 | loss 5.63 | ppl 277.59 | epoch 2 | 1600/ 2981 batches | lr 4.51 | ms/batch 28.45 | loss 5.66 | ppl 287.09 | epoch 2 | 1800/ 2981 batches | lr 4.51 | ms/batch 28.44 | loss 5.58 | ppl 266.00 | epoch 2 | 2000/ 2981 batches | lr 4.51 | ms/batch 28.44 | loss 5.61 | ppl 272.58 | epoch 2 | 2200/ 2981 batches | lr 4.51 | ms/batch 28.44 | loss 5.50 | ppl 244.59 | epoch 2 | 2400/ 2981 batches | lr 4.51 | ms/batch 28.44 | loss 5.57 | ppl 262.87 | epoch 2 | 2600/ 2981 batches | lr 4.51 | ms/batch 28.44 | loss 5.58 | ppl 265.65 | epoch 2 | 2800/ 2981 batches | lr 4.51 | ms/batch 28.44 | loss 5.51 | ppl 246.48 ----------------------------------------------------------------------------------------- | end of epoch 2 | time: 88.16s | valid loss 5.53 | valid ppl 253.40 ----------------------------------------------------------------------------------------- | epoch 3 | 200/ 2981 batches | lr 4.29 | ms/batch 28.58 | loss 5.55 | ppl 256.02 | epoch 3 | 400/ 2981 batches | lr 4.29 | ms/batch 28.43 | loss 5.55 | ppl 256.76 | epoch 3 | 600/ 2981 batches | lr 4.29 | ms/batch 28.46 | loss 5.36 | ppl 212.31 | epoch 3 | 800/ 2981 batches | lr 4.29 | ms/batch 28.44 | loss 5.42 | ppl 225.88 | epoch 3 | 1000/ 2981 batches | lr 4.29 | ms/batch 28.46 | loss 5.38 | ppl 217.24 | epoch 3 | 1200/ 2981 batches | lr 4.29 | ms/batch 28.45 | loss 5.41 | ppl 223.82 | epoch 3 | 1400/ 2981 batches | lr 4.29 | ms/batch 28.43 | loss 5.42 | ppl 226.87 | epoch 3 | 1600/ 2981 batches | lr 4.29 | ms/batch 28.44 | loss 5.47 | ppl 238.34 | epoch 3 | 1800/ 2981 batches | lr 4.29 | ms/batch 28.45 | loss 5.41 | ppl 223.13 | epoch 3 | 2000/ 2981 batches | lr 4.29 | ms/batch 28.45 | loss 5.44 | ppl 230.23 | epoch 3 | 2200/ 2981 batches | lr 4.29 | ms/batch 28.44 | loss 5.32 | ppl 205.28 | epoch 3 | 2400/ 2981 batches | lr 4.29 | ms/batch 28.44 | loss 5.40 | ppl 221.60 | epoch 3 | 2600/ 2981 batches | lr 4.29 | ms/batch 28.45 | loss 5.42 | ppl 224.76 | epoch 3 | 2800/ 2981 batches | lr 4.29 | ms/batch 28.44 | loss 5.34 | ppl 209.38 ----------------------------------------------------------------------------------------- | end of epoch 3 | time: 88.18s | valid loss 5.48 | valid ppl 240.75 ----------------------------------------------------------------------------------------- 使用测试数据集评估模型 应用最佳模型以检查测试数据集的结果。 test_loss = evaluate(best_model, test_data) print('=' * 89) print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format( test_loss, math.exp(test_loss))) print('=' * 89) Out: ========================================================================================= | End of training | test loss 5.39 | test ppl 219.13 ========================================================================================= 脚本的总运行时间：(4 分钟 39.556 秒） Download Python source code: transformer_tutorial.py Download Jupyter notebook: transformer_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:39:43 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"24.html":{"url":"24.html","title":"(实验性）PyTorch 中的命名张量简介","keywords":"","body":"(实验性）PyTorch 中的命名张量简介 原文： https://pytorch.org/tutorials/intermediate/named_tensor_tutorial.html 注意 单击此处的下载完整的示例代码 作者： Richard Zou 命名张量旨在通过允许用户将显式名称与张量维度相关联来使张量更易于使用。 在大多数情况下，采用尺寸参数的操作将接受尺寸名称，从而无需按位置跟踪尺寸。 此外，命名张量使用名称来自动检查运行时是否正确使用了 API，从而提供了额外的安全性。 名称也可以用于重新排列尺寸，例如，支持“按名称广播”而不是“按位置广播”。 本教程旨在作为 1.3 启动中将包含的功能的指南。 到最后，您将能够： 创建具有命名尺寸的张量，以及删除或重命名这些尺寸 了解操作如何传播维度名称的基础 See how naming dimensions enables clearer code in two key areas: 广播业务 展平和展平尺寸 最后，我们将通过使用命名张量编写多头注意力模块来将其付诸实践。 PyTorch 中的命名张量受 Sasha Rush 的启发并与之合作。 Sasha 在他的 2019 年 1 月博客文章中提出了最初的想法和概念证明。 基础知识：命名尺寸 PyTorch 现在允许张量具有命名尺寸； 工厂函数采用新的名称参数，该参数将名称与每个维度相关联。 这适用于大多数工厂功能，例如 张量 为空 个 零 兰恩 兰特 在这里，我们使用名称构造张量： import torch imgs = torch.randn(1, 2, 2, 3, names=('N', 'C', 'H', 'W')) print(imgs.names) 出： ('N', 'C', 'H', 'W') 与中的原始命名张量博客文章不同，命名维度是有序的：tensor.names[i]是tensor的第i个维度的名称。 重命名Tensor尺寸的方法有两种： # Method #1: set the .names attribute (this changes name in-place) imgs.names = ['batch', 'channel', 'width', 'height'] print(imgs.names) # Method #2: specify new names (this changes names out-of-place) imgs = imgs.rename(channel='C', width='W', height='H') print(imgs.names) Out: ('batch', 'channel', 'width', 'height') ('batch', 'C', 'W', 'H') 删除名称的首选方法是调用tensor.rename(None)： imgs = imgs.rename(None) print(imgs.names) Out: (None, None, None, None) 未命名的张量(没有命名尺寸的张量）仍然可以正常工作，并且在其repr中没有名称。 unnamed = torch.randn(2, 1, 3) print(unnamed) print(unnamed.names) Out: tensor([[[-0.1654, 0.5440, -0.1883]], [[ 1.8791, -0.1997, 2.4531]]]) (None, None, None) 命名张量不需要命名所有尺寸。 imgs = torch.randn(3, 1, 1, 2, names=('N', None, None, None)) print(imgs.names) Out: ('N', None, None, None) 因为命名张量可以与未命名张量共存，所以我们需要一种不错的方式来编写可识别命名张量的代码，该代码可用于命名张量和未命名张量。 使用tensor.refine_names(*names)优化尺寸并将未命名的暗淡提升为已命名的暗淡。 细化维度定义为“重命名”，并具有以下限制： 可以将None暗号细化为任何名称 命名的 dim 只能精简为具有相同的名称。 imgs = torch.randn(3, 1, 1, 2) named_imgs = imgs.refine_names('N', 'C', 'H', 'W') print(named_imgs.names) # Refine the last two dims to 'H' and 'W'. In Python 2, use the string '...' # instead of ... named_imgs = imgs.refine_names(..., 'H', 'W') print(named_imgs.names) def catch_error(fn): try: fn() assert False except RuntimeError as err: err = str(err) if len(err) > 180: err = err[:180] + \"...\" print(err) named_imgs = imgs.refine_names('N', 'C', 'H', 'W') # Tried to refine an existing name to a different name catch_error(lambda: named_imgs.refine_names('N', 'C', 'H', 'width')) Out: ('N', 'C', 'H', 'W') (None, None, 'H', 'W') refine_names: cannot coerce Tensor['N', 'C', 'H', 'W'] to Tensor['N', 'C', 'H', 'width'] because 'W' is different from 'width' at index 3 大多数简单的操作都会传播名称。 命名张量的最终目标是所有操作以合理，直观的方式传播名称。 在 1.3 发行版中已添加了对许多常用操作的支持。 例如，这里是.abs()： print(named_imgs.abs().names) Out: ('N', 'C', 'H', 'W') 存取器和减少 可以使用尺寸名称来引用尺寸，而不是位置尺寸。 这些操作还传播名称。 索引(基本索引和高级索引）尚未实施，但仍在规划中。 使用上方的named_imgs张量，我们可以执行以下操作： output = named_imgs.sum('C') # Perform a sum over the channel dimension print(output.names) img0 = named_imgs.select('N', 0) # get one image print(img0.names) Out: ('N', 'H', 'W') ('C', 'H', 'W') 名称推断 名称在称为名称推断的两步过程中在操作上传播： 检查名称：操作员可以在运行时执行自动检查，以检查某些尺寸名称是否必须匹配。 传播名称：名称推断将输出名称传播到输出张量。 让我们看一个非常小的例子，添加 2 个一维张量，不进行广播。 x = torch.randn(3, names=('X',)) y = torch.randn(3) z = torch.randn(3, names=('Z',)) 检查名称：首先，我们将检查这两个张量的名称是否与相匹配。 当且仅当两个名称相等(字符串相等）或至少一个为None(None本质上是一个特殊的通配符名称）时，两个名称才匹配。 因此，这三者中唯一会出错的是x + z： catch_error(lambda: x + z) Out: Error when attempting to broadcast dims ['X'] and dims ['Z']: dim 'X' and dim 'Z' are at the same position from the right but do not match. 传播名称：通过返回两个名称中最精确的名称来统一这两个名称。 使用x + y，X比None更精细。 print((x + y).names) Out: ('X',) 大多数名称推断规则都很简单明了，但其中一些可能具有意料之外的语义。 让我们来看看您可能会遇到的一对：广播和矩阵乘法。 广播 命名张量不会改变广播行为； 他们仍然按位置广播。 但是，在检查两个尺寸是否可以广播时，PyTorch 还会检查这些尺寸的名称是否匹配。 这导致命名张量防止广播操作期间意外对齐。 在下面的示例中，我们将per_batch_scale应用于imgs。 imgs = torch.randn(2, 2, 2, 2, names=('N', 'C', 'H', 'W')) per_batch_scale = torch.rand(2, names=('N',)) catch_error(lambda: imgs * per_batch_scale) Out: Error when attempting to broadcast dims ['N', 'C', 'H', 'W'] and dims ['N']: dim 'W' and dim 'N' are at the same position from the right but do not match. 如果没有names，则per_batch_scale张量与imgs的最后一个尺寸对齐，这不是我们想要的。 我们确实想通过将per_batch_scale与imgs的批次尺寸对齐来执行操作。 有关如何按名称对齐张量的信息，请参见新的“按名称显式广播”功能，如下所述。 矩阵乘法 torch.mm(A, B)在A的第二个暗角和B的第一个暗角之间执行点积，返回具有A的第一个暗角和B的第二个暗角的张量。 (其他 matmul 函数，例如torch.matmul，torch.mv和torch.dot的行为类似）。 markov_states = torch.randn(128, 5, names=('batch', 'D')) transition_matrix = torch.randn(5, 5, names=('in', 'out')) # Apply one transition new_state = markov_states @ transition_matrix print(new_state.names) Out: ('batch', 'out') 如您所见，矩阵乘法不会检查收缩尺寸是否具有相同的名称。 接下来，我们将介绍命名张量启用的两个新行为：按名称的显式广播以及按名称的展平和展平尺寸 新行为：按名称明确广播 有关使用多个维度的主要抱怨之一是需要unsqueeze“虚拟”维度，以便可以进行操作。 例如，在之前的每批比例示例中，使用未命名的张量，我们将执行以下操作： imgs = torch.randn(2, 2, 2, 2) # N, C, H, W per_batch_scale = torch.rand(2) # N correct_result = imgs * per_batch_scale.view(2, 1, 1, 1) # N, C, H, W incorrect_result = imgs * per_batch_scale.expand_as(imgs) assert not torch.allclose(correct_result, incorrect_result) 通过使用名称，我们可以使这些操作更安全(并且易于与维数无关）。 我们提供了一个新的tensor.align_as(other)操作，可以对张量的尺寸进行排列以匹配other.names中指定的顺序，并在适当的地方添加一个尺寸的尺寸(tensor.align_to(*names)也可以）： imgs = imgs.refine_names('N', 'C', 'H', 'W') per_batch_scale = per_batch_scale.refine_names('N') named_result = imgs * per_batch_scale.align_as(imgs) # note: named tensors do not yet work with allclose assert torch.allclose(named_result.rename(None), correct_result) 新行为：按名称展平和展平尺寸 一种常见的操作是展平和展平尺寸。 现在，用户可以使用view，reshape或flatten来执行此操作； 用例包括展平批处理尺寸以将张量发送到必须采用一定数量尺寸的输入的运算符(即 conv2d 采用 4D 输入）。 为了使这些操作比查看或整形更具语义意义，我们引入了一种新的tensor.unflatten(dim, namedshape)方法并更新flatten以使用名称：tensor.flatten(dims, new_dim)。 flatten只能展平相邻的尺寸，但也可以用于不连续的暗光。 必须将名称为的传递到unflatten中，该形状是(dim, size)元组的列表，以指定如何展开暗淡。 可以在flatten期间保存unflatten的尺寸，但我们尚未这样做。 imgs = imgs.flatten(['C', 'H', 'W'], 'features') print(imgs.names) imgs = imgs.unflatten('features', (('C', 2), ('H', 2), ('W', 2))) print(imgs.names) Out: ('N', 'features') ('N', 'C', 'H', 'W') Autograd 支持 Autograd 当前会忽略所有张量上的名称，只是将它们视为常规张量。 梯度计算是正确的，但是我们失去了名称赋予我们的安全性。 在路线图上引入名称以自动分级的处理。 x = torch.randn(3, names=('D',)) weight = torch.randn(3, names=('D',), requires_grad=True) loss = (x - weight).abs() grad_loss = torch.randn(3) loss.backward(grad_loss) correct_grad = weight.grad.clone() print(correct_grad) # Unnamed for now. Will be named in the future weight.grad.zero_() grad_loss = grad_loss.refine_names('C') loss = (x - weight).abs() # Ideally we'd check that the names of loss and grad_loss match, but we don't # yet loss.backward(grad_loss) print(weight.grad) # still unnamed assert torch.allclose(weight.grad, correct_grad) Out: tensor([-1.4406, 0.6030, 0.1825]) tensor([-1.4406, 0.6030, 0.1825]) 其他受支持(和不受支持）的功能 有关 1.3 发行版支持的功能的详细分类，请参见此处。 特别是，我们要指出当前不支持的三个重要功能： 通过torch.save或torch.load保存或加载命名张量 通过torch.multiprocessing进行多重处理 JIT 支持； 例如，以下将错误 imgs_named = torch.randn(1, 2, 2, 3, names=('N', 'C', 'H', 'W')) @torch.jit.script def fn(x): return x catch_error(lambda: fn(imgs_named)) Out: NYI: Named tensors are currently unsupported in TorchScript. As a workaround please drop names via `tensor = tensor.rename(None)`. 解决方法是，在使用尚不支持命名张量的任何东西之前，请通过tensor = tensor.rename(None)删除名称。 更长的例子：多头注意力 现在，我们将通过一个完整的示例来实现一个常见的 PyTorch nn.Module：多头注意。 我们假设读者已经熟悉多头注意； 要进行复习，请查看此说明或此说明。 我们采用 ParlAI 来实现多头注意力的实现； 特别是此处。 阅读该示例中的代码； 然后，与下面的代码进行比较，注意有四个标记为(I），(II），(III）和(IV）的位置，使用命名张量可以使代码更易读； 在代码块之后，我们将深入探讨其中的每一个。 import torch.nn as nn import torch.nn.functional as F import math class MultiHeadAttention(nn.Module): def __init__(self, n_heads, dim, dropout=0): super(MultiHeadAttention, self).__init__() self.n_heads = n_heads self.dim = dim self.attn_dropout = nn.Dropout(p=dropout) self.q_lin = nn.Linear(dim, dim) self.k_lin = nn.Linear(dim, dim) self.v_lin = nn.Linear(dim, dim) nn.init.xavier_normal_(self.q_lin.weight) nn.init.xavier_normal_(self.k_lin.weight) nn.init.xavier_normal_(self.v_lin.weight) self.out_lin = nn.Linear(dim, dim) nn.init.xavier_normal_(self.out_lin.weight) def forward(self, query, key=None, value=None, mask=None): # (I) query = query.refine_names(..., 'T', 'D') self_attn = key is None and value is None if self_attn: mask = mask.refine_names(..., 'T') else: mask = mask.refine_names(..., 'T', 'T_key') # enc attn dim = query.size('D') assert dim == self.dim, \\ f'Dimensions do not match: {dim} query vs {self.dim} configured' assert mask is not None, 'Mask is None, please specify a mask' n_heads = self.n_heads dim_per_head = dim // n_heads scale = math.sqrt(dim_per_head) # (II) def prepare_head(tensor): tensor = tensor.refine_names(..., 'T', 'D') return (tensor.unflatten('D', [('H', n_heads), ('D_head', dim_per_head)]) .align_to(..., 'H', 'T', 'D_head')) assert value is None if self_attn: key = value = query elif value is None: # key and value are the same, but query differs key = key.refine_names(..., 'T', 'D') value = key dim = key.size('D') # Distinguish between query_len (T) and key_len (T_key) dims. k = prepare_head(self.k_lin(key)).rename(T='T_key') v = prepare_head(self.v_lin(value)).rename(T='T_key') q = prepare_head(self.q_lin(query)) dot_prod = q.div_(scale).matmul(k.align_to(..., 'D_head', 'T_key')) dot_prod.refine_names(..., 'H', 'T', 'T_key') # just a check # (III) attn_mask = (mask == 0).align_as(dot_prod) dot_prod.masked_fill_(attn_mask, -float(1e20)) attn_weights = self.attn_dropout(F.softmax(dot_prod / scale, dim='T_key')) # (IV) attentioned = ( attn_weights.matmul(v).refine_names(..., 'H', 'T', 'D_head') .align_to(..., 'T', 'H', 'D_head') .flatten(['H', 'D_head'], 'D') ) return self.out_lin(attentioned).refine_names(..., 'T', 'D') (I）细化输入张量调光 def forward(self, query, key=None, value=None, mask=None): # (I) query = query.refine_names(..., 'T', 'D') query = query.refine_names(..., 'T', 'D')用作可执行的文档，并将输入尺寸提升为名称。 它检查是否可以将最后两个维度调整为['T', 'D']，以防止在以后出现潜在的静默或混乱的尺寸不匹配错误。 (II）在 prepare_head 中操纵尺寸 # (II) def prepare_head(tensor): tensor = tensor.refine_names(..., 'T', 'D') return (tensor.unflatten('D', [('H', n_heads), ('D_head', dim_per_head)]) .align_to(..., 'H', 'T', 'D_head')) 首先要注意的是代码如何清楚地说明输入和输出尺寸：输入张量必须以T和D变暗结束，输出张量应以H，T和D_head结束 昏暗。 要注意的第二件事是代码清楚地描述了正在发生的事情。 prepare_head 获取键，查询和值，并将嵌入的 dim 拆分为多个 head，最后将 dim 顺序重新排列为[..., 'H', 'T', 'D_head']。 ParlAI 使用view和transpose操作实现以下prepare_head： def prepare_head(tensor): # input is [batch_size, seq_len, n_heads * dim_per_head] # output is [batch_size * n_heads, seq_len, dim_per_head] batch_size, seq_len, _ = tensor.size() tensor = tensor.view(batch_size, tensor.size(1), n_heads, dim_per_head) tensor = ( tensor.transpose(1, 2) .contiguous() .view(batch_size * n_heads, seq_len, dim_per_head) ) return tensor 我们命名的张量变量使用的操作虽然较为冗长，但比view和transpose具有更多的语义含义，并包含名称形式的可执行文档。 (III）按名称明确广播 def ignore(): # (III) attn_mask = (mask == 0).align_as(dot_prod) dot_prod.masked_fill_(attn_mask, -float(1e20)) mask通常具有暗淡[N, T](在自我关注的情况下）或[N, T, T_key](对于编码器注意的情况），而dot_prod具有暗淡[N, H, T, T_key]。 为了使mask与dot_prod正确广播，我们通常会在自注意的情况下将的调暗1和-1压下，在编码器的情况下，将unsqueeze调暗unsqueeze调暗 。 使用命名张量，我们只需使用align_as将attn_mask与dot_prod对齐，而不必担心unsqueeze变暗的位置。 (IV）使用 align_to 和展平进行更多尺寸操作 def ignore(): # (IV) attentioned = ( attn_weights.matmul(v).refine_names(..., 'H', 'T', 'D_head') .align_to(..., 'T', 'H', 'D_head') .flatten(['H', 'D_head'], 'D') ) 在这里，与(II）一样，align_to和flatten在语义上比view和transpose更有意义(尽管更冗长）。 运行示例 n, t, d, h = 7, 5, 2 * 3, 3 query = torch.randn(n, t, d, names=('N', 'T', 'D')) mask = torch.ones(n, t, names=('N', 'T')) attn = MultiHeadAttention(h, d) output = attn(query, mask=mask) # works as expected! print(output.names) Out: ('N', 'T', 'D') 以上工作正常。 此外，请注意，在代码中我们根本没有提到批处理维度的名称。 实际上，我们的MultiHeadAttention模块与批次尺寸的存在无关。 query = torch.randn(t, d, names=('T', 'D')) mask = torch.ones(t, names=('T',)) output = attn(query, mask=mask) print(output.names) Out: ('T', 'D') 结论 感谢您的阅读！ 命名张量仍在发展中。 如果您有反馈和/或改进建议，请通过创建问题来通知我们。 脚本的总运行时间：(0 分钟 0.074 秒） Download Python source code: named_tensor_tutorial.py Download Jupyter notebook: named_tensor_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"26.html":{"url":"26.html","title":"强化学习(DQN）教程","keywords":"","body":"强化学习(DQN）教程 原文： https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html 注意 单击此处的下载完整的示例代码 作者　　： Adam Paszke 翻译校验： Dynmi Wang 本教程介绍了如何使用 PyTorch 在 OpenAI Gym 上的 CartPole-v0 任务上训练深度 Q-learning(DQN)智能体。 任务 智能体必须在两个动作之间做出决定-向左或向右移动小车来使其上的杆保持直立。 您可以在 Gym 网站上找到具有各种算法和可视化的官方排行榜。 当智能体观察环境的当前状态并选择一个动作时，环境将转换到新状态，并且还会返回表示该动作结果的奖励。 在此任务中，每前进一个时间步，奖励为+1，并且如果杆子掉落得太远或小车离中心的距离超过 2.4 个单位，则对局终止。 这意味着性能更好的操作方案将持续更长的时间，从而积累更大的回报。 Cartpole任务的设计为智能点输入代表环境状态(位置、速度等）的4个实际值。 但是，神经网络可以完全通过查看场景来解决任务，因此我们将以小车为中心的一部分屏幕作为输入。 因此，我们的结果无法直接与官方排行榜上的结果进行比较-我们的任务更加艰巨。 不幸的是，这确实减慢了训练速度，因为我们必须渲染所有帧。 严格地说，我们将以当前帧和前一个帧之间的差异来呈现状态。这将允许代理从一张图像中考虑杆子的速度。 软件包 首先，让我们导入所需的软件包。 首先，我们需要针对环境的体育馆(使用 pip install Gym 进行安装）。 我们还将使用 PyTorch 中的以下内容： 神经网络(torch.nn） 优化(torch.optim） 自动微分(torch.autograd） 专门做视觉处理的工具(torchvision-单独的软件包）。 import gym import math import random import numpy as np import matplotlib import matplotlib.pyplot as plt from collections import namedtuple from itertools import count from PIL import Image import torch import torch.nn as nn import torch.optim as optim import torch.nn.functional as F import torchvision.transforms as T env = gym.make('CartPole-v0').unwrapped # set up matplotlib is_ipython = 'inline' in matplotlib.get_backend() if is_ipython: from IPython import display plt.ion() # if gpu is to be used device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") 经验回放 我们将使用经验回放内存来训练我们的 DQN。 它存储智能体观察到的转换，使我们以后可以重用此数据。 通过从中随机抽样，可以构建成批的过渡。 实践表明，这极大稳定并改进了 DQN 训练过程。 为此，我们需要两个类： Transition　 -一个命名元组，表示我们环境中的单个转换。 本质上它是将(state,action）对映射到紧随其后的(next_state,reward）结果，状态是屏幕差异图像，如下所述。 ReplayMemory　-一个有界大小的循环缓冲区，用于保存最近观察到的转换。 它还实现了.sample()方法，从经验库中随机选择一批transitions，方便直接拿去训练智能体。 Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward')) class ReplayMemory(object): def __init__(self, capacity): self.capacity = capacity self.memory = [] self.position = 0 def push(self, *args): \"\"\"Saves a transition.\"\"\" if len(self.memory) 现在我们来定义自己的模型。 首先快速回顾一下DQN基础知识。 DQN 算法 我们的环境是确定的，故为简单起见，这里提出的所有方程也都是确定性的。 在强化学习文献中，它们还将包含对环境中随机转换的期望。 我们的目标是训练并得到一种试图最大化带衰减的累积奖励的策略，其中也称为收获。 衰减率应该是和之间的常数，以确保总和收敛。 它使不确定的远期回报对于我们的智能体而言不如对它可以相当有信心的近期回报重要。 Q-learning背后的思想是，如果我们有一个函数，它可以告诉我们我们的回报是什么，如果我们要在特定状态下采取行动，那么我们可以轻松地构建一个最大化收获的策略： 但是，我们并不了解世界的一切，因此我们无法访问。 但是，由于神经网络是通用的函数逼近器，因此我们可以轻松创建一个并训练它为类似于的函数。 对于我们的训练更新规则，我们将假设－－某些策略的每个函数都遵循 Bellman 方程： 等式两边之间的差异称为时间差误差： 为了尽量减小这个错误，我们将使用 Huber 损失。 当误差较小时，Huber 损失类似于均方误差；而当误差较大时，表现为平均绝对误差－－这使得当的估计值非常嘈杂时，对异常值的鲁棒性更强。 我们通过从经验回放中取样的一批转换来计算： Q－Network 我们的模型将是一个卷积神经网络，该卷积神经网络将吸收当前屏幕补丁与先前屏幕补丁之间的差异。 它有两个输出，分别表示和(其中是网络的输入）。 实际上，网络正尝试预测在给定当前输入的情况下执行每个action的预期收获。 class DQN(nn.Module): def __init__(self, h, w, outputs): super(DQN, self).__init__() self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2) self.bn1 = nn.BatchNorm2d(16) self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2) self.bn2 = nn.BatchNorm2d(32) self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2) self.bn3 = nn.BatchNorm2d(32) # Number of Linear input connections depends on output of conv2d layers # and therefore the input image size, so compute it. def conv2d_size_out(size, kernel_size = 5, stride = 2): return (size - (kernel_size - 1) - 1) // stride + 1 convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w))) convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h))) linear_input_size = convw * convh * 32 self.head = nn.Linear(linear_input_size, outputs) # Called with either one element to determine next action, or a batch # during optimization. Returns tensor([[left0exp,right0exp]...]). def forward(self, x): x = F.relu(self.bn1(self.conv1(x))) x = F.relu(self.bn2(self.conv2(x))) x = F.relu(self.bn3(self.conv3(x))) return self.head(x.view(x.size(0), -1)) 获取输入 以下代码是用于从环境中提取和处理渲染图像的实用程序。 它使用torchvision包，可轻松组合图像变换。 运行单元后，它将显示它提取的示例帧。 resize = T.Compose([T.ToPILImage(), T.Resize(40, interpolation=Image.CUBIC), T.ToTensor()]) def get_cart_location(screen_width): world_width = env.x_threshold * 2 scale = screen_width / world_width return int(env.state[0] * scale + screen_width / 2.0) # MIDDLE OF CART def get_screen(): # Returned screen requested by gym is 400x600x3, but is sometimes larger # such as 800x1200x3\\. Transpose it into torch order (CHW). screen = env.render(mode='rgb_array').transpose((2, 0, 1)) # Cart is in the lower half, so strip off the top and bottom of the screen _, screen_height, screen_width = screen.shape screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)] view_width = int(screen_width * 0.6) cart_location = get_cart_location(screen_width) if cart_location (screen_width - view_width // 2): slice_range = slice(-view_width, None) else: slice_range = slice(cart_location - view_width // 2, cart_location + view_width // 2) # Strip off the edges, so that we have a square image centered on a cart screen = screen[:, :, slice_range] # Convert to float, rescale, convert to torch tensor # (this doesn't require a copy) screen = np.ascontiguousarray(screen, dtype=np.float32) / 255 screen = torch.from_numpy(screen) # Resize, and add a batch dimension (BCHW) return resize(screen).unsqueeze(0).to(device) env.reset() plt.figure() plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(), interpolation='none') plt.title('Example extracted screen') plt.show() 训练 超参数和配置 该单元实例化我们的模型及其优化器，并定义超参数： select_action- 将根据 epsilon-greedy策略选择一个行为。 简而言之，我们有时会使用我们的模型来选择行为，有时我们只会对其中一个进行统一采样。 选择随机行为的概率将从EPS_START开始，并朝EPS_END呈指数衰减。 EPS_DECAY控制衰减率。 plot_durations- 一个帮助绘制迭代次数持续时间，以及过去100迭代次数的平均值(官方评估中使用的度量）。 迭代次数将在包含主训练循环的单元下方，并在每次迭代之后更新。 BATCH_SIZE = 128 GAMMA = 0.999 EPS_START = 0.9 EPS_END = 0.05 EPS_DECAY = 200 TARGET_UPDATE = 10 # 获取屏幕大小，以便我们可以根据从ai-gym返回的形状正确初始化层。 # 这一点上的平常尺寸接近3x40x90，这是在get_screen(）中抑制和缩小的渲染缓冲区的结果。 init_screen = get_screen() _, _, screen_height, screen_width = init_screen.shape # Get number of actions from gym action space n_actions = env.action_space.n policy_net = DQN(screen_height, screen_width, n_actions).to(device) target_net = DQN(screen_height, screen_width, n_actions).to(device) target_net.load_state_dict(policy_net.state_dict()) target_net.eval() optimizer = optim.RMSprop(policy_net.parameters()) memory = ReplayMemory(10000) steps_done = 0 def select_action(state): global steps_done sample = random.random() eps_threshold = EPS_END + (EPS_START - EPS_END) * \\ math.exp(-1\\. * steps_done / EPS_DECAY) steps_done += 1 if sample > eps_threshold: with torch.no_grad(): # t.max(1) will return largest column value of each row. # second column on max result is index of where max element was # found, so we pick action with the larger expected reward. return policy_net(state).max(1)[1].view(1, 1) else: return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long) episode_durations = [] def plot_durations(): plt.figure(2) plt.clf() durations_t = torch.tensor(episode_durations, dtype=torch.float) plt.title('Training...') plt.xlabel('Episode') plt.ylabel('Duration') plt.plot(durations_t.numpy()) # Take 100 episode averages and plot them too if len(durations_t) >= 100: means = durations_t.unfold(0, 100, 1).mean(1).view(-1) means = torch.cat((torch.zeros(99), means)) plt.plot(means.numpy()) plt.pause(0.001) # pause a bit so that plots are updated if is_ipython: display.clear_output(wait=True) display.display(plt.gcf()) 训练循环 最后，训练我们的模型，其实就是优化我们的智能体。 在这里，您可以找到执行优化步骤的optimize_model函数。 它首先对一批进行采样，将所有张量连接成一个张量，计算和，然后将它们组合成我们的损失。 根据定义，如果为对局结束状态，则设置。 我们还使用目标网络来计算，以提高稳定性。 目标网络的权重大部分时间保持不变，但每隔一段时间就会更新一次价值网络权重。这是一组固定的步骤，但为了简单起见，我们将使用迭代次数。 def optimize_model(): if len(memory) 在下面，您可以找到主要的训练循环。 首先，我们重置环境并初始化state Tensor。 然后，我们采样一个动作，执行它，观察下一个屏幕和奖励(总是 1），并一次优化我们的模型。 当情节结束(我们的模型失败）时，我们重新开始循环。 下面，将 num_episodes 设置得较小。 您应该下载笔记本并运行更多的片段，例如 300 多个片段，以实现有意义的持续时间改进。 num_episodes = 50 for i_episode in range(num_episodes): # Initialize the environment and state env.reset() last_screen = get_screen() current_screen = get_screen() state = current_screen - last_screen for t in count(): # Select and perform an action action = select_action(state) _, reward, done, _ = env.step(action.item()) reward = torch.tensor([reward], device=device) # Observe new state last_screen = current_screen current_screen = get_screen() if not done: next_state = current_screen - last_screen else: next_state = None # Store the transition in memory memory.push(state, action, next_state, reward) # Move to the next state state = next_state # Perform one step of the optimization (on the target network) optimize_model() if done: episode_durations.append(t + 1) plot_durations() break # Update the target network, copying all weights and biases in DQN if i_episode % TARGET_UPDATE == 0: target_net.load_state_dict(policy_net.state_dict()) print('Complete') env.render() env.close() plt.ioff() plt.show() 下面这张图是对整个DQN算法的总结： 行为可以是随机选择的，也可以是基于一个策略，从Gym环境中获取下一步的样本。我们将结果记录在经验回放库中，并在每次迭代中运行优化步骤。优化从经验回放中随机抽取一批来训练新策略。 “旧的”target_net也用于优化计算预期的Q值；它偶尔会更新以保持其最新。 脚本的总运行时间：(0 分钟 0.000 秒） Download Python source code: reinforcement_q_learning.py Download Jupyter notebook: reinforcement_q_learning.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-17 18:08:15 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"28.html":{"url":"28.html","title":"通过带有 Flask 的 REST API 在 Python 中部署 PyTorch","keywords":"","body":"通过带有 Flask 的 REST API 在 Python 中部署 PyTorch 原文： https://pytorch.org/tutorials/intermediate/flask_rest_api_tutorial.html 注意 单击此处的下载完整的示例代码 作者： Avinash Sajjanshetty 在本教程中，我们将使用 Flask 部署 PyTorch 模型，并公开用于模型推理的 REST API。 特别是，我们将部署预训练的 DenseNet 121 模型来检测图像。 小费 此处使用的所有代码均以 MIT 许可发布，可在 Github 上找到。 这是在生产中部署 PyTorch 模型的系列教程中的第一篇。 到目前为止，以这种方式使用 Flask 是开始为 PyTorch 模型提供服务的最简单方法，但不适用于具有高性能要求的用例。 为了那个原因： 如果您已经熟悉 TorchScript，可以直接进入我们的用 C ++加载 TorchScript 模型教程。 如果您首先需要在 TorchScript 上进行复习，请查看我们的 TorchScript 入门教程。 API 定义 我们将首先定义 API 端点，请求和响应类型。 我们的 API 端点将位于/predict，该端点通过包含图片的file参数接受 HTTP POST 请求。 响应将是包含预测的 JSON 响应： {\"class_id\": \"n02124075\", \"class_name\": \"Egyptian_cat\"} 依存关系 通过运行以下命令来安装所需的依赖项： $ pip install Flask==1.0.3 torchvision-0.3.0 简单的 Web 服务器 以下是一个简单的网络服务器，摘自 Flask 的文档 from flask import Flask app = Flask(__name__) @app.route('/') def hello(): return 'Hello World!' 将以上代码段保存在名为app.py的文件中，您现在可以通过输入以下内容来运行 Flask 开发服务器： $ FLASK_ENV=development FLASK_APP=app.py flask run 当您在网络浏览器中访问http://localhost:5000/时，将看到Hello World!文字 我们将对上面的代码段进行一些更改，以使其适合我们的 API 定义。 首先，我们将方法重命名为predict。 我们将端点路径更新为/predict。 由于图像文件将通过 HTTP POST 请求发送，因此我们将对其进行更新，使其也仅接受 POST 请求： @app.route('/predict', methods=['POST']) def predict(): return 'Hello World!' 我们还将更改响应类型，以使其返回包含 ImageNet 类 ID 和名称的 JSON 响应。 更新后的app.py文件现在为： from flask import Flask, jsonify app = Flask(__name__) @app.route('/predict', methods=['POST']) def predict(): return jsonify({'class_id': 'IMAGE_NET_XXX', 'class_name': 'Cat'}) 推理 在下一部分中，我们将重点介绍编写推理代码。 这将涉及两部分，第一部分是准备图像，以便可以将其馈送到 DenseNet；第二部分，我们将编写代码以从模型中获取实际的预测。 准备图像 DenseNet 模型要求图像为尺寸为 224 x 224 的 3 通道 RGB 图像。我们还将使用所需的均值和标准偏差值对图像张量进行归一化。 您可以在上阅读有关它的更多信息。 我们将使用torchvision库中的transforms并建立一个转换管道，该转换管道可根据需要转换图像。 您可以在上阅读有关变换的更多信息。 import io import torchvision.transforms as transforms from PIL import Image def transform_image(image_bytes): my_transforms = transforms.Compose([transforms.Resize(255), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize( [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]) image = Image.open(io.BytesIO(image_bytes)) return my_transforms(image).unsqueeze(0) 上面的方法以字节为单位获取图像数据，应用一系列变换并返回张量。 要测试上述方法，请以字节模式读取图像文件(首先将 ../_static/img/sample_file.jpeg 替换为计算机上文件的实际路径），然后查看是否获得张量 背部： with open(\"../_static/img/sample_file.jpeg\", 'rb') as f: image_bytes = f.read() tensor = transform_image(image_bytes=image_bytes) print(tensor) 出： tensor([[[[ 0.4508, 0.4166, 0.3994, ..., -1.3473, -1.3302, -1.3473], [ 0.5364, 0.4851, 0.4508, ..., -1.2959, -1.3130, -1.3302], [ 0.7077, 0.6392, 0.6049, ..., -1.2959, -1.3302, -1.3644], ..., [ 1.3755, 1.3927, 1.4098, ..., 1.1700, 1.3584, 1.6667], [ 1.8893, 1.7694, 1.4440, ..., 1.2899, 1.4783, 1.5468], [ 1.6324, 1.8379, 1.8379, ..., 1.4783, 1.7352, 1.4612]], [[ 0.5728, 0.5378, 0.5203, ..., -1.3704, -1.3529, -1.3529], [ 0.6604, 0.6078, 0.5728, ..., -1.3004, -1.3179, -1.3354], [ 0.8529, 0.7654, 0.7304, ..., -1.3004, -1.3354, -1.3704], ..., [ 1.4657, 1.4657, 1.4832, ..., 1.3256, 1.5357, 1.8508], [ 2.0084, 1.8683, 1.5182, ..., 1.4657, 1.6583, 1.7283], [ 1.7458, 1.9384, 1.9209, ..., 1.6583, 1.9209, 1.6408]], [[ 0.7228, 0.6879, 0.6531, ..., -1.6476, -1.6302, -1.6476], [ 0.8099, 0.7576, 0.7228, ..., -1.6476, -1.6476, -1.6650], [ 1.0017, 0.9145, 0.8797, ..., -1.6476, -1.6650, -1.6999], ..., [ 1.6291, 1.6291, 1.6465, ..., 1.6291, 1.8208, 2.1346], [ 2.1868, 2.0300, 1.6814, ..., 1.7685, 1.9428, 2.0125], [ 1.9254, 2.0997, 2.0823, ..., 1.9428, 2.2043, 1.9080]]]]) 预测 现在将使用预训练的 DenseNet 121 模型来预测图像类别。 我们将使用torchvision库中的一个，加载模型并进行推断。 在此示例中，我们将使用预训练的模型，但您可以对自己的模型使用相同的方法。 在此教程中查看有关加载模型的更多信息。 from torchvision import models # Make sure to pass `pretrained` as `True` to use the pretrained weights: model = models.densenet121(pretrained=True) # Since we are using our model only for inference, switch to `eval` mode: model.eval() def get_prediction(image_bytes): tensor = transform_image(image_bytes=image_bytes) outputs = model.forward(tensor) _, y_hat = outputs.max(1) return y_hat 张量y_hat将包含预测的类 ID 的索引。 但是，我们需要一个人类可读的类名。 为此，我们需要一个类 ID 来进行名称映射。 将这个文件下载为imagenet_class_index.json，并记住它的保存位置(或者，如果您按照本教程中的确切步骤操作，请将其保存在 tutorials / _static 中）。 该文件包含 ImageNet 类 ID 到 ImageNet 类名称的映射。 我们将加载此 JSON 文件并获取预测索引的类名称。 import json imagenet_class_index = json.load(open('../_static/imagenet_class_index.json')) def get_prediction(image_bytes): tensor = transform_image(image_bytes=image_bytes) outputs = model.forward(tensor) _, y_hat = outputs.max(1) predicted_idx = str(y_hat.item()) return imagenet_class_index[predicted_idx] 在使用imagenet_class_index字典之前，首先我们将张量值转换为字符串值，因为imagenet_class_index字典中的键是字符串。 我们将测试上述方法： with open(\"../_static/img/sample_file.jpeg\", 'rb') as f: image_bytes = f.read() print(get_prediction(image_bytes=image_bytes)) Out: ['n02124075', 'Egyptian_cat'] 您应该得到如下响应： ['n02124075', 'Egyptian_cat'] 数组中的第一项是 ImageNet 类 ID，第二项是人类可读的名称。 Note 您是否注意到model变量不属于get_prediction方法？ 还是为什么模型是全局变量？ 就内存和计算而言，加载模型可能是一项昂贵的操作。 如果我们在get_prediction方法中加载模型，则每次调用该方法时都会不必要地加载该模型。 由于我们正在构建一个 Web 服务器，因此每秒可能有成千上万的请求，因此我们不应该浪费时间为每个推断重复加载模型。 因此，我们仅将模型加载到内存中一次。 在生产系统中，必须有效利用计算以能够大规模处理请求，因此通常应在处理请求之前加载模型。 将模型集成到我们的 API 服务器中 在最后一部分中，我们将模型添加到 Flask API 服务器中。 由于我们的 API 服务器应该获取图像文件，因此我们将更新predict方法以从请求中读取文件： from flask import request @app.route('/predict', methods=['POST']) def predict(): if request.method == 'POST': # we will get the file from the request file = request.files['file'] # convert that to bytes img_bytes = file.read() class_id, class_name = get_prediction(image_bytes=img_bytes) return jsonify({'class_id': class_id, 'class_name': class_name}) app.py文件现在完成。 以下是完整版本； 将路径替换为保存文件的路径，它应运行： import io import json from torchvision import models import torchvision.transforms as transforms from PIL import Image from flask import Flask, jsonify, request app = Flask(__name__) imagenet_class_index = json.load(open('/imagenet_class_index.json')) model = models.densenet121(pretrained=True) model.eval() def transform_image(image_bytes): my_transforms = transforms.Compose([transforms.Resize(255), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize( [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]) image = Image.open(io.BytesIO(image_bytes)) return my_transforms(image).unsqueeze(0) def get_prediction(image_bytes): tensor = transform_image(image_bytes=image_bytes) outputs = model.forward(tensor) _, y_hat = outputs.max(1) predicted_idx = str(y_hat.item()) return imagenet_class_index[predicted_idx] @app.route('/predict', methods=['POST']) def predict(): if request.method == 'POST': file = request.files['file'] img_bytes = file.read() class_id, class_name = get_prediction(image_bytes=img_bytes) return jsonify({'class_id': class_id, 'class_name': class_name}) if __name__ == '__main__': app.run() 让我们测试一下我们的网络服务器！ 跑： $ FLASK_ENV=development FLASK_APP=app.py flask run 我们可以使用请求库将 POST 请求发送到我们的应用： import requests resp = requests.post(\"http://localhost:5000/predict\", files={\"file\": open('/cat.jpg','rb')}) 现在打印 resp.json(）将显示以下内容： {\"class_id\": \"n02124075\", \"class_name\": \"Egyptian_cat\"} 下一步 我们编写的服务器非常琐碎，可能无法完成生产应用程序所需的一切。 因此，您可以采取一些措施来改善它： 端点/predict假定请求中始终会有一个图像文件。 并非所有请求都适用。 我们的用户可能发送带有其他参数的图像，或者根本不发送任何图像。 用户也可以发送非图像类型的文件。 由于我们没有处理错误，因此这将破坏我们的服务器。 添加显式的错误处理路径将引发异常，这将使我们能够更好地处理错误的输入 即使模型可以识别大量类别的图像，也可能无法识别所有图像。 增强实现以处理模型无法识别图像中的任何情况的情况。 我们在开发模式下运行 Flask 服务器，该服务器不适合在生产中进行部署。 您可以查看本教程的，以在生产环境中部署 Flask 服务器。 您还可以通过创建一个带有表单的页面来添加 UI，该表单可以拍摄图像并显示预测。 查看类似项目的演示及其源代码。 在本教程中，我们仅展示了如何构建可以一次返回单个图像预测的服务。 我们可以修改我们的服务，以便能够一次返回多个图像的预测。 此外，服务流媒体库会自动将对服务的请求排队，并将请求采样到微型批次中，这些微型批次可输入模型中。 您可以查看本教程。 最后，我们鼓励您在页面顶部查看链接到的有关部署 PyTorch 模型的其他教程。 脚本的总运行时间：(0 分钟 1.971 秒） Download Python source code: flask_rest_api_tutorial.py Download Jupyter notebook: flask_rest_api_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"29.html":{"url":"29.html","title":"TorchScript 简介","keywords":"","body":"TorchScript 简介 原文： https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html 注意 单击此处的下载完整的示例代码 James Reed(jamesreed@fb.com），Michael Suo(suo@fb.com），rev2 本教程是 TorchScript 的简介，TorchScript 是 PyTorch 模型(nn.Module的子类）的中间表示形式，可以在高性能环境(例如 C ++）中运行。 在本教程中，我们将介绍： PyTorch 中的模型创作基础，包括： 模组 定义forward功能 将模块组成模块的层次结构 将 PyTorch 模块转换为 TorchScript(我们的高性能部署运行时）的特定方法 跟踪现有模块 使用脚本直接编译模块 如何组合这两种方法 保存和加载 TorchScript 模块 我们希望在完成本教程后，您将继续学习和后续教程，该教程将引导您完成一个从 C ++实际调用 TorchScript 模型的示例。 import torch # This is all you need to use both PyTorch and TorchScript! print(torch.__version__) 出： 1.4.0 PyTorch 模型创作的基础 首先定义一个简单的Module。 Module是 PyTorch 中组成的基本单位。 它包含了： 构造函数，为调用准备模块 一组Parameters和子Modules。 这些由构造函数初始化，并且可以在调用期间由模块使用。 forward功能。 这是调用模块时运行的代码。 我们来看一个小例子： class MyCell(torch.nn.Module): def __init__(self): super(MyCell, self).__init__() def forward(self, x, h): new_h = torch.tanh(x + h) return new_h, new_h my_cell = MyCell() x = torch.rand(3, 4) h = torch.rand(3, 4) print(my_cell(x, h)) Out: (tensor([[0.9541, 0.7233, 0.4907, 0.6169], [0.9117, 0.2329, 0.2512, 0.7751], [0.2949, 0.2434, 0.8694, 0.4242]]), tensor([[0.9541, 0.7233, 0.4907, 0.6169], [0.9117, 0.2329, 0.2512, 0.7751], [0.2949, 0.2434, 0.8694, 0.4242]])) 因此，我们已经： 创建了一个子类torch.nn.Module的类。 定义一个构造函数。 构造函数没有做太多事情，只是调用super的构造函数。 定义了forward函数，该函数具有两个输入并返回两个输出。 forward函数的实际内容并不是很重要，但它是一种伪造的 RNN 单元格，即，该函数应用于循环。 我们实例化了该模块，并制作了x和y，它们只是 3x4 随机值矩阵。 然后，我们使用my_cell(x, h)调用该单元格。 这依次调用我们的forward函数。 让我们做一些更有趣的事情： class MyCell(torch.nn.Module): def __init__(self): super(MyCell, self).__init__() self.linear = torch.nn.Linear(4, 4) def forward(self, x, h): new_h = torch.tanh(self.linear(x) + h) return new_h, new_h my_cell = MyCell() print(my_cell) print(my_cell(x, h)) Out: MyCell( (linear): Linear(in_features=4, out_features=4, bias=True) ) (tensor([[ 0.2940, 0.0822, -0.1697, 0.6644], [ 0.3065, -0.1165, 0.3684, 0.4877], [ 0.0409, 0.2764, 0.4881, 0.5211]], grad_fn=), tensor([[ 0.2940, 0.0822, -0.1697, 0.6644], [ 0.3065, -0.1165, 0.3684, 0.4877], [ 0.0409, 0.2764, 0.4881, 0.5211]], grad_fn=)) 我们已经重新定义了模块MyCell，但是这次我们添加了self.linear属性，并在 forward 函数中调用了self.linear。 这里到底发生了什么？ torch.nn.Linear是 PyTorch 标准库中的Module。 就像MyCell一样，可以使用调用语法来调用它。 我们正在建立Module的层次结构。 Module上的print将直观地表示Module的子类层次结构。 在我们的示例中，我们可以看到Linear子类及其参数。 通过以这种方式组成Module，我们可以简洁易读地编写具有可重用组件的模型。 您可能已经在输出上注意到grad_fn。 这是 PyTorch 自动区分方法的详细信息，称为 autograd 。 简而言之，该系统允许我们通过潜在的复杂程序来计算导数。 该设计为模型创作提供了极大的灵活性。 现在让我们检查一下灵活性： class MyDecisionGate(torch.nn.Module): def forward(self, x): if x.sum() > 0: return x else: return -x class MyCell(torch.nn.Module): def __init__(self): super(MyCell, self).__init__() self.dg = MyDecisionGate() self.linear = torch.nn.Linear(4, 4) def forward(self, x, h): new_h = torch.tanh(self.dg(self.linear(x)) + h) return new_h, new_h my_cell = MyCell() print(my_cell) print(my_cell(x, h)) Out: MyCell( (dg): MyDecisionGate() (linear): Linear(in_features=4, out_features=4, bias=True) ) (tensor([[ 0.7407, 0.4486, 0.2651, -0.0298], [ 0.8582, 0.3146, 0.1919, -0.1760], [ 0.6428, 0.0017, 0.1307, -0.1543]], grad_fn=), tensor([[ 0.7407, 0.4486, 0.2651, -0.0298], [ 0.8582, 0.3146, 0.1919, -0.1760], [ 0.6428, 0.0017, 0.1307, -0.1543]], grad_fn=)) 我们再次重新定义了 MyCell 类，但在这里我们定义了MyDecisionGate。 该模块利用控制流。 控制流包括循环和if语句之类的内容。 给定完整的程序表示形式，许多框架都采用计算符号导数的方法。 但是，在 PyTorch 中，我们使用渐变色带。 我们记录发生的操作，并在计算派生时向后回放。 这样，框架不必为语言中的所有构造显式定义派生类。 autograd 的工作原理 TorchScript 的基础 现在，让我们以正在运行的示例为例，看看如何应用 TorchScript。 简而言之，即使 PyTorch 具有灵活和动态的特性，TorchScript 也提供了捕获模型定义的工具。 让我们开始研究所谓的跟踪。 追踪Modules class MyCell(torch.nn.Module): def __init__(self): super(MyCell, self).__init__() self.linear = torch.nn.Linear(4, 4) def forward(self, x, h): new_h = torch.tanh(self.linear(x) + h) return new_h, new_h my_cell = MyCell() x, h = torch.rand(3, 4), torch.rand(3, 4) traced_cell = torch.jit.trace(my_cell, (x, h)) print(traced_cell) traced_cell(x, h) Out: MyCell( original_name=MyCell (linear): Linear(original_name=Linear) ) 我们倒退了一点，并学习了MyCell类的第二个版本。 和以前一样，我们实例化了它，但是这一次，我们调用了torch.jit.trace，并传入了Module，并传入了示例输入，网络可能会看到。 这到底是做什么的？ 它调用了Module，记录了运行Module时发生的操作，并创建了torch.jit.ScriptModule的实例(其中TracedModule是实例） TorchScript 在中间表示(或 IR）中记录其定义，在深度学习中通常将其称为图。 我们可以使用.graph属性检查图形： print(traced_cell.graph) Out: graph(%self.1 : __torch__.torch.nn.modules.module.___torch_mangle_1.Module, %input : Float(3, 4), %h : Float(3, 4)): %19 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"linear\"](%self.1) %21 : Tensor = prim::CallMethod[name=\"forward\"](%19, %input) %12 : int = prim::Constant[value=1]() # /var/lib/jenkins/workspace/beginner_source/Intro_to_TorchScript_tutorial.py:188:0 %13 : Float(3, 4) = aten::add(%21, %h, %12) # /var/lib/jenkins/workspace/beginner_source/Intro_to_TorchScript_tutorial.py:188:0 %14 : Float(3, 4) = aten::tanh(%13) # /var/lib/jenkins/workspace/beginner_source/Intro_to_TorchScript_tutorial.py:188:0 %15 : (Float(3, 4), Float(3, 4)) = prim::TupleConstruct(%14, %14) return (%15) 但是，这是一个非常低级的表示形式，图中包含的大多数信息对最终用户没有用。 相反，我们可以使用.code属性给出代码的 Python 语法解释： print(traced_cell.code) Out: def forward(self, input: Tensor, h: Tensor) -> Tuple[Tensor, Tensor]: _0 = torch.add((self.linear).forward(input, ), h, alpha=1) _1 = torch.tanh(_0) return (_1, _1) 那么为什么我们要进行所有这些操作？ 有以下几个原因： TorchScript 代码可以在其自己的解释器中调用，该解释器基本上是受限制的 Python 解释器。 该解释器不获取全局解释器锁定，因此可以在同一实例上同时处理许多请求。 这种格式允许我们将整个模型保存到磁盘上，然后将其加载到另一个环境中，例如在以 Python 以外的语言编写的服务器中 TorchScript 为我们提供了一种表示形式，其中我们可以对代码进行编译器优化以提供更有效的执行 TorchScript 允许我们与许多后端/设备运行时进行交互，与单个操作员相比，它们要求更广泛的程序视图。 我们可以看到，调用traced_cell会产生与 Python 模块相同的结果： print(my_cell(x, h)) print(traced_cell(x, h)) Out: (tensor([[0.8188, 0.8444, 0.6618, 0.5024], [0.8359, 0.2624, 0.7421, 0.1236], [0.7331, 0.5259, 0.6288, 0.5338]], grad_fn=), tensor([[0.8188, 0.8444, 0.6618, 0.5024], [0.8359, 0.2624, 0.7421, 0.1236], [0.7331, 0.5259, 0.6288, 0.5338]], grad_fn=)) (tensor([[0.8188, 0.8444, 0.6618, 0.5024], [0.8359, 0.2624, 0.7421, 0.1236], [0.7331, 0.5259, 0.6288, 0.5338]], grad_fn=), tensor([[0.8188, 0.8444, 0.6618, 0.5024], [0.8359, 0.2624, 0.7421, 0.1236], [0.7331, 0.5259, 0.6288, 0.5338]], grad_fn=)) 使用脚本转换模块 原因是我们使用了模块的第二版，而不是使用带有控制流的子模块的第二版。 现在让我们检查一下： class MyDecisionGate(torch.nn.Module): def forward(self, x): if x.sum() > 0: return x else: return -x class MyCell(torch.nn.Module): def __init__(self, dg): super(MyCell, self).__init__() self.dg = dg self.linear = torch.nn.Linear(4, 4) def forward(self, x, h): new_h = torch.tanh(self.dg(self.linear(x)) + h) return new_h, new_h my_cell = MyCell(MyDecisionGate()) traced_cell = torch.jit.trace(my_cell, (x, h)) print(traced_cell.code) Out: def forward(self, input: Tensor, h: Tensor) -> Tuple[Tensor, Tensor]: _0 = self.dg _1 = (self.linear).forward(input, ) _2 = (_0).forward(_1, ) _3 = torch.tanh(torch.add(_1, h, alpha=1)) return (_3, _3) 查看.code输出，我们可以发现找不到if-else分支！ 为什么？ 跟踪完全按照我们所说的去做：运行代码，记录发生的操作，并构造一个可以做到这一点的 ScriptModule。 不幸的是，诸如控制流之类的东西被抹去了。 我们如何在 TorchScript 中忠实地表示此模块？ 我们提供了脚本编译器，它可以直接分析您的 Python 源代码以将其转换为 TorchScript。 让我们使用脚本编译器转换MyDecisionGate： scripted_gate = torch.jit.script(MyDecisionGate()) my_cell = MyCell(scripted_gate) traced_cell = torch.jit.script(my_cell) print(traced_cell.code) Out: def forward(self, x: Tensor, h: Tensor) -> Tuple[Tensor, Tensor]: _0 = (self.dg).forward((self.linear).forward(x, ), ) new_h = torch.tanh(torch.add(_0, h, alpha=1)) return (new_h, new_h) 万岁！ 现在，我们已经忠实地捕获了我们在 TorchScript 中程序的行为。 现在，让我们尝试运行该程序： # New inputs x, h = torch.rand(3, 4), torch.rand(3, 4) traced_cell(x, h) 混合脚本和跟踪 在某些情况下，需要使用跟踪而不是脚本(例如，一个模块具有许多基于不变的 Python 值做出的架构决策，而我们不希望它们出现在 TorchScript 中）。 在这种情况下，可以通过跟踪来组成脚本：torch.jit.script将内联被跟踪模块的代码，而跟踪将内联脚本模块的代码。 第一种情况的示例： class MyRNNLoop(torch.nn.Module): def __init__(self): super(MyRNNLoop, self).__init__() self.cell = torch.jit.trace(MyCell(scripted_gate), (x, h)) def forward(self, xs): h, y = torch.zeros(3, 4), torch.zeros(3, 4) for i in range(xs.size(0)): y, h = self.cell(xs[i], h) return y, h rnn_loop = torch.jit.script(MyRNNLoop()) print(rnn_loop.code) Out: def forward(self, xs: Tensor) -> Tuple[Tensor, Tensor]: h = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None) y = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None) y0 = y h0 = h for i in range(torch.size(xs, 0)): _0 = (self.cell).forward(torch.select(xs, 0, i), h0, ) y1, h1, = _0 y0, h0 = y1, h1 return (y0, h0) 还有第二种情况的示例： class WrapRNN(torch.nn.Module): def __init__(self): super(WrapRNN, self).__init__() self.loop = torch.jit.script(MyRNNLoop()) def forward(self, xs): y, h = self.loop(xs) return torch.relu(y) traced = torch.jit.trace(WrapRNN(), (torch.rand(10, 3, 4))) print(traced.code) Out: def forward(self, argument_1: Tensor) -> Tensor: _0, h, = (self.loop).forward(argument_1, ) return torch.relu(h) 这样，当情况需要它们时，可以使用脚本和跟踪并将它们一起使用。 保存和加载模型 我们提供 API，以存档格式将 TorchScript 模块保存到磁盘或从磁盘加载 TorchScript 模块。 这种格式包括代码，参数，属性和调试信息，这意味着归档文件是模型的独立表示，可以在完全独立的过程中加载。 让我们保存并加载包装好的 RNN 模块： traced.save('wrapped_rnn.zip') loaded = torch.jit.load('wrapped_rnn.zip') print(loaded) print(loaded.code) Out: RecursiveScriptModule( original_name=Module (loop): RecursiveScriptModule( original_name=MyRNNLoop (cell): RecursiveScriptModule( original_name=Module (dg): RecursiveScriptModule(original_name=MyDecisionGate) (linear): RecursiveScriptModule(original_name=Module) ) ) ) def forward(self, argument_1: Tensor) -> Tensor: _0, h, = (self.loop).forward(argument_1, ) return torch.relu(h) 如您所见，序列化保留了模块层次结构和我们一直在研究的代码。 也可以将模型加载到中，例如到 C ++ 中，以实现不依赖 Python 的执行。 进一步阅读 我们已经完成了教程！ 有关更多涉及的演示，请查看 NeurIPS 演示以使用 TorchScript 转换机器翻译模型： https://colab.research.google.com/drive/1HiICg6jRkBnr5hvK2-VnMi88Vi9pUzEJ 脚本的总运行时间：(0 分钟 0.251 秒） Download Python source code: Intro_to_TorchScript_tutorial.py Download Jupyter notebook: Intro_to_TorchScript_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"30.html":{"url":"30.html","title":"在 C ++中加载 TorchScript 模型","keywords":"","body":"在 C ++中加载 TorchScript 模型 原文： https://pytorch.org/tutorials/advanced/cpp_export.html 顾名思义，PyTorch 的主要接口是 Python 编程语言。 尽管 Python 是许多需要动态性和易于迭代的场景的合适且首选的语言，但是在同样许多情况下，Python 的这些属性恰恰是不利的。 后者经常应用的一种环境是生产 –低延迟和严格部署要求的土地。 对于生产场景，即使仅将 C ++绑定到 Java，Rust 或 Go 之类的另一种语言中，它也是经常选择的语言。 以下段落将概述 PyTorch 提供的从现有 Python 模型到序列化表示形式的路径，该序列化表示形式可以加载和完全由 C ++执行，不依赖于 Python。 步骤 1：将 PyTorch 模型转换为 Torch 脚本 PyTorch 模型从 Python 到 C ++的旅程由 Torch 脚本启用，它是 PyTorch 模型的表示形式，可以由 Torch 脚本编译器理解，编译和序列化。 如果您是从使用香草“渴望” API 编写的现有 PyTorch 模型开始的，则必须首先将模型转换为 Torch 脚本。 在最常见的情况下(如下所述），只需很少的努力。 如果您已经有了 Torch 脚本模块，则可以跳到本教程的下一部分。 有两种将 PyTorch 模型转换为 Torch 脚本的方法。 第一种称为跟踪，该机制通过使用示例输入对模型的结构进行一次评估并记录这些输入在模型中的流量来捕获模型的结构。 这适用于有限使用控制流的模型。 第二种方法是在模型中添加显式批注，以告知 Torch Script 编译器可以根据 Torch Script 语言施加的约束直接解析和编译模型代码。 小费 您可以在官方torch脚本参考中找到这两种方法的完整文档，以及使用方法的进一步指导。 通过跟踪转换为 Torch 脚本 要将 PyTorch 模型通过跟踪转换为 Torch 脚本，必须将模型的实例以及示例输入传递给torch.jit.trace函数。 这将产生一个torch.jit.ScriptModule对象，并将模型评估的轨迹嵌入到模块的forward方法中： import torch import torchvision # An instance of your model. model = torchvision.models.resnet18() # An example input you would normally provide to your model's forward() method. example = torch.rand(1, 3, 224, 224) # Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing. traced_script_module = torch.jit.trace(model, example) 现在可以对跟踪的ScriptModule进行评估，使其与常规 PyTorch 模块相同： In[1]: output = traced_script_module(torch.ones(1, 3, 224, 224)) In[2]: output[0, :5] Out[2]: tensor([-0.2698, -0.0381, 0.4023, -0.3010, -0.0448], grad_fn=) 通过注释转换为 Torch 脚本 在某些情况下，例如，如果模型采用特定形式的控制流，则可能需要直接在 Torch 脚本中编写模型并相应地注释模型。 例如，假设您具有以下香草 Pytorch 模型： import torch class MyModule(torch.nn.Module): def __init__(self, N, M): super(MyModule, self).__init__() self.weight = torch.nn.Parameter(torch.rand(N, M)) def forward(self, input): if input.sum() > 0: output = self.weight.mv(input) else: output = self.weight + input return output 因为此模块的forward方法使用取决于输入的控制流，所以它不适合跟踪。 相反，我们可以将其转换为ScriptModule。 为了将模块转换为ScriptModule，需要使用torch.jit.script编译模块，如下所示： class MyModule(torch.nn.Module): def __init__(self, N, M): super(MyModule, self).__init__() self.weight = torch.nn.Parameter(torch.rand(N, M)) def forward(self, input): if input.sum() > 0: output = self.weight.mv(input) else: output = self.weight + input return output my_module = MyModule(10,20) sm = torch.jit.script(my_module) 如果您需要在nn.Module中排除某些方法，因为它们使用了 TorchScript 尚不支持的 Python 功能，则可以使用@torch.jit.ignore注释这些方法 my_module是已准备好进行序列化的ScriptModule的实例。 步骤 2：将脚本模块序列化为文件 跟踪或注释 PyTorch 模型后，一旦您有了ScriptModule，就可以将其序列化为文件了。 稍后，您将可以使用 C ++从此文件加载模块并执行它，而无需依赖 Python。 假设我们要序列化先前在跟踪示例中显示的ResNet18模型。 要执行此序列化，只需在模块上调用保存并为其传递文件名： traced_script_module.save(\"traced_resnet_model.pt\") 这将在您的工作目录中生成一个traced_resnet_model.pt文件。 如果您还想序列化my_module，请致电my_module.save(\"my_module_model.pt\")。我们现在已经正式离开 Python 领域，并准备跨入 C ++领域。 步骤 3：在 C ++中加载脚本模块 要在 C ++中加载序列化的 PyTorch 模型，您的应用程序必须依赖于 PyTorch C ++ API –也称为 LibTorch 。 LibTorch 发行版包含共享库，头文件和 CMake 构建配置文件的集合。 虽然 CMake 不是依赖 LibTorch 的要求，但它是推荐的方法，将来会得到很好的支持。 对于本教程，我们将使用 CMake 和 LibTorch 构建一个最小的 C ++应用程序，该应用程序简单地加载并执行序列化的 PyTorch 模型。 最小的 C ++应用程序 让我们从讨论加载模块的代码开始。 以下将已经做： #include // One-stop header. #include #include int main(int argc, const char* argv[]) { if (argc != 2) { std::cerr \\n\"; return -1; } torch::jit::script::Module module; try { // Deserialize the ScriptModule from a file using torch::jit::load(). module = torch::jit::load(argv[1]); } catch (const c10::Error& e) { std::cerr &lt;torch/script.h&gt;标头包含了运行示例所需的 LibTorch 库中的所有相关包含。 我们的应用程序接受序列化 PyTorch ScriptModule的文件路径作为其唯一的命令行参数，然后继续使用torch::jit::load()函数对该模块进行反序列化，该函数将这个文件路径作为输入。 作为回报，我们收到一个torch::jit::script::Module对象。 我们将稍后讨论如何执行它。 取决于 LibTorch 和构建应用程序 假设我们将以上代码存储到名为example-app.cpp的文件中。 最小的CMakeLists.txt构建起来看起来很简单： cmake_minimum_required(VERSION 3.0 FATAL_ERROR) project(custom_ops) find_package(Torch REQUIRED) add_executable(example-app example-app.cpp) target_link_libraries(example-app \"${TORCH_LIBRARIES}\") set_property(TARGET example-app PROPERTY CXX_STANDARD 14) 构建示例应用程序的最后一件事是 LibTorch 发行版。 您可以随时从 PyTorch 网站上的下载页面获取最新的稳定版本。 如果下载并解压缩最新的归档文件，则应该收到具有以下目录结构的文件夹： libtorch/ bin/ include/ lib/ share/ lib/文件夹包含您必须链接的共享库， include/文件夹包含程序需要包含的头文件， share/文件夹包含必要的 CMake 配置，以启用上面的简单find_package(Torch)命令。 Tip 在 Windows 上，调试和发行版本不兼容 ABI。 如果您打算以调试模式构建项目，请尝试使用 LibTorch 的调试版本。 另外，请确保在下面的cmake --build .行中指定正确的配置。 最后一步是构建应用程序。 为此，假定示例目录的布局如下： example-app/ CMakeLists.txt example-app.cpp 现在，我们可以运行以下命令从example-app/文件夹中构建应用程序： mkdir build cd build cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch .. cmake --build . --config Release 其中/path/to/libtorch应该是解压缩的 LibTorch 发行版的完整路径。 如果一切顺利，它将看起来像这样： root@4b5a67132e81:/example-app# mkdir build root@4b5a67132e81:/example-app# cd build root@4b5a67132e81:/example-app/build# cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch .. -- The C compiler identification is GNU 5.4.0 -- The CXX compiler identification is GNU 5.4.0 -- Check for working C compiler: /usr/bin/cc -- Check for working C compiler: /usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Detecting C compile features -- Detecting C compile features - done -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Looking for pthread.h -- Looking for pthread.h - found -- Looking for pthread_create -- Looking for pthread_create - not found -- Looking for pthread_create in pthreads -- Looking for pthread_create in pthreads - not found -- Looking for pthread_create in pthread -- Looking for pthread_create in pthread - found -- Found Threads: TRUE -- Configuring done -- Generating done -- Build files have been written to: /example-app/build root@4b5a67132e81:/example-app/build# make Scanning dependencies of target example-app [ 50%] Building CXX object CMakeFiles/example-app.dir/example-app.cpp.o [100%] Linking CXX executable example-app [100%] Built target example-app 如果我们提供到先前创建的跟踪ResNet18模型traced_resnet_model.pt到生成的example-app二进制文件的路径，则应该以友好的“ ok”作为奖励。 请注意，如果尝试使用my_module_model.pt运行此示例，则会收到一条错误消息，提示您输入的形状不兼容。 my_module_model.pt期望使用 1D 而不是 4D。 root@4b5a67132e81:/example-app/build# ./example-app /traced_resnet_model.pt ok 步骤 4：在 C ++中执行脚本模块 在用 C ++成功加载序列化的ResNet18之后，我们现在离执行它仅几行代码了！ 让我们将这些行添加到 C ++应用程序的main()函数中： // Create a vector of inputs. std::vector inputs; inputs.push_back(torch::ones({1, 3, 224, 224})); // Execute the model and turn its output into a tensor. at::Tensor output = module.forward(inputs).toTensor(); std::cout 前两行设置了我们模型的输入。 我们创建一个torch::jit::IValue的向量(类型擦除的值类型script::Module方法接受并返回），并添加单个输入。 要创建输入张量，我们使用torch::ones()，等效于 C ++ API 中的torch.ones。 然后，我们运行script::Module的forward方法，并将其传递给我们创建的输入向量。 作为回报，我们得到一个新的IValue，我们可以通过调用toTensor()将其转换为张量。 Tip 要总体上了解有关torch::ones和 PyTorch C ++ API 之类的功能的更多信息，请参阅 https://pytorch.org/cppdocs 上的文档。 PyTorch C ++ API 提供了与 Python API 差不多的功能奇偶校验，使您可以像在 Python 中一样进一步操纵和处理张量。 在最后一行，我们打印输出的前五个条目。 由于在本教程前面的部分中，我们向 Python 中的模型提供了相同的输入，因此理想情况下，我们应该看到相同的输出。 让我们通过重新编译我们的应用程序并以相同的序列化模型运行它来进行尝试： root@4b5a67132e81:/example-app/build# make Scanning dependencies of target example-app [ 50%] Building CXX object CMakeFiles/example-app.dir/example-app.cpp.o [100%] Linking CXX executable example-app [100%] Built target example-app root@4b5a67132e81:/example-app/build# ./example-app traced_resnet_model.pt -0.2698 -0.0381 0.4023 -0.3010 -0.0448 [ Variable[CPUFloatType]{1,5} ] 作为参考，Python 以前的输出为： tensor([-0.2698, -0.0381, 0.4023, -0.3010, -0.0448], grad_fn=) 看起来很不错！ Tip 要将模型移至 GPU 内存，可以编写model.to(at::kCUDA);。 通过调用tensor.to(at::kCUDA)来确保模型的输入也位于 CUDA 内存中，这将在 CUDA 内存中返回新的张量。 第 5 步：获取帮助并探索 API 本教程有望使您对 PyTorch 模型从 Python 到 C ++的路径有一个大致的了解。 使用本教程中描述的概念，您应该能够从原始的“急切” PyTorch 模型，到 Python 中已编译的ScriptModule，再到磁盘上的序列化文件，以及–关闭循环–到可执行文件script::Module在 C ++中。 当然，有许多我们没有介绍的概念。 例如，您可能会发现自己想要扩展使用 C ++或 CUDA 实现的自定义运算符来扩展ScriptModule，并希望在纯 C ++生产环境中加载的ScriptModule内执行该自定义运算符。 好消息是：这是可能的，并且得到了很好的支持！ 现在，您可以浏览这个文件夹作为示例，我们将很快提供一个教程。 目前，以下链接通常可能会有所帮助： torch脚本参考： https://pytorch.org/docs/master/jit.html PyTorch C ++ API 文档： https://pytorch.org/cppdocs/ PyTorch Python API 文档： https://pytorch.org/docs/ 与往常一样，如果您遇到任何问题或疑问，可以使用我们的论坛或 GitHub 问题进行联系。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"31.html":{"url":"31.html","title":"(可选）将模型从 PyTorch 导出到 ONNX 并使用 ONNX Runtime 运行","keywords":"","body":"(可选）将模型从 PyTorch 导出到 ONNX 并使用 ONNX Runtime 运行 原文： https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html 注意 单击此处的下载完整的示例代码 在本教程中，我们描述了如何将 PyTorch 中定义的模型转换为 ONNX 格式，然后在 ONNX Runtime 中运行它。 ONNX Runtime 是针对 ONNX 模型的以性能为中心的引擎，可在多个平台和硬件(Windows，Linux 和 Mac 以及 CPU 和 GPU 上）高效地进行推理。 如此处所述，事实证明，ONNX Runtime 可大大提高多个模型的性能。 对于本教程，您将需要安装 ONNX 和 ONNX Runtime 。 您可以使用pip install onnx onnxruntime获得 ONNX 和 ONNX Runtime 的二进制版本。 请注意，ONNX 运行时与 Python 3.5 至 3.7 版本兼容。 NOTE：本教程需要 PyTorch master 分支，可以按照此处的说明进行安装 # Some standard imports import io import numpy as np from torch import nn import torch.utils.model_zoo as model_zoo import torch.onnx 超分辨率是提高图像，视频分辨率的一种方式，广泛用于图像处理或视频编辑中。 在本教程中，我们将使用一个小的超分辨率模型。 首先，让我们在 PyTorch 中创建一个 SuperResolution 模型。 该模型使用了“使用高效的子像素卷积神经网络的实时单图像和视频超分辨率”(Shi 等人）中描述的有效的子像素卷积层来提高图像的分辨率 受高档因素的影响。 该模型期望输入图像的 YCbCr 的 Y 分量作为输入，并以超分辨率输出放大的 Y 分量。 模型直接来自 PyTorch 的示例，未经修改： # Super Resolution model definition in PyTorch import torch.nn as nn import torch.nn.init as init class SuperResolutionNet(nn.Module): def __init__(self, upscale_factor, inplace=False): super(SuperResolutionNet, self).__init__() self.relu = nn.ReLU(inplace=inplace) self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2)) self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1)) self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1)) self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1)) self.pixel_shuffle = nn.PixelShuffle(upscale_factor) self._initialize_weights() def forward(self, x): x = self.relu(self.conv1(x)) x = self.relu(self.conv2(x)) x = self.relu(self.conv3(x)) x = self.pixel_shuffle(self.conv4(x)) return x def _initialize_weights(self): init.orthogonal_(self.conv1.weight, init.calculate_gain('relu')) init.orthogonal_(self.conv2.weight, init.calculate_gain('relu')) init.orthogonal_(self.conv3.weight, init.calculate_gain('relu')) init.orthogonal_(self.conv4.weight) # Create the super-resolution model by using the above model definition. torch_model = SuperResolutionNet(upscale_factor=3) 通常，您现在将训练该模型。 但是，在本教程中，我们将下载一些预训练的权重。 请注意，此模型未经过充分训练以提供良好的准确性，在此仅用于演示目的。 在导出模型之前，请先调用torch_model.eval()或torch_model.train(False)，以将模型转换为推理模式，这一点很重要。 这是必需的，因为像 dropout 或 batchnorm 这样的运算符在推断和训练模式下的行为会有所不同。 # Load pretrained model weights model_url = 'https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth' batch_size = 1 # just a random number # Initialize model with the pretrained weights map_location = lambda storage, loc: storage if torch.cuda.is_available(): map_location = None torch_model.load_state_dict(model_zoo.load_url(model_url, map_location=map_location)) # set the model to inference mode torch_model.eval() 在 PyTorch 中导出模型是通过跟踪或脚本编写的。 本教程将以通过跟踪导出的模型为例。 要导出模型，我们调用torch.onnx.export()函数。 这将执行模型，并记录使用什么运算符计算输出的轨迹。 因为export运行模型，所以我们需要提供输入张量x。 只要是正确的类型和大小，其中的值就可以是随机的。 请注意，除非指定为动态轴，否则输入尺寸将在导出的 ONNX 图形中固定为所有输入尺寸。 在此示例中，我们使用输入 batch_size 1 导出模型，但随后在torch.onnx.export()的dynamic_axes参数中将第一维指定为动态。 因此，导出的模型将接受大小为[batch_size，1、224、224]的输入，其中 batch_size 可以是可变的。 要了解有关 PyTorch 导出界面的更多详细信息，请查看 torch.onnx 文档。 # Input to the model x = torch.randn(batch_size, 1, 224, 224, requires_grad=True) torch_out = torch_model(x) # Export the model torch.onnx.export(torch_model, # model being run x, # model input (or a tuple for multiple inputs) \"super_resolution.onnx\", # where to save the model (can be a file or file-like object) export_params=True, # store the trained parameter weights inside the model file opset_version=10, # the ONNX version to export the model to do_constant_folding=True, # whether to execute constant folding for optimization input_names = ['input'], # the model's input names output_names = ['output'], # the model's output names dynamic_axes={'input' : {0 : 'batch_size'}, # variable lenght axes 'output' : {0 : 'batch_size'}}) 我们还计算了torch_out，即模型之后的输出，我们将用来验证导出的模型在 ONNX Runtime 中运行时是否计算出相同的值。 但是，在通过 ONNX Runtime 验证模型的输出之前，我们将使用 ONNX 的 API 检查 ONNX 模型。 首先，onnx.load(\"super_resolution.onnx\")将加载保存的模型并输出 onnx.ModelProto 结构(用于捆绑 ML 模型的顶级文件/容器格式。有关更多信息，请参见 onnx.proto 文档。）。 然后，onnx.checker.check_model(onnx_model)将验证模型的结构并确认模型具有有效的架构。 通过检查模型的版本，图形的结构以及节点及其输入和输出，可以验证 ONNX 图的有效性。 import onnx onnx_model = onnx.load(\"super_resolution.onnx\") onnx.checker.check_model(onnx_model) 现在，我们使用 ONNX 运行时的 Python API 计算输出。 这部分通常可以在单独的过程中或在另一台机器上完成，但是我们将继续同一过程，以便我们可以验证 ONNX Runtime 和 PyTorch 正在为网络计算相同的值。 为了使用 ONNX Runtime 运行模型，我们需要使用所选的配置参数为模型创建一个推理会话(此处使用默认配置）。 创建会话后，我们将使用 run(）API 评估模型。 此调用的输出是一个列表，其中包含由 ONNX Runtime 计算的模型的输出。 import onnxruntime ort_session = onnxruntime.InferenceSession(\"super_resolution.onnx\") def to_numpy(tensor): return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy() # compute ONNX Runtime output prediction ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)} ort_outs = ort_session.run(None, ort_inputs) # compare ONNX Runtime and PyTorch results np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05) print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\") 我们应该看到 PyTorch 和 ONNX Runtime 的输出在数值上与给定的精度匹配(rtol = 1e-03 和 atol = 1e-05）。 附带说明一下，如果它们不匹配，则说明 ONNX 导出器中存在问题，因此请与我们联系。 使用 ONNX Runtime 在图像上运行模型 到目前为止，我们已经从 PyTorch 导出了一个模型，并演示了如何使用虚拟张量作为输入在 ONNX Runtime 中加载和运行该模型。 在本教程中，我们将使用广泛使用的著名猫图像，如下图所示 首先，让我们加载图片，使用标准 PIL python 库对其进行预处理。 请注意，此预处理是处理数据以训练/测试神经网络的标准做法。 我们首先调整图像大小以适合模型输入的大小(224x224）。 然后，我们将图像分为 Y，Cb 和 Cr 分量。 这些分量代表灰度图像(Y），蓝差(Cb）和红差(Cr）色度分量。 Y 分量对人眼更敏感，我们对将要转换的 Y 分量感兴趣。 提取 Y 分量后，我们将其转换为张量，这将是模型的输入。 from PIL import Image import torchvision.transforms as transforms img = Image.open(\"./_static/img/cat.jpg\") resize = transforms.Resize([224, 224]) img = resize(img) img_ycbcr = img.convert('YCbCr') img_y, img_cb, img_cr = img_ycbcr.split() to_tensor = transforms.ToTensor() img_y = to_tensor(img_y) img_y.unsqueeze_(0) 现在，作为下一步，让我们使用代表灰度尺寸调整后的猫图像的张量，并按照先前的说明在 ONNX Runtime 中运行超分辨率模型。 ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img_y)} ort_outs = ort_session.run(None, ort_inputs) img_out_y = ort_outs[0] 此时，模型的输出为张量。 现在，我们将处理模型的输出，以根据输出张量构造最终的输出图像，并保存图像。 后处理步骤已从此处的超分辨率模型的 PyTorch 实现中采用。 img_out_y = Image.fromarray(np.uint8((img_out_y[0] * 255.0).clip(0, 255)[0]), mode='L') # get the output image follow post-processing step from PyTorch implementation final_img = Image.merge( \"YCbCr\", [ img_out_y, img_cb.resize(img_out_y.size, Image.BICUBIC), img_cr.resize(img_out_y.size, Image.BICUBIC), ]).convert(\"RGB\") # Save the image, we will compare this with the output image from mobile device final_img.save(\"./_static/img/cat_superres_with_ort.jpg\") ONNX Runtime 是跨平台引擎，您可以跨多个平台在 CPU 和 GPU 上运行它。 还可以使用 Azure 机器学习服务将 ONNX Runtime 部署到云中以进行模型推断。 更多信息此处。 在上了解有关 ONNX 运行时性能的更多信息。 有关 ONNX 运行时的更多信息，请参见。 脚本的总运行时间：(0 分钟 0.000 秒） Download Python source code: super_resolution_with_onnxruntime.py Download Jupyter notebook: super_resolution_with_onnxruntime.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"33.html":{"url":"33.html","title":"单机模型并行最佳实践","keywords":"","body":"单机模型并行最佳实践 原文： https://pytorch.org/tutorials/intermediate/model_parallel_tutorial.html 注意 单击此处的下载完整的示例代码 作者：申力 模型并行在分布式训练技术中被广泛使用。 先前的帖子已经解释了如何使用 DataParallel 在多个 GPU 上训练神经网络； 此功能将相同的模型复制到所有 GPU，其中每个 GPU 消耗输入数据的不同分区。 尽管它可以极大地加快训练过程，但不适用于某些模型太大而无法放入单个 GPU 的用例。 这篇文章展示了如何通过使用模型并行解决该问题，与DataParallel相比，该模型将单个模型拆分到不同的 GPU 上，而不是在每个 GPU 上复制整个模型(具体来说， 假设模型m包含 10 层：使用DataParallel时，每个 GPU 都具有这 10 层中每个层的副本，而当在两个 GPU 上并行使用模型时，每个 GPU 可以承载 5 层）。 模型并行化的高级思想是将模型的不同子网放置在不同的设备上，并相应地实现forward方法以在设备之间移动中间输出。 由于模型的一部分仅在任何单个设备上运行，因此一组设备可以共同为更大的模型服务。 在本文中，我们不会尝试构建庞大的模型并将其压缩到有限数量的 GPU 中。 相反，本文着重展示并行模型的概念。 读者可以将这些想法应用到实际应用中。 Note 对于模型跨越多个服务器的分布式模型并行训练，请参见分布式 RPC 框架入门，以获取示例和详细信息。 基本用法 让我们从包含两个线性层的玩具模型开始。 要在两个 GPU 上运行此模型，只需将每个线性层放在不同的 GPU 上，然后移动输入和中间输出以匹配层设备。 import torch import torch.nn as nn import torch.optim as optim class ToyModel(nn.Module): def __init__(self): super(ToyModel, self).__init__() self.net1 = torch.nn.Linear(10, 10).to('cuda:0') self.relu = torch.nn.ReLU() self.net2 = torch.nn.Linear(10, 5).to('cuda:1') def forward(self, x): x = self.relu(self.net1(x.to('cuda:0'))) return self.net2(x.to('cuda:1')) 请注意，除了五个to(device)调用将线性层和张量放置在适当的设备上之外，上述ToyModel看起来非常类似于在单个 GPU 上实现它的方式。 那是模型中唯一需要更改的地方。 backward()和torch.optim将自动处理渐变，就像模型在一个 GPU 上一样。 调用损失函数时，只需确保标签与输出位于同一设备上。 model = ToyModel() loss_fn = nn.MSELoss() optimizer = optim.SGD(model.parameters(), lr=0.001) optimizer.zero_grad() outputs = model(torch.randn(20, 10)) labels = torch.randn(20, 5).to('cuda:1') loss_fn(outputs, labels).backward() optimizer.step() 将模型并行应用于现有模块 只需进行几行更改，就可以在多个 GPU 上运行现有的单 GPU 模块。 以下代码显示了如何将torchvision.models.reset50()分解为两个 GPU。 这个想法是继承现有的ResNet模块，并在构建过程中将层拆分为两个 GPU。 然后，通过相应地移动中间输出，覆盖forward方法来缝合两个子网。 from torchvision.models.resnet import ResNet, Bottleneck num_classes = 1000 class ModelParallelResNet50(ResNet): def __init__(self, *args, **kwargs): super(ModelParallelResNet50, self).__init__( Bottleneck, [3, 4, 6, 3], num_classes=num_classes, *args, **kwargs) self.seq1 = nn.Sequential( self.conv1, self.bn1, self.relu, self.maxpool, self.layer1, self.layer2 ).to('cuda:0') self.seq2 = nn.Sequential( self.layer3, self.layer4, self.avgpool, ).to('cuda:1') self.fc.to('cuda:1') def forward(self, x): x = self.seq2(self.seq1(x).to('cuda:1')) return self.fc(x.view(x.size(0), -1)) 对于模型太大而无法放入单个 GPU 的情况，上述实现解决了该问题。 但是，您可能已经注意到，如果您的模型合适，它将比在单个 GPU 上运行它要慢。 这是因为在任何时间点，两个 GPU 中只有一个在工作，而另一个在那儿什么也没做。 由于中间输出需要在layer2和layer3之间从cuda:0复制到cuda:1，因此性能进一步恶化。 让我们进行实验以更定量地了解执行时间。 在此实验中，我们通过运行随机输入和标签来训练ModelParallelResNet50和现有的torchvision.models.reset50()。 训练后，模型将不会产生任何有用的预测，但是我们可以对执行时间有一个合理的了解。 import torchvision.models as models num_batches = 3 batch_size = 120 image_w = 128 image_h = 128 def train(model): model.train(True) loss_fn = nn.MSELoss() optimizer = optim.SGD(model.parameters(), lr=0.001) one_hot_indices = torch.LongTensor(batch_size) \\ .random_(0, num_classes) \\ .view(batch_size, 1) for _ in range(num_batches): # generate random inputs and labels inputs = torch.randn(batch_size, 3, image_w, image_h) labels = torch.zeros(batch_size, num_classes) \\ .scatter_(1, one_hot_indices, 1) # run forward pass optimizer.zero_grad() outputs = model(inputs.to('cuda:0')) # run backward pass labels = labels.to(outputs.device) loss_fn(outputs, labels).backward() optimizer.step() 上面的train(model)方法使用nn.MSELoss作为损失函数，并使用optim.SGD作为优化器。 它模拟了对128 X 128图像的训练，这些图像分为 3 批，每批包含 120 张图像。 然后，我们使用timeit来运行train(model)方法 10 次，并绘制带有标准偏差的执行时间。 import matplotlib.pyplot as plt plt.switch_backend('Agg') import numpy as np import timeit num_repeat = 10 stmt = \"train(model)\" setup = \"model = ModelParallelResNet50()\" # globals arg is only available in Python 3\\. In Python 2, use the following # import __builtin__ # __builtin__.__dict__.update(locals()) mp_run_times = timeit.repeat( stmt, setup, number=1, repeat=num_repeat, globals=globals()) mp_mean, mp_std = np.mean(mp_run_times), np.std(mp_run_times) setup = \"import torchvision.models as models;\" + \\ \"model = models.resnet50(num_classes=num_classes).to('cuda:0')\" rn_run_times = timeit.repeat( stmt, setup, number=1, repeat=num_repeat, globals=globals()) rn_mean, rn_std = np.mean(rn_run_times), np.std(rn_run_times) def plot(means, stds, labels, fig_name): fig, ax = plt.subplots() ax.bar(np.arange(len(means)), means, yerr=stds, align='center', alpha=0.5, ecolor='red', capsize=10, width=0.6) ax.set_ylabel('ResNet50 Execution Time (Second)') ax.set_xticks(np.arange(len(means))) ax.set_xticklabels(labels) ax.yaxis.grid(True) plt.tight_layout() plt.savefig(fig_name) plt.close(fig) plot([mp_mean, rn_mean], [mp_std, rn_std], ['Model Parallel', 'Single GPU'], 'mp_vs_rn.png') 结果表明，模型并行实现的执行时间比现有的单 GPU 实现长4.02/3.75-1=7%。 因此，我们可以得出结论，在 GPU 之间来回复制张量大约有 7％的开销。 有改进的余地，因为我们知道两个 GPU 之一在整个执行过程中处于空闲状态。 一种选择是将每个批次进一步划分为拆分管道，这样，当一个拆分到达第二个子网时，可以将下一个拆分馈入第一个子网。 这样，两个连续的拆分可以在两个 GPU 上同时运行。 通过流水线输入加速 在以下实验中，我们将每个 120 图像批次进一步划分为 20 图像分割。 当 PyTorch 异步启动 CUDA 操作时，该实现无需生成多个线程即可实现并发。 class PipelineParallelResNet50(ModelParallelResNet50): def __init__(self, split_size=20, *args, **kwargs): super(PipelineParallelResNet50, self).__init__(*args, **kwargs) self.split_size = split_size def forward(self, x): splits = iter(x.split(self.split_size, dim=0)) s_next = next(splits) s_prev = self.seq1(s_next).to('cuda:1') ret = [] for s_next in splits: # A. s_prev runs on cuda:1 s_prev = self.seq2(s_prev) ret.append(self.fc(s_prev.view(s_prev.size(0), -1))) # B. s_next runs on cuda:0, which can run concurrently with A s_prev = self.seq1(s_next).to('cuda:1') s_prev = self.seq2(s_prev) ret.append(self.fc(s_prev.view(s_prev.size(0), -1))) return torch.cat(ret) setup = \"model = PipelineParallelResNet50()\" pp_run_times = timeit.repeat( stmt, setup, number=1, repeat=num_repeat, globals=globals()) pp_mean, pp_std = np.mean(pp_run_times), np.std(pp_run_times) plot([mp_mean, rn_mean, pp_mean], [mp_std, rn_std, pp_std], ['Model Parallel', 'Single GPU', 'Pipelining Model Parallel'], 'mp_vs_rn_vs_pp.png') 请注意，设备到设备的张量复制操作在源设备和目标设备上的当前流上同步。 如果创建多个流，则必须确保复制操作正确同步。 在完成复制操作之前写入源张量或读取/写入目标张量可能导致不确定的行为。 上面的实现仅在源设备和目标设备上都使用默认流，因此没有必要强制执行其他同步。 实验结果表明，对并行 ResNet50 进行建模的流水线输入可大致加快3.75/2.51-1=49%的速度，加快训练过程。 距理想的 100％加速仍然相去甚远。 由于我们在管道并行实现中引入了新参数split_sizes，因此尚不清楚新参数如何影响整体训练时间。 直观地讲，使用较小的split_size会导致许多小的 CUDA 内核启动，而使用较大的split_size会导致在第一次和最后一次拆分期间出现较长的空闲时间。 都不是最佳选择。 对于此特定实验，可能会有最佳的split_size配置。 让我们尝试通过使用几个不同的split_size值进行实验来找到它。 means = [] stds = [] split_sizes = [1, 3, 5, 8, 10, 12, 20, 40, 60] for split_size in split_sizes: setup = \"model = PipelineParallelResNet50(split_size=%d)\" % split_size pp_run_times = timeit.repeat( stmt, setup, number=1, repeat=num_repeat, globals=globals()) means.append(np.mean(pp_run_times)) stds.append(np.std(pp_run_times)) fig, ax = plt.subplots() ax.plot(split_sizes, means) ax.errorbar(split_sizes, means, yerr=stds, ecolor='red', fmt='ro') ax.set_ylabel('ResNet50 Execution Time (Second)') ax.set_xlabel('Pipeline Split Size') ax.set_xticks(split_sizes) ax.yaxis.grid(True) plt.tight_layout() plt.savefig(\"split_size_tradeoff.png\") plt.close(fig) 结果表明，将split_size设置为 12 可获得最快的训练速度，从而导致3.75/2.43-1=54%加速。 仍有机会进一步加快训练过程。 例如，对cuda:0的所有操作都放在其默认流上。 这意味着下一个拆分的计算不能与上一个拆分的复制操作重叠。 但是，由于上一个和下一个拆分是不同的张量，因此将一个计算与另一个副本重叠是没有问题的。 实现需要在两个 GPU 上使用多个流，并且不同的子网结构需要不同的流管理策略。 由于没有通用的多流解决方案适用于所有模型并行用例，因此在本教程中将不再讨论。 注意： 这篇文章显示了几个性能指标。 当您在自己的计算机上运行相同的代码时，您可能会看到不同的数字，因为结果取决于底层的硬件和软件。 为了使您的环境获得最佳性能，一种正确的方法是首先生成曲线以找出最佳分割尺寸，然后将该分割尺寸用于管道输入。 脚本的总运行时间：(5 分钟 53.174 秒） Download Python source code: model_parallel_tutorial.py Download Jupyter notebook: model_parallel_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"34.html":{"url":"34.html","title":"分布式数据并行入门","keywords":"","body":"分布式数据并行入门 原文： https://pytorch.org/tutorials/intermediate/ddp_tutorial.html 作者：申力 DistributedDataParallel (DDP）在模块级别实现数据并行性。 它使用 Torch.distributed 程序包中的通信集合来同步梯度，参数和缓冲区。 并行性在流程内和跨流程均可用。 在一个过程中，DDP 将输入模块复制到device_ids中指定的设备，将输入沿批次维度分散，然后将输出收集到output_device，这与 DataParallel 相似。 在整个过程中，DDP 在正向传递中插入必要的参数同步，在反向传递中插入梯度同步。 用户可以将进程映射到可用资源，只要进程不共享 GPU 设备即可。 推荐的方法(通常是最快的方法）是为每个模块副本创建一个过程，即在一个过程中不进行任何模块复制。 本教程中的代码在 8-GPU 服务器上运行，但可以轻松地推广到其他环境。 DataParallel和DistributedDataParallel之间的比较 在深入探讨之前，让我们澄清一下为什么尽管增加了复杂性，但还是考虑使用DistributedDataParallel而不是DataParallel： 首先，请回顾先前的教程，如果模型太大而无法容纳在单个 GPU 上，则必须使用模型并行将其拆分到多个 GPU 中。 DistributedDataParallel与模型并行一起使用； DataParallel目前没有。 DataParallel是单进程，多线程，并且只能在单台机器上运行，而DistributedDataParallel是多进程，并且适用于单机和多机训练。 因此，即使在单机训练中，数据足够小以适合单机，DistributedDataParallel仍比DataParallel快。 DistributedDataParallel还预先复制模型，而不是在每次迭代时复制模型，并避免了全局解释器锁定。 如果您的两个数据都太大而无法容纳在一台计算机和上，而您的模型又太大了以至于无法安装在单个 GPU 上，则可以将模型并行(跨多个 GPU 拆分单个模型）与DistributedDataParallel结合使用。 在这种情况下，每个DistributedDataParallel进程都可以并行使用模型，而所有进程都将并行使用数据。 基本用例 要创建 DDP 模块，请首先正确设置过程组。 更多细节可以在用 PyTorch 编写分布式应用程序中找到。 import os import tempfile import torch import torch.distributed as dist import torch.nn as nn import torch.optim as optim import torch.multiprocessing as mp from torch.nn.parallel import DistributedDataParallel as DDP def setup(rank, world_size): os.environ['MASTER_ADDR'] = 'localhost' os.environ['MASTER_PORT'] = '12355' # initialize the process group dist.init_process_group(\"gloo\", rank=rank, world_size=world_size) # Explicitly setting seed to make sure that models created in two processes # start from same random weights and biases. torch.manual_seed(42) def cleanup(): dist.destroy_process_group() 现在，让我们创建一个玩具模块，将其与 DDP 封装在一起，并提供一些虚拟输入数据。 请注意，如果训练从随机参数开始，则可能要确保所有 DDP 进程都使用相同的初始值。 否则，全局梯度同步将没有意义。 class ToyModel(nn.Module): def __init__(self): super(ToyModel, self).__init__() self.net1 = nn.Linear(10, 10) self.relu = nn.ReLU() self.net2 = nn.Linear(10, 5) def forward(self, x): return self.net2(self.relu(self.net1(x))) def demo_basic(rank, world_size): setup(rank, world_size) # setup devices for this process, rank 1 uses GPUs [0, 1, 2, 3] and # rank 2 uses GPUs [4, 5, 6, 7]. n = torch.cuda.device_count() // world_size device_ids = list(range(rank * n, (rank + 1) * n)) # create model and move it to device_ids[0] model = ToyModel().to(device_ids[0]) # output_device defaults to device_ids[0] ddp_model = DDP(model, device_ids=device_ids) loss_fn = nn.MSELoss() optimizer = optim.SGD(ddp_model.parameters(), lr=0.001) optimizer.zero_grad() outputs = ddp_model(torch.randn(20, 10)) labels = torch.randn(20, 5).to(device_ids[0]) loss_fn(outputs, labels).backward() optimizer.step() cleanup() def run_demo(demo_fn, world_size): mp.spawn(demo_fn, args=(world_size,), nprocs=world_size, join=True) 如您所见，DDP 包装了较低级别的分布式通信详细信息，并提供了干净的 API，就好像它是本地模型一样。 对于基本用例，DDP 仅需要几个 LoC 来设置流程组。 在将 DDP 应用到更高级的用例时，需要注意一些警告。 偏斜的处理速度 在 DDP 中，构造函数，转发方法和输出的微分是分布式同步点。 期望不同的过程以相同的顺序到达同步点，并在大致相同的时间进入每个同步点。 否则，快速流程可能会提早到达，并在等待流浪者时超时。 因此，用户负责平衡流程之间的工作负载分配。 有时，由于例如网络延迟，资源争用，不可预测的工作量峰值，不可避免地会出现偏斜的处理速度。 为了避免在这些情况下超时，请在调用 init_process_group 时传递足够大的timeout值。 保存和加载检查点 在训练过程中通常使用torch.save和torch.load来检查点模块并从检查点中恢复。 有关更多详细信息，请参见保存和加载模型。 使用 DDP 时，一种优化方法是仅在一个进程中保存模型，然后将其加载到所有进程中，从而减少写开销。 这是正确的，因为所有过程都从相同的参数开始，并且梯度在向后传递中同步，因此优化程序应将参数设置为相同的值。 如果使用此优化，请确保在保存完成之前不要启动所有进程。 此外，在加载模块时，您需要提供适当的map_location参数，以防止进程进入其他设备。 如果缺少map_location，则torch.load将首先将该模块加载到 CPU，然后将每个参数复制到其保存位置，这将导致同一台机器上的所有进程使用同一组设备。 def demo_checkpoint(rank, world_size): setup(rank, world_size) # setup devices for this process, rank 1 uses GPUs [0, 1, 2, 3] and # rank 2 uses GPUs [4, 5, 6, 7]. n = torch.cuda.device_count() // world_size device_ids = list(range(rank * n, (rank + 1) * n)) model = ToyModel().to(device_ids[0]) # output_device defaults to device_ids[0] ddp_model = DDP(model, device_ids=device_ids) loss_fn = nn.MSELoss() optimizer = optim.SGD(ddp_model.parameters(), lr=0.001) CHECKPOINT_PATH = tempfile.gettempdir() + \"/model.checkpoint\" if rank == 0: # All processes should see same parameters as they all start from same # random parameters and gradients are synchronized in backward passes. # Therefore, saving it in one process is sufficient. torch.save(ddp_model.state_dict(), CHECKPOINT_PATH) # Use a barrier() to make sure that process 1 loads the model after process # 0 saves it. dist.barrier() # configure map_location properly rank0_devices = [x - rank * len(device_ids) for x in device_ids] device_pairs = zip(rank0_devices, device_ids) map_location = {'cuda:%d' % x: 'cuda:%d' % y for x, y in device_pairs} ddp_model.load_state_dict( torch.load(CHECKPOINT_PATH, map_location=map_location)) optimizer.zero_grad() outputs = ddp_model(torch.randn(20, 10)) labels = torch.randn(20, 5).to(device_ids[0]) loss_fn = nn.MSELoss() loss_fn(outputs, labels).backward() optimizer.step() # Use a barrier() to make sure that all processes have finished reading the # checkpoint dist.barrier() if rank == 0: os.remove(CHECKPOINT_PATH) cleanup() 将 DDP 与模型并行性结合 DDP 还可以与多 GPU 模型一起使用，但是不支持进程内的复制。 您需要为每个模块副本创建一个进程，与每个进程的多个副本相比，通常可以提高性能。 当训练具有大量数据的大型模型时，DDP 包装多 GPU 模型特别有用。 使用此功能时，需要小心地实现多 GPU 模型，以避免使用硬编码的设备，因为会将不同的模型副本放置到不同的设备上。 class ToyMpModel(nn.Module): def __init__(self, dev0, dev1): super(ToyMpModel, self).__init__() self.dev0 = dev0 self.dev1 = dev1 self.net1 = torch.nn.Linear(10, 10).to(dev0) self.relu = torch.nn.ReLU() self.net2 = torch.nn.Linear(10, 5).to(dev1) def forward(self, x): x = x.to(self.dev0) x = self.relu(self.net1(x)) x = x.to(self.dev1) return self.net2(x) 将多 GPU 模型传递给 DDP 时，不得设置device_ids和output_device。 输入和输出数据将通过应用程序或模型forward()方法放置在适当的设备中。 def demo_model_parallel(rank, world_size): setup(rank, world_size) # setup mp_model and devices for this process dev0 = rank * 2 dev1 = rank * 2 + 1 mp_model = ToyMpModel(dev0, dev1) ddp_mp_model = DDP(mp_model) loss_fn = nn.MSELoss() optimizer = optim.SGD(ddp_mp_model.parameters(), lr=0.001) optimizer.zero_grad() # outputs will be on dev1 outputs = ddp_mp_model(torch.randn(20, 10)) labels = torch.randn(20, 5).to(dev1) loss_fn(outputs, labels).backward() optimizer.step() cleanup() if __name__ == \"__main__\": run_demo(demo_basic, 2) run_demo(demo_checkpoint, 2) if torch.cuda.device_count() >= 8: run_demo(demo_model_parallel, 4) 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"35.html":{"url":"35.html","title":"用 PyTorch 编写分布式应用程序","keywords":"","body":"用 PyTorch 编写分布式应用程序 原文： https://pytorch.org/tutorials/intermediate/dist_tuto.html 作者：SébArnold 在这个简短的教程中，我们将介绍 PyTorch 的分布式软件包。 我们将了解如何设置分布式设置，使用不同的交流策略以及如何仔细查看软件包的内部结构。 设定 PyTorch 中包含的分布式软件包(即torch.distributed）使研究人员和从业人员可以轻松地并行化他们在跨进程和机器集群的计算。 为此，它利用了传递消息的语义，从而允许每个进程将数据传递给其他任何进程。 与并行处理(HTG1）包相反，进程可以使用不同的通信后端，而不仅限于在同一台计算机上执行。 为了开始，我们需要能够同时运行多个进程的能力。 如果您有权访问计算群集，则应咨询本地系统管理员或使用您喜欢的协调工具。 (例如 pdsh ， clustershell 或其他）。出于本教程的目的，我们将使用以下模板使用一台计算机并分叉多个进程。 \"\"\"run.py:\"\"\" #!/usr/bin/env python import os import torch import torch.distributed as dist from torch.multiprocessing import Process def run(rank, size): \"\"\" Distributed function to be implemented later. \"\"\" pass def init_process(rank, size, fn, backend='gloo'): \"\"\" Initialize the distributed environment. \"\"\" os.environ['MASTER_ADDR'] = '127.0.0.1' os.environ['MASTER_PORT'] = '29500' dist.init_process_group(backend, rank=rank, world_size=size) fn(rank, size) if __name__ == \"__main__\": size = 2 processes = [] for rank in range(size): p = Process(target=init_process, args=(rank, size, run)) p.start() processes.append(p) for p in processes: p.join() 上面的脚本产生了两个进程，每个进程将设置分布式环境，初始化进程组(dist.init_process_group），最后执行给定的run函数。 让我们看一下init_process功能。 它确保每个进程将能够使用相同的 IP 地址和端口通过主机进行协调。 请注意，我们使用了gloo后端，但其他后端也可用。 (请参阅 5.1 节），我们将在本教程的结尾部分介绍dist.init_process_group中发生的魔术，但实际上，它允许进程通过共享位置相互进行通信。 点对点通讯 发送和接收 数据从一个进程到另一个进程的传输称为点对点通信。 这些是通过send和recv功能或它们的直接对应部分isend和irecv实现的。 \"\"\"Blocking point-to-point communication.\"\"\" def run(rank, size): tensor = torch.zeros(1) if rank == 0: tensor += 1 # Send the tensor to process 1 dist.send(tensor=tensor, dst=1) else: # Receive tensor from process 0 dist.recv(tensor=tensor, src=0) print('Rank ', rank, ' has data ', tensor[0]) 在上面的示例中，两个进程都从零张量开始，然后进程 0 递增张量并将其发送到进程 1，以便它们都以 1.0 结尾。 请注意，进程 1 需要分配内存以存储它将接收的数据。 另请注意，send / recv被阻塞：两个过程都停止，直到通信完成。 另一方面，无阻塞； 脚本继续执行，方法返回Work对象，我们可以选择wait()对象。 \"\"\"Non-blocking point-to-point communication.\"\"\" def run(rank, size): tensor = torch.zeros(1) req = None if rank == 0: tensor += 1 # Send the tensor to process 1 req = dist.isend(tensor=tensor, dst=1) print('Rank 0 started sending') else: # Receive tensor from process 0 req = dist.irecv(tensor=tensor, src=0) print('Rank 1 started receiving') req.wait() print('Rank ', rank, ' has data ', tensor[0]) 使用立即数时，我们必须谨慎使用已发送和已接收的张量。 由于我们不知道何时将数据传递给其他进程，因此在req.wait()完成之前，我们既不应该修改发送的张量也不应该访问接收的张量。 换一种说法， 在dist.isend()之后写入tensor将导致不确定的行为。 在dist.irecv()之后从tensor读取将导致不确定的行为。 但是，在执行req.wait()之后，我们可以确保进行了通信，并且tensor[0]中存储的值为 1.0。 当我们希望对流程的通信进行精细控制时，点对点通信非常有用。 它们可用于实现精美的算法，例如百度的 DeepSpeech 或 Facebook 的大规模实验中使用的算法。(请参阅 4.1 节） 集体交流 | 分散 | 收集 | | 降低 | 全减少 | | 广播 | 全聚 | 与点对点通信相反，集合允许跨组中所有进程的通信模式。 小组是我们所有过程的子集。 要创建组，我们可以将等级列表传递给dist.new_group(group)。 默认情况下，集合在所有进程(也称为世界）上执行。 例如，为了获得所有过程中所有张量的总和，我们可以使用dist.all_reduce(tensor, op, group)集合。 \"\"\" All-Reduce example.\"\"\" def run(rank, size): \"\"\" Simple point-to-point communication. \"\"\" group = dist.new_group([0, 1]) tensor = torch.ones(1) dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group) print('Rank ', rank, ' has data ', tensor[0]) 由于我们需要组中所有张量的总和，因此我们将dist.reduce_op.SUM用作化简运算符。 一般来说，任何可交换的数学运算都可以用作运算符。 PyTorch 开箱即用，带有 4 个这样的运算符，它们都在元素级运行： dist.reduce_op.SUM， dist.reduce_op.PRODUCT， dist.reduce_op.MAX， dist.reduce_op.MIN。 除了dist.all_reduce(tensor, op, group)之外，PyTorch 中目前共有 6 个集合体。 dist.broadcast(tensor, src, group)：将tensor从src复制到所有其他进程。 dist.reduce(tensor, dst, op, group)：将op应用于所有tensor，并将结果存储在dst中。 dist.all_reduce(tensor, op, group)：与 reduce 相同，但是结果存储在所有进程中。 dist.scatter(tensor, src, scatter_list, group)：将张量scatter_list[i]复制到过程。 dist.gather(tensor, dst, gather_list, group)：从dst中的所有进程复制tensor。 dist.all_gather(tensor_list, tensor, group)：将所有进程中的tensor从所有进程复制到tensor_list。 dist.barrier(group)：阻止组中的所有进程，直到每个进程都进入此功能。 分布式训练 注意：您可以在此 GitHub 存储库的中找到本节的示例脚本。 现在我们了解了分布式模块的工作原理，让我们用它编写一些有用的东西。 我们的目标是复制 DistributedDataParallel 的功能。 当然，这将是一个教学示例，在现实世界中，您应该使用上面链接的经过官方测试，优化的最佳版本。 很简单，我们想要实现随机梯度下降的分布式版本。 我们的脚本将允许所有进程在其数据批次上计算其模型的梯度，然后平均其梯度。 为了在更改进程数时确保相似的收敛结果，我们首先必须对数据集进行分区。 (您也可以使用 tnt.dataset.SplitDataset 代替下面的代码段。） \"\"\" Dataset partitioning helper \"\"\" class Partition(object): def __init__(self, data, index): self.data = data self.index = index def __len__(self): return len(self.index) def __getitem__(self, index): data_idx = self.index[index] return self.data[data_idx] class DataPartitioner(object): def __init__(self, data, sizes=[0.7, 0.2, 0.1], seed=1234): self.data = data self.partitions = [] rng = Random() rng.seed(seed) data_len = len(data) indexes = [x for x in range(0, data_len)] rng.shuffle(indexes) for frac in sizes: part_len = int(frac * data_len) self.partitions.append(indexes[0:part_len]) indexes = indexes[part_len:] def use(self, partition): return Partition(self.data, self.partitions[partition]) 使用上面的代码片段，我们现在可以使用以下几行简单地对任何数据集进行分区： \"\"\" Partitioning MNIST \"\"\" def partition_dataset(): dataset = datasets.MNIST('./data', train=True, download=True, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])) size = dist.get_world_size() bsz = 128 / float(size) partition_sizes = [1.0 / size for _ in range(size)] partition = DataPartitioner(dataset, partition_sizes) partition = partition.use(dist.get_rank()) train_set = torch.utils.data.DataLoader(partition, batch_size=bsz, shuffle=True) return train_set, bsz 假设我们有 2 个副本，则每个进程的train_set为 60000/2 = 30000 个样本。 我们还将批量大小除以副本数，以使整体批量大小保持为 128。 现在，我们可以编写通常的向前-向后优化训练代码，并添加一个函数调用以平均模型的梯度。 (以下内容主要是受 PyTorch MNIST 官方示例的启发）。 \"\"\" Distributed Synchronous SGD Example \"\"\" def run(rank, size): torch.manual_seed(1234) train_set, bsz = partition_dataset() model = Net() optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5) num_batches = ceil(len(train_set.dataset) / float(bsz)) for epoch in range(10): epoch_loss = 0.0 for data, target in train_set: optimizer.zero_grad() output = model(data) loss = F.nll_loss(output, target) epoch_loss += loss.item() loss.backward() average_gradients(model) optimizer.step() print('Rank ', dist.get_rank(), ', epoch ', epoch, ': ', epoch_loss / num_batches) 仍然需要执行average_gradients(model)函数，该函数只需要一个模型并在整个世界上平均其梯度即可。 \"\"\" Gradient averaging. \"\"\" def average_gradients(model): size = float(dist.get_world_size()) for param in model.parameters(): dist.all_reduce(param.grad.data, op=dist.reduce_op.SUM) param.grad.data /= size 等！ 我们成功实现了分布式同步 SGD，并且可以在大型计算机集群上训练任何模型。 注意：尽管从技术上来说最后一句话是是正确的，但要实现同步 SGD 的生产级实现，还需要更多技巧。 同样，请使用经过测试和优化的。 我们自己的环减少 另一个挑战是，假设我们要实现 DeepSpeech 的高效环网减少。 使用点对点集合很容易实现。 \"\"\" Implementation of a ring-reduce with addition. \"\"\" def allreduce(send, recv): rank = dist.get_rank() size = dist.get_world_size() send_buff = th.zeros(send.size()) recv_buff = th.zeros(send.size()) accum = th.zeros(send.size()) accum[:] = send[:] left = ((rank - 1) + size) % size right = (rank + 1) % size for i in range(size - 1): if i % 2 == 0: # Send send_buff send_req = dist.isend(send_buff, right) dist.recv(recv_buff, left) accum[:] += recv[:] else: # Send recv_buff send_req = dist.isend(recv_buff, right) dist.recv(send_buff, left) accum[:] += send[:] send_req.wait() recv[:] = accum[:] 在上面的脚本中，allreduce(send, recv)函数的签名与 PyTorch 中的签名略有不同。 它需要一个recv张量，并将所有send张量的总和存储在其中。 作为练习留给读者，我们的版本与 DeepSpeech 中的版本之间仍然有一个区别：它们的实现将梯度张量划分为个块，以便最佳地利用通信带宽。 (提示： torch.chunk) 进阶主题 现在，我们准备发现torch.distributed的一些更高级的功能。 由于涉及的内容很多，因此本节分为两个小节： 通讯后端：我们在这里学习如何使用 MPI 和 Gloo 进行 GPU-GPU 通讯。 初始化方法：我们了解如何最好地设置dist.init_process_group()中的初始协调阶段。 通讯后端 torch.distributed最优雅的方面之一是它具有抽象能力，并且可以在不同的后端之上构建。 如前所述，目前在 PyTorch 中实现了三个后端：Glo，NCCL 和 MPI。 它们各自具有不同的规格和权衡，具体取决于所需的用例。 可以在中找到支持功能的对照表。 Gloo 后端 到目前为止，我们已经广泛使用 Gloo 后端。 它作为开发平台非常方便，因为它已包含在预编译的 PyTorch 二进制文件中，并且可在 Linux(自 0.2 开始）和 macOS(自 1.3 开始）上运行。 它支持 CPU 上的所有点对点和集合操作，以及 GPU 上的所有集合操作。 CUDA 张量的集体运算的实现未像 NCCL 后端提供的那样优化。 如您所知，如果将model放在 GPU 上，我们的分布式 SGD 示例将无法正常工作。 为了使用多个 GPU，让我们还进行以下修改： 使用device = torch.device(\"cuda:{}\".format(rank)) model = Net() model = Net().to(device) 使用data, target = data.to(device), target.to(device) 经过上述修改，我们的模型现在可以在两个 GPU 上训练，您可以使用watch nvidia-smi监视其使用情况。 MPI 后端 消息传递接口(MPI）是来自高性能计算领域的标准化工具。 它允许进行点对点和集体通信，并且是torch.distributed API 的主要灵感。 存在几种针对不同目的而优化的 MPI 实现(例如 Open-MPI ， MVAPICH2 ， Intel MPI)。 使用 MPI 后端的优势在于 MPI 在大型计算机群集上的广泛可用性和高水平的优化。 一些 最近的 实现也能够利用 CUDA IPC 和 GPU Direct 技术来避免通过 CPU 进行内存复制。 不幸的是，PyTorch 的二进制文件不能包含 MPI 实现，我们将不得不手动对其进行重新编译。 幸运的是，鉴于编译后，PyTorch 会单独查看以查找可用的 MPI 实现，因此此过程相当简单。 以下步骤通过从源安装 PyTorch 来安装 MPI 后端。 创建并激活您的 Anaconda 环境，按照指南的要求安装所有先决条件，但是尚未运行。 选择并安装您喜欢的 MPI 实现。 请注意，启用支持 CUDA 的 MPI 可能需要一些其他步骤。 在我们的情况下，我们将坚持不支持 GPU 的 Open-MPI ：conda install -c conda-forge openmpi 现在，转到克隆的 PyTorch 存储库并执行python setup.py install。 为了测试我们新安装的后端，需要进行一些修改。 将if __name__ == '__main__':下的内容替换为init_process(0, 0, run, backend='mpi')。 运行mpirun -n 4 python myscript.py。 这些更改的原因是，MPI 需要在生成流程之前创建自己的环境。 MPI 也将生成自己的进程，并执行初始化方法中描述的握手，使init_process_group的rank和size参数多余。 实际上，这非常强大，因为您可以将附加参数传递给mpirun，以便为每个进程定制计算资源。 (诸如每个进程的内核数量，将计算机手动分配给特定等级，以及等之类的东西。）这样做，您应该获得与其他通信后端相同的熟悉输出。 NCCL 后端 NCCL 后端提供了针对 CUDA 张量的集体操作的优化实现。 如果仅将 CUDA 张量用于集体操作，请考虑使用此后端以获得最佳性能。 NCCL 后端包含在具有 CUDA 支持的预构建二进制文件中。 初始化方法 为了完成本教程，我们来谈谈我们称为的第一个功能：dist.init_process_group(backend, init_method)。 特别是，我们将介绍负责每个过程之间初始协调步骤的不同初始化方法。 这些方法使您可以定义协调方式。 根据您的硬件设置，这些方法之一自然应该比其他方法更合适。 除了以下各节之外，您还应该查看官方文档。 环境变量 在本教程中，我们一直在使用环境变量初始化方法。 通过在所有计算机上设置以下四个环境变量，所有进程将能够正确连接到主服务器，获取有关其他进程的信息，最后与它们握手。 MASTER_PORT：计算机上的空闲端口，它将托管等级为 0 的进程。 MASTER_ADDR：将以等级 0 托管进程的计算机的 IP 地址。 WORLD_SIZE：进程总数，这样主机可以知道要等待多少个工人。 RANK：每个进程的等级，因此他们将知道它是否是工人的主人。 共享文件系统 共享文件系统要求所有进程都有权访问共享文件系统，并将通过共享文件进行协调。 这意味着每个进程都将打开文件，写入文件信息，然后等到每个人都打开文件。 之后，所有必需的信息将可用于所有过程。 为了避免争用情况，文件系统必须通过 fcntl 支持锁定。 dist.init_process_group( init_method='file:///mnt/nfs/sharedfile', rank=args.rank, world_size=4) TCP 通过提供等级 0 和可访问的端口号的进程的 IP 地址，可以实现通过 TCP 进行初始化。 在这里，所有工作人员都可以连接到等级为 0 的流程，并交换有关如何相互联系的信息。 dist.init_process_group( init_method='tcp://10.1.1.20:23456', rank=args.rank, world_size=4) **致谢** 我要感谢 PyTorch 开发人员在实现，文档和测试方面做得如此出色。 当代码不清楚时，我总是可以依靠文档或测试来找到答案。 我要特别感谢 Soumith Chintala，Adam Paszke 和 Natalia Gimelshein 提供的有见地的评论并回答了有关初稿的问题。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"36.html":{"url":"36.html","title":"分布式 RPC 框架入门","keywords":"","body":"分布式 RPC 框架入门 原文： https://pytorch.org/tutorials/intermediate/rpc_tutorial.html 作者：申力 警告 torch.distributed.rpc 程序包是实验性的，随时可能更改。 它还需要 PyTorch 1.4.0+才能运行，因为这是第一个支持 RPC 的版本。 本教程使用两个简单的示例来演示如何使用 torch.distributed.rpc 软件包构建分布式训练，该软件包首先在 PyTorch v1.4 中作为实验功能引入。 这两个示例的源代码可以在 PyTorch 示例中找到。 先前的教程分布式数据并行入门和用 PyTorch 编写分布式应用程序，描述了 DistributedDataParallel ，该模型支持特定的训练范例，其中模型可以在多个过程中复制 每个进程都会处理输入数据的拆分。 有时，您可能会遇到需要不同训练范例的场景。 例如： 在强化学习中，从环境中获取训练数据可能相对昂贵，而模型本身可能很小。 在这种情况下，产生多个并行运行的观察者并共享一个代理可能会很有用。 在这种情况下，代理将在本地负责训练，但是应用程序仍将需要库在观察者和训练者之间发送和接收数据。 您的模型可能太大，无法容纳在一台计算机上的 GPU 中，因此需要一个库来帮助将模型拆分到多台计算机上。 或者，您可能正在实现参数服务器训练框架，其中模型参数和训练器位于不同的机器上。 torch.distributed.rpc 程序包可以帮助解决上述情况。 在情况 1 中， RPC 和 RRef 允许将数据从一个工作程序发送到另一个工作程序，同时轻松引用远程数据对象。 在情况 2 中，分布式 autograd 和分布式优化器使执行反向传递和优化器步骤就像本地训练一样。 在接下来的两节中，我们将使用强化学习示例和语言模型示例来演示 torch.distributed.rpc 的 API。 请注意，本教程并非旨在构建最准确或最有效的模型来解决给定的问题，相反，此处的主要目标是演示如何使用 torch.distributed.rpc 包来构建分布式训练 应用程序。 使用 RPC 和 RRef 进行分布式强化学习 本节介绍了使用 RPC 建立玩具分布式强化学习模型以解决 OpenAI Gym 中的 CartPole-v1 的步骤。 策略代码主要是从现有的单线程示例中借用的，如下所示。 我们将跳过Policy设计的详细信息，并将重点介绍 RPC 的用法。 import torch.nn as nn import torch.nn.functional as F class Policy(nn.Module): def __init__(self): super(Policy, self).__init__() self.affine1 = nn.Linear(4, 128) self.dropout = nn.Dropout(p=0.6) self.affine2 = nn.Linear(128, 2) self.saved_log_probs = [] self.rewards = [] def forward(self, x): x = self.affine1(x) x = self.dropout(x) x = F.relu(x) action_scores = self.affine2(x) return F.softmax(action_scores, dim=1) 首先，让我们准备一个帮助程序，以在RRef的所有者工作程序上远程运行功能。 您将在本教程的示例中的多个地方找到该功能。 理想情况下， torch.distributed.rpc 程序包应立即提供这些帮助程序功能。 例如，如果应用程序可以直接调用RRef.some_func(*arg)，然后将其转换为RRef所有者的 RPC，将会更容易。 在 pytorch / pytorch＃31743 中跟踪了此 API 的进度。 from torch.distributed.rpc import rpc_sync def _call_method(method, rref, *args, **kwargs): return method(rref.local_value(), *args, **kwargs) def _remote_method(method, rref, *args, **kwargs): args = [method, rref] + list(args) return rpc_sync(rref.owner(), _call_method, args=args, kwargs=kwargs) # to call a function on an rref, we could do the following # _remote_method(some_func, rref, *args) 我们准备介绍观察员。 在此示例中，每个观察者创建自己的环境，并等待代理的命令来运行情节。 在每个情节中，一个观察者最多循环n_steps个迭代，并且在每个迭代中，它使用 RPC 将其环境状态传递给代理并取回操作。 然后，它将该操作应用于其环境，并从环境中获取奖励和下一个状态。 之后，观察者使用另一个 RPC 向代理报告奖励。 同样，请注意，这显然不是最有效的观察者实现。 例如，一个简单的优化可能是将当前状态和最后的报酬打包到一个 RPC 中，以减少通信开销。 但是，目标是演示 RPC API，而不是为 CartPole 构建最佳的求解器。 因此，在此示例中，让逻辑保持简单，并明确两个步骤。 import argparse import gym import torch.distributed.rpc as rpc parser = argparse.ArgumentParser( description=\"RPC Reinforcement Learning Example\", formatter_class=argparse.ArgumentDefaultsHelpFormatter, ) parser.add_argument('--world_size', default=2, help='Number of workers') parser.add_argument('--log_interval', default=1, help='Log every log_interval episodes') parser.add_argument('--gamma', default=0.1, help='how much to value future rewards') parser.add_argument('--seed', default=1, help='random seed for reproducibility') args = parser.parse_args() class Observer: def __init__(self): self.id = rpc.get_worker_info().id self.env = gym.make('CartPole-v1') self.env.seed(args.seed) def run_episode(self, agent_rref, n_steps): state, ep_reward = self.env.reset(), 0 for step in range(n_steps): # send the state to the agent to get an action action = _remote_method(Agent.select_action, agent_rref, self.id, state) # apply the action to the environment, and get the reward state, reward, done, _ = self.env.step(action) # report the reward to the agent for training purpose _remote_method(Agent.report_reward, agent_rref, self.id, reward) if done: break agent 的代码稍微复杂一点，我们将其分为多部分。 在此示例中，代理既充当训练者又充当主人，因此它向多个分布式观察者发送命令以运行情节，并且还记录所有本地行为和奖励，这些行为和奖赏将在每个情节之后的训练阶段中使用。 下面的代码显示了Agent构造函数，其中大多数行都在初始化各种组件。 最后的循环在其他工作者上远程初始化观察者，并在本地将RRefs保留给这些观察者。 代理稍后将使用那些观察者RRefs发送命令。 应用程序无需担心RRefs的寿命。 每个RRef的所有者维护一个参考计数图以跟踪其生命周期，并保证只要该RRef的任何活动用户都不会删除远程数据对象。 有关详细信息，请参考RRef 设计文档。 import gym import numpy as np import torch import torch.distributed.rpc as rpc import torch.optim as optim from torch.distributed.rpc import RRef, rpc_async, remote from torch.distributions import Categorical class Agent: def __init__(self, world_size): self.ob_rrefs = [] self.agent_rref = RRef(self) self.rewards = {} self.saved_log_probs = {} self.policy = Policy() self.optimizer = optim.Adam(self.policy.parameters(), lr=1e-2) self.eps = np.finfo(np.float32).eps.item() self.running_reward = 0 self.reward_threshold = gym.make('CartPole-v1').spec.reward_threshold for ob_rank in range(1, world_size): ob_info = rpc.get_worker_info(OBSERVER_NAME.format(ob_rank)) self.ob_rrefs.append(remote(ob_info, Observer)) self.rewards[ob_info.id] = [] self.saved_log_probs[ob_info.id] = [] 接下来，代理向观察者公开两个 API，以供他们选择动作和报告奖励。 这些功能仅在代理上本地运行，但是将由观察者通过 RPC 触发。 class Agent: ... def select_action(self, ob_id, state): state = torch.from_numpy(state).float().unsqueeze(0) probs = self.policy(state) m = Categorical(probs) action = m.sample() self.saved_log_probs[ob_id].append(m.log_prob(action)) return action.item() def report_reward(self, ob_id, reward): self.rewards[ob_id].append(reward) 让我们在代理上添加run_episode函数，该函数告诉所有观察者执行片段。 在此函数中，它首先创建一个列表，以从异步 RPC 收集期货，然后在所有观察者RRefs上循环以生成异步 RPC。 在这些 RPC 中，代理还将自身的RRef传递给观察者，以便观察者也可以在代理上调用函数。 如上所示，每个观察者都将 RPC 返回给代理，它们是嵌套的 RPC。 在每个情节之后，saved_log_probs和rewards将包含记录的动作概率和奖励。 class Agent: ... def run_episode(self, n_steps=0): futs = [] for ob_rref in self.ob_rrefs: # make async RPC to kick off an episode on all observers futs.append( rpc_async( ob_rref.owner(), _call_method, args=(Observer.run_episode, ob_rref, self.agent_rref, n_steps) ) ) # wait until all obervers have finished this episode for fut in futs: fut.wait() 最后，在一集之后，代理需要训练模型，该模型在下面的finish_episode函数中实现。 此函数中没有 RPC，并且大多数是从单线程示例中借用的。 因此，我们跳过描述其内容。 class Agent: ... def finish_episode(self): # joins probs and rewards from different observers into lists R, probs, rewards = 0, [], [] for ob_id in self.rewards: probs.extend(self.saved_log_probs[ob_id]) rewards.extend(self.rewards[ob_id]) # use the minimum observer reward to calculate the running reward min_reward = min([sum(self.rewards[ob_id]) for ob_id in self.rewards]) self.running_reward = 0.05 * min_reward + (1 - 0.05) * self.running_reward # clear saved probs and rewards for ob_id in self.rewards: self.rewards[ob_id] = [] self.saved_log_probs[ob_id] = [] policy_loss, returns = [], [] for r in rewards[::-1]: R = r + args.gamma * R returns.insert(0, R) returns = torch.tensor(returns) returns = (returns - returns.mean()) / (returns.std() + self.eps) for log_prob, R in zip(probs, returns): policy_loss.append(-log_prob * R) self.optimizer.zero_grad() policy_loss = torch.cat(policy_loss).sum() policy_loss.backward() self.optimizer.step() return min_reward 使用Policy，Observer和Agent类，我们准备启动多个进程来执行分布式训练。 在此示例中，所有进程都运行相同的run_worker函数，并且它们使用等级来区分其角色。 等级 0 始终是代理，其他所有等级都是观察者。 代理通过重复调用run_episode和finish_episode充当主控，直到运行的奖励超过环境指定的奖励阈值为止。 所有观察者都被动地等待来自代理的命令。 该代码由 rpc.init_rpc 和 rpc.shutdown 包装，它们分别初始化和终止 RPC 实例。 API 页面中提供了更多详细信息。 import os from itertools import count import torch.multiprocessing as mp AGENT_NAME = \"agent\" OBSERVER_NAME=\"obs\" TOTAL_EPISODE_STEP = 100 def run_worker(rank, world_size): os.environ['MASTER_ADDR'] = 'localhost' os.environ['MASTER_PORT'] = '29500' if rank == 0: # rank0 is the agent rpc.init_rpc(AGENT_NAME, rank=rank, world_size=world_size) agent = Agent(world_size) for i_episode in count(1): n_steps = int(TOTAL_EPISODE_STEP / (args.world_size - 1)) agent.run_episode(n_steps=n_steps) last_reward = agent.finish_episode() if i_episode % args.log_interval == 0: print('Episode {}\\tLast reward: {:.2f}\\tAverage reward: {:.2f}'.format( i_episode, last_reward, agent.running_reward)) if agent.running_reward > agent.reward_threshold: print(\"Solved! Running reward is now {}!\".format(agent.running_reward)) break else: # other ranks are the observer rpc.init_rpc(OBSERVER_NAME.format(rank), rank=rank, world_size=world_size) # observers passively waiting for instructions from the agent # block until all rpcs finish, and shutdown the RPC instance rpc.shutdown() mp.spawn( run_worker, args=(args.world_size, ), nprocs=args.world_size, join=True ) 以下是使用 world_size = 2 进行训练时的一些示例输出。 Episode 10 Last reward: 26.00 Average reward: 10.01 Episode 20 Last reward: 16.00 Average reward: 11.27 Episode 30 Last reward: 49.00 Average reward: 18.62 Episode 40 Last reward: 45.00 Average reward: 26.09 Episode 50 Last reward: 44.00 Average reward: 30.03 Episode 60 Last reward: 111.00 Average reward: 42.23 Episode 70 Last reward: 131.00 Average reward: 70.11 Episode 80 Last reward: 87.00 Average reward: 76.51 Episode 90 Last reward: 86.00 Average reward: 95.93 Episode 100 Last reward: 13.00 Average reward: 123.93 Episode 110 Last reward: 33.00 Average reward: 91.39 Episode 120 Last reward: 73.00 Average reward: 76.38 Episode 130 Last reward: 137.00 Average reward: 88.08 Episode 140 Last reward: 89.00 Average reward: 104.96 Episode 150 Last reward: 97.00 Average reward: 98.74 Episode 160 Last reward: 150.00 Average reward: 100.87 Episode 170 Last reward: 126.00 Average reward: 104.38 Episode 180 Last reward: 500.00 Average reward: 213.74 Episode 190 Last reward: 322.00 Average reward: 300.22 Episode 200 Last reward: 165.00 Average reward: 272.71 Episode 210 Last reward: 168.00 Average reward: 233.11 Episode 220 Last reward: 184.00 Average reward: 195.02 Episode 230 Last reward: 284.00 Average reward: 208.32 Episode 240 Last reward: 395.00 Average reward: 247.37 Episode 250 Last reward: 500.00 Average reward: 335.42 Episode 260 Last reward: 500.00 Average reward: 386.30 Episode 270 Last reward: 500.00 Average reward: 405.29 Episode 280 Last reward: 500.00 Average reward: 443.29 Episode 290 Last reward: 500.00 Average reward: 464.65 Solved! Running reward is now 475.3163778435275! 在此示例中，我们展示了如何使用 RPC 作为通信工具来跨工作人员传递数据，以及如何使用 RRef 引用远程对象。 的确，您可以直接在ProcessGroup send和recv API 之上构建整个结构，也可以使用其他通信/ RPC 库。 但是，通过使用 torch.distributed.rpc ，您可以在后台获得本机支持并不断优化性能。 接下来，我们将展示如何将 RPC 和 RRef 与分布式 autograd 和分布式优化器结合起来执行分布式模型并行训练。 使用 Distributed Autograd 和 Distributed Optimizer 的 Distributed RNN 在本节中，我们将使用 RNN 模型来展示如何使用 RPC API 构建分布式模型并行训练。 示例 RNN 模型非常小，可以轻松地放入单个 GPU 中，但是我们仍将其层划分为两个不同的工作人员来演示这一想法。 开发人员可以应用类似的技术在多个设备和机器上分布更大的模型。 RNN 模型设计是从 PyTorch 示例存储库中的词语言模型中借用的，该存储库包含三个主要组件，一个嵌入表，一个LSTM层和一个解码器。 下面的代码将嵌入表和解码器包装到子模块中，以便它们的构造函数可以传递给 RPC API。 在EmbeddingTable子模块中，我们有意将Embedding层放在 GPU 上以涵盖用例。 在 v1.4 中，RPC 始终在目标工作线程上创建 CPU 张量参数或返回值。 如果函数使用 GPU 张量，则需要将其显式移动到适当的设备。 class EmbeddingTable(nn.Module): r\"\"\" Encoding layers of the RNNModel \"\"\" def __init__(self, ntoken, ninp, dropout): super(EmbeddingTable, self).__init__() self.drop = nn.Dropout(dropout) self.encoder = nn.Embedding(ntoken, ninp).cuda() self.encoder.weight.data.uniform_(-0.1, 0.1) def forward(self, input): return self.drop(self.encoder(input.cuda()).cpu() class Decoder(nn.Module): def __init__(self, ntoken, nhid, dropout): super(Decoder, self).__init__() self.drop = nn.Dropout(dropout) self.decoder = nn.Linear(nhid, ntoken) self.decoder.bias.data.zero_() self.decoder.weight.data.uniform_(-0.1, 0.1) def forward(self, output): return self.decoder(self.drop(output)) 使用上述子模块，我们现在可以使用 RPC 将它们组合在一起以创建 RNN 模型。 在下面的代码中，ps代表参数服务器，该服务器托管嵌入表和解码器的参数。 构造函数使用远程 API 在参数服务器上创建EmbeddingTable对象和Decoder对象，并在本地创建LSTM子模块。 在正向传递过程中，训练师使用EmbeddingTable RRef查找远程子模块，然后使用 RPC 将输入数据传递到EmbeddingTable，并获取查找结果。 然后，它通过本地LSTM层运行嵌入，最后使用另一个 RPC 将输出发送到Decoder子模块。 通常，要实施分布式模型并行训练，开发人员可以将模型划分为子模块，调用 RPC 远程创建子模块实例，并在必要时使用RRef查找它们。 如下面的代码所示，它看起来与单机模型并行训练非常相似。 主要区别是用 RPC 功能替换了Tensor.to(device)。 class RNNModel(nn.Module): def __init__(self, ps, ntoken, ninp, nhid, nlayers, dropout=0.5): super(RNNModel, self).__init__() # setup embedding table remotely self.emb_table_rref = rpc.remote(ps, EmbeddingTable, args=(ntoken, ninp, dropout)) # setup LSTM locally self.rnn = nn.LSTM(ninp, nhid, nlayers, dropout=dropout) # setup decoder remotely self.decoder_rref = rpc.remote(ps, Decoder, args=(ntoken, nhid, dropout)) def forward(self, input, hidden): # pass input to the remote embedding table and fetch emb tensor back emb = _remote_method(EmbeddingTable.forward, self.emb_table_rref, input) output, hidden = self.rnn(emb, hidden) # pass output to the rremote decoder and get the decoded output back decoded = _remote_method(Decoder.forward, self.decoder_rref, output) return decoded, hidden 在介绍分布式优化器之前，让我们添加一个辅助函数来生成模型参数的 RRef 列表，这些列表将由分布式优化器使用。 在本地训练中，应用程序可以调用Module.parameters()来获取对所有参数张量的引用，并将其传递给本地优化器以进行后续更新。 但是，由于某些参数存在于远程计算机上，因此同一 API 在分布式训练方案中不起作用。 因此，分布式优化器不采用参数Tensors的列表，而是采用RRefs的列表，对于本地和远程模型参数，每个模型参数一个RRef。 辅助函数非常简单，只需调用Module.parameters()并在每个参数上创建一个本地RRef。 def _parameter_rrefs(module): param_rrefs = [] for param in module.parameters(): param_rrefs.append(RRef(param)) return param_rrefs 然后，由于RNNModel包含三个子模块，因此我们需要调用_parameter_rrefs三次，并将其包装到另一个辅助函数中。 class RNNModel(nn.Module): ... def parameter_rrefs(self): remote_params = [] # get RRefs of embedding table remote_params.extend(_remote_method(_parameter_rrefs, self.emb_table_rref)) # create RRefs for local parameters remote_params.extend(_parameter_rrefs(self.rnn)) # get RRefs of decoder remote_params.extend(_remote_method(_parameter_rrefs, self.decoder_rref)) return remote_params 现在，我们准备实施训练循环。 初始化模型参数后，我们创建RNNModel和DistributedOptimizer。 分布式优化器将采用参数RRefs的列表，查找所有不同的所有者工作器，并在每个所有者工作器上创建给定的本地优化器(即，在这种情况下，您也可以使用其他本地优化器SGD） 使用给定的参数(即lr=0.05）。 在训练循环中，它首先创建一个分布式 autograd 上下文，这将帮助分布式 autograd 引擎查找渐变和涉及的 RPC 发送/接收功能。 分布式 autograd 引擎的设计详细信息可以在其设计说明中找到。 然后，它像本地模型一样开始前进，并运行分布式后退。 对于后向分布，您只需要指定一个根列表，在这种情况下，就是损失Tensor。 分布式 autograd 引擎将自动遍历分布式图形并正确编写渐变。 接下来，它在分布式优化器上运行step函数，该函数将与所有涉及的本地优化器联系以更新模型参数。 与本地训练相比，一个较小的差异是您不需要运行zero_grad()，因为每个 autograd 上下文都有专用的空间来存储梯度，并且在每次迭代创建上下文时，来自不同迭代的那些梯度不会累积到 同一组Tensors。 def run_trainer(): batch = 5 ntoken = 10 ninp = 2 nhid = 3 nindices = 3 nlayers = 4 hidden = ( torch.randn(nlayers, nindices, nhid), torch.randn(nlayers, nindices, nhid) ) model = rnn.RNNModel('ps', ntoken, ninp, nhid, nlayers) # setup distributed optimizer opt = DistributedOptimizer( optim.SGD, model.parameter_rrefs(), lr=0.05, ) criterion = torch.nn.CrossEntropyLoss() def get_next_batch(): for _ in range(5): data = torch.LongTensor(batch, nindices) % ntoken target = torch.LongTensor(batch, ntoken) % nindices yield data, target # train for 10 iterations for epoch in range(10): # create distributed autograd context for data, target in get_next_batch(): with dist_autograd.context(): hidden[0].detach_() hidden[1].detach_() output, hidden = model(data, hidden) loss = criterion(output, target) # run distributed backward pass dist_autograd.backward([loss]) # run distributed optimizer opt.step() # not necessary to zero grads as each iteration creates a different # distributed autograd context which hosts different grads print(\"Training epoch {}\".format(epoch)) 最后，让我们添加一些粘合代码以启动参数服务器和训练师流程。 def run_worker(rank, world_size): os.environ['MASTER_ADDR'] = 'localhost' os.environ['MASTER_PORT'] = '29500' if rank == 1: rpc.init_rpc(\"trainer\", rank=rank, world_size=world_size) _run_trainer() else: rpc.init_rpc(\"ps\", rank=rank, world_size=world_size) # parameter server do nothing pass # block until all rpcs finish rpc.shutdown() if __name__==\"__main__\": world_size = 2 mp.spawn(run_worker, args=(world_size, ), nprocs=world_size, join=True) 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"37.html":{"url":"37.html","title":"(高级）带有 Amazon AWS 的 PyTorch 1.0 分布式训练师","keywords":"","body":"(高级）带有 Amazon AWS 的 PyTorch 1.0 分布式训练师 原文： https://pytorch.org/tutorials/beginner/aws_distributed_training_tutorial.html 注意 单击此处的下载完整的示例代码 作者： Nathan Inkawhich 由编辑：滕力 在本教程中，我们将展示如何在两个多 GPU Amazon AWS 节点之间设置，编码和运行 PyTorch 1.0 分布式训练师。 我们将首先描述 AWS 设置，然后是 PyTorch 环境配置，最后是分布式训练师的代码。 希望您会发现将当前的训练代码扩展到分布式应用程序实际上只需很少的代码更改，并且大部分工作都在一次性环境设置中。 Amazon AWS 安装程序 在本教程中，我们将在两个多 GPU 节点之间进行分布式训练。 在本节中，我们将首先介绍如何创建节点，然后介绍如何设置安全组，以便节点之间可以相互通信。 创建节点 在 Amazon AWS 中，有七个创建实例的步骤。 首先，登录并选择 Launch Instance 。 步骤 1：选择一个亚马逊机器映像(AMI）-在这里，我们将选择Deep Learning AMI (Ubuntu) Version 14.0。 如前所述，此实例随附了许多最受欢迎的深度学习框架，并且已预先配置了 CUDA，cuDNN 和 NCCL。 这是本教程的一个很好的起点。 步骤 2：选择实例类型-现在，选择名为p2.8xlarge的 GPU 计算单元。 请注意，每个实例的成本都不同，但是此实例每个节点提供 8 个 NVIDIA Tesla K80 GPU，并为多 GPU 分布式训练提供了良好的体系结构。 步骤 3：配置实例详细信息-此处唯一要更改的设置是将实例数增至 2。默认情况下，所有其他配置都可以保留。 步骤 4：添加存储-注意，默认情况下，这些节点没有很多存储(只有 75 GB）。 对于本教程，由于我们仅使用 STL-10 数据集，因此有足够的存储空间。 但是，如果要在较大的数据集(如 ImageNet）上进行训练，则必须添加更多的存储空间以适合数据集和要保存的任何训练后的模型。 步骤 5：添加标签-此处无需执行任何操作，只需继续。 步骤 6：配置安全组-这是配置过程中的关键步骤。 默认情况下，同一安全组中的两个节点将无法在分布式训练设置中进行通信。 在这里，我们要为要加入的两个节点创建一个新的安全组。但是，我们无法在此步骤中完成配置。 现在，只需记住您的新安全组名称(例如 launch-wizard-12），然后继续执行步骤 7。 步骤 7：查看实例启动-在这里，查看实例然后启动它。 默认情况下，这将自动开始初始化两个实例。 您可以从仪表板监视初始化进度。 配置安全组 回想一下，我们在创建实例时无法正确配置安全组。 启动实例后，在 EC2 仪表板中选择网络&安全>安全组选项卡。 这将显示您有权访问的安全组的列表。 选择您在步骤 6 中创建的新安全组(即 launch-wizard-12），该安全组将弹出名为 Description，Inbound，Outbound 和 Tags 的标签。 首先，选择入站选项卡，然后选择编辑，添加一个规则，以允许 launch-wizard-12 安全组中“源”的“所有流量”。 然后选择出站选项卡，并执行完全相同的操作。 现在，我们已经有效地允许了 launch-wizard-12 安全组中节点之间所有类型的所有入站和出站流量。 必要信息 在继续之前，我们必须找到并记住两个节点的 IP 地址。 在 EC2 仪表板中找到正在运行的实例。 对于这两种情况，记下 IPv4 公用 IP 和专用 IP 。 在本文档的其余部分，我们将它们称为 node0-publicIP ， node0-privateIP ， node1-publicIP 和 node1- privateIP 。 公用 IP 是我们将用于 SSH 的地址，而专用 IP 将用于节点间的通信。 环境设定 下一个关键步骤是每个节点的设置。 不幸的是，我们不能同时配置两个节点，因此必须在每个节点上分别完成此过程。 但是，这是一次设置，因此一旦正确配置了节点，就无需为将来的分布式训练项目重新配置。 一旦登录到节点，第一步就是使用 python 3.6 和 numpy 创建一个新的 conda 环境。 创建后，激活环境。 $ conda create -n nightly_pt python=3.6 numpy $ source activate nightly_pt 接下来，我们将在 conda 环境中安装启用了 Cuda 9.0 的 PyTorch 的每晚构建。 $ pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu90/torch_nightly.html 我们还必须安装 torchvision，以便可以使用 torchvision 模型和数据集。 目前，我们必须从源代码构建 torchvision，因为默认情况下，pip 安装将在我们刚刚安装的每晚构建的基础上安装旧版本的 PyTorch。 $ cd $ git clone https://github.com/pytorch/vision.git $ cd vision $ python setup.py install 最后，非常重要的步骤是设置 NCCL 套接字的网络接口名称。 这是通过环境变量NCCL_SOCKET_IFNAME设置的。 要获得正确的名称，请在节点上运行ifconfig命令，然后查看与该节点的 privateIP 相对应的接口名称(例如 ens3）。 然后将环境变量设置为 $ export NCCL_SOCKET_IFNAME=ens3 请记住，在两个节点上都执行此操作。 您也可以考虑将 NCCLSOCKET_IFNAME 设置添加到 .bashrc_ 中。 一个重要的观察结果是我们没有在节点之间设置共享文件系统。 因此，每个节点都必须具有代码的副本和数据集的副本。 有关在节点之间设置共享网络文件系统的更多信息，请参见。 分布式训练守则 通过运行实例和环境设置，我们现在可以进入训练代码。 这里的大多数代码均来自 PyTorch ImageNet 示例，该示例也支持分布式训练。 该代码为定制训练师提供了一个很好的起点，因为它具有许多样板训练循环，验证循环和准确性跟踪功能。 但是，您会注意到，为简单起见，已删除了参数解析和其他非必要功能。 在此示例中，我们将使用 torchvision.models.resnet18 模型，并将其训练在 torchvision.datasets.STL10 数据集上。 为了适应 STL-10 与 Resnet18 的尺寸不匹配，我们将通过变换将每个图像的大小调整为 224x224。 注意，模型和数据集的选择与分布式训练代码正交，您可以使用所需的任何数据集和模型，并且过程相同。 首先处理导入，然后讨论一些辅助函数。 然后，我们将定义训练和测试功能，这些功能很大程度上取自 ImageNet 示例。 最后，我们将构建处理分布式训练设置的代码的主要部分。 最后，我们将讨论如何实际运行代码。 进口货 这里重要的分布式训练专用导入是 torch.nn.parallel ， torch.distributed ， torch.utils.data.distributed 和torch.并行处理。 将并行处理启动方法设置为生成或 forkserver (仅在 Python 3 中受支持），这一点也很重要，因为默认值为 fork ，这在发生以下情况时可能导致死锁 使用多个工作进程进行数据加载。 import time import sys import torch import torch.nn as nn import torch.nn.parallel import torch.distributed as dist import torch.optim import torch.utils.data import torch.utils.data.distributed import torchvision.transforms as transforms import torchvision.datasets as datasets import torchvision.models as models from torch.multiprocessing import Pool, Process 辅助功能 我们还必须定义一些辅助函数和类，以使训练更加容易。 AverageMeter类跟踪训练统计信息，例如准确性和迭代计数。 accuracy函数计算并返回模型的 top-k 精度，因此我们可以跟踪学习进度。 两者都是为了训练方便而提供的，但都不是专门针对分布式训练的。 class AverageMeter(object): \"\"\"Computes and stores the average and current value\"\"\" def __init__(self): self.reset() def reset(self): self.val = 0 self.avg = 0 self.sum = 0 self.count = 0 def update(self, val, n=1): self.val = val self.sum += val * n self.count += n self.avg = self.sum / self.count def accuracy(output, target, topk=(1,)): \"\"\"Computes the precision@k for the specified values of k\"\"\" with torch.no_grad(): maxk = max(topk) batch_size = target.size(0) _, pred = output.topk(maxk, 1, True, True) pred = pred.t() correct = pred.eq(target.view(1, -1).expand_as(pred)) res = [] for k in topk: correct_k = correct[:k].view(-1).float().sum(0, keepdim=True) res.append(correct_k.mul_(100.0 / batch_size)) return res 火车功能 为了简化主循环，最好将训练纪元步骤分离为一个称为train的函数。 此函数为 train_loader 的一个时期训练输入模型。 此功能中唯一的分布式训练工件是在正向传递之前将数据和标签张量的 non_blocking 属性设置为True。 这允许数据的异步 GPU 副本，意味着传输可以与计算重叠。 此功能还会沿途输出训练统计信息，以便我们可以跟踪整个时期的进度。 在此定义的另一个功能是adjust_learning_rate，它以固定的时间表衰减初始学习率。 这是另一个样板训练器功能，可用于训练准确的模型。 def train(train_loader, model, criterion, optimizer, epoch): batch_time = AverageMeter() data_time = AverageMeter() losses = AverageMeter() top1 = AverageMeter() top5 = AverageMeter() # switch to train mode model.train() end = time.time() for i, (input, target) in enumerate(train_loader): # measure data loading time data_time.update(time.time() - end) # Create non_blocking tensors for distributed training input = input.cuda(non_blocking=True) target = target.cuda(non_blocking=True) # compute output output = model(input) loss = criterion(output, target) # measure accuracy and record loss prec1, prec5 = accuracy(output, target, topk=(1, 5)) losses.update(loss.item(), input.size(0)) top1.update(prec1[0], input.size(0)) top5.update(prec5[0], input.size(0)) # compute gradients in a backward pass optimizer.zero_grad() loss.backward() # Call step of optimizer to update model params optimizer.step() # measure elapsed time batch_time.update(time.time() - end) end = time.time() if i % 10 == 0: print('Epoch: [{0}][{1}/{2}]\\t' 'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t' 'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t' 'Loss {loss.val:.4f} ({loss.avg:.4f})\\t' 'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t' 'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format( epoch, i, len(train_loader), batch_time=batch_time, data_time=data_time, loss=losses, top1=top1, top5=top5)) def adjust_learning_rate(initial_lr, optimizer, epoch): \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\" lr = initial_lr * (0.1 ** (epoch // 30)) for param_group in optimizer.param_groups: param_group['lr'] = lr 验证功能 为了跟踪泛化性能并进一步简化主循环，我们还可以将验证步骤提取到一个名为validate的函数中。 此函数在输入验证数据加载器上运行输入模型的完整验证步骤，并在验证集上返回模型的 top-1 准确性。 再次，您会注意到这里唯一的分布式训练功能是在将训练数据和标签传递到模型之前为它们设置non_blocking=True。 def validate(val_loader, model, criterion): batch_time = AverageMeter() losses = AverageMeter() top1 = AverageMeter() top5 = AverageMeter() # switch to evaluate mode model.eval() with torch.no_grad(): end = time.time() for i, (input, target) in enumerate(val_loader): input = input.cuda(non_blocking=True) target = target.cuda(non_blocking=True) # compute output output = model(input) loss = criterion(output, target) # measure accuracy and record loss prec1, prec5 = accuracy(output, target, topk=(1, 5)) losses.update(loss.item(), input.size(0)) top1.update(prec1[0], input.size(0)) top5.update(prec5[0], input.size(0)) # measure elapsed time batch_time.update(time.time() - end) end = time.time() if i % 100 == 0: print('Test: [{0}/{1}]\\t' 'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t' 'Loss {loss.val:.4f} ({loss.avg:.4f})\\t' 'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t' 'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format( i, len(val_loader), batch_time=batch_time, loss=losses, top1=top1, top5=top5)) print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}' .format(top1=top1, top5=top5)) return top1.avg 输入项 借助辅助功能，现在我们到达了有趣的部分。 在这里，我们将定义运行的输入。 一些输入是标准模型训练输入，例如批次大小和训练时期数，而某些则特定于我们的分布式训练任务。 所需的输入是： batch_size -分布式训练组中每个进程的的批处理大小。 整个分布式模型的总批次大小为 batch_size * world_size worker -每个进程中与数据加载器一起使用的工作进程数 num_epochs -要训练的时期总数 starting_lr -训练的开始学习率 world_size -分布式训练环境中的进程数 dist_backend -用于分布式训练通信(即 NCCL，Glo，MPI 等）的后端。 在本教程中，由于我们使用了多个多 GPU 节点，因此建议使用 NCCL。 dist_url -用于指定进程组的初始化方法的 URL。 它可能包含 rank0 进程的 IP 地址和端口，或者是共享文件系统上不存在的文件。 在这里，由于我们没有共享文件系统，因此它将合并 node0-privateIP 和 node0 上要使用的端口。 print(\"Collect Inputs...\") # Batch Size for training and testing batch_size = 32 # Number of additional worker processes for dataloading workers = 2 # Number of epochs to train for num_epochs = 2 # Starting Learning Rate starting_lr = 0.1 # Number of distributed processes world_size = 4 # Distributed backend type dist_backend = 'nccl' # Url used to setup distributed training dist_url = \"tcp://172.31.22.234:23456\" 初始化流程组 在 PyTorch 中，分布式训练最重要的部分之一就是正确设置过程组，这是初始化torch.distributed包时首先执行的步骤。 为此，我们将使用torch.distributed.init_process_group函数，该函数需要多个输入。 首先，后端输入指定要使用的后端(即 NCCL，Gloo，MPI 等）。 init_method 输入，该 URL 是包含 rank0 计算机的地址和端口的 url，或者是共享文件系统上不存在的文件的路径。 注意，要使用文件 initmethod，所有计算机都必须有权访问该文件，对于 url 方法而言，所有计算机都必须能够在网络上进行通信，因此请确保配置所有防火墙和网络设置以使其适应。 _init_process_group 函数还采用等级和 world_size 自变量，它们分别指定运行时此进程的等级和集合中的进程数。 init_method 输入也可以是“ env：//”。 在这种情况下，将分别从以下两个环境变量中读取 rank0 机器的地址和端口：MASTERADDR，MASTER_PORT。 如果在 _init_process_group 函数中未指定等级和 world_size 参数，则也可以分别从以下两个环境变量中读取它们：RANK，WORLD_SIZE。 另一个重要步骤(尤其是当每个节点具有多个 GPU 时）是设置此过程的 local_rank 。 例如，如果您有两个节点，每个节点有 8 个 GPU，并且您希望对其全部进行训练，则，每个节点将具有本地等级 0-7 的进程。 此 local_rank 用于设置进程的设备(即使用哪个 GPU），后来在创建分布式数据并行模型时用于设置设备。 还建议在此假设环境中使用 NCCL 后端，因为对于多 GPU 节点，首选 NCCL。 print(\"Initialize Process Group...\") # Initialize Process Group # v1 - init with url dist.init_process_group(backend=dist_backend, init_method=dist_url, rank=int(sys.argv[1]), world_size=world_size) # v2 - init with file # dist.init_process_group(backend=\"nccl\", init_method=\"file:///home/ubuntu/pt-distributed-tutorial/trainfile\", rank=int(sys.argv[1]), world_size=world_size) # v3 - init with environment variables # dist.init_process_group(backend=\"nccl\", init_method=\"env://\", rank=int(sys.argv[1]), world_size=world_size) # Establish Local Rank and set device on this node local_rank = int(sys.argv[2]) dp_device_ids = [local_rank] torch.cuda.set_device(local_rank) 初始化模型 下一步是初始化要训练的模型。 在这里，我们将使用torchvision.models中的 resnet18 模型，但可以使用任何模型。 首先，我们初始化模型并将其放置在 GPU 内存中。 接下来，我们制作模型DistributedDataParallel，该模型处理与模型之间的数据分配，这对于分布式训练至关重要。 DistributedDataParallel模块还可以处理世界范围内的梯度平均，因此我们不必在训练步骤中明确地对梯度进行平均。 重要的是要注意，这是一个阻塞函数，这意味着程序执行将在此函数等待，直到 world_size 进程加入进程组为止。 另外，请注意，我们将设备 ID 列表作为参数传递，其中包含我们正在使用的本地排名(即 GPU）。 最后，我们指定损失函数和优化器来训练模型。 print(\"Initialize Model...\") # Construct Model model = models.resnet18(pretrained=False).cuda() # Make model DistributedDataParallel model = torch.nn.parallel.DistributedDataParallel(model, device_ids=dp_device_ids, output_device=local_rank) # define loss function (criterion) and optimizer criterion = nn.CrossEntropyLoss().cuda() optimizer = torch.optim.SGD(model.parameters(), starting_lr, momentum=0.9, weight_decay=1e-4) 初始化数据加载器 准备训练的最后一步是指定要使用的数据集。 这里，我们使用 torchvision.datasets.STL10 中的 STL-10 数据集。 STL10 数据集是 96x96px 彩色图像的 10 类数据集。 为了与我们的模型一起使用，我们在转换中将图像的大小调整为 224x224px。 本节中的一项分布式训练特定项目是将DistributedSampler用于训练集，该训练集旨在与DistributedDataParallel模型结合使用。 该对象处理整个分布式环境中数据集的分区，因此并非所有模型都在同一数据子集上进行训练，这会适得其反。 最后，我们创建DataLoader，负责将数据馈送到流程中。 如果节点不存在，STL-10 数据集将自动在节点上下载。 如果您希望使用自己的数据集，则应下载数据，编写自己的数据集处理程序，并在此处为数据集构造一个数据加载器。 print(\"Initialize Dataloaders...\") # Define the transform for the data. Notice, we must resize to 224x224 with this dataset and model. transform = transforms.Compose( [transforms.Resize(224), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # Initialize Datasets. STL10 will automatically download if not present trainset = datasets.STL10(root='./data', split='train', download=True, transform=transform) valset = datasets.STL10(root='./data', split='test', download=True, transform=transform) # Create DistributedSampler to handle distributing the dataset across nodes when training # This can only be called after torch.distributed.init_process_group is called train_sampler = torch.utils.data.distributed.DistributedSampler(trainset) # Create the Dataloaders to feed data to the training and validation steps train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=(train_sampler is None), num_workers=workers, pin_memory=False, sampler=train_sampler) val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=workers, pin_memory=False) 训练循环 最后一步是定义训练循环。 我们已经完成了设置分布式训练的大部分工作，因此这不是特定于分布式训练的。 唯一的细节是在DistributedSampler中设置当前纪元计数，因为采样器会根据纪元确定性地随机整理进入每个进程的数据。 更新采样器后，循环将运行一个完整的训练时期，运行一个完整的验证步骤，然后将当前模型的性能与迄今为止性能最佳的模型进行比较。 训练完 num_epochs 之后，循环退出，并且教程已完成。 注意，由于这是一项练习，因此我们没有保存模型，但是可能希望跟踪性能最佳的模型，然后在训练结束时保存模型(请参见，在此处）。 best_prec1 = 0 for epoch in range(num_epochs): # Set epoch count for DistributedSampler train_sampler.set_epoch(epoch) # Adjust learning rate according to schedule adjust_learning_rate(starting_lr, optimizer, epoch) # train for one epoch print(\"\\nBegin Training Epoch {}\".format(epoch+1)) train(train_loader, model, criterion, optimizer, epoch) # evaluate on validation set print(\"Begin Validation @ Epoch {}\".format(epoch+1)) prec1 = validate(val_loader, model, criterion) # remember best prec@1 and save checkpoint if desired # is_best = prec1 > best_prec1 best_prec1 = max(prec1, best_prec1) print(\"Epoch Summary: \") print(\"\\tEpoch Accuracy: {}\".format(prec1)) print(\"\\tBest Accuracy: {}\".format(best_prec1)) 运行代码 与大多数其他 PyTorch 教程不同，此代码可能无法直接在笔记本中运行。 要运行，请下载此文件的.py 版本(或使用此进行转换），然后将副本上载到两个节点。 精明的读者会注意到，我们对 node0-privateIP 和进行了硬编码，但输入了等级和 local_rank 输入为 arg [1]和 arg [ 2]命令行参数。 上传后，在每个节点中打开两个 ssh 终端。 在 node0 的第一个终端上，运行$ python main.py 0 0 在 node0 的第二个终端上运行$ python main.py 1 1 在节点 1 的第一个终端上，运行$ python main.py 2 0 在 node1 的第二个终端上运行$ python main.py 3 1 在打印“ Initialize Model…”之后，程序将启动并等待所有四个进程加入该进程组。 请注意，第一个参数没有重复，因为这是该过程的唯一全局等级。 重复第二个参数，因为这是在节点上运行的进程的本地等级。 如果在每个节点上运行nvidia-smi，则将在每个节点上看到两个进程，一个在 GPU0 上运行，一个在 GPU1 上运行。 我们现在已经完成了分布式训练示例！ 希望您能看到如何使用本教程来帮助您在自己的数据集上训练自己的模型，即使您没有使用完全相同的分布式环境。 如果您使用的是 AWS，请不要忘记按一下来关闭您的节点，否则在月底可能会发现一张大笔的账单。 接下来要去哪里 查看启动器实用程序，以其他方式开始运行 查看 torch.multiprocessing.spawn 实用程序，了解启动多个分布式进程的另一种简便方法。 PyTorch ImageNet 示例已实现并可以演示如何使用它。 如果可能，请设置一个 NFS，以便您仅需要数据集的一个副本 脚本的总运行时间：(0 分钟 0.000 秒） Download Python source code: aws_distributed_training_tutorial.py Download Jupyter notebook: aws_distributed_training_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"39.html":{"url":"39.html","title":"使用自定义 C ++运算符扩展 TorchScript","keywords":"","body":"使用自定义 C ++运算符扩展 TorchScript 原文： https://pytorch.org/tutorials/advanced/torch_script_custom_ops.html PyTorch 1.0 版本向 PyTorch 引入了一种新的编程模型，称为 TorchScript 。 TorchScript 是 Python 编程语言的子集，可以通过 TorchScript 编译器进行解析，编译和优化。 此外，已编译的 TorchScript 模型可以选择序列化为磁盘文件格式，然后可以从纯 C ++(以及 Python）加载并运行该文件格式以进行推理。 TorchScript 支持torch包提供的大量操作子集，使您可以纯粹表示为 PyTorch 的“标准库”中的一系列张量操作来表示多种复杂模型。 但是，有时您可能需要使用自定义 C ++或 CUDA 函数扩展 TorchScript。 虽然我们建议您仅在无法(简单有效地）将您的想法表达为简单的 Python 函数时才诉诸该选项，但我们确实提供了一个非常友好且简单的界面，用于使用 ATen 定义自定义 C ++和 CUDA 内核。 ，PyTorch 的高性能 C ++张量库。 绑定到 TorchScript 后，您可以将这些自定义内核(或“ ops”）嵌入到 TorchScript 模型中，并以 Python 或直接以 C ++的序列化形式执行它们。 以下段落提供了编写 TorchScript 自定义操作以调用 OpenCV (使用 C ++编写的计算机视觉库）的示例。 我们将讨论如何在 C ++中使用张量，如何有效地将它们转换为第三方张量格式(在这种情况下为 OpenCV 或 Mat），如何在 TorchScript 运行时中注册您的运算符 最后是如何编译运算符并在 Python 和 C ++中使用它。 在 C ++中实现自定义运算符 在本教程中，我们将公开 warpPerspective 函数，该函数将透视转换应用于图像，从 OpenCV 到 TorchScript 作为自定义运算符。 第一步是用 C ++编写自定义运算符的实现。 让我们将此实现的文件称为op.cpp，并使其如下所示： #include #include torch::Tensor warp_perspective(torch::Tensor image, torch::Tensor warp) { cv::Mat image_mat(/*rows=*/image.size(0), /*cols=*/image.size(1), /*type=*/CV_32FC1, /*data=*/image.data()); cv::Mat warp_mat(/*rows=*/warp.size(0), /*cols=*/warp.size(1), /*type=*/CV_32FC1, /*data=*/warp.data()); cv::Mat output_mat; cv::warpPerspective(image_mat, output_mat, warp_mat, /*dsize=*/{8, 8}); torch::Tensor output = torch::from_blob(output_mat.ptr(), /*sizes=*/{8, 8}); return output.clone(); } 该运算符的代码很短。 在文件顶部，我们包含 OpenCV 标头文件opencv2/opencv.hpp和torch/script.h标头，该标头暴露了 PyTorch C ++ API 中所有需要编写自定义 TorchScript 运算符的必需属性。 我们的函数warp_perspective具有两个参数：输入image和我们希望应用于图像的warp变换矩阵。 这些输入的类型是torch::Tensor，这是 C ++中 PyTorch 的张量类型(也是 Python 中所有张量的基础类型）。 我们的warp_perspective函数的返回类型也将是torch::Tensor。 小费 有关 ATen 的更多信息，请参见本说明，ATen 是为 PyTorch 提供Tensor类的库。 此外，本教程的描述了如何在 C ++中分配和初始化新的张量对象(此运算符不需要）。 注意 TorchScript 编译器了解固定数量的类型。 只有这些类型可以用作自定义运算符的参数。 当前这些类型是：这些类型的torch::Tensor，torch::Scalar，double，int64_t和std::vector。 请注意，仅，，double和不，，float，仅，，int64_t和，等其他整数类型，例如int 支持short或long。 在函数内部，我们要做的第一件事是将 PyTorch 张量转换为 OpenCV 矩阵，因为 OpenCV 的warpPerspective期望cv::Mat对象作为输入。 幸运的是，有一种方法可以执行此，而无需复制任何数据。 在前几行中 cv::Mat image_mat(/*rows=*/image.size(0), /*cols=*/image.size(1), /*type=*/CV_32FC1, /*data=*/image.data()); 我们正在将称为 OpenCV Mat类的构造函数，将张量转换为Mat对象。 我们将原始image张量的行数和列数，数据类型(在此示例中，我们将其固定为float32）传递给它，最后传递指向基础数据的原始指针– float*。 Mat类的此构造方法的特殊之处在于它不会复制输入数据。 取而代之的是，它将简单地引用此内存来执行Mat上的所有操作。 如果在image_mat上执行就地操作，这将反映在原始image张量中(反之亦然）。 即使我们实际上将数据存储在 PyTorch 张量中，这也使我们能够使用库的本机矩阵类型调用后续的 OpenCV 例程。 我们重复此过程将warp PyTorch 张量转换为warp_mat OpenCV 矩阵： cv::Mat warp_mat(/*rows=*/warp.size(0), /*cols=*/warp.size(1), /*type=*/CV_32FC1, /*data=*/warp.data()); 接下来，我们准备调用我们渴望在 TorchScript 中使用的 OpenCV 函数：warpPerspective。 为此，我们将image_mat和warp_mat矩阵以及称为output_mat的空输出矩阵传递给 OpenCV 函数。 我们还指定了我们希望输出矩阵(图像）为dsize的大小。 对于此示例，它被硬编码为8 x 8： cv::Mat output_mat; cv::warpPerspective(image_mat, output_mat, warp_mat, /*dsize=*/{8, 8}); 我们的自定义运算符实现的最后一步是将output_mat转换回 PyTorch 张量，以便我们可以在 PyTorch 中进一步使用它。 这与我们先前在另一个方向进行转换的操作极为相似。 在这种情况下，PyTorch 提供了torch::from_blob方法。 在这种情况下， blob 旨在表示一些不透明的，扁平的指向内存的指针，我们希望将其解释为 PyTorch 张量。 对torch::from_blob的调用如下所示： torch::from_blob(output_mat.ptr(), /*sizes=*/{8, 8}) 我们在 OpenCV Mat类上使用.ptr&lt;float&gt;()方法来获取指向基础数据的原始指针(就像之前的 PyTorch 张量的.data&lt;float&gt;()一样）。 我们还指定了张量的输出形状，我们将其硬编码为8 x 8。 然后torch::from_blob的输出是torch::Tensor，指向 OpenCV 矩阵拥有的内存。 从我们的运算符实现返回该张量之前，我们必须在张量上调用.clone()以执行基础数据的存储副本。 这样做的原因是torch::from_blob返回的张量不拥有其数据。 那时，数据仍归 OpenCV 矩阵所有。 但是，此 OpenCV 矩阵将超出范围，并在函数末尾重新分配。 如果我们按原样返回output张量，那么当我们在函数外使用它时，它将指向无效的内存。 调用.clone()将返回一个新的张量，其中包含新张量自己拥有的原始数据的副本。 因此，返回外部世界是安全的。 使用 TorchScript 注册自定义运算符 现在，已经在 C ++中实现了自定义运算符，我们需要在 T​​orchScript 运行时和编译器中将注册为。 这将使 TorchScript 编译器可以在 TorchScript 代码中解析对我们自定义运算符的引用。 注册非常简单。 对于我们的情况，我们需要编写： static auto registry = torch::RegisterOperators(\"my_ops::warp_perspective\", &warp_perspective); op.cpp文件的全局范围内的某个位置。 这将创建一个全局变量registry，该变量将在其构造函数中向 TorchScript 注册我们的运算符(即每个程序一次）。 我们指定运算符的名称，以及指向其实现的指针(我们之前编写的函数）。 该名称包括两部分：命名空间(my_ops）和我们正在注册的特定运算符的名称(warp_perspective）。 名称空间和操作员名称由两个冒号(::）分隔。 Tip 如果要注册多个运算符，可以在构造函数之后将调用链接到.op()： static auto registry = torch::RegisterOperators(\"my_ops::warp_perspective\", &warp_perspective) .op(\"my_ops::another_op\", &another_op) .op(\"my_ops::and_another_op\", &and_another_op); 在后台，RegisterOperators将执行许多相当复杂的 C ++模板元编程魔术技巧，以推断我们传递给它的函数指针的参数和返回值类型(&warp_perspective）。 此信息用于为我们的操作员形成功能模式。 函数模式是操作员的结构化表示形式，一种“签名”或“原型”，由 TorchScript 编译器用来验证 TorchScript 程序的正确性。 建立自定义操作员 现在，我们已经用 C ++实现了自定义运算符并编写了其注册代码，是时候将该运算符构建到一个(共享的）库中了，可以将其加载到 Python 中进行研究和实验，或者加载到 C ++中以在非 Python 中进行推理。 环境。 有多种方法可以使用纯 CMake 或setuptools之类的 Python 替代方法来构建我们的运算符。 为简洁起见，以下段落仅讨论 CMake 方法。 本教程的附录深入探讨了基于 Python 的替代方法。 用 CMake 构建 为了使用 CMake 构建系统将自定义运算符构建到共享库中，我们需要编写一个简短的CMakeLists.txt文件并将其与之前的op.cpp文件一起放置。 为此，让我们就一个看起来像这样的目录结构达成一致： warp-perspective/ op.cpp CMakeLists.txt 另外，请确保从 pytorch.org 中获取 LibTorch 发行版的最新版本，该软件包打包了 PyTorch 的 C ++库和 CMake 构建文件。 将解压缩的发行版放置在文件系统中可访问的位置。 以下段落将将该位置称为/path/to/libtorch。 我们的CMakeLists.txt文件的内容应为以下内容： cmake_minimum_required(VERSION 3.1 FATAL_ERROR) project(warp_perspective) find_package(Torch REQUIRED) find_package(OpenCV REQUIRED) # Define our library target add_library(warp_perspective SHARED op.cpp) # Enable C++11 target_compile_features(warp_perspective PRIVATE cxx_range_for) # Link against LibTorch target_link_libraries(warp_perspective \"${TORCH_LIBRARIES}\") # Link against OpenCV target_link_libraries(warp_perspective opencv_core opencv_imgproc) 警告 此设置对构建环境进行了一些假设，特别是有关 OpenCV 安装的假设。 上面的CMakeLists.txt文件已在运行 Ubuntu Xenial 的 Docker 容器中通过apt安装了libopencv-dev进行了测试。 如果它对您不起作用，并且您感到困惑，请使用随附的教程资料库中的Dockerfile构建一个隔离的，可复制的环境，在其中可以使用本教程中的代码。 如果您遇到其他麻烦，请在教程资料库中提交问题，或在我们的论坛中发布问题。 现在要构建我们的操作员，我们可以从warp_perspective文件夹中运行以下命令： $ mkdir build $ cd build $ cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch .. -- The C compiler identification is GNU 5.4.0 -- The CXX compiler identification is GNU 5.4.0 -- Check for working C compiler: /usr/bin/cc -- Check for working C compiler: /usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Detecting C compile features -- Detecting C compile features - done -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Looking for pthread.h -- Looking for pthread.h - found -- Looking for pthread_create -- Looking for pthread_create - not found -- Looking for pthread_create in pthreads -- Looking for pthread_create in pthreads - not found -- Looking for pthread_create in pthread -- Looking for pthread_create in pthread - found -- Found Threads: TRUE -- Found torch: /libtorch/lib/libtorch.so -- Configuring done -- Generating done -- Build files have been written to: /warp_perspective/build $ make -j Scanning dependencies of target warp_perspective [ 50%] Building CXX object CMakeFiles/warp_perspective.dir/op.cpp.o [100%] Linking CXX shared library libwarp_perspective.so [100%] Built target warp_perspective 它将在build文件夹中放置libwarp_perspective.so共享库文件。 在上面的cmake命令中，应将/path/to/libtorch替换为未压缩的 LibTorch 发行版的路径。 我们将在下面进一步探讨如何使用和调用我们的运算符，但是为了早日获得成功，我们可以尝试在 Python 中运行以下代码： >>> import torch >>> torch.ops.load_library(\"/path/to/libwarp_perspective.so\") >>> print(torch.ops.my_ops.warp_perspective) 在这里，/path/to/libwarp_perspective.so应该是我们刚刚构建的libwarp_perspective.so共享库的相对或绝对路径。 如果一切顺利，这应该打印类似 这是我们稍后将用来调用自定义运算符的 Python 函数。 在 Python 中使用 TorchScript 自定义运算符 将我们的自定义运算符构建到共享库后，我们就可以在 Python 的 TorchScript 模型中使用此运算符了。 这有两个部分：首先将运算符加载到 Python 中，其次在 TorchScript 代码中使用运算符。 您已经了解了如何将运算符导入 Python：torch.ops.load_library()。 此函数采用包含自定义运算符的共享库的路径，并将其加载到当前进程中。 加载共享库还将执行我们放入自定义运算符实现文件中的全局RegisterOperators对象的构造函数。 这将在 TorchScript 编译器中注册我们的自定义运算符，并允许我们在 TorchScript 代码中使用该运算符。 您可以将已加载的运算符称为torch.ops.&lt;namespace&gt;.&lt;function&gt;，其中&lt;namespace&gt;是运算符名称的名称空间部分，而&lt;function&gt;是运算符的函数名称。 对于我们上面编写的运算符，名称空间为my_ops，函数名称为warp_perspective，这意味着我们的运算符可以作为torch.ops.my_ops.warp_perspective使用。 尽管可以在脚本化或跟踪的 TorchScript 模块中使用此函数，但我们也可以仅在原始的 PyTorch 中使用它，并将其传递给常规 PyTorch 张量： >>> import torch >>> torch.ops.load_library(\"libwarp_perspective.so\") >>> torch.ops.my_ops.warp_perspective(torch.randn(32, 32), torch.rand(3, 3)) tensor([[0.0000, 0.3218, 0.4611, ..., 0.4636, 0.4636, 0.4636], [0.3746, 0.0978, 0.5005, ..., 0.4636, 0.4636, 0.4636], [0.3245, 0.0169, 0.0000, ..., 0.4458, 0.4458, 0.4458], ..., [0.1862, 0.1862, 0.1692, ..., 0.0000, 0.0000, 0.0000], [0.1862, 0.1862, 0.1692, ..., 0.0000, 0.0000, 0.0000], [0.1862, 0.1862, 0.1692, ..., 0.0000, 0.0000, 0.0000]]) 注意 幕后发生的事情是，第一次使用 Python 访问torch.ops.namespace.function时，TorchScript 编译器(在 C ++平台上）将查看是否已注册函数namespace::function，如果已注册，则将 Python 句柄返回给该函数， 我们可以随后使用它从 Python 调用我们的 C ++运算符实现。 这是 TorchScript 自定义运算符和 C ++扩展之间的一个值得注意的区别：C ++扩展是使用 pybind11 手动绑定的，而 TorchScript 自定义操作则是由 PyTorch 自己动态绑定的。 Pybind11 在绑定到 Python 的类型和类方面为您提供了更大的灵活性，因此建议将其用于纯粹渴望的代码，但 TorchScript ops 不支持它。 从这里开始，您可以在脚本或跟踪代码中使用自定义运算符，就像torch包中的其他函数一样。 实际上，诸如torch.matmul之类的“标准库”功能与自定义运算符的注册路径大致相同，这使得自定义运算符在 TorchScript 中的使用方式和位置方面真正成为一等公民。 使用自定义运算符进行跟踪 首先，将我们的运算符嵌入到跟踪函数中。 回想一下，为了进行跟踪，我们从一些原始的 Pytorch 代码开始： def compute(x, y, z): return x.matmul(y) + torch.relu(z) 然后调用torch.jit.trace。 我们进一步传递torch.jit.trace一些示例输入，它将输入到我们的实现中，以记录输入流过它时发生的操作顺序。 这样的结果实际上是渴望的 PyTorch 程序的“冻结”版本，TorchScript 编译器可以对其进行进一步的分析，优化和序列化： >>> inputs = [torch.randn(4, 8), torch.randn(8, 5), torch.randn(4, 5)] >>> trace = torch.jit.trace(compute, inputs) >>> print(trace.graph) graph(%x : Float(4, 8) %y : Float(8, 5) %z : Float(4, 5)) { %3 : Float(4, 5) = aten::matmul(%x, %y) %4 : Float(4, 5) = aten::relu(%z) %5 : int = prim::Constant[value=1]() %6 : Float(4, 5) = aten::add(%3, %4, %5) return (%6); } 现在，令人兴奋的启示是，我们可以简单地将自定义运算符放到 PyTorch 跟踪中，就好像它是torch.relu或任何其他torch函数一样： torch.ops.load_library(\"libwarp_perspective.so\") def compute(x, y, z): x = torch.ops.my_ops.warp_perspective(x, torch.eye(3)) return x.matmul(y) + torch.relu(z) 然后像以前一样跟踪它： >>> inputs = [torch.randn(4, 8), torch.randn(8, 5), torch.randn(8, 5)] >>> trace = torch.jit.trace(compute, inputs) >>> print(trace.graph) graph(%x.1 : Float(4, 8) %y : Float(8, 5) %z : Float(8, 5)) { %3 : int = prim::Constant[value=3]() %4 : int = prim::Constant[value=6]() %5 : int = prim::Constant[value=0]() %6 : int[] = prim::Constant[value=[0, -1]]() %7 : Float(3, 3) = aten::eye(%3, %4, %5, %6) %x : Float(8, 8) = my_ops::warp_perspective(%x.1, %7) %11 : Float(8, 5) = aten::matmul(%x, %y) %12 : Float(8, 5) = aten::relu(%z) %13 : int = prim::Constant[value=1]() %14 : Float(8, 5) = aten::add(%11, %12, %13) return (%14); } 如此简单地将 TorchScript 自定义操作集成到跟踪的 PyTorch 代码中！ 将自定义运算符与脚本一起使用 除了跟踪之外，获得 PyTorch 程序的 TorchScript 表示形式的另一种方法是直接在 TorchScript 中编写代码。 TorchScript 在很大程度上是 Python 语言的子集，它具有一些限制，使 TorchScript 编译器更容易推理程序。 您可以使用@torch.jit.script标记免费功能，使用@torch.jit.script_method标记类中的方法(也必须从torch.jit.ScriptModule派生），将常规 PyTorch 代码转换为 TorchScript。 有关 TorchScript 注释的更多详细信息，请参见此处的。 使用 TorchScript 而不是跟踪的一个特殊原因是，跟踪无法捕获 PyTorch 代码中的控制流。 因此，让我们考虑使用控制流的此函数： def compute(x, y): if bool(x[0][0] == 42): z = 5 else: z = 10 return x.matmul(y) + z 要将此功能从原始 PyTorch 转换为 TorchScript，我们用@torch.jit.script对其进行注释： @torch.jit.script def compute(x, y): if bool(x[0][0] == 42): z = 5 else: z = 10 return x.matmul(y) + z 这将及时将compute函数编译为图形表示形式，我们可以在compute.graph属性中进行检查： >>> compute.graph graph(%x : Dynamic %y : Dynamic) { %14 : int = prim::Constant[value=1]() %2 : int = prim::Constant[value=0]() %7 : int = prim::Constant[value=42]() %z.1 : int = prim::Constant[value=5]() %z.2 : int = prim::Constant[value=10]() %4 : Dynamic = aten::select(%x, %2, %2) %6 : Dynamic = aten::select(%4, %2, %2) %8 : Dynamic = aten::eq(%6, %7) %9 : bool = prim::TensorToBool(%8) %z : int = prim::If(%9) block0() { -> (%z.1) } block1() { -> (%z.2) } %13 : Dynamic = aten::matmul(%x, %y) %15 : Dynamic = aten::add(%13, %z, %14) return (%15); } 现在，就像以前一样，我们可以像脚本代码中的任何其他函数一样使用自定义运算符： torch.ops.load_library(\"libwarp_perspective.so\") @torch.jit.script def compute(x, y): if bool(x[0] == 42): z = 5 else: z = 10 x = torch.ops.my_ops.warp_perspective(x, torch.eye(3)) return x.matmul(y) + z 当 TorchScript 编译器看到对torch.ops.my_ops.warp_perspective的引用时，它将找到我们通过 C ++中的RegisterOperators对象注册的实现，并将其编译为图形表示形式： >>> compute.graph graph(%x.1 : Dynamic %y : Dynamic) { %20 : int = prim::Constant[value=1]() %16 : int[] = prim::Constant[value=[0, -1]]() %14 : int = prim::Constant[value=6]() %2 : int = prim::Constant[value=0]() %7 : int = prim::Constant[value=42]() %z.1 : int = prim::Constant[value=5]() %z.2 : int = prim::Constant[value=10]() %13 : int = prim::Constant[value=3]() %4 : Dynamic = aten::select(%x.1, %2, %2) %6 : Dynamic = aten::select(%4, %2, %2) %8 : Dynamic = aten::eq(%6, %7) %9 : bool = prim::TensorToBool(%8) %z : int = prim::If(%9) block0() { -> (%z.1) } block1() { -> (%z.2) } %17 : Dynamic = aten::eye(%13, %14, %2, %16) %x : Dynamic = my_ops::warp_perspective(%x.1, %17) %19 : Dynamic = aten::matmul(%x, %y) %21 : Dynamic = aten::add(%19, %z, %20) return (%21); } 请特别注意图形末尾对my_ops::warp_perspective的引用。 Attention TorchScript 图形表示仍可能更改。 不要依靠它看起来像这样。 在 Python 中使用自定义运算符时，确实如此。 简而言之，您可以使用torch.ops.load_library导入包含运算符的库，并像其他任何torch运算符一样，从跟踪或编写脚本的 TorchScript 代码中调用自定义操作。 在 C ++中使用 TorchScript 自定义运算符 TorchScript 的一项有用功能是能够将模型序列化到磁盘文件中。 该文件可以通过有线方式发送，存储在文件系统中，或者更重要的是，可以动态反序列化和执行，而无需保留原始源代码。 这在 Python 中是可能的，但在 C ++中也是可能的。 为此，PyTorch 为提供了纯 C ++ API ，用于反序列化以及执行 TorchScript 模型。 如果还没有的话，请阅读有关使用 C ++ 加载和运行序列化 TorchScript 模型的教程，接下来的几段将基于该教程构建。 简而言之，即使从文件反序列化并以 C ++运行，也可以像常规torch运算符一样执行自定义运算符。 唯一的要求是将我们先前构建的自定义运算符共享库与执行模型的 C ++应用程序链接。 在 Python 中，只需调用torch.ops.load_library即可。 在 C ++中，您需要在使用的任何构建系统中将共享库与主应用程序链接。 下面的示例将使用 CMake 展示这一点。 Note 从技术上讲，您还可以在运行时将共享库动态加载到 C ++应用程序中，就像在 Python 中一样。 在 Linux 上，可以使用 dlopen 来执行此操作。 在其他平台上也存在等效项。 在上面链接的 C ++执行教程的基础上，让我们从一个文件中的最小 C ++应用程序开始，该文件位于与自定义运算符不同的文件夹中的main.cpp，该文件加载并执行序列化的 TorchScript 模型： #include // One-stop header. #include #include int main(int argc, const char* argv[]) { if (argc != 2) { std::cerr \\n\"; return -1; } // Deserialize the ScriptModule from a file using torch::jit::load(). std::shared_ptr module = torch::jit::load(argv[1]); std::vector inputs; inputs.push_back(torch::randn({4, 8})); inputs.push_back(torch::randn({8, 5})); torch::Tensor output = module->forward(std::move(inputs)).toTensor(); std::cout 以及一个小的CMakeLists.txt文件： cmake_minimum_required(VERSION 3.1 FATAL_ERROR) project(example_app) find_package(Torch REQUIRED) add_executable(example_app main.cpp) target_link_libraries(example_app \"${TORCH_LIBRARIES}\") target_compile_features(example_app PRIVATE cxx_range_for) 在这一点上，我们应该能够构建应用程序： $ mkdir build $ cd build $ cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch .. -- The C compiler identification is GNU 5.4.0 -- The CXX compiler identification is GNU 5.4.0 -- Check for working C compiler: /usr/bin/cc -- Check for working C compiler: /usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Detecting C compile features -- Detecting C compile features - done -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Looking for pthread.h -- Looking for pthread.h - found -- Looking for pthread_create -- Looking for pthread_create - not found -- Looking for pthread_create in pthreads -- Looking for pthread_create in pthreads - not found -- Looking for pthread_create in pthread -- Looking for pthread_create in pthread - found -- Found Threads: TRUE -- Found torch: /libtorch/lib/libtorch.so -- Configuring done -- Generating done -- Build files have been written to: /example_app/build $ make -j Scanning dependencies of target example_app [ 50%] Building CXX object CMakeFiles/example_app.dir/main.cpp.o [100%] Linking CXX executable example_app [100%] Built target example_app 并在尚未通过模型的情况下运行它： $ ./example_app usage: example_app 接下来，让我们序列化我们先前编写的使用自定义运算符的脚本函数： torch.ops.load_library(\"libwarp_perspective.so\") @torch.jit.script def compute(x, y): if bool(x[0][0] == 42): z = 5 else: z = 10 x = torch.ops.my_ops.warp_perspective(x, torch.eye(3)) return x.matmul(y) + z compute.save(\"example.pt\") 最后一行将脚本功能序列化为一个名为“ example.pt”的文件。 如果我们随后将此序列化模型传递给我们的 C ++应用程序，则可以立即运行它： $ ./example_app example.pt terminate called after throwing an instance of 'torch::jit::script::ErrorReport' what(): Schema not found for node. File a bug report. Node: %16 : Dynamic = my_ops::warp_perspective(%0, %19) 或者可能不是。 也许还没有。 当然！ 我们尚未将自定义运算符库与我们的应用程序链接。 让我们立即执行此操作，并正确进行操作，让我们稍微更新一下文件组织，如下所示： example_app/ CMakeLists.txt main.cpp warp_perspective/ CMakeLists.txt op.cpp 这将允许我们将warp_perspective库 CMake 目标添加为应用目标的子目录。 example_app文件夹中的顶层CMakeLists.txt应该如下所示： cmake_minimum_required(VERSION 3.1 FATAL_ERROR) project(example_app) find_package(Torch REQUIRED) add_subdirectory(warp_perspective) add_executable(example_app main.cpp) target_link_libraries(example_app \"${TORCH_LIBRARIES}\") target_link_libraries(example_app -Wl,--no-as-needed warp_perspective) target_compile_features(example_app PRIVATE cxx_range_for) 基本的 CMake 配置与以前非常相似，只是我们将warp_perspective CMake 构建添加为子目录。 一旦其 CMake 代码运行，我们就将我们的example_app应用程序与warp_perspective共享库链接起来。 Attention 上面的示例中嵌入了一个关键细节：warp_perspective链接行的-Wl,--no-as-needed前缀。 这是必需的，因为我们实际上不会在应用程序代码中从warp_perspective共享库中调用任何函数。 我们只需要运行全局RegisterOperators对象的构造函数即可。 麻烦的是，这使链接器感到困惑，并使其认为可以完全跳过针对库的链接。 在 Linux 上，-Wl,--no-as-needed标志强制执行链接(注意：该标志特定于 Linux！）。 还有其他解决方法。 最简单的方法是在操作员库中定义一些函数，您需要从主应用程序中调用该函数。 这可能就像在某个标头中声明的函数void init();一样简单，然后在运算符库中将其定义为void init() { }。 在主应用程序中调用此init()函数会给链接器以印象，这是一个值得链接的库。 不幸的是，这不在我们的控制范围之内，我们宁愿让您知道其原因和简单的解决方法，而不是让您将一些不透明的宏放入代码中。 现在，由于我们现在在顶层找到了Torch软件包，因此warp_perspective子目录中的CMakeLists.txt文件可以缩短一些。 它看起来应该像这样： find_package(OpenCV REQUIRED) add_library(warp_perspective SHARED op.cpp) target_compile_features(warp_perspective PRIVATE cxx_range_for) target_link_libraries(warp_perspective PRIVATE \"${TORCH_LIBRARIES}\") target_link_libraries(warp_perspective PRIVATE opencv_core opencv_photo) 让我们重新构建示例应用程序，该应用程序还将与自定义运算符库链接。 在顶层example_app目录中： $ mkdir build $ cd build $ cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch .. -- The C compiler identification is GNU 5.4.0 -- The CXX compiler identification is GNU 5.4.0 -- Check for working C compiler: /usr/bin/cc -- Check for working C compiler: /usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Detecting C compile features -- Detecting C compile features - done -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Looking for pthread.h -- Looking for pthread.h - found -- Looking for pthread_create -- Looking for pthread_create - not found -- Looking for pthread_create in pthreads -- Looking for pthread_create in pthreads - not found -- Looking for pthread_create in pthread -- Looking for pthread_create in pthread - found -- Found Threads: TRUE -- Found torch: /libtorch/lib/libtorch.so -- Configuring done -- Generating done -- Build files have been written to: /warp_perspective/example_app/build $ make -j Scanning dependencies of target warp_perspective [ 25%] Building CXX object warp_perspective/CMakeFiles/warp_perspective.dir/op.cpp.o [ 50%] Linking CXX shared library libwarp_perspective.so [ 50%] Built target warp_perspective Scanning dependencies of target example_app [ 75%] Building CXX object CMakeFiles/example_app.dir/main.cpp.o [100%] Linking CXX executable example_app [100%] Built target example_app 如果现在运行example_app二进制文件并将其传递给序列化模型，我们应该得出一个圆满的结局： $ ./example_app example.pt 11.4125 5.8262 9.5345 8.6111 12.3997 7.4683 13.5969 9.0850 11.0698 9.4008 7.4597 15.0926 12.5727 8.9319 9.0666 9.4834 11.1747 9.0162 10.9521 8.6269 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 [ Variable[CPUFloatType]{8,5} ] 成功！ 您现在可以推断了。 结论 本教程向您介绍了如何在 C ++中实现自定义 TorchScript 运算符，如何将其构建到共享库中，如何在 Python 中使用它来定义 TorchScript 模型，最后如何将其加载到 C ++应用程序中以进行推理工作负载。 现在，您可以使用与第三方 C ++库进行接口的 C ++运算符扩展 TorchScript 模型，编写自定义的高性能 CUDA 内核，或实现任何其他需要 Python，TorchScript 和 C ++之间的界线才能平稳融合的用例。 与往常一样，如果您遇到任何问题或疑问，可以使用我们的论坛或 GitHub 问题进行联系。 另外，我们的常见问题解答(FAQ）页面可能包含有用的信息。 附录 A：建立自定义操作员的更多方法 “构建自定义运算符”一节介绍了如何使用 CMake 将自定义运算符构建到共享库中。 本附录概述了两种进一步的编译方法。 他们俩都使用 Python 作为编译过程的“驱动程序”或“接口”。 此外，两者都重新使用了现有基础结构 PyTorch 提供了 C ++扩展 ，它们是依赖于 [pybind11 用于将功能从 C ++“显式”绑定到 Python。 第一种方法是使用 C ++扩展程序的方便的即时(JIT）编译界面在您首次运行 PyTorch 脚本时在后台编译代码。 第二种方法依赖于古老的setuptools包，并涉及编写单独的setup.py文件。 这样可以进行更高级的配置，并与其他基于setuptools的项目集成。 我们将在下面详细探讨这两种方法。 使用 JIT 编译进行构建 PyTorch C ++扩展工具包提供的 JIT 编译功能可将您的自定义运算符的编译直接嵌入到您的 Python 代码中，例如 在训练脚本的顶部。 Note 这里的“ JIT 编译”与 TorchScript 编译器中用于优化程序的 JIT 编译无关。 这只是意味着您的自定义运算符 C ++代码将在您首次导入时在系统 / tmp 目录下的文件夹中编译，就像您自己事先对其进行编译一样。 此 JIT 编译功能有两种形式。 首先，您仍然将操作员实现保存在单独的文件(op.cpp）中，然后使用torch.utils.cpp_extension.load()编译扩展名。 通常，此函数将返回暴露您的 C ++扩展的 Python 模块。 但是，由于我们没有将自定义运算符编译到其自己的 Python 模块中，因此我们只想编译一个普通的共享库。 幸运的是，torch.utils.cpp_extension.load()有一个参数is_python_module，可以将其设置为False，以表明我们仅对构建共享库感兴趣，而对 Python 模块不感兴趣。 然后torch.utils.cpp_extension.load()将会编译并将共享库也加载到当前进程中，就像torch.ops.load_library之前所做的那样： import torch.utils.cpp_extension torch.utils.cpp_extension.load( name=\"warp_perspective\", sources=[\"op.cpp\"], extra_ldflags=[\"-lopencv_core\", \"-lopencv_imgproc\"], is_python_module=False, verbose=True ) print(torch.ops.my_ops.warp_perspective) 这应该大致打印： JIT 编译的第二种形式使您可以将自定义 TorchScript 运算符的源代码作为字符串传递。 为此，请使用torch.utils.cpp_extension.load_inline： import torch import torch.utils.cpp_extension op_source = \"\"\" #include #include torch::Tensor warp_perspective(torch::Tensor image, torch::Tensor warp) { cv::Mat image_mat(/*rows=*/image.size(0), /*cols=*/image.size(1), /*type=*/CV_32FC1, /*data=*/image.data()); cv::Mat warp_mat(/*rows=*/warp.size(0), /*cols=*/warp.size(1), /*type=*/CV_32FC1, /*data=*/warp.data()); cv::Mat output_mat; cv::warpPerspective(image_mat, output_mat, warp_mat, /*dsize=*/{64, 64}); torch::Tensor output = torch::from_blob(output_mat.ptr(), /*sizes=*/{64, 64}); return output.clone(); } static auto registry = torch::RegisterOperators(\"my_ops::warp_perspective\", &warp_perspective); \"\"\" torch.utils.cpp_extension.load_inline( name=\"warp_perspective\", cpp_sources=op_source, extra_ldflags=[\"-lopencv_core\", \"-lopencv_imgproc\"], is_python_module=False, verbose=True, ) print(torch.ops.my_ops.warp_perspective) 自然，最佳实践是仅在源代码相当短的情况下才使用torch.utils.cpp_extension.load_inline。 请注意，如果您在 Jupyter Notebook 中使用此功能，则不应多次执行单元格的注册，因为每次执行都会注册一个新库并重新注册自定义运算符。 如果需要重新执行它，请事先重新启动笔记本的 Python 内核。 使用 Setuptools 构建 从 Python 专门构建自定义运算符的第二种方法是使用setuptools。 这样做的好处是setuptools具有用于构建用 C ++编写的 Python 模块的功能非常强大且广泛的接口。 但是，由于setuptools实际上是用于构建 Python 模块而不是普通的共享库(它们没有 Python 期望从模块中获得的必要入口点），因此这种方法可能有点古怪。 也就是说，您需要的是一个setup.py文件来代替CMakeLists.txt，该文件看起来像这样： from setuptools import setup from torch.utils.cpp_extension import BuildExtension, CppExtension setup( name=\"warp_perspective\", ext_modules=[ CppExtension( \"warp_perspective\", [\"example_app/warp_perspective/op.cpp\"], libraries=[\"opencv_core\", \"opencv_imgproc\"], ) ], cmdclass={\"build_ext\": BuildExtension.with_options(no_python_abi_suffix=True)}, ) 请注意，我们在底部的BuildExtension中启用了no_python_abi_suffix选项。 这指示setuptools在产生的共享库的名称中省略任何特定于 Python-3 的 ABI 后缀。 否则，例如在 Python 3.7 上，该库可能被称为warp_perspective.cpython-37m-x86_64-linux-gnu.so，其中cpython-37m-x86_64-linux-gnu是 ABI 标签，但我们确实只是希望将其称为warp_perspective.so 如果现在从setup.py所在的文件夹中的终端中运行python setup.py build develop，我们应该看到类似以下内容： $ python setup.py build develop running build running build_ext building 'warp_perspective' extension creating build creating build/temp.linux-x86_64-3.7 gcc -pthread -B /root/local/miniconda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/root/local/miniconda/lib/python3.7/site-packages/torch/lib/include -I/root/local/miniconda/lib/python3.7/site-packages/torch/lib/include/torch/csrc/api/include -I/root/local/miniconda/lib/python3.7/site-packages/torch/lib/include/TH -I/root/local/miniconda/lib/python3.7/site-packages/torch/lib/include/THC -I/root/local/miniconda/include/python3.7m -c op.cpp -o build/temp.linux-x86_64-3.7/op.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=warp_perspective -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11 cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++ creating build/lib.linux-x86_64-3.7 g++ -pthread -shared -B /root/local/miniconda/compiler_compat -L/root/local/miniconda/lib -Wl,-rpath=/root/local/miniconda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/op.o -lopencv_core -lopencv_imgproc -o build/lib.linux-x86_64-3.7/warp_perspective.so running develop running egg_info creating warp_perspective.egg-info writing warp_perspective.egg-info/PKG-INFO writing dependency_links to warp_perspective.egg-info/dependency_links.txt writing top-level names to warp_perspective.egg-info/top_level.txt writing manifest file 'warp_perspective.egg-info/SOURCES.txt' reading manifest file 'warp_perspective.egg-info/SOURCES.txt' writing manifest file 'warp_perspective.egg-info/SOURCES.txt' running build_ext copying build/lib.linux-x86_64-3.7/warp_perspective.so -> Creating /root/local/miniconda/lib/python3.7/site-packages/warp-perspective.egg-link (link to .) Adding warp-perspective 0.0.0 to easy-install.pth file Installed /warp_perspective Processing dependencies for warp-perspective==0.0.0 Finished processing dependencies for warp-perspective==0.0.0 这将产生一个名为warp_perspective.so的共享库，我们可以像之前那样将其传递给torch.ops.load_library，以使我们的操作员对 TorchScript 可见： >>> import torch >>> torch.ops.load_library(\"warp_perspective.so\") >>> print(torch.ops.custom.warp_perspective) 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"40.html":{"url":"40.html","title":"使用自定义 C ++类扩展 TorchScript","keywords":"","body":"使用自定义 C ++类扩展 TorchScript 原文： https://pytorch.org/tutorials/advanced/torch_script_custom_classes.html 本教程是自定义运算符教程的后续教程，并介绍了我们为将 C ++类同时绑定到 TorchScript 和 Python 而构建的 API。 该 API 与 pybind11 非常相似，如果您熟悉该系统，则大多数概念都将转移过来。 在 C ++中实现和绑定类 在本教程中，我们将定义一个简单的 C ++类，该类在成员变量中保持持久状态。 // This header is all you need to do the C++ portions of this // tutorial #include // This header is what defines the custom class registration // behavior specifically. script.h already includes this, but // we include it here so you know it exists in case you want // to look at the API or implementation. #include #include #include template struct Stack : torch::jit::CustomClassHolder { std::vector stack_; Stack(std::vector init) : stack_(init.begin(), init.end()) {} void push(T x) { stack_.push_back(x); } T pop() { auto val = stack_.back(); stack_.pop_back(); return val; } c10::intrusive_ptr clone() const { return c10::make_intrusive(stack_); } void merge(const c10::intrusive_ptr& c) { for (auto& elem : c->stack_) { push(elem); } } }; 有几件事要注意： torch/custom_class.h是您需要使用自定义类扩展 TorchScript 的标头。 注意，无论何时使用自定义类的实例，我们都通过c10::intrusive_ptr&lt;&gt;的实例来实现。 将intrusive_ptr视为类似于std::shared_ptr的智能指针。 使用此智能指针的原因是为了确保在语言(C ++，Python 和 TorchScript）之间对对象实例进行一致的生命周期管理。 注意的第二件事是用户定义的类必须继承自torch::jit::CustomClassHolder。 这确保了所有设置都可以处理前面提到的生命周期管理系统。 现在让我们看一下如何使该类对 TorchScript 可见，该过程称为绑定该类： // Notice a few things: // - We pass the class to be registered as a template parameter to // `torch::jit::class_`. In this instance, we've passed the // specialization of the Stack class ``Stack``. // In general, you cannot register a non-specialized template // class. For non-templated classes, you can just pass the // class name directly as the template parameter. // - The single parameter to ``torch::jit::class_()`` is a // string indicating the name of the class. This is the name // the class will appear as in both Python and TorchScript. // For example, our Stack class would appear as ``torch.classes.Stack``. static auto testStack = torch::jit::class_>(\"Stack\") // The following line registers the contructor of our Stack // class that takes a single `std::vector` argument, // i.e. it exposes the C++ method `Stack(std::vector init)`. // Currently, we do not support registering overloaded // constructors, so for now you can only `def()` one instance of // `torch::jit::init`. .def(torch::jit::init>()) // The next line registers a stateless (i.e. no captures) C++ lambda // function as a method. Note that a lambda function must take a // `c10::intrusive_ptr` (or some const/ref version of that) // as the first argument. Other arguments can be whatever you want. .def(\"top\", [](const c10::intrusive_ptr>& self) { return self->stack_.back(); }) // The following four lines expose methods of the Stack // class as-is. `torch::jit::class_` will automatically examine the // argument and return types of the passed-in method pointers and // expose these to Python and TorchScript accordingly. Finally, notice // that we must take the *address* of the fully-qualified method name, // i.e. use the unary `&` operator, due to C++ typing rules. .def(\"push\", &Stack::push) .def(\"pop\", &Stack::pop) .def(\"clone\", &Stack::clone) .def(\"merge\", &Stack::merge); 使用 CMake 将示例构建为 C ++项目 现在，我们将使用 CMake 构建系统来构建上述 C ++代码。 首先，将到目前为止介绍的所有 C ++代码放入class.cpp文件中。 然后，编写一个简单的CMakeLists.txt文件并将其放置在同一目录中。 CMakeLists.txt的外观如下： cmake_minimum_required(VERSION 3.1 FATAL_ERROR) project(custom_class) find_package(Torch REQUIRED) # Define our library target add_library(custom_class SHARED class.cpp) set(CMAKE_CXX_STANDARD 14) # Link against LibTorch target_link_libraries(custom_class \"${TORCH_LIBRARIES}\") 另外，创建一个build目录。 您的文件树应如下所示： custom_class_project/ class.cpp CMakeLists.txt build/ 现在，要构建项目，请继续从 PyTorch 网站下载适当的 libtorch 二进制文件。 将 zip 存档解压缩到某个位置(在项目目录中可能很方便），并记下将其解压缩到的路径。 接下来，继续调用 cmake，然后进行构建项目： $ cd build $ cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch .. -- The C compiler identification is GNU 7.3.1 -- The CXX compiler identification is GNU 7.3.1 -- Check for working C compiler: /opt/rh/devtoolset-7/root/usr/bin/cc -- Check for working C compiler: /opt/rh/devtoolset-7/root/usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Detecting C compile features -- Detecting C compile features - done -- Check for working CXX compiler: /opt/rh/devtoolset-7/root/usr/bin/c++ -- Check for working CXX compiler: /opt/rh/devtoolset-7/root/usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Looking for pthread.h -- Looking for pthread.h - found -- Looking for pthread_create -- Looking for pthread_create - not found -- Looking for pthread_create in pthreads -- Looking for pthread_create in pthreads - not found -- Looking for pthread_create in pthread -- Looking for pthread_create in pthread - found -- Found Threads: TRUE -- Found torch: /torchbind_tutorial/libtorch/lib/libtorch.so -- Configuring done -- Generating done -- Build files have been written to: /torchbind_tutorial/build $ make -j Scanning dependencies of target custom_class [ 50%] Building CXX object CMakeFiles/custom_class.dir/class.cpp.o [100%] Linking CXX shared library libcustom_class.so [100%] Built target custom_class 您会发现，构建目录中现在有一个动态库文件。 在 Linux 上，它可能名为libcustom_class.so。 因此，文件树应如下所示： custom_class_project/ class.cpp CMakeLists.txt build/ libcustom_class.so 从 Python 和 TorchScript 使用 C ++类 现在我们已经将我们的类及其注册编译为.so文件，我们可以将 .so 加载到 Python 中并进行尝试。 这是一个演示脚本的脚本： import torch # `torch.classes.load_library()` allows you to pass the path to your .so file # to load it in and make the custom C++ classes available to both Python and # TorchScript torch.classes.load_library(\"libcustom_class.so\") # You can query the loaded libraries like this: print(torch.classes.loaded_libraries) # prints {'/custom_class_project/build/libcustom_class.so'} # We can find and instantiate our custom C++ class in python by using the # `torch.classes` namespace: # # This instantiation will invoke the Stack(std::vector init) constructor # we registered earlier s = torch.classes.Stack([\"foo\", \"bar\"]) # We can call methods in Python s.push(\"pushed\") assert s.pop() == \"pushed\" # Returning and passing instances of custom classes works as you'd expect s2 = s.clone() s.merge(s2) for expected in [\"bar\", \"foo\", \"bar\", \"foo\"]: assert s.pop() == expected # We can also use the class in TorchScript # For now, we need to assign the class's type to a local in order to # annotate the type on the TorchScript function. This may change # in the future. Stack = torch.classes.Stack @torch.jit.script def do_stacks(s : Stack): # We can pass a custom class instance to TorchScript s2 = torch.classes.Stack([\"hi\", \"mom\"]) # We can instantiate the class s2.merge(s) # We can call a method on the class return s2.clone(), s2.top() # We can also return instances of the class # from TorchScript function/methods stack, top = do_stacks(torch.classes.Stack([\"wow\"])) assert top == \"wow\" for expected in [\"wow\", \"mom\", \"hi\"]: assert stack.pop() == expected 使用自定义类保存，加载和运行 TorchScript 代码 我们也可以在使用 libtorch 的 C ++进程中使用自定义注册的 C ++类。 举例来说，让我们定义一个简单的nn.Module，该实例在我们的 Stack 类上实例化并调用一个方法： import torch torch.classes.load_library('libcustom_class.so') class Foo(torch.nn.Module): def __init__(self): super().__init__() def forward(self, s : str) -> str: stack = torch.classes.Stack([\"hi\", \"mom\"]) return stack.pop() + s scripted_foo = torch.jit.script(Foo()) print(scripted_foo.graph) scripted_foo.save('foo.pt') 我们文件系统中的foo.pt现在包含我们刚刚定义的序列化 TorchScript 程序。 现在，我们将定义一个新的 CMake 项目，以展示如何加载此模型及其所需的.so 文件。 有关如何执行此操作的完整说明，请查看在 C ++教程中加载 TorchScript 模型。 与之前类似，让我们创建一个包含以下内容的文件结构： cpp_inference_example/ infer.cpp CMakeLists.txt foo.pt build/ custom_class_project/ class.cpp CMakeLists.txt build/ 请注意，我们已经复制了序列化的foo.pt文件以及上面custom_class_project的源代码树。 我们将添加custom_class_project作为对此 C ++项目的依赖项，以便我们可以将自定义类构建到二进制文件中。 让我们用以下内容填充infer.cpp： #include #include #include int main(int argc, const char* argv[]) { torch::jit::script::Module module; try { // Deserialize the ScriptModule from a file using torch::jit::load(). module = torch::jit::load(\"foo.pt\"); } catch (const c10::Error& e) { std::cerr inputs = {\"foobarbaz\"}; auto output = module.forward(inputs).toString(); std::cout string() 同样，让我们​​定义我们的 CMakeLists.txt 文件： cmake_minimum_required(VERSION 3.1 FATAL_ERROR) project(infer) find_package(Torch REQUIRED) add_subdirectory(custom_class_project) # Define our library target add_executable(infer infer.cpp) set(CMAKE_CXX_STANDARD 14) # Link against LibTorch target_link_libraries(infer \"${TORCH_LIBRARIES}\") # This is where we link in our libcustom_class code, making our # custom class available in our binary. target_link_libraries(infer -Wl,--no-as-needed custom_class) 您知道练习：cd build，cmake和make： $ cd build $ cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch .. -- The C compiler identification is GNU 7.3.1 -- The CXX compiler identification is GNU 7.3.1 -- Check for working C compiler: /opt/rh/devtoolset-7/root/usr/bin/cc -- Check for working C compiler: /opt/rh/devtoolset-7/root/usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Detecting C compile features -- Detecting C compile features - done -- Check for working CXX compiler: /opt/rh/devtoolset-7/root/usr/bin/c++ -- Check for working CXX compiler: /opt/rh/devtoolset-7/root/usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Looking for pthread.h -- Looking for pthread.h - found -- Looking for pthread_create -- Looking for pthread_create - not found -- Looking for pthread_create in pthreads -- Looking for pthread_create in pthreads - not found -- Looking for pthread_create in pthread -- Looking for pthread_create in pthread - found -- Found Threads: TRUE -- Found torch: /local/miniconda3/lib/python3.7/site-packages/torch/lib/libtorch.so -- Configuring done -- Generating done -- Build files have been written to: /cpp_inference_example/build $ make -j Scanning dependencies of target custom_class [ 25%] Building CXX object custom_class_project/CMakeFiles/custom_class.dir/class.cpp.o [ 50%] Linking CXX shared library libcustom_class.so [ 50%] Built target custom_class Scanning dependencies of target infer [ 75%] Building CXX object CMakeFiles/infer.dir/infer.cpp.o [100%] Linking CXX executable infer [100%] Built target infer 现在我们可以运行令人兴奋的 C ++二进制文件： $ ./infer momfoobarbaz 难以置信！ 定义自定义 C ++类的序列化/反序列化方法 如果您尝试将具有自定义绑定 C ++类的ScriptModule保存为属性，则会出现以下错误： # export_attr.py import torch torch.classes.load_library('libcustom_class.so') class Foo(torch.nn.Module): def __init__(self): super().__init__() self.stack = torch.classes.Stack([\"just\", \"testing\"]) def forward(self, s : str) -> str: return self.stack.pop() + s scripted_foo = torch.jit.script(Foo()) scripted_foo.save('foo.pt') $ python export_attr.py RuntimeError: Cannot serialize custom bound C++ class __torch__.torch.classes.Stack. Please define serialization methods via torch::jit::pickle_ for this class. (pushIValueImpl at ../torch/csrc/jit/pickler.cpp:128) 这是因为 TorchScript 无法自动找出 C ++类中保存的信息。 您必须手动指定。 这样做的方法是使用class_上的特殊def_pickle方法在类上定义__getstate__和__setstate__方法。 注意 TorchScript 中__getstate__和__setstate__的语义与 Python pickle 模块的语义相同。 您可以阅读更多有关如何使用这些方法的信息。 这是一个如何更新Stack类的注册码以包含序列化方法的示例： static auto testStack = torch::jit::class_>(\"Stack\") .def(torch::jit::init>()) .def(\"top\", [](const c10::intrusive_ptr>& self) { return self->stack_.back(); }) .def(\"push\", &Stack::push) .def(\"pop\", &Stack::pop) .def(\"clone\", &Stack::clone) .def(\"merge\", &Stack::merge) // class_<>::def_pickle allows you to define the serialization // and deserialization methods for your C++ class. // Currently, we only support passing stateless lambda functions // as arguments to def_pickle .def_pickle( // __getstate__ // This function defines what data structure should be produced // when we serialize an instance of this class. The function // must take a single `self` argument, which is an intrusive_ptr // to the instance of the object. The function can return // any type that is supported as a return value of the TorchScript // custom operator API. In this instance, we've chosen to return // a std::vector as the salient data to preserve // from the class. [](const c10::intrusive_ptr>& self) -> std::vector { return self->stack_; }, // __setstate__ // This function defines how to create a new instance of the C++ // class when we are deserializing. The function must take a // single argument of the same type as the return value of // `__getstate__`. The function must return an intrusive_ptr // to a new instance of the C++ class, initialized however // you would like given the serialized state. [](std::vector state) -> c10::intrusive_ptr> { // A convenient way to instantiate an object and get an // intrusive_ptr to it is via `make_intrusive`. We use // that here to allocate an instance of Stack // and call the single-argument std::vector // constructor with the serialized state. return c10::make_intrusive>(std::move(state)); }); Note 我们采用与 pickle API 中的 pybind11 不同的方法。 pybind11 作为传递给class_::def()的特殊功能pybind11::pickle()，为此我们有一个单独的方法def_pickle。 这是因为名称torch::jit::pickle已经被使用，我们不想引起混淆。 以这种方式定义(反）序列化行为后，脚本现在可以成功运行： import torch torch.classes.load_library('libcustom_class.so') class Foo(torch.nn.Module): def __init__(self): super().__init__() self.stack = torch.classes.Stack([\"just\", \"testing\"]) def forward(self, s : str) -> str: return self.stack.pop() + s scripted_foo = torch.jit.script(Foo()) scripted_foo.save('foo.pt') loaded = torch.jit.load('foo.pt') print(loaded.stack.pop()) $ python ../export_attr.py testing 结论 本教程向您介绍了如何向 TorchScript(以及扩展为 Python）公开 C ++类，如何注册其方法，如何从 Python 和 TorchScript 使用该类以及如何使用该类保存和加载代码以及运行该代码。 在独立的 C ++过程中。 现在，您可以使用与第三方 C ++库接口的 C ++类扩展 TorchScript 模型，或实现需要 Python，TorchScript 和 C ++之间的界线才能平滑融合的任何其他用例。 与往常一样，如果您遇到任何问题或疑问，可以使用我们的论坛或 GitHub 问题进行联系。 另外，我们的常见问题解答(FAQ）页面可能包含有用的信息。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"41.html":{"url":"41.html","title":"使用 numpy 和 scipy 创建扩展","keywords":"","body":"使用 numpy 和 scipy 创建扩展 原文： https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html 注意 单击此处的下载完整的示例代码 作者： Adam Paszke 已由更新： Adam Dziedzic 在本教程中，我们将完成两个任务： 创建没有参数的神经网络层。 > 调用 *numpy 作为其实现的一部分 创建具有可学习权重的神经网络层 > 作为其实现的一部分，它引发 *SciPy import torch from torch.autograd import Function 无参数的例子 该层并没有做任何有用的或数学上正确的事情。 它被恰当地命名为 BadFFTFunction 层实现 from numpy.fft import rfft2, irfft2 class BadFFTFunction(Function): @staticmethod def forward(ctx, input): numpy_input = input.detach().numpy() result = abs(rfft2(numpy_input)) return input.new(result) @staticmethod def backward(ctx, grad_output): numpy_go = grad_output.numpy() result = irfft2(numpy_go) return grad_output.new(result) # since this layer does not have any parameters, we can # simply declare this as a function, rather than as an nn.Module class def incorrect_fft(input): return BadFFTFunction.apply(input) 创建的图层的用法示例： input = torch.randn(8, 8, requires_grad=True) result = incorrect_fft(input) print(result) result.backward(torch.randn(result.size())) print(input) 出： tensor([[ 3.4193, 6.2492, 1.4814, 3.9813, 14.7739], [ 5.8865, 2.3533, 1.4765, 4.1547, 5.1887], [ 6.9061, 4.7597, 5.9473, 11.8609, 10.0465], [10.6724, 6.5964, 11.6951, 3.7400, 9.3114], [ 4.9715, 5.7563, 10.5443, 4.6442, 2.3052], [10.6724, 12.7221, 1.7242, 7.2647, 9.3114], [ 6.9061, 8.1754, 4.0003, 3.1523, 10.0465], [ 5.8865, 15.8094, 6.9266, 3.8533, 5.1887]], grad_fn=) tensor([[ 0.4963, 0.5220, -0.0559, 0.2241, 2.1238, 0.0324, -0.1219, 0.7318], [ 1.0476, -0.1841, -0.2717, 0.5470, -1.3174, -0.6817, 1.0102, -0.2014], [-1.1131, 1.0054, 0.3593, 0.6158, 0.5398, 2.3020, -0.1305, -0.8611], [-0.4693, -1.3720, -0.8196, -1.4975, -0.4474, -0.1150, -0.3285, 1.8079], [-0.2928, 1.4333, -0.2744, -0.9194, -0.2592, 0.4996, 0.7862, 0.3972], [ 0.7595, 0.5625, -0.7585, -0.1439, -0.5243, -1.0789, 0.4915, 1.5880], [-0.6971, 0.0267, 0.2316, -0.8939, -1.9865, -0.7424, -0.6252, 0.8415], [-0.9989, 1.0916, 0.2223, 2.1130, -0.3831, 0.9612, -1.8703, 0.4848]], requires_grad=True) 参数化示例 在深度学习文献中，该层被混淆地称为卷积，而实际操作是互相关的(唯一的区别是滤波器被卷积以进行卷积，而互相关不是这种情况）。 具有可学习的权重的层的实现，其中互相关具有表示权重的过滤器(内核）。 反向通过计算输入的梯度和过滤器的梯度。 from numpy import flip import numpy as np from scipy.signal import convolve2d, correlate2d from torch.nn.modules.module import Module from torch.nn.parameter import Parameter class ScipyConv2dFunction(Function): @staticmethod def forward(ctx, input, filter, bias): # detach so we can cast to NumPy input, filter, bias = input.detach(), filter.detach(), bias.detach() result = correlate2d(input.numpy(), filter.numpy(), mode='valid') result += bias.numpy() ctx.save_for_backward(input, filter, bias) return torch.as_tensor(result, dtype=input.dtype) @staticmethod def backward(ctx, grad_output): grad_output = grad_output.detach() input, filter, bias = ctx.saved_tensors grad_output = grad_output.numpy() grad_bias = np.sum(grad_output, keepdims=True) grad_input = convolve2d(grad_output, filter.numpy(), mode='full') # the previous line can be expressed equivalently as: # grad_input = correlate2d(grad_output, flip(flip(filter.numpy(), axis=0), axis=1), mode='full') grad_filter = correlate2d(input.numpy(), grad_output, mode='valid') return torch.from_numpy(grad_input), torch.from_numpy(grad_filter).to(torch.float), torch.from_numpy(grad_bias).to(torch.float) class ScipyConv2d(Module): def __init__(self, filter_width, filter_height): super(ScipyConv2d, self).__init__() self.filter = Parameter(torch.randn(filter_width, filter_height)) self.bias = Parameter(torch.randn(1, 1)) def forward(self, input): return ScipyConv2dFunction.apply(input, self.filter, self.bias) 用法示例： module = ScipyConv2d(3, 3) print(\"Filter and bias: \", list(module.parameters())) input = torch.randn(10, 10, requires_grad=True) output = module(input) print(\"Output from the convolution: \", output) output.backward(torch.randn(8, 8)) print(\"Gradient for the input map: \", input.grad) Out: Filter and bias: [Parameter containing: tensor([[-0.4935, -1.9784, -0.7520], [ 0.0575, -1.3029, -1.9318], [ 1.1692, 0.3187, -0.3044]], requires_grad=True), Parameter containing: tensor([[-0.9122]], requires_grad=True)] Output from the convolution: tensor([[ 1.9228e+00, 5.1708e+00, -1.7722e-01, 6.0846e-01, 3.1403e+00, 2.8270e+00, -2.7449e+00, -7.5212e+00], [ 9.2997e-01, 1.4772e-01, -1.7859e+00, -4.8096e+00, -3.2894e+00, 2.9466e+00, 2.2201e+00, -1.7857e+00], [-3.4693e+00, 1.0293e-01, -1.6728e+00, -6.0165e+00, -6.5472e+00, -8.0421e-01, -2.2059e+00, -7.3037e+00], [-7.1793e+00, 2.5055e-01, 1.0368e+00, -1.6319e+00, -8.3195e+00, -4.6471e+00, -1.6651e+00, -3.5958e+00], [-1.3189e+00, 1.9218e+00, 4.4448e+00, 2.2613e+00, -4.9712e+00, -7.1531e+00, -7.3305e-01, -1.7002e+00], [ 8.7136e-01, 6.6128e-01, 2.9627e+00, 1.1253e+00, -4.1352e+00, -2.5405e+00, 2.5132e+00, 5.8881e+00], [ 1.4052e+00, -2.3034e+00, -8.8434e-01, -5.1262e-02, -1.0159e+01, -5.9782e+00, -2.7782e-01, 1.6121e+00], [ 2.0402e+00, 1.7031e-03, 1.5932e+00, 4.6277e+00, -8.4549e+00, -1.4017e+01, -6.9038e+00, -2.8451e+00]], grad_fn=) Gradient for the input map: tensor([[ 3.5673e-01, 1.5783e+00, 5.5266e-01, -2.2223e+00, -1.1648e+00, 1.3576e-01, -9.2908e-01, -9.5302e-01, -1.0746e-01, 4.7559e-02], [-8.7051e-01, -2.4345e+00, 2.0736e-01, -1.8105e+00, -2.6859e+00, -1.2512e+00, -3.8021e-01, -6.9782e-01, 2.8626e+00, 1.4599e+00], [-1.1194e+00, -4.4828e+00, -2.9077e+00, 1.2989e+00, 7.7022e-01, 1.9482e+00, 8.1654e-01, 4.3522e+00, 4.5537e+00, 3.8784e+00], [ 2.0067e+00, 3.9783e-01, 5.8589e-01, -1.2962e+00, -1.7774e+00, 2.7983e-01, 2.0063e+00, -5.3575e-01, 1.9437e+00, 9.2401e-01], [ 9.6117e-01, 1.1666e+00, 2.1162e+00, 2.9779e+00, -4.0048e+00, -2.1271e-01, 3.6012e-01, -1.5548e-03, -2.2730e+00, -1.9148e+00], [-5.5450e-01, -3.5749e+00, 2.1108e-01, 2.7341e+00, -5.4415e-01, -1.0326e-01, 5.2842e+00, 6.0280e+00, 1.7129e+00, -1.0743e+00], [-4.5225e-01, -3.2305e+00, -3.9962e+00, -1.4418e+00, -6.6439e+00, -6.6198e+00, -4.7138e+00, 2.4043e-01, 3.5485e+00, -2.6767e-01], [ 1.2502e+00, 1.5484e-01, 4.7037e+00, 4.7502e+00, -2.7102e-01, -5.2364e+00, -7.6462e+00, -1.5124e+00, 3.1666e+00, 1.0458e+00], [ 7.6941e-01, 1.0242e-01, 3.4887e+00, 6.9709e+00, 4.7607e+00, 1.1723e+00, -2.5379e+00, 1.0167e+00, 3.5257e+00, 2.5870e+00], [ 1.8773e-01, -2.9968e+00, -2.2132e+00, -2.2993e-01, 2.0811e+00, 5.9679e-01, -1.6988e+00, -1.8538e+00, -1.1920e-01, 4.0583e-01]]) 检查渐变： from torch.autograd.gradcheck import gradcheck moduleConv = ScipyConv2d(3, 3) input = [torch.randn(20, 20, dtype=torch.double, requires_grad=True)] test = gradcheck(moduleConv, input, eps=1e-6, atol=1e-4) print(\"Are the gradients correct: \", test) Out: Are the gradients correct: True 脚本的总运行时间：(0 分钟 4.206 秒） Download Python source code: numpy_extensions_tutorial.py Download Jupyter notebook: numpy_extensions_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"42.html":{"url":"42.html","title":"自定义 C ++和 CUDA 扩展","keywords":"","body":"自定义 C ++和 CUDA 扩展 原文： https://pytorch.org/tutorials/advanced/cpp_extension.html 作者： Peter Goldsborough PyTorch 提供了与神经网络，任意张量代数，数据整理和其他目的有关的大量操作。 但是，您仍然可能会发现自己需要更多的自定义操作。 例如，您可能想使用论文中发现的新颖的激活功能，或者实现您在研究过程中开发的操作。 在 PyTorch 中集成这样的自定义操作的最简单方法是通过扩展此处概述的Function和Module在 Python 中编写它。 这为您提供了自动区分的全部功能(使您不必编写派生函数）以及 Python 的通常表达能力。 但是，有时您的操作可以用 C ++更好地实现。 例如，您的代码可能需要确实快速，因为在模型中它经常被调用，或者即使很少调用也很昂贵。 另一个合理的原因是它依赖于其他 C 或 C ++库或与之交互。 为了解决这种情况，PyTorch 提供了一种非常简单的方式来编写自定义 C ++扩展。 C ++扩展是我们开发的一种机制，允许用户(您）创建源外定义的 PyTorch 运算符，即，即与 PyTorch 后端分开。 该方法与与不同于本机 PyTorch 操作的实现方式。 C ++扩展旨在为您节省大量与将操作与 PyTorch 后端集成在一起相关的样板，同时为基于 PyTorch 的项目提供高度的灵活性。 但是，一旦您将操作定义为 C ++扩展，将其转换为本地 PyTorch 函数在很大程度上取决于代码组织，如果您决定在上游进行操作，则可以解决此问题。 动机与榜样 本说明的其余部分将逐步介绍编写和使用 C ++(和 CUDA）扩展的实际示例。 如果您被追捕，或者在一天结束前仍未完成该操作，就会有人开除您，则可以跳过本节，直接进入下一部分的实施细节。 假设您想出了一种新型的循环装置，发现与现有技术相比，它具有更好的性能。 该循环单元类似于 LSTM，但不同之处在于它缺少遗忘门，并使用指数线性单元(ELU）作为其内部激活功能。 由于此设备永远不会忘记，因此我们将其称为 LLTM 或长期内存单元。 LLTM 与普通 LSTM 的两种区别非常重要，以至于我们无法为自己的目的配置 PyTorch 的LSTMCell，因此我们必须创建一个自定义单元。 这样做的第一个也是最简单的方法，并且在所有情况下都可能是一个好的第一步，是使用 Python 在纯 PyTorch 中实现我们所需的功能。 为此，我们需要继承torch.nn.Module，并实现 LLTM 的前向传递。 看起来像这样： class LLTM(torch.nn.Module): def __init__(self, input_features, state_size): super(LLTM, self).__init__() self.input_features = input_features self.state_size = state_size # 3 * state_size for input gate, output gate and candidate cell gate. # input_features + state_size because we will multiply with [input, h]. self.weights = torch.nn.Parameter( torch.empty(3 * state_size, input_features + state_size)) self.bias = torch.nn.Parameter(torch.empty(3 * state_size)) self.reset_parameters() def reset_parameters(self): stdv = 1.0 / math.sqrt(self.state_size) for weight in self.parameters(): weight.data.uniform_(-stdv, +stdv) def forward(self, input, state): old_h, old_cell = state X = torch.cat([old_h, input], dim=1) # Compute the input, output and candidate cell gates with one MM. gate_weights = F.linear(X, self.weights, self.bias) # Split the combined gate weight matrix into its components. gates = gate_weights.chunk(3, dim=1) input_gate = torch.sigmoid(gates[0]) output_gate = torch.sigmoid(gates[1]) # Here we use an ELU instead of the usual tanh. candidate_cell = F.elu(gates[2]) # Compute the new cell state. new_cell = old_cell + candidate_cell * input_gate # Compute the new hidden state and output. new_h = torch.tanh(new_cell) * output_gate return new_h, new_cell 然后我们可以按预期使用： import torch X = torch.randn(batch_size, input_features) h = torch.randn(batch_size, state_size) C = torch.randn(batch_size, state_size) rnn = LLTM(input_features, state_size) new_h, new_C = rnn(X, (h, C)) 自然，如果可能的话，您应该使用这种方法扩展 PyTorch。 由于 PyTorch 对 CPU 和 GPU 的操作进行了高度优化的实现，并由 NVIDIA cuDNN ， Intel MKL 或 NNPACK 等库提供支持 ，上面的 PyTorch 代码通常会足够快。 但是，我们还可以看到为什么在某些情况下还有进一步改进性能的空间。 最明显的原因是 PyTorch 不了解您要实现的算法。 它仅知道您用于组成算法的单个操作。 因此，PyTorch 必须一个接一个地执行您的操作。 由于对操作的实现(或内核）的每个单独调用(可能涉及 CUDA 内核的启动）都具有一定的开销，因此该开销在许多函数调用中可能变得很重要。 此外，运行我们的代码的 Python 解释器本身可能会使我们的程序变慢。 因此，一种确定的加速方法是用 C ++(或 CUDA）和熔断特定操作组来重写零件。 融合意味着将许多功能的实现组合到一个功能中，这可以从更少的内核启动以及我们可以通过提高全局数据流可见性而执行的其他优化中获利。 让我们看看如何使用 C ++扩展来实现 LLTM 的融合版本。 首先，我们使用 ATen 库以普通的 C ++语言编写代码，该库为 PyTorch 的许多后端提供了强大的支持，并了解它使我们轻松转换 Python 代码的方式。 然后，我们将模型的某些部分移至 CUDA 内核，以从 GPU 提供的大量并行处理中受益，从而进一步加快处理速度。 编写 C ++扩展 C ++扩展有两种形式：它们可以使用setuptools提前构建，也可以通过torch.utils.cpp_extension.load()适时构建。 我们将从第一种方法开始，稍后再讨论后者。 使用setuptools构建 为了“提前”，我们通过编写一个setup.py脚本来构建 C ++扩展，该脚本使用 setuptools 编译我们的 C ++代码。 对于 LLTM，它看起来像这样简单： from setuptools import setup, Extension from torch.utils import cpp_extension setup(name='lltm_cpp', ext_modules=[cpp_extension.CppExtension('lltm_cpp', ['lltm.cpp'])], cmdclass={'build_ext': cpp_extension.BuildExtension}) 在此代码中，CppExtension是setuptools.Extension的便利包装，它传递正确的包含路径并将扩展语言设置为 C ++。 等效的原始setuptools代码将是： Extension( name='lltm_cpp', sources=['lltm.cpp'], include_dirs=cpp_extension.include_paths(), language='c++') BuildExtension执行许多必需的配置步骤，并检查和管理混合 C ++ / CUDA 扩展的混合编译。 这就是我们现在真正需要了解的有关构建 C ++扩展的全部信息！ 现在让我们看一下lltm.cpp中 C ++扩展的实现。 编写 C ++ Op 让我们开始以 C ++实现 LLTM！ 我们需要向后传递的一项功能是 S 形导数。 这是一小段代码，用于讨论编写 C ++扩展时可供我们使用的总体环境： #include #include torch::Tensor d_sigmoid(torch::Tensor z) { auto s = torch::sigmoid(z); return (1 - s) * s; } &lt;torch/extension.h&gt;是一站式标头，其中包含编写 C ++扩展所需的所有必需的 PyTorch 位。 这包括： ATen 库，这是我们用于张量计算的主要 API， pybind11 ，这是我们为 C ++代码创建 Python 绑定的方式， 标头，用于管理 ATen 与 pybind11 之间的交互的详细信息。 d_sigmoid()的实现显示了如何使用 ATen API。 PyTorch 的张量和变量接口是从 ATen 库自动生成的，因此我们可以将 Python 实现 1：1 或多或少地转换为 C ++。 我们用于所有计算的主要数据类型将为torch::Tensor。 可以在中检查其完整的 API。 还要注意，我们可以包括&lt;iostream&gt;或任何其他 C 或 C ++头文件 –我们拥有 C ++ 11 的全部功能。 前进通行证 接下来，我们可以将整个正向传递到 C ++： #include std::vector lltm_forward( torch::Tensor input, torch::Tensor weights, torch::Tensor bias, torch::Tensor old_h, torch::Tensor old_cell) { auto X = torch::cat({old_h, input}, /*dim=*/1); auto gate_weights = torch::addmm(bias, X, weights.transpose(0, 1)); auto gates = gate_weights.chunk(3, /*dim=*/1); auto input_gate = torch::sigmoid(gates[0]); auto output_gate = torch::sigmoid(gates[1]); auto candidate_cell = torch::elu(gates[2], /*alpha=*/1.0); auto new_cell = old_cell + candidate_cell * input_gate; auto new_h = torch::tanh(new_cell) * output_gate; return {new_h, new_cell, input_gate, output_gate, candidate_cell, X, gate_weights}; } 后退通行证 C ++扩展 API 当前不提供为我们自动生成向后函数的方法。 因此，我们还必须实现 LLTM 的后向传递，它计算相对于前向传递的每个输入的损耗导数。 最终，我们将前进和后退功能放入torch.autograd.Function中，以创建一个不错的 Python 绑定。 向后函数的功能稍微复杂一些，因此我们将不深入研究代码(如果您有兴趣，请阅读 Alex Graves 的论文，以获取有关此方面的更多信息）： // tanh'(z) = 1 - tanh^2(z) torch::Tensor d_tanh(torch::Tensor z) { return 1 - z.tanh().pow(2); } // elu'(z) = relu'(z) + { alpha * exp(z) if (alpha * (exp(z) - 1)) 0).type_as(z) + mask.type_as(z) * (alpha * e); } std::vector lltm_backward( torch::Tensor grad_h, torch::Tensor grad_cell, torch::Tensor new_cell, torch::Tensor input_gate, torch::Tensor output_gate, torch::Tensor candidate_cell, torch::Tensor X, torch::Tensor gate_weights, torch::Tensor weights) { auto d_output_gate = torch::tanh(new_cell) * grad_h; auto d_tanh_new_cell = output_gate * grad_h; auto d_new_cell = d_tanh(new_cell) * d_tanh_new_cell + grad_cell; auto d_old_cell = d_new_cell; auto d_candidate_cell = input_gate * d_new_cell; auto d_input_gate = candidate_cell * d_new_cell; auto gates = gate_weights.chunk(3, /*dim=*/1); d_input_gate *= d_sigmoid(gates[0]); d_output_gate *= d_sigmoid(gates[1]); d_candidate_cell *= d_elu(gates[2]); auto d_gates = torch::cat({d_input_gate, d_output_gate, d_candidate_cell}, /*dim=*/1); auto d_weights = d_gates.t().mm(X); auto d_bias = d_gates.sum(/*dim=*/0, /*keepdim=*/true); auto d_X = d_gates.mm(weights); const auto state_size = grad_h.size(1); auto d_old_h = d_X.slice(/*dim=*/1, 0, state_size); auto d_input = d_X.slice(/*dim=*/1, state_size); return {d_old_h, d_input, d_weights, d_bias, d_old_cell}; } 绑定到 Python 一旦用 C ++和 ATen 编写了操作，就可以使用 pybind11 以非常简单的方式将 C ++函数或类绑定到 Python 中。 您对 PyTorch C ++扩展部分的疑问或问题将在 pybind11 文档中得到解决。 对于我们的扩展，必要的绑定代码仅跨越四行： PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) { m.def(\"forward\", &lltm_forward, \"LLTM forward\"); m.def(\"backward\", &lltm_backward, \"LLTM backward\"); } 这里要注意的一点是宏TORCH_EXTENSION_NAME。 torch扩展程序构建会将其定义为您在setup.py脚本中为扩展程序指定的名称。 在这种情况下，TORCH_EXTENSION_NAME的值为“ lltm”。 这是为了避免必须在两个位置(构建脚本和 C ++代码）维护扩展名，因为两者之间的不匹配会导致令人讨厌且难以跟踪的问题。 使用扩展 现在，我们准备将扩展名导入 PyTorch 中。 此时，目录结构可能如下所示： pytorch/ lltm-extension/ lltm.cpp setup.py 现在，运行python setup.py install来构建和安装扩展程序。 看起来应该像这样： running install running bdist_egg running egg_info creating lltm_cpp.egg-info writing lltm_cpp.egg-info/PKG-INFO writing dependency_links to lltm_cpp.egg-info/dependency_links.txt writing top-level names to lltm_cpp.egg-info/top_level.txt writing manifest file 'lltm_cpp.egg-info/SOURCES.txt' reading manifest file 'lltm_cpp.egg-info/SOURCES.txt' writing manifest file 'lltm_cpp.egg-info/SOURCES.txt' installing library code to build/bdist.linux-x86_64/egg running install_lib running build_ext building 'lltm_cpp' extension creating build creating build/temp.linux-x86_64-3.7 gcc -pthread -B ~/local/miniconda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I~/local/miniconda/lib/python3.7/site-packages/torch/include -I~/local/miniconda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I~/local/miniconda/lib/python3.7/site-packages/torch/include/TH -I~/local/miniconda/lib/python3.7/site-packages/torch/include/THC -I~/local/miniconda/include/python3.7m -c lltm.cpp -o build/temp.linux-x86_64-3.7/lltm.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=lltm_cpp -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++11 cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++ creating build/lib.linux-x86_64-3.7 g++ -pthread -shared -B ~/local/miniconda/compiler_compat -L~/local/miniconda/lib -Wl,-rpath=~/local/miniconda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/lltm.o -o build/lib.linux-x86_64-3.7/lltm_cpp.cpython-37m-x86_64-linux-gnu.so creating build/bdist.linux-x86_64 creating build/bdist.linux-x86_64/egg copying build/lib.linux-x86_64-3.7/lltm_cpp.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg creating stub loader for lltm_cpp.cpython-37m-x86_64-linux-gnu.so byte-compiling build/bdist.linux-x86_64/egg/lltm_cpp.py to lltm_cpp.cpython-37.pyc creating build/bdist.linux-x86_64/egg/EGG-INFO copying lltm_cpp.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO copying lltm_cpp.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO copying lltm_cpp.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO copying lltm_cpp.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt zip_safe flag not set; analyzing archive contents... __pycache__.lltm_cpp.cpython-37: module references __file__ creating 'dist/lltm_cpp-0.0.0-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it removing 'build/bdist.linux-x86_64/egg' (and everything under it) Processing lltm_cpp-0.0.0-py3.7-linux-x86_64.egg removing '~/local/miniconda/lib/python3.7/site-packages/lltm_cpp-0.0.0-py3.7-linux-x86_64.egg' (and everything under it) creating ~/local/miniconda/lib/python3.7/site-packages/lltm_cpp-0.0.0-py3.7-linux-x86_64.egg Extracting lltm_cpp-0.0.0-py3.7-linux-x86_64.egg to ~/local/miniconda/lib/python3.7/site-packages lltm-cpp 0.0.0 is already the active version in easy-install.pth Installed ~/local/miniconda/lib/python3.7/site-packages/lltm_cpp-0.0.0-py3.7-linux-x86_64.egg Processing dependencies for lltm-cpp==0.0.0 Finished processing dependencies for lltm-cpp==0.0.0 关于编译器的小注释：由于 ABI 版本问题，用于构建 C ++扩展的编译器必须为，并且 PyTorch 编译器是与 ABI 兼容的。 实际上，这意味着您必须在 Linux 上使用 GCC 4.9 及更高版本。 对于 Ubuntu 16.04 和其他较新的 Linux 发行版，这应该已经是默认编译器。 在 MacOS 上，您必须使用 clang(它没有任何 ABI 版本控制问题）。 在最坏的情况下，您可以使用编译器从源代码构建 PyTorch，然后使用相同的编译器构建扩展。 扩展程序构建完成后，您可以使用在setup.py脚本中指定的名称，简单地将其导入 Python。 只需确保先import torch，因为这将解决动态链接器必须看到的一些符号： In [1]: import torch In [2]: import lltm_cpp In [3]: lltm_cpp.forward Out[3]: 如果在函数或模块上调用help()，则可以看到其签名与我们的 C ++代码匹配： In[4] help(lltm_cpp.forward) forward(...) method of builtins.PyCapsule instance forward(arg0: torch::Tensor, arg1: torch::Tensor, arg2: torch::Tensor, arg3: torch::Tensor, arg4: torch::Tensor) -> List[torch::Tensor] LLTM forward 由于我们现在可以从 Python 调用 C ++函数，因此可以将它们包装为torch.autograd.Function和torch.nn.Module以使其成为 PyTorch 的一等公民： import math import torch # Our module! import lltm_cpp class LLTMFunction(torch.autograd.Function): @staticmethod def forward(ctx, input, weights, bias, old_h, old_cell): outputs = lltm_cpp.forward(input, weights, bias, old_h, old_cell) new_h, new_cell = outputs[:2] variables = outputs[1:] + [weights] ctx.save_for_backward(*variables) return new_h, new_cell @staticmethod def backward(ctx, grad_h, grad_cell): outputs = lltm_cpp.backward( grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_variables) d_old_h, d_input, d_weights, d_bias, d_old_cell = outputs return d_input, d_weights, d_bias, d_old_h, d_old_cell class LLTM(torch.nn.Module): def __init__(self, input_features, state_size): super(LLTM, self).__init__() self.input_features = input_features self.state_size = state_size self.weights = torch.nn.Parameter( torch.empty(3 * state_size, input_features + state_size)) self.bias = torch.nn.Parameter(torch.empty(3 * state_size)) self.reset_parameters() def reset_parameters(self): stdv = 1.0 / math.sqrt(self.state_size) for weight in self.parameters(): weight.data.uniform_(-stdv, +stdv) def forward(self, input, state): return LLTMFunction.apply(input, self.weights, self.bias, *state) 性能比较 既然我们已经能够使用和调用 PyTorch 的 C ++代码，我们就可以运行一个小型基准测试，以查看通过用 C ++重写 op 获得的性能。 我们将向前和向后运行 LLTM 几次，并测量持续时间： import time import torch batch_size = 16 input_features = 32 state_size = 128 X = torch.randn(batch_size, input_features) h = torch.randn(batch_size, state_size) C = torch.randn(batch_size, state_size) rnn = LLTM(input_features, state_size) forward = 0 backward = 0 for _ in range(100000): start = time.time() new_h, new_C = rnn(X, (h, C)) forward += time.time() - start start = time.time() (new_h.sum() + new_C.sum()).backward() backward += time.time() - start print('Forward: {:.3f} us | Backward {:.3f} us'.format(forward * 1e6/1e5, backward * 1e6/1e5)) 如果我们使用本文开头用纯 Python 编写的原始 LLTM 来运行此代码，则会得到以下数字(在我的机器上）： Forward: 506.480 us | Backward 444.694 us 以及我们的新 C ++版本： Forward: 349.335 us | Backward 443.523 us 我们已经可以看到前进功能的显着提速(超过 30％）。 对于后退功能，可以看到加速，尽管不是主要的。 我在上面编写的后向通行证没有特别优化，并且肯定可以改进。 而且，PyTorch 的自动微分引擎可以自动并行化计算图，可以整体上使用更高效的操作流程，并且也可以用 C ++实现，因此有望实现更快的速度。 尽管如此，这是一个良好的开始。 GPU 设备上的性能 关于 PyTorch 的 ATen 后端的一个奇妙事实是，它抽象了您正在运行的计算设备。 这意味着我们为 CPU 编写的相同代码可以也可以在 GPU 上运行，并且各个操作将相应地分派到 GPU 优化的实现。 对于某些运算，例如矩阵乘法(例如mm或addmm），这是一个很大的胜利。 让我们看一下使用 CUDA 张量运行 C ++代码所获得的性能。 无需更改实现，只需将张量从 Python 放到 GPU 内存中，在创建时添加device=cuda_device参数，或者在创建后使用.to(cuda_device)： import torch assert torch.cuda.is_available() cuda_device = torch.device(\"cuda\") # device object representing GPU batch_size = 16 input_features = 32 state_size = 128 # Note the device=cuda_device arguments here X = torch.randn(batch_size, input_features, device=cuda_device) h = torch.randn(batch_size, state_size, device=cuda_device) C = torch.randn(batch_size, state_size, device=cuda_device) rnn = LLTM(input_features, state_size).to(cuda_device) forward = 0 backward = 0 for _ in range(100000): start = time.time() new_h, new_C = rnn(X, (h, C)) torch.cuda.synchronize() forward += time.time() - start start = time.time() (new_h.sum() + new_C.sum()).backward() torch.cuda.synchronize() backward += time.time() - start print('Forward: {:.3f} us | Backward {:.3f} us'.format(forward * 1e6/1e5, backward * 1e6/1e5)) 再次将普通的 PyTorch 代码与 C ++版本(现在都在 CUDA 设备上运行）进行比较，我们再次看到了性能提升。 对于 Python / PyTorch： Forward: 187.719 us | Backward 410.815 us 和 C ++ / ATen： Forward: 149.802 us | Backward 393.458 us 与非 CUDA 代码相比，这可以大大提高整体速度。 但是，通过编写自定义 CUDA 内核，我们可以从 C ++代码中获得更多性能，我们将很快深入其中。 在此之前，让我们讨论构建 C ++扩展的另一种方法。 JIT 编译扩展 之前，我提到过有两种构建 C ++扩展的方法：使用setuptools或即时(JIT）。 在介绍了前者之后，让我们详细介绍后者。 JIT 编译机制通过调用 PyTorch API 中称为torch.utils.cpp_extension.load()的简单函数，为您动态编译和加载扩展程序。 对于 LLTM，这看起来像这样简单： from torch.utils.cpp_extension import load lltm_cpp = load(name=\"lltm_cpp\", sources=[\"lltm.cpp\"]) 在此，我们为函数提供与setuptools相同的信息。 在后台，这将执行以下操作： 创建一个临时目录/tmp/torch_extensions/lltm， 将 Ninja 构建文件发送到该临时目录中， 将您的源文件编译到共享库中， 将此共享库导入为 Python 模块。 实际上，如果将verbose=True传递给cpp_extension.load()，则会通知您有关过程： Using /tmp/torch_extensions as PyTorch extensions root... Emitting ninja build file /tmp/torch_extensions/lltm_cpp/build.ninja... Building extension module lltm_cpp... Loading extension module lltm_cpp... 生成的 Python 模块将与 setuptools 生成的模块完全相同，但是消除了必须维护单独的setup.py构建文件的要求。 如果您的设置更加复杂，并且确实需要setuptools的全部功能，则可以编写自己的setup.py –但是在许多情况下，这种 JIT 技术就可以了。 第一次运行此行时，将需要一些时间，因为扩展程序是在后台编译的。 由于我们使用 Ninja 构建系统来构建您的源代码，因此重新编译是增量的，因此在您第二次运行 Python 模块时重新加载扩展程序非常快捷，而且如果您不更改扩展程序的源文件，则开销很低。 编写混合的 C ++ / CUDA 扩展 为了将实现真正提升到一个新的水平，我们可以使用自定义 CUDA 内核来手写前进和后退传递的部分内容。 对于 LLTM，这具有特别有效的前景，因为有大量按顺序进行的逐点操作，这些操作都可以在单个 CUDA 内核中融合和并行化。 让我们看看如何编写这种 CUDA 内核，并使用此扩展机制将其与 PyTorch 集成。 编写 CUDA 扩展的一般策略是首先编写一个 C ++文件，该文件定义将从 Python 调用的函数，然后使用 pybind11 将这些函数绑定到 Python。 此外，此文件还将声明在 CUDA(.cu）文件中定义的函数。 然后，C ++函数将进行一些检查，并最终将其调用转发给 CUDA 函数。 在 CUDA 文件中，我们编写了实际的 CUDA 内核。 然后cpp_extension包将负责使用gcc等 C ++编译器来编译 C ++源代码，并使用 NVIDIA 的nvcc编译器来编译 CUDA 源。 这样可以确保每个编译器都照顾最了解要编译的文件。 最终，它们将被链接到一个共享库中，该库可以从 Python 代码中获得。 我们将从 C ++文件开始，我们将其称为lltm_cuda.cpp，例如： #include #include // CUDA forward declarations std::vector lltm_cuda_forward( torch::Tensor input, torch::Tensor weights, torch::Tensor bias, torch::Tensor old_h, torch::Tensor old_cell); std::vector lltm_cuda_backward( torch::Tensor grad_h, torch::Tensor grad_cell, torch::Tensor new_cell, torch::Tensor input_gate, torch::Tensor output_gate, torch::Tensor candidate_cell, torch::Tensor X, torch::Tensor gate_weights, torch::Tensor weights); // C++ interface #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\") #define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\") #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x) std::vector lltm_forward( torch::Tensor input, torch::Tensor weights, torch::Tensor bias, torch::Tensor old_h, torch::Tensor old_cell) { CHECK_INPUT(input); CHECK_INPUT(weights); CHECK_INPUT(bias); CHECK_INPUT(old_h); CHECK_INPUT(old_cell); return lltm_cuda_forward(input, weights, bias, old_h, old_cell); } std::vector lltm_backward( torch::Tensor grad_h, torch::Tensor grad_cell, torch::Tensor new_cell, torch::Tensor input_gate, torch::Tensor output_gate, torch::Tensor candidate_cell, torch::Tensor X, torch::Tensor gate_weights, torch::Tensor weights) { CHECK_INPUT(grad_h); CHECK_INPUT(grad_cell); CHECK_INPUT(input_gate); CHECK_INPUT(output_gate); CHECK_INPUT(candidate_cell); CHECK_INPUT(X); CHECK_INPUT(gate_weights); CHECK_INPUT(weights); return lltm_cuda_backward( grad_h, grad_cell, new_cell, input_gate, output_gate, candidate_cell, X, gate_weights, weights); } PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) { m.def(\"forward\", &lltm_forward, \"LLTM forward (CUDA)\"); m.def(\"backward\", &lltm_backward, \"LLTM backward (CUDA)\"); } 如您所见，它主要是样板文件，检查并转发到我们将在 CUDA 文件中定义的功能。 我们将此文件命名为lltm_cuda_kernel.cu(请注意.cu扩展名！）。 NVCC 可以合理地编译 C ++ 11，因此我们仍然可以使用 ATen 和 C ++标准库(但不能使用torch.h）。 请注意，setuptools无法处理具有相同名称但扩展名不同的文件，因此，如果您使用setup.py方法而不是 JIT 方法，则必须给 CUDA 文件指定一个与 C ++文件不同的名称(对于 JIT 方法， lltm.cpp和lltm.cu可以正常工作）。 让我们看一下该文件的外观： #include #include #include #include template __device__ __forceinline__ scalar_t sigmoid(scalar_t z) { return 1.0 / (1.0 + exp(-z)); } 在这里，我们看到了我刚刚描述的标头，以及我们正在使用特定于 CUDA 的声明(例如__device__和__forceinline__）以及函数(例如exp）的事实。 让我们继续一些我们需要的辅助功​​能： template __device__ __forceinline__ scalar_t d_sigmoid(scalar_t z) { const auto s = sigmoid(z); return (1.0 - s) * s; } template __device__ __forceinline__ scalar_t d_tanh(scalar_t z) { const auto t = tanh(z); return 1 - (t * t); } template __device__ __forceinline__ scalar_t elu(scalar_t z, scalar_t alpha = 1.0) { return fmax(0.0, z) + fmin(0.0, alpha * (exp(z) - 1.0)); } template __device__ __forceinline__ scalar_t d_elu(scalar_t z, scalar_t alpha = 1.0) { const auto e = exp(z); const auto d_relu = z 现在要真正实现一个函数，我们将再次需要两件事：一个函数执行我们不希望手工编写并调用 CUDA 内核的操作，然后是要加速的部分的实际 CUDA 内核。 。 对于前向传递，第一个函数应如下所示： std::vector lltm_cuda_forward( torch::Tensor input, torch::Tensor weights, torch::Tensor bias, torch::Tensor old_h, torch::Tensor old_cell) { auto X = torch::cat({old_h, input}, /*dim=*/1); auto gates = torch::addmm(bias, X, weights.transpose(0, 1)); const auto batch_size = old_cell.size(0); const auto state_size = old_cell.size(1); auto new_h = torch::zeros_like(old_cell); auto new_cell = torch::zeros_like(old_cell); auto input_gate = torch::zeros_like(old_cell); auto output_gate = torch::zeros_like(old_cell); auto candidate_cell = torch::zeros_like(old_cell); const int threads = 1024; const dim3 blocks((state_size + threads - 1) / threads, batch_size); AT_DISPATCH_FLOATING_TYPES(gates.type(), \"lltm_forward_cuda\", ([&] { lltm_cuda_forward_kernel>>( gates.data(), old_cell.data(), new_h.data(), new_cell.data(), input_gate.data(), output_gate.data(), candidate_cell.data(), state_size); })); return {new_h, new_cell, input_gate, output_gate, candidate_cell, X, gates}; } 这里的主要关注点是AT_DISPATCH_FLOATING_TYPES宏和内核启动(由&lt;&lt;&lt;...&gt;&gt;&gt;指示）。 尽管 ATen 提取了我们处理过的张量的设备和数据类型，但张量在运行时仍将由具体设备上具体类型的内存支持。 因此，我们需要一种在运行时确定张量是什么类型，然后有选择地调用具有相应正确类型签名的函数的方法。 手动完成后，(在概念上）将如下所示： switch (tensor.type().scalarType()) { case torch::ScalarType::Double: return function(tensor.data()); case torch::ScalarType::Float: return function(tensor.data()); ... } AT_DISPATCH_FLOATING_TYPES的目的是为我们处理此调度。 它需要一个类型(在我们的示例中为gates.type()），一个名称(用于错误消息）和一个 lambda 函数。 在此 lambda 函数中，类型别名scalar_t可用，并且定义为该上下文中张量实际上在运行时的类型。 这样，如果我们有一个模板函数(CUDA 内核将使用它），则可以使用此scalar_t别名实例化它，然后将调用正确的函数。 在这种情况下，我们还希望检索张量的数据指针作为scalar_t类型的指针。 如果您想分派所有类型而不仅仅是浮点类型(Float和Double），则可以使用AT_DISPATCH_ALL_TYPES。 请注意，我们使用普通的 ATen 执行一些操作。 这些操作仍将在 GPU 上运行，但使用 ATen 的默认实现。 这是有道理的，因为 ATen 会针对矩阵乘法(例如addmm）或卷积使用高度优化的例程，而这将很难实现和改善。 至于内核启动本身，我们在这里指定每个 CUDA 块将具有 1024 个线程，并且将整个 GPU 网格分为所需的1 x 1024线程块，以便用每个组件一个线程填充矩阵。 例如，如果我们的状态大小为 2048，批处理大小为 4，则我们将以每 1024 个线程总共启动4 x 2 = 8块。 如果您以前从未听说过 CUDA 的“障碍”或“网格”，那么简介 CUDA 可能会有所帮助。 实际的 CUDA 内核非常简单(如果您曾经编程过 GPU）： template __global__ void lltm_cuda_forward_kernel( const scalar_t* __restrict__ gates, const scalar_t* __restrict__ old_cell, scalar_t* __restrict__ new_h, scalar_t* __restrict__ new_cell, scalar_t* __restrict__ input_gate, scalar_t* __restrict__ output_gate, scalar_t* __restrict__ candidate_cell, size_t state_size) { const int column = blockIdx.x * blockDim.x + threadIdx.x; const int index = blockIdx.y * state_size + column; const int gates_row = blockIdx.y * (state_size * 3); if (column 这里最有趣的是，我们能够为门矩阵中的每个单独的组件完全并行地计算所有这些逐点运算。 如果您想象必须用一个串行的百万个元素的for巨型循环来执行此操作，那么您会明白为什么这样做会快得多。 使用访问器 您可以在 CUDA 内核中看到，我们直接处理正确类型的指针。 确实，直接在 cuda 内核中使用高级类型不可知张量会非常低效。 但是，这是以易于使用和可读性为代价的，尤其是对于高维数据。 在我们的示例中，例如，我们知道连续的gates张量具有 3 个维度： 批次，batch_size的大小和3*state_size的步幅 3的行，大小和state_size的步幅 指数，state_size的大小和1的步幅 那么我们如何访问内核中的元素gates[n][row][column]？ 事实证明，您需要通过一些简单的算法就可以大步访问元素。 gates.data()[n*3*state_size + row*state_size + column] 除了冗长之外，该表达式还需要跨步才能被明确地知道，并因此在其参数中传递给内核函数。 您会看到，在内核函数接受具有不同大小的多个张量的情况下，您将得到很长的参数列表。 对我们来说幸运的是，ATen 提供了通过动态检查 Tensor 是尺寸的类型和数量而创建的访问器。 然后，访问器公开一个 API，可以有效地访问 Tensor 元素，而不必转换为单个指针： torch::Tensor foo = torch::rand({12, 12}); // assert foo is 2-dimensional and holds floats. auto foo_a = foo.accessor(); float trace = 0; for(int i = 0; i 访问器对象具有较高级别的接口，具有.size()和.stride()方法以及多维索引。 .accessor&lt;&gt;接口旨在在 CPU 张量上有效访问数据。 cuda 张量的等效项是packed_accessor64&lt;&gt;和packed_accessor32&lt;&gt;，它们产生具有 64 位或 32 位整数索引的压缩访问器。 与 Accessor 的根本区别在于，打包的 Accessor 在其结构内部复制大小和跨度数据，而不是指向它。 它允许我们将其传递给 CUDA 内核函数并在其中使用其接口。 我们可以设计一个使用压缩访问器而不是指针的函数。 __global__ void lltm_cuda_forward_kernel( const torch::PackedTensorAccessor32 gates, const torch::PackedTensorAccessor32 old_cell, torch::PackedTensorAccessor32 new_h, torch::PackedTensorAccessor32 new_cell, torch::PackedTensorAccessor32 input_gate, torch::PackedTensorAccessor32 output_gate, torch::PackedTensorAccessor32 candidate_cell) 让我们分解一下这里使用的模板。 前两个参数scalar_t和2与常规访问器相同。 参数torch::RestrictPtrTraits指示必须使用__restrict__关键字。 另请注意，我们使用了PackedAccessor32变体，将变体和步幅存储在int32_t中。 这很重要，因为使用 64 位变体(PackedAccessor64）会使内核变慢。 函数声明变为 template __global__ void lltm_cuda_forward_kernel( const torch::PackedTensorAccessor32 gates, const torch::PackedTensorAccessor32 old_cell, torch::PackedTensorAccessor32 new_h, torch::PackedTensorAccessor32 new_cell, torch::PackedTensorAccessor32 input_gate, torch::PackedTensorAccessor32 output_gate, torch::PackedTensorAccessor32 candidate_cell) { //batch index const int n = blockIdx.y; // column index const int c = blockIdx.x * blockDim.x + threadIdx.x; if (c 该实现更具可读性！ 然后，通过在主机函数内使用.packed_accessor32&lt;&gt;方法创建压缩访问器来调用此函数。 std::vector lltm_cuda_forward( torch::Tensor input, torch::Tensor weights, torch::Tensor bias, torch::Tensor old_h, torch::Tensor old_cell) { auto X = torch::cat({old_h, input}, /*dim=*/1); auto gate_weights = torch::addmm(bias, X, weights.transpose(0, 1)); const auto batch_size = old_cell.size(0); const auto state_size = old_cell.size(1); auto gates = gate_weights.reshape({batch_size, 3, state_size}); auto new_h = torch::zeros_like(old_cell); auto new_cell = torch::zeros_like(old_cell); auto input_gate = torch::zeros_like(old_cell); auto output_gate = torch::zeros_like(old_cell); auto candidate_cell = torch::zeros_like(old_cell); const int threads = 1024; const dim3 blocks((state_size + threads - 1) / threads, batch_size); AT_DISPATCH_FLOATING_TYPES(gates.type(), \"lltm_forward_cuda\", ([&] { lltm_cuda_forward_kernel>>( gates.packed_accessor32(), old_cell.packed_accessor32(), new_h.packed_accessor32(), new_cell.packed_accessor32(), input_gate.packed_accessor32(), output_gate.packed_accessor32(), candidate_cell.packed_accessor32()); })); return {new_h, new_cell, input_gate, output_gate, candidate_cell, X, gates}; } 向后传递遵循相同的模式，在此我不再赘述： template __global__ void lltm_cuda_backward_kernel( torch::PackedTensorAccessor32 d_old_cell, torch::PackedTensorAccessor32 d_gates, const torch::PackedTensorAccessor32 grad_h, const torch::PackedTensorAccessor32 grad_cell, const torch::PackedTensorAccessor32 new_cell, const torch::PackedTensorAccessor32 input_gate, const torch::PackedTensorAccessor32 output_gate, const torch::PackedTensorAccessor32 candidate_cell, const torch::PackedTensorAccessor32 gate_weights) { //batch index const int n = blockIdx.y; // column index const int c = blockIdx.x * blockDim.x + threadIdx.x; if (c lltm_cuda_backward( torch::Tensor grad_h, torch::Tensor grad_cell, torch::Tensor new_cell, torch::Tensor input_gate, torch::Tensor output_gate, torch::Tensor candidate_cell, torch::Tensor X, torch::Tensor gates, torch::Tensor weights) { auto d_old_cell = torch::zeros_like(new_cell); auto d_gates = torch::zeros_like(gates); const auto batch_size = new_cell.size(0); const auto state_size = new_cell.size(1); const int threads = 1024; const dim3 blocks((state_size + threads - 1) / threads, batch_size); AT_DISPATCH_FLOATING_TYPES(X.type(), \"lltm_forward_cuda\", ([&] { lltm_cuda_backward_kernel>>( d_old_cell.packed_accessor32(), d_gates.packed_accessor32(), grad_h.packed_accessor32(), grad_cell.packed_accessor32(), new_cell.packed_accessor32(), input_gate.packed_accessor32(), output_gate.packed_accessor32(), candidate_cell.packed_accessor32(), gates.packed_accessor32()); })); auto d_gate_weights = d_gates.reshape({batch_size, 3*state_size}); auto d_weights = d_gate_weights.t().mm(X); auto d_bias = d_gate_weights.sum(/*dim=*/0, /*keepdim=*/true); auto d_X = d_gate_weights.mm(weights); auto d_old_h = d_X.slice(/*dim=*/1, 0, state_size); auto d_input = d_X.slice(/*dim=*/1, state_size); return {d_old_h, d_input, d_weights, d_bias, d_old_cell, d_gates}; } 将 C ++ / CUDA 操作与 PyTorch 集成 同样，将支持 CUDA 的 op 与 PyTorch 集成非常简单。 如果要编写setup.py脚本，它可能如下所示： from setuptools import setup from torch.utils.cpp_extension import BuildExtension, CUDAExtension setup( name='lltm', ext_modules=[ CUDAExtension('lltm_cuda', [ 'lltm_cuda.cpp', 'lltm_cuda_kernel.cu', ]) ], cmdclass={ 'build_ext': BuildExtension }) 现在，我们使用CUDAExtension()代替CppExtension()。 我们只需要指定.cu文件和.cpp文件即可–该库将为您解决所有麻烦。 JIT 机制甚至更简单： from torch.utils.cpp_extension import load lltm = load(name='lltm', sources=['lltm_cuda.cpp', 'lltm_cuda_kernel.cu']) Performance Comparison 我们的希望是，将我们的代码的逐点操作与 CUDA 并行化和融合，将改善 LLTM 的性能。 让我们看看这是否成立。 我们可以运行前面列出的代码来运行基准测试。 我们之前最快的版本是基于 CUDA 的 C ++代码： Forward: 149.802 us | Backward 393.458 us 现在使用我们的自定义 CUDA 内核： Forward: 129.431 us | Backward 304.641 us 更多性能提升！ 结论 现在，您应该已经对 PyTorch 的 C ++扩展机制有了很好的了解，并有使用它们的动机。 您可以在此处找到本说明中显示的代码示例。 如有疑问，请使用论坛。 如果您遇到任何问题，也请务必查看我们的常见问题解答。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"44.html":{"url":"44.html","title":"LSTM Word 语言模型上的(实验）动态量化","keywords":"","body":"LSTM Word 语言模型上的(实验）动态量化 原文： https://pytorch.org/tutorials/advanced/dynamic_quantization_tutorial.html 注意 单击此处的下载完整的示例代码 作者： James Reed 由编辑：赛斯·魏德曼 介绍 量化涉及将模型的权重和激活从 float 转换为 int，这可能会导致模型尺寸更小，推断速度更快，而对准确性的影响很小。 在本教程中，我们将最简单的量化形式-动态量化应用于基于 LSTM 的下一个单词预测模型，紧紧遵循 PyTorch 示例中的单词语言模型 。 # imports import os from io import open import time import torch import torch.nn as nn import torch.nn.functional as F 1.定义模型 在这里，我们根据词语言模型示例中的模型定义 LSTM 模型体系结构。 class LSTMModel(nn.Module): \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\" def __init__(self, ntoken, ninp, nhid, nlayers, dropout=0.5): super(LSTMModel, self).__init__() self.drop = nn.Dropout(dropout) self.encoder = nn.Embedding(ntoken, ninp) self.rnn = nn.LSTM(ninp, nhid, nlayers, dropout=dropout) self.decoder = nn.Linear(nhid, ntoken) self.init_weights() self.nhid = nhid self.nlayers = nlayers def init_weights(self): initrange = 0.1 self.encoder.weight.data.uniform_(-initrange, initrange) self.decoder.bias.data.zero_() self.decoder.weight.data.uniform_(-initrange, initrange) def forward(self, input, hidden): emb = self.drop(self.encoder(input)) output, hidden = self.rnn(emb, hidden) output = self.drop(output) decoded = self.decoder(output) return decoded, hidden def init_hidden(self, bsz): weight = next(self.parameters()) return (weight.new_zeros(self.nlayers, bsz, self.nhid), weight.new_zeros(self.nlayers, bsz, self.nhid)) 2.加载文本数据 接下来，我们再次根据单词模型示例对预处理，将 Wikitext-2 数据集加载到语料库中。 class Dictionary(object): def __init__(self): self.word2idx = {} self.idx2word = [] def add_word(self, word): if word not in self.word2idx: self.idx2word.append(word) self.word2idx[word] = len(self.idx2word) - 1 return self.word2idx[word] def __len__(self): return len(self.idx2word) class Corpus(object): def __init__(self, path): self.dictionary = Dictionary() self.train = self.tokenize(os.path.join(path, 'train.txt')) self.valid = self.tokenize(os.path.join(path, 'valid.txt')) self.test = self.tokenize(os.path.join(path, 'test.txt')) def tokenize(self, path): \"\"\"Tokenizes a text file.\"\"\" assert os.path.exists(path) # Add words to the dictionary with open(path, 'r', encoding=\"utf8\") as f: for line in f: words = line.split() + [''] for word in words: self.dictionary.add_word(word) # Tokenize file content with open(path, 'r', encoding=\"utf8\") as f: idss = [] for line in f: words = line.split() + [''] ids = [] for word in words: ids.append(self.dictionary.word2idx[word]) idss.append(torch.tensor(ids).type(torch.int64)) ids = torch.cat(idss) return ids model_data_filepath = 'data/' corpus = Corpus(model_data_filepath + 'wikitext-2') 3.加载预训练的模型 这是有关动态量化的教程，动态量化是在训练模型后应用的一种量化技术。 因此，我们只需将一些预先训练的权重加载到此模型架构中即可； 这些权重是通过使用单词语言模型示例中的默认设置训练五个纪元而获得的。 ntokens = len(corpus.dictionary) model = LSTMModel( ntoken = ntokens, ninp = 512, nhid = 256, nlayers = 5, ) model.load_state_dict( torch.load( model_data_filepath + 'word_language_model_quantize.pth', map_location=torch.device('cpu') ) ) model.eval() print(model) 出： LSTMModel( (drop): Dropout(p=0.5, inplace=False) (encoder): Embedding(33278, 512) (rnn): LSTM(512, 256, num_layers=5, dropout=0.5) (decoder): Linear(in_features=256, out_features=33278, bias=True) ) 现在，我们生成一些文本以确保预先训练的模型能够正常工作-与以前类似，我们在此处遵循 input_ = torch.randint(ntokens, (1, 1), dtype=torch.long) hidden = model.init_hidden(1) temperature = 1.0 num_words = 1000 with open(model_data_filepath + 'out.txt', 'w') as outf: with torch.no_grad(): # no tracking history for i in range(num_words): output, hidden = model(input_, hidden) word_weights = output.squeeze().div(temperature).exp().cpu() word_idx = torch.multinomial(word_weights, 1)[0] input_.fill_(word_idx) word = corpus.dictionary.idx2word[word_idx] outf.write(str(word.encode('utf-8')) + ('\\n' if i % 20 == 19 else ' ')) if i % 100 == 0: print('| Generated {}/{} words'.format(i, 1000)) with open(model_data_filepath + 'out.txt', 'r') as outf: all_output = outf.read() print(all_output) Out: | Generated 0/1000 words | Generated 100/1000 words | Generated 200/1000 words | Generated 300/1000 words | Generated 400/1000 words | Generated 500/1000 words | Generated 600/1000 words | Generated 700/1000 words | Generated 800/1000 words | Generated 900/1000 words b'and' b'O' b'\\xe2\\x80\\x99' b'Gacy' b',' b'and' b'then' b'defined' b'that' b'next' b'novel' b'succeeded' b'large' b'property' b',' b'so' b'neither' b'number' b'is' b'currently' b'a' b'identical' b'planet' b'by' b'stiff' b'culture' b'.' b'Mosley' b'may' b'settle' b'in' b'non' b'@-@' b'bands' b'for' b'the' b'beginning' b'of' b'its' b'home' b'stations' b',' b'being' b'also' b'in' b'charge' b'for' b'two' b'other' b'@-@' b'month' b'ceremonies' b'.' b'The' b'first' b'Star' b'Overseas' b'took' b'to' b'have' b'met' b'its' b'leadership' b'for' b'investigation' b'such' b'as' b'Discovered' b'lbw' b',' b'club' b',' b'' b',' b'' b',' b'or' b'Crac' b\"'Malley\" b',' b'although' b'with' b'the' b'other' b'victory' b',' b'assumes' b'it' b'.' b'(' b'not' b'containment' b'to' b'a' b'recent' b'problem' b')' b'.' b'His' b'traditional' b'scheme' b'process' b'is' b'proceeded' b'outdoor' b'in' b'overweight' b'clusters' b';' b'God' b'Davis' b'was' b'interested' b'on' b'her' b'right' b'touring' b',' b'although' b'they' b'had' b'previously' b'previously' b'risen' b'near' b'eclipse' b'in' b'his' b'work' b'by' b'the' b'latter' b'@-@' b'perspective' b'.' b'During' b'the' b'release' b'of' b'Bell' b',' b'the' b'first' b'promotional' b'mention' b'included' b'a' b'Magnetic' b'seam' b'was' b'put' b'into' b'Shakespeare' b\"'s\" b'Special' b'Company' b'is' b'katra' b'than' b'chops' b'@-@' b'up' b'history' b'for' b'frets' b'of' b'actions' b'.' b'' b'Until' b'arrival' b',' b'Griffin' b'wrote' b'that' b'a' b'\"' b'sense' b'\"' b'included' b'especially' b'declining' b'individual' b'forces' b',' b'though' b'are' b'stronger' b'' b'.' b'According' b'to' b'lessen' b'very' b'role' b',' b'Ceres' b'believed' b'he' b'each' b'conflicted' b'pump' b'fight' b'follows' b'the' b'malignant' b'polynomial' b'to' b'make' b'Albani' b'.' b'The' b'nobility' b'found' b'a' b'spinners' b'from' b'a' b'special' b'to' b'vertical' b'@-@' b'term' b'crimes' b',' b'and' b'the' b'Neapolitan' b'apparent' b'' b'show' b'forcing' b'no' b'of' b'the' b'worst' b'traditions' b'of' b'tallest' b'' b'teacher' b'+' b'green' b'crushing' b',' b'with' b'4' b'%' b',' b'and' b'560' b'doctrines' b',' b'with' b'other' b'Asian' b'assistance' b'' b'.' b'The' b'game' b'is' b'unadorned' b',' b'especially' b'or' b'steadily' b'favoured' b'according' b'to' b'its' b'inside' b',' b'leading' b'to' b'the' b'removal' b'of' b'gauges' b'.' b'vanishing' b',' b'a' b'jagged' b'race' b'rested' b'with' b'be' b'rich' b'if' b'these' b'legislation' b'remained' b'together' b'.' b'The' b'anthology' b'and' b'initially' b'regularly' b'Cases' b'Cererian' b'and' b'acknowledge' b'individual' b'being' b'poured' b'with' b'the' b'Chicago' b'melee' b'.' b'Europium' b',' b'' b',' b'and' b'Lars' b'life' b'for' b'electron' b'plumage' b',' b'will' b'deprive' b'themselves' b'.' b'The' b'' b'gryllotalpa' b'behave' b'have' b'Emerald' b'doubt' b'.' b'When' b'limited' b'cubs' b'are' b'rather' b'attempting' b'to' b'address' b'.' b'Two' b'birds' b'as' b'being' b'also' b'' b',' b'such' b'as' b'\"' b'' b'\"' b',' b'and' b'possessing' b'criminal' b'spots' b',' b'lambskin' b'ponderosa' b'mosses' b',' b'which' b'might' b'seek' b'to' b'begin' b'less' b'different' b'delineated' b'techniques' b'.' b'Known' b',' b'on' b'the' b'ground' b',' b'and' b'only' b'cooler' b',' b'first' b'on' b'other' b'females' b'factory' b'in' b'mathematics' b'.' b'Pilgrim' b'alone' b'has' b'a' b'critical' b'substance' b',' b'probably' b'in' b'line' b'.' b'He' b'used' b'a' b'' b',' b'with' b'the' b'resin' b'being' b'transported' b'to' b'the' b'12th' b'island' b'during' b'the' b'year' b'of' b'a' b'mixture' b'show' b'that' b'it' b'is' b'serving' b';' b'they' b'are' b'headed' b'by' b'prone' b'too' b'species' b',' b'rather' b'than' b'the' b'risk' b'of' b'carbon' b'.' b'In' b'all' b'other' b'typical' b',' b'faith' b'consist' b'of' b'' b'whereas' b'' b'when' b'quotes' b'they' b'Abrams' b'restructuring' b'vessels' b'.' b'It' b'also' b'emerged' b'even' b'when' b'any' b'lack' b'of' b'birds' b'has' b'wide' b'pinkish' b'structures' b',' b'directing' b'a' b'chelicerae' b'of' b'amputated' b'elementary' b',' b'only' b'they' b'on' b'objects' b'.' b'A' b'female' b'and' b'a' b'female' b'Leisler' b'@-@' b'shaped' b'image' b'for' b'51' b'@.@' b'5' b'm' b'(' b'5' b'lb' b')' b'Frenchman' b'2' b'at' b'sea' b'times' b'is' b'approximately' b'2' b'years' b'ago' b',' b'particularly' b'behind' b'reducing' b'Trujillo' b\"'s\" b'and' b'food' b'specific' b'spores' b'.' b'Males' b'fibrous' b'females' b'can' b'be' b'severely' b'gregarious' b'.' b'The' b'same' b'brood' b'behind' b'100' b'minutes' b'after' b'it' b'is' b'estimated' b'by' b'damaging' b'the' b'nest' b'base' b',' b'with' b'some' b'other' b'rare' b'birds' b'and' b'behavior' b',' b'no' b'transport' b'and' b'Duty' b'demand' b'.' b'Two' b'rare' b'chicks' b'have' b'from' b'feed' b'engage' b'to' b'come' b'with' b'some' b'part' b'of' b'nesting' b'.' b'The' b'1808' b'to' b'be' b'reduced' b'to' b'Scots' b'and' b'fine' b'stones' b'.' b'There' b'they' b'also' b'purple' b'limitations' b'of' b'certain' b'skin' b'material' b'usually' b'move' b'during' b'somewhat' b'.' b'A' b'mothers' b'of' b'external' b'take' b'from' b'poaching' b',' b'typically' b'have' b'people' b'processes' b'and' b'toll' b';' b'while' b'bird' b'plumage' b'differs' b'to' b'Fight' b',' b'they' b'may' b'be' b'open' b'after' b'' b',' b'thus' b'rarely' b'their' b'' b'for' b'a' b'emotional' b'circle' b'.' b'Rough' b'Dahlan' b'probably' b'suggested' b'how' b'they' b'impose' b'their' b'cross' b'of' b'relapse' b'where' b'they' b'changed' b'.' b'They' b'popularisation' b'them' b'of' b'their' b'' b',' b'charming' b'by' b'limited' b'or' b'Palestinians' b'the' b'' b'' b'.' b'Traffic' b'of' b'areas' b'headed' b',' b'and' b'their' b'push' b'will' b'articulate' b'.' b'' b'' b'would' b'be' b'criticized' b'by' b'protein' b'rice' b',' b'particularly' b'often' b'rather' b'of' b'the' b'cellular' b'extent' b'.' b'They' b'could' b'overlap' b'forward' b',' b'and' b'there' b'are' b'no' b'governing' b'land' b',' b'they' b'do' b'not' b'find' b'it' b'.' b'In' b'one' b'place' b',' b'reddish' b'kakapo' b'(' b'kakapo' b'' b')' b'might' b'be' b'performed' b'that' b'conduct' b',' b'stadia' b',' b'gene' b'or' b'air' b',' b'noise' b',' b'and' b'offensive' b'or' b'skin' b',' b'which' b'may' b'be' b'commercially' b'organized' b'strong' b'method' b'.' b'In' b'changing' b',' b'Chen' b'and' b'eukaryotes' b'were' b'Membrane' b'spiders' b'in' b'larger' b'growth' b',' b'by' b'some' b'regions' b'.' b'If' b'up' b'about' b'5' b'%' b'of' b'the' b'males' b',' b'there' b'are' b'displays' b'that' b'shift' b'the' b'bird' b'inclination' b'after' b'supreme' b'' b'to' b'move' b'outside' b'tests' b'.' b'The' b'aim' b'of' b'Mouquet' b'Sites' b'is' b'faster' b'as' b'an' b'easy' b'asteroid' b',' b'with' b'ocean' b'or' b'grey' b',' b'albeit' b',' b'as' b'they' b'they' b'CBs' b',' b'and' b'do' b'not' b'be' b'performed' b',' b'greatly' b'on' b'other' b'insects' b',' b'they' b'can' b'write' b'chromosomes' b',' b'and' b'planners' b',' b'galericulata' b'should' b'be' b'a' b'bird' b'.' b'Also' b'on' b'a' b'holodeck' b'they' b'were' b'divine' b'out' b'of' b'bare' b'handwriting' b'.' b'Unlike' b'this' b',' b'they' b'makes' b'only' b'anything' b'a' b'variation' b'of' b'skin' b'skeletons' b'further' b'.' b'They' b'have' b'to' b'be' b'able' b'under' b'their' b'herding' b'tree' b',' b'or' b'dart' b'.' b'When' b'many' b'hypothesis' b'(' b'plant' b',' b'they' b'were' b'@-@' b'looped' b'aged' b'play' b')' b'is' b'very' b'clear' b'as' b'very' b'on' b'comparison' b'.' b'' b'Furthermore' b',' b'Wikimania' b'decorations' b'@-@' b'sponsored' b'naming' b'hydrogen' b'when' b'the' b'kakapo' b'commenced' b',' b'they' b'are' b'slowly' b'on' b'heavy' b'isolation' b'.' b'Sometimes' b'that' b'Larssen' b'leave' b'gently' b',' b'they' b'usually' b'made' b'short' b'care' b'of' b'feral' b'or' b'any' b'dual' b'species' b'.' b'' b'Further' b'males' b'that' b'outfitting' b',' b'when' b'there' b'are' b'two' b'envelope' b'shorter' b'flocks' b'to' b'be' b'males' b'ideally' b'they' b'are' b'highly' b'emission' b'.' b'' b'As' b'of' b'danger' b',' b'taking' b'in' b'one' b'of' b'the' b'other' b'surviving' b'structure' b'of' b'Ceres' b'can' b'be' b'rebuffed' b'to' b'be' b'caused' b'by' b'any' b'combination' b'of' b'food' b'or' b'modified' b'its' 它不是 GPT-2，但看起来该模型已开始学习语言结构！ 我们几乎准备好演示动态量化。 我们只需要定义一些辅助函数： bptt = 25 criterion = nn.CrossEntropyLoss() eval_batch_size = 1 # create test data set def batchify(data, bsz): # Work out how cleanly we can divide the dataset into bsz parts. nbatch = data.size(0) // bsz # Trim off any extra elements that wouldn't cleanly fit (remainders). data = data.narrow(0, 0, nbatch * bsz) # Evenly divide the data across the bsz batches. return data.view(bsz, -1).t().contiguous() test_data = batchify(corpus.test, eval_batch_size) # Evaluation functions def get_batch(source, i): seq_len = min(bptt, len(source) - 1 - i) data = source[i:i+seq_len] target = source[i+1:i+1+seq_len].view(-1) return data, target def repackage_hidden(h): \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\" if isinstance(h, torch.Tensor): return h.detach() else: return tuple(repackage_hidden(v) for v in h) def evaluate(model_, data_source): # Turn on evaluation mode which disables dropout. model_.eval() total_loss = 0. hidden = model_.init_hidden(eval_batch_size) with torch.no_grad(): for i in range(0, data_source.size(0) - 1, bptt): data, targets = get_batch(data_source, i) output, hidden = model_(data, hidden) hidden = repackage_hidden(hidden) output_flat = output.view(-1, ntokens) total_loss += len(data) * criterion(output_flat, targets).item() return total_loss / (len(data_source) - 1) 4.测试动态量化 最后，我们可以在模型上调用torch.quantization.quantize_dynamic！ 特别， 我们指定我们要对模型中的nn.LSTM和nn.Linear模块进行量化 我们指定希望将权重转换为int8值 import torch.quantization quantized_model = torch.quantization.quantize_dynamic( model, {nn.LSTM, nn.Linear}, dtype=torch.qint8 ) print(quantized_model) Out: LSTMModel( (drop): Dropout(p=0.5, inplace=False) (encoder): Embedding(33278, 512) (rnn): DynamicQuantizedLSTM( 512, 256, num_layers=5, dropout=0.5 (_all_weight_values): ModuleList( (0): PackedParameter() (1): PackedParameter() (2): PackedParameter() (3): PackedParameter() (4): PackedParameter() (5): PackedParameter() (6): PackedParameter() (7): PackedParameter() (8): PackedParameter() (9): PackedParameter() ) ) (decoder): DynamicQuantizedLinear( in_features=256, out_features=33278 (_packed_params): LinearPackedParams() ) ) 该模型看起来相同； 这对我们有什么好处？ 首先，我们看到模型尺寸显着减小： def print_size_of_model(model): torch.save(model.state_dict(), \"temp.p\") print('Size (MB):', os.path.getsize(\"temp.p\")/1e6) os.remove('temp.p') print_size_of_model(model) print_size_of_model(quantized_model) Out: Size (MB): 113.941574 Size (MB): 76.807204 其次，我们看到了更快的推断时间，而评估损失没有差异： 注意：由于量化模型运行单线程，因此用于单线程比较的线程数为 1。 torch.set_num_threads(1) def time_model_evaluation(model, test_data): s = time.time() loss = evaluate(model, test_data) elapsed = time.time() - s print('''loss: {0:.3f}\\nelapsed time (seconds): {1:.1f}'''.format(loss, elapsed)) time_model_evaluation(model, test_data) time_model_evaluation(quantized_model, test_data) Out: loss: 5.167 elapsed time (seconds): 233.9 loss: 5.168 elapsed time (seconds): 164.9 在 MacBook Pro 上本地运行此程序，无需进行量化，推理大约需要 200 秒，而进行量化则只需大约 100 秒。 结论 动态量化可能是减小模型大小的简单方法，而对精度的影响有限。 谢谢阅读！ 与往常一样，我们欢迎您提供任何反馈，因此，如果有任何问题，请在此处创建一个问题。 脚本的总运行时间：(6 分钟 43.291 秒） Download Python source code: dynamic_quantization_tutorial.py Download Jupyter notebook: dynamic_quantization_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"45.html":{"url":"45.html","title":"(实验性）在 PyTorch 中使用 Eager 模式进行静态量化","keywords":"","body":"(实验性）在 PyTorch 中使用 Eager 模式进行静态量化 原文： https://pytorch.org/tutorials/advanced/static_quantization_tutorial.html 注意 单击此处的下载完整的示例代码 作者： Raghuraman Krishnamoorthi 由编辑：赛斯·魏德曼 本教程介绍了如何进行训练后的静态量化，并说明了两种更先进的技术-每通道量化和量化感知训练-可以进一步提高模型的准确性。 请注意，目前仅支持 CPU 量化，因此在本教程中我们将不使用 GPU / CUDA。 在本教程结束时，您将看到 PyTorch 中的量化如何导致模型大小显着减小同时提高速度。 此外，您将在此处看到如何轻松应用中显示的一些高级量化技术，从而使量化后的模型获得的准确性降低得多。 警告：我们使用了许多其他 PyTorch 仓库中的样板代码，例如，定义MobileNetV2模型架构，定义数据加载器等。 我们当然鼓励您阅读它； 但是如果要使用量化功能，请随时跳至“ 4。 训练后静态量化”部分。 我们将从进行必要的导入开始： import numpy as np import torch import torch.nn as nn import torchvision from torch.utils.data import DataLoader from torchvision import datasets import torchvision.transforms as transforms import os import time import sys import torch.quantization # # Setup warnings import warnings warnings.filterwarnings( action='ignore', category=DeprecationWarning, module=r'.*' ) warnings.filterwarnings( action='default', module=r'torch.quantization' ) # Specify random seed for repeatable results torch.manual_seed(191009) 1.模型架构 我们首先定义 MobileNetV2 模型体系结构，并进行了一些值得注意的修改以实现量化： 用nn.quantized.FloatFunctional代替加法运算 在网络的开头和结尾处插入QuantStub和DeQuantStub。 用 ReLU 替换 ReLU6 注意：此代码取自此处。 from torch.quantization import QuantStub, DeQuantStub def _make_divisible(v, divisor, min_value=None): \"\"\" This function is taken from the original tf repo. It ensures that all layers have a channel number that is divisible by 8 It can be seen here: https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py :param v: :param divisor: :param min_value: :return: \"\"\" if min_value is None: min_value = divisor new_v = max(min_value, int(v + divisor / 2) // divisor * divisor) # Make sure that round down does not go down by more than 10%. if new_v 2.助手功能 接下来，我们定义一些帮助程序功能以帮助模型评估。 这些主要来自这里。 class AverageMeter(object): \"\"\"Computes and stores the average and current value\"\"\" def __init__(self, name, fmt=':f'): self.name = name self.fmt = fmt self.reset() def reset(self): self.val = 0 self.avg = 0 self.sum = 0 self.count = 0 def update(self, val, n=1): self.val = val self.sum += val * n self.count += n self.avg = self.sum / self.count def __str__(self): fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})' return fmtstr.format(**self.__dict__) def accuracy(output, target, topk=(1,)): \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\" with torch.no_grad(): maxk = max(topk) batch_size = target.size(0) _, pred = output.topk(maxk, 1, True, True) pred = pred.t() correct = pred.eq(target.view(1, -1).expand_as(pred)) res = [] for k in topk: correct_k = correct[:k].view(-1).float().sum(0, keepdim=True) res.append(correct_k.mul_(100.0 / batch_size)) return res def evaluate(model, criterion, data_loader, neval_batches): model.eval() top1 = AverageMeter('Acc@1', ':6.2f') top5 = AverageMeter('Acc@5', ':6.2f') cnt = 0 with torch.no_grad(): for image, target in data_loader: output = model(image) loss = criterion(output, target) cnt += 1 acc1, acc5 = accuracy(output, target, topk=(1, 5)) print('.', end = '') top1.update(acc1[0], image.size(0)) top5.update(acc5[0], image.size(0)) if cnt >= neval_batches: return top1, top5 return top1, top5 def load_model(model_file): model = MobileNetV2() state_dict = torch.load(model_file) model.load_state_dict(state_dict) model.to('cpu') return model def print_size_of_model(model): torch.save(model.state_dict(), \"temp.p\") print('Size (MB):', os.path.getsize(\"temp.p\")/1e6) os.remove('temp.p') 3.定义数据集和数据加载器 作为最后的主要设置步骤，我们为训练和测试集定义了数据加载器。 ImageNet 数据 我们为本教程创建的特定数据集仅包含来自 ImageNet 数据的 1000 张图像，每个类别都有一张(该数据集的大小刚好超过 250 MB，可以相对轻松地下载）。 此自定义数据集的 URL 为： https://s3.amazonaws.com/pytorch-tutorial-assets/imagenet_1k.zip 要使用 Python 在本地下载此数据，可以使用： import requests url = 'https://s3.amazonaws.com/pytorch-tutorial-assets/imagenet_1k.zip` filename = '~/Downloads/imagenet_1k_data.zip' r = requests.get(url) with open(filename, 'wb') as f: f.write(r.content) 为了运行本教程，我们下载了这些数据，并使用 Makefile 中的这些行将其移到正确的位置。 另一方面，要使用整个 ImageNet 数据集运行本教程中的代码，可以在后面的之后使用torchvision下载数据。 例如，要下载训练集并对其进行一些标准转换，可以使用： import torchvision import torchvision.transforms as transforms imagenet_dataset = torchvision.datasets.ImageNet( '~/.data/imagenet', split='train', download=True, transforms.Compose([ transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) 下载完数据后，我们在下面显示了一些函数，这些函数定义了用于读取该数据的数据加载器。 这些功能主要来自此处。 def prepare_data_loaders(data_path): traindir = os.path.join(data_path, 'train') valdir = os.path.join(data_path, 'val') normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) dataset = torchvision.datasets.ImageFolder( traindir, transforms.Compose([ transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), normalize, ])) dataset_test = torchvision.datasets.ImageFolder( valdir, transforms.Compose([ transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), normalize, ])) train_sampler = torch.utils.data.RandomSampler(dataset) test_sampler = torch.utils.data.SequentialSampler(dataset_test) data_loader = torch.utils.data.DataLoader( dataset, batch_size=train_batch_size, sampler=train_sampler) data_loader_test = torch.utils.data.DataLoader( dataset_test, batch_size=eval_batch_size, sampler=test_sampler) return data_loader, data_loader_test 接下来，我们将加载经过预先​​训练的 MobileNetV2 模型。 我们在中提供从torchvision 中下载数据的 URL。 data_path = 'data/imagenet_1k' saved_model_dir = 'data/' float_model_file = 'mobilenet_pretrained_float.pth' scripted_float_model_file = 'mobilenet_quantization_scripted.pth' scripted_quantized_model_file = 'mobilenet_quantization_scripted_quantized.pth' train_batch_size = 30 eval_batch_size = 30 data_loader, data_loader_test = prepare_data_loaders(data_path) criterion = nn.CrossEntropyLoss() float_model = load_model(saved_model_dir + float_model_file).to('cpu') 接下来，我们将“融合模块”； 通过节省内存访问量，这可以使模型更快，同时还可以提高数值精度。 尽管这可以用于任何模型，但在量化模型中尤为常见。 print('\\n Inverted Residual Block: Before fusion \\n\\n', float_model.features[1].conv) float_model.eval() # Fuses modules float_model.fuse_model() # Note fusion of Conv+BN+Relu and Conv+Relu print('\\n Inverted Residual Block: After fusion\\n\\n',float_model.features[1].conv) 出： Inverted Residual Block: Before fusion Sequential( (0): ConvBNReLU( (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False) (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) Inverted Residual Block: After fusion Sequential( (0): ConvBNReLU( (0): ConvReLU2d( (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32) (1): ReLU() ) (1): Identity() (2): Identity() ) (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1)) (2): Identity() ) 最后，要获得“基准”精度，让我们看看带有融合模块的未量化模型的精度 num_eval_batches = 10 print(\"Size of baseline model\") print_size_of_model(float_model) top1, top5 = evaluate(float_model, criterion, data_loader_test, neval_batches=num_eval_batches) print('Evaluation accuracy on %d images, %2.2f'%(num_eval_batches * eval_batch_size, top1.avg)) torch.jit.save(torch.jit.script(float_model), saved_model_dir + scripted_float_model_file) Out: Size of baseline model Size (MB): 13.981375 ..........Evaluation accuracy on 300 images, 78.00 我们看到 300 张图像的准确率达到 78％，这是 ImageNet 的坚实基础，尤其是考虑到我们的模型只有 14.0 MB 时。 这将是我们比较的基准。 接下来，让我们尝试不同的量化方法 4.训练后静态量化 训练后的静态量化不仅涉及像动态量化中那样将权重从 float 转换为 int，而且还执行额外的步骤，即首先通过网络馈送一批数据并计算不同激活的结果分布(具体而言，这是 通过在记录此数据的不同点插入观察者模块来完成）。 然后使用这些分布来确定在推理时如何具体量化不同的激活(一种简单的技术将简单地将整个激活范围划分为 256 个级别，但我们也支持更复杂的方法）。 重要的是，此附加步骤使我们能够在操作之间传递量化值，而不是在每次操作之间将这些值转换为浮点数，然后再转换为整数，从而显着提高了速度。 num_calibration_batches = 10 myModel = load_model(saved_model_dir + float_model_file).to('cpu') myModel.eval() # Fuse Conv, bn and relu myModel.fuse_model() # Specify quantization configuration # Start with simple min/max range estimation and per-tensor quantization of weights myModel.qconfig = torch.quantization.default_qconfig print(myModel.qconfig) torch.quantization.prepare(myModel, inplace=True) # Calibrate first print('Post Training Quantization Prepare: Inserting Observers') print('\\n Inverted Residual Block:After observer insertion \\n\\n', myModel.features[1].conv) # Calibrate with the training set evaluate(myModel, criterion, data_loader, neval_batches=num_calibration_batches) print('Post Training Quantization: Calibration done') # Convert to quantized model torch.quantization.convert(myModel, inplace=True) print('Post Training Quantization: Convert done') print('\\n Inverted Residual Block: After fusion and quantization, note fused modules: \\n\\n',myModel.features[1].conv) print(\"Size of model after quantization\") print_size_of_model(myModel) top1, top5 = evaluate(myModel, criterion, data_loader_test, neval_batches=num_eval_batches) print('Evaluation accuracy on %d images, %2.2f'%(num_eval_batches * eval_batch_size, top1.avg)) Out: QConfig(activation=functools.partial(, reduce_range=True), weight=functools.partial(, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric)) Post Training Quantization Prepare: Inserting Observers Inverted Residual Block:After observer insertion Sequential( (0): ConvBNReLU( (0): ConvReLU2d( (0): Conv2d( 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32 (activation_post_process): MinMaxObserver(min_val=None, max_val=None) ) (1): ReLU( (activation_post_process): MinMaxObserver(min_val=None, max_val=None) ) ) (1): Identity() (2): Identity() ) (1): Conv2d( 32, 16, kernel_size=(1, 1), stride=(1, 1) (activation_post_process): MinMaxObserver(min_val=None, max_val=None) ) (2): Identity() ) ..........Post Training Quantization: Calibration done Post Training Quantization: Convert done Inverted Residual Block: After fusion and quantization, note fused modules: Sequential( (0): ConvBNReLU( (0): QuantizedConvReLU2d(32, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.15092508494853973, zero_point=0, padding=(1, 1), groups=32) (1): Identity() (2): Identity() ) (1): QuantizedConv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), scale=0.1737997829914093, zero_point=72) (2): Identity() ) Size of model after quantization Size (MB): 3.58906 ..........Evaluation accuracy on 300 images, 63.33 对于这个量化模型，我们发现在这 300 张相同的图像上，准确率仅低至〜62％。 但是，我们确实将模型的大小减小到了 3.6 MB 以下，几乎减少了 4 倍。 此外，我们可以简单地通过使用不同的量化配置来显着提高准确性。 我们使用推荐的配置对 x86 架构进行量化，重复相同的练习。 此配置执行以下操作： 量化每个通道的权重 使用直方图观察器，该直方图观察器收集激活的直方图，然后以最佳方式选择量化参数。 per_channel_quantized_model = load_model(saved_model_dir + float_model_file) per_channel_quantized_model.eval() per_channel_quantized_model.fuse_model() per_channel_quantized_model.qconfig = torch.quantization.get_default_qconfig('fbgemm') print(per_channel_quantized_model.qconfig) torch.quantization.prepare(per_channel_quantized_model, inplace=True) evaluate(per_channel_quantized_model,criterion, data_loader, num_calibration_batches) torch.quantization.convert(per_channel_quantized_model, inplace=True) top1, top5 = evaluate(per_channel_quantized_model, criterion, data_loader_test, neval_batches=num_eval_batches) print('Evaluation accuracy on %d images, %2.2f'%(num_eval_batches * eval_batch_size, top1.avg)) torch.jit.save(torch.jit.script(per_channel_quantized_model), saved_model_dir + scripted_quantized_model_file) Out: QConfig(activation=functools.partial(, reduce_range=True), weight=functools.partial(, dtype=torch.qint8, qscheme=torch.per_channel_symmetric)) ....................Evaluation accuracy on 300 images, 77.33 仅更改这种量化配置方法，就可以将准确性提高到 76％以上！ 尽管如此，这仍比上述 78％的基准差 1-2％。 因此，让我们尝试量化意识的训练。 5.量化意识训练 量化意识训练(QAT）是通常导致最高准确性的量化方法。 使用 QAT，在训练的正向和反向过程中，所有权重和激活都被“伪量化”：也就是说，浮点值会四舍五入以模拟 int8 值，但所有计算仍将使用浮点数进行。 因此，在训练过程中进行所有权重调整，同时“意识到”模型将最终被量化的事实。 因此，在量化之后，此方法通常比动态量化或训练后静态量化具有更高的准确性。 实际执行 QAT 的总体工作流程与之前非常相似： 我们可以使用与以前相同的模型：量化意识训练不需要额外的准备。 我们需要使用qconfig来指定要在权重和激活之后插入哪种伪量化，而不是指定观察者 我们首先定义一个训练函数： def train_one_epoch(model, criterion, optimizer, data_loader, device, ntrain_batches): model.train() top1 = AverageMeter('Acc@1', ':6.2f') top5 = AverageMeter('Acc@5', ':6.2f') avgloss = AverageMeter('Loss', '1.5f') cnt = 0 for image, target in data_loader: start_time = time.time() print('.', end = '') cnt += 1 image, target = image.to(device), target.to(device) output = model(image) loss = criterion(output, target) optimizer.zero_grad() loss.backward() optimizer.step() acc1, acc5 = accuracy(output, target, topk=(1, 5)) top1.update(acc1[0], image.size(0)) top5.update(acc5[0], image.size(0)) avgloss.update(loss, image.size(0)) if cnt >= ntrain_batches: print('Loss', avgloss.avg) print('Training: * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}' .format(top1=top1, top5=top5)) return print('Full imagenet train set: * Acc@1 {top1.global_avg:.3f} Acc@5 {top5.global_avg:.3f}' .format(top1=top1, top5=top5)) return 我们像以前一样融合模块 qat_model = load_model(saved_model_dir + float_model_file) qat_model.fuse_model() optimizer = torch.optim.SGD(qat_model.parameters(), lr = 0.0001) qat_model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm') 最后，prepare_qat执行“伪量化”，为量化感知训练准备模型 torch.quantization.prepare_qat(qat_model, inplace=True) print('Inverted Residual Block: After preparation for QAT, note fake-quantization modules \\n',qat_model.features[1].conv) Out: Inverted Residual Block: After preparation for QAT, note fake-quantization modules Sequential( (0): ConvBNReLU( (0): ConvBnReLU2d( 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False (activation_post_process): FakeQuantize( fake_quant_enabled=True, observer_enabled=True, scale=None, zero_point=None (activation_post_process): MovingAverageMinMaxObserver(min_val=None, max_val=None) ) (weight_fake_quant): FakeQuantize( fake_quant_enabled=True, observer_enabled=True, scale=None, zero_point=None (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=None, max_val=None) ) ) (1): Identity() (2): Identity() ) (1): ConvBn2d( 32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False (activation_post_process): FakeQuantize( fake_quant_enabled=True, observer_enabled=True, scale=None, zero_point=None (activation_post_process): MovingAverageMinMaxObserver(min_val=None, max_val=None) ) (weight_fake_quant): FakeQuantize( fake_quant_enabled=True, observer_enabled=True, scale=None, zero_point=None (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=None, max_val=None) ) ) (2): Identity() ) 高精度训练量化模型需要在推断时对数字进行精确建模。 因此，对于量化感知训练，我们通过以下方式修改训练循环： 在训练快要结束时切换批处理规范以使用运行均值和方差，以更好地匹配推理数字。 我们还冻结了量化器参数(比例和零点），并对权重进行了微调。 num_train_batches = 20 # Train and check accuracy after each epoch for nepoch in range(8): train_one_epoch(qat_model, criterion, optimizer, data_loader, torch.device('cpu'), num_train_batches) if nepoch > 3: # Freeze quantizer parameters qat_model.apply(torch.quantization.disable_observer) if nepoch > 2: # Freeze batch norm mean and variance estimates qat_model.apply(torch.nn.intrinsic.qat.freeze_bn_stats) # Check the accuracy after each epoch quantized_model = torch.quantization.convert(qat_model.eval(), inplace=False) quantized_model.eval() top1, top5 = evaluate(quantized_model,criterion, data_loader_test, neval_batches=num_eval_batches) print('Epoch %d :Evaluation accuracy on %d images, %2.2f'%(nepoch, num_eval_batches * eval_batch_size, top1.avg)) Out: ....................Loss tensor(2.0660, grad_fn=) Training: * Acc@1 53.000 Acc@5 77.167 ..........Epoch 0 :Evaluation accuracy on 300 images, 78.67 ....................Loss tensor(2.0398, grad_fn=) Training: * Acc@1 56.000 Acc@5 77.667 ..........Epoch 1 :Evaluation accuracy on 300 images, 74.67 ....................Loss tensor(2.0917, grad_fn=) Training: * Acc@1 52.833 Acc@5 77.333 ..........Epoch 2 :Evaluation accuracy on 300 images, 75.33 ....................Loss tensor(1.9406, grad_fn=) Training: * Acc@1 55.000 Acc@5 79.333 ..........Epoch 3 :Evaluation accuracy on 300 images, 77.67 ....................Loss tensor(1.8255, grad_fn=) Training: * Acc@1 59.833 Acc@5 82.000 ..........Epoch 4 :Evaluation accuracy on 300 images, 77.00 ....................Loss tensor(1.8275, grad_fn=) Training: * Acc@1 58.167 Acc@5 80.167 ..........Epoch 5 :Evaluation accuracy on 300 images, 76.67 ....................Loss tensor(1.9429, grad_fn=) Training: * Acc@1 56.333 Acc@5 79.833 ..........Epoch 6 :Evaluation accuracy on 300 images, 76.33 ....................Loss tensor(1.8643, grad_fn=) Training: * Acc@1 57.333 Acc@5 81.000 ..........Epoch 7 :Evaluation accuracy on 300 images, 75.67 在这里，我们只对少数几个时期执行量化感知训练。 尽管如此，量化感知训练在整个 imagenet 数据集上的准确性仍超过 71％，接近 71.9％的浮点准确性。 有关量化意识训练的更多信息： QAT 是后期训练量化技术的超集，可以进行更多调试。 例如，我们可以分析模型的准确性是否受到权重或激活量化的限制。 由于我们使用伪量化来对实际量化算术的数值建模，因此我们还可以在浮点中模拟量化模型的准确性。 我们也可以轻松地模拟训练后量化。 量化加速 最后，让我们确认一下我们上面提到的内容：量化模型实际上执行推理的速度更快吗？ 让我们测试一下： def run_benchmark(model_file, img_loader): elapsed = 0 model = torch.jit.load(model_file) model.eval() num_batches = 5 # Run the scripted model on a few batches of images for i, (images, target) in enumerate(img_loader): if i Out: Elapsed time: 16 ms Elapsed time: 10 ms 在 MacBook Pro 上本地运行此程序，常规模型的运行时间为 61 毫秒，而量化模型的运行时间仅为 20 毫秒，这说明了量化模型与浮点模型相比，典型的 2-4 倍加速。 结论 在本教程中，我们展示了两种量化方法-训练后静态量化和量化感知训练-描述它们在“幕后”进行的操作以及如何在 PyTorch 中使用它们。 谢谢阅读！ 与往常一样，我们欢迎您提供任何反馈，因此，如果有任何问题，请在此处创建一个问题。 脚本的总运行时间：(9 分钟 43.065 秒） Download Python source code: static_quantization_tutorial.py Download Jupyter notebook: static_quantization_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-23 10:44:47 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"46.html":{"url":"46.html","title":"(实验性）计算机视觉教程的量化转移学习","keywords":"","body":"(实验性）计算机视觉教程的量化转移学习 原文： https://pytorch.org/tutorials/intermediate/quantized_transfer_learning_tutorial.html 小费 为了充分利用本教程，我们建议使用此 Colab 版本。 这将使您可以尝试以下信息。 作者： Zafar Takhirov 被审核： Raghuraman Krishnamoorthi 由编辑：林 ess 琳 本教程以 Sasank Chilamkurthy 编写的原始 PyTorch 转移学习教程为基础。 转移学习是指利用预训练的模型应用于不同数据集的技术。 使用转移学习的主要方式有两种： 作为固定特征提取器的 ConvNet ：在这里，您“冻结” 网络中所有参数的权重，但最后几层(又称“头部”）的权重通常 连接的图层）。 将这些最后一层替换为使用随机权重初始化的新层，并且仅训练这些层。 对 ConvNet 进行微调：使用随机训练的网络初始化模型，而不是随机初始化，然后像往常一样进行训练，但使用另一个数据集。 通常，如果输出数量不同，则在网络中也会更换磁头(或磁头的一部分）。 这种方法通常将学习率设置为较小的值。 这样做是因为已经对网络进行了训练，并且只需进行较小的更改即可将其“微调”到新的数据集。 您还可以结合以上两种方法：首先，可以冻结特征提取器，并训练头部。 之后，您可以解冻特征提取器(或其一部分），将学习率设置为较小的值，然后继续进行训练。 在本部分中，您将使用第一种方法-使用量化模型提取特征。 第 0 部分。先决条件 在深入学习迁移学习之前，让我们回顾一下“先决条件”，例如安装和数据加载/可视化。 # Imports import copy import matplotlib.pyplot as plt import numpy as np import os import time plt.ion() 安装每夜构建 因为您将使用 PyTorch 的实验部分，所以建议安装最新版本的torch和torchvision。 您可以在中找到有关本地安装的最新说明。 例如，要在没有 GPU 支持的情况下进行安装： pip install numpy pip install --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html # For CUDA support use https://download.pytorch.org/whl/nightly/cu101/torch_nightly.html 载入资料 注意 本部分与原始的迁移学习教程相同。 我们将使用torchvision和torch.utils.data包加载数据。 您今天要解决的问题是从图像中对蚂蚁和蜜蜂进行分类。 该数据集包含约 120 张针对蚂蚁和蜜蜂的训练图像。 每个类别有 75 个验证图像。 可以认为这是一个很小的数据集。 但是，由于我们正在使用迁移学习，因此我们应该能够很好地概括。 此数据集是 imagenet 的很小子集。 Note 从此处下载数据，并将其提取到data目录。 import torch from torchvision import transforms, datasets # Data augmentation and normalization for training # Just normalization for validation data_transforms = { 'train': transforms.Compose([ transforms.Resize(224), transforms.RandomCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]), 'val': transforms.Compose([ transforms.Resize(224), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]), } data_dir = 'data/hymenoptera_data' image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']} dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=8) for x in ['train', 'val']} dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']} class_names = image_datasets['train'].classes device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") 可视化一些图像 让我们可视化一些训练图像，以了解数据扩充。 import torchvision def imshow(inp, title=None, ax=None, figsize=(5, 5)): \"\"\"Imshow for Tensor.\"\"\" inp = inp.numpy().transpose((1, 2, 0)) mean = np.array([0.485, 0.456, 0.406]) std = np.array([0.229, 0.224, 0.225]) inp = std * inp + mean inp = np.clip(inp, 0, 1) if ax is None: fig, ax = plt.subplots(1, figsize=figsize) ax.imshow(inp) ax.set_xticks([]) ax.set_yticks([]) if title is not None: ax.set_title(title) # Get a batch of training data inputs, classes = next(iter(dataloaders['train'])) # Make a grid from batch out = torchvision.utils.make_grid(inputs, nrow=4) fig, ax = plt.subplots(1, figsize=(10, 10)) imshow(out, title=[class_names[x] for x in classes], ax=ax) 模型训练的支持功能 以下是模型训练的通用功能。 此功能也 安排学习率 保存最佳模型 def train_model(model, criterion, optimizer, scheduler, num_epochs=25, device='cpu'): \"\"\" Support function for model training. Args: model: Model to be trained criterion: Optimization criterion (loss) optimizer: Optimizer to use for training scheduler: Instance of ``torch.optim.lr_scheduler`` num_epochs: Number of epochs device: Device to run the training on. Must be 'cpu' or 'cuda' \"\"\" since = time.time() best_model_wts = copy.deepcopy(model.state_dict()) best_acc = 0.0 for epoch in range(num_epochs): print('Epoch {}/{}'.format(epoch, num_epochs - 1)) print('-' * 10) # Each epoch has a training and validation phase for phase in ['train', 'val']: if phase == 'train': model.train() # Set model to training mode else: model.eval() # Set model to evaluate mode running_loss = 0.0 running_corrects = 0 # Iterate over data. for inputs, labels in dataloaders[phase]: inputs = inputs.to(device) labels = labels.to(device) # zero the parameter gradients optimizer.zero_grad() # forward # track history if only in train with torch.set_grad_enabled(phase == 'train'): outputs = model(inputs) _, preds = torch.max(outputs, 1) loss = criterion(outputs, labels) # backward + optimize only if in training phase if phase == 'train': loss.backward() optimizer.step() # statistics running_loss += loss.item() * inputs.size(0) running_corrects += torch.sum(preds == labels.data) if phase == 'train': scheduler.step() epoch_loss = running_loss / dataset_sizes[phase] epoch_acc = running_corrects.double() / dataset_sizes[phase] print('{} Loss: {:.4f} Acc: {:.4f}'.format( phase, epoch_loss, epoch_acc)) # deep copy the model if phase == 'val' and epoch_acc > best_acc: best_acc = epoch_acc best_model_wts = copy.deepcopy(model.state_dict()) print() time_elapsed = time.time() - since print('Training complete in {:.0f}m {:.0f}s'.format( time_elapsed // 60, time_elapsed % 60)) print('Best val Acc: {:4f}'.format(best_acc)) # load best model weights model.load_state_dict(best_model_wts) return model 可视化模型预测的支持功能 通用功能可显示一些图像的预测 def visualize_model(model, rows=3, cols=3): was_training = model.training model.eval() current_row = current_col = 0 fig, ax = plt.subplots(rows, cols, figsize=(cols*2, rows*2)) with torch.no_grad(): for idx, (imgs, lbls) in enumerate(dataloaders['val']): imgs = imgs.cpu() lbls = lbls.cpu() outputs = model(imgs) _, preds = torch.max(outputs, 1) for jdx in range(imgs.size()[0]): imshow(imgs.data[jdx], ax=ax[current_row, current_col]) ax[current_row, current_col].axis('off') ax[current_row, current_col].set_title('predicted: {}'.format(class_names[preds[jdx]])) current_col += 1 if current_col >= cols: current_row += 1 current_col = 0 if current_row >= rows: model.train(mode=was_training) return model.train(mode=was_training) 第 1 部分。训练基于量化特征提取器的自定义分类器 在本部分中，您将使用“冻结”量化特征提取器，并在其顶部训练自定义分类器头。 与浮点模型不同，您不需要为量化模型设置 require_grad = False，因为它没有可训练的参数。 请参阅文档了解更多详细信息。 加载预训练的模型：在本练习中，您将使用 ResNet-18 。 import torchvision.models.quantization as models # You will need the number of filters in the `fc` for future use. # Here the size of each output sample is set to 2. # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)). model_fe = models.resnet18(pretrained=True, progress=True, quantize=True) num_ftrs = model_fe.fc.in_features 此时，您需要修改预训练模型。 该模型在开始和结束时都有量化/去量化块。 但是，由于只使用要素提取器，因此反量化层必须在线性层(头部）之前移动。 最简单的方法是将模型包装在nn.Sequential模块中。 第一步是在 ResNet 模型中隔离特征提取器。 尽管在本示例中，您被责成使用fc以外的所有图层作为特征提取器，但实际上，您可以根据需要选择任意数量的零件。 如果您也想替换一些卷积层，这将很有用。 Note 将特征提取器与量化模型的其余部分分开时，必须手动将量化器/去量化器放置在要保持量化的部分的开头和结尾。 下面的函数创建一个带有自定义头部的模型。 from torch import nn def create_combined_model(model_fe): # Step 1\\. Isolate the feature extractor. model_fe_features = nn.Sequential( model_fe.quant, # Quantize the input model_fe.conv1, model_fe.bn1, model_fe.relu, model_fe.maxpool, model_fe.layer1, model_fe.layer2, model_fe.layer3, model_fe.layer4, model_fe.avgpool, model_fe.dequant, # Dequantize the output ) # Step 2\\. Create a new \"head\" new_head = nn.Sequential( nn.Dropout(p=0.5), nn.Linear(num_ftrs, 2), ) # Step 3\\. Combine, and don't forget the quant stubs. new_model = nn.Sequential( model_fe_features, nn.Flatten(1), new_head, ) return new_model 警告 当前，量化模型只能在 CPU 上运行。 但是，可以将模型的未量化部分发送到 GPU。 import torch.optim as optim new_model = create_combined_model(model_fe) new_model = new_model.to('cpu') criterion = nn.CrossEntropyLoss() # Note that we are only training the head. optimizer_ft = optim.SGD(new_model.parameters(), lr=0.01, momentum=0.9) # Decay LR by a factor of 0.1 every 7 epochs exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1) 训练和评估 此步骤在 CPU 上大约需要 15-25 分钟。 由于量化模型只能在 CPU 上运行，因此您不能在 GPU 上运行训练。 new_model = train_model(new_model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25, device='cpu') visualize_model(new_model) plt.tight_layout() 第 2 部分。微调可量化模型 在这一部分中，我们将微调用于迁移学习的特征提取器，并对特征提取器进行量化。 请注意，在第 1 部分和第 2 部分中，特征提取器都是量化的。 不同之处在于，在第 1 部分中，我们使用了预训练的量化模型。 在这一部分中，我们将在对感兴趣的数据集进行微调之后创建一个量化的特征提取器，因此这是一种在具有量化优势的同时通过转移学习获得更好的准确性的方法。 请注意，在我们的特定示例中，训练集非常小(120 张图像），因此微调整个模型的好处并不明显。 但是，此处显示的过程将提高使用较大数据集进行传递学习的准确性。 预训练特征提取器必须是可量化的。 为确保其可量化，请执行以下步骤： 使用torch.quantization.fuse_modules熔断(Conv, BN, ReLU)，(Conv, BN)和(Conv, ReLU)。 将特征提取器与自定义顶端连接。这需要对特征提取器的输出进行反量化。 在特征提取器的适当位置插入伪量化模块，以模拟训练期间的量化。 对于步骤(1），我们使用torchvision/models/quantization中的模型，这些模型具有成员方法fuse_model。 此功能将所有conv，bn和relu模块融合在一起。 对于定制模型，这将需要使用模块列表调用torch.quantization.fuse_modules API 进行手动融合。 步骤(2）由上一节中使用的create_combined_model功能执行。 步骤(3）通过使用torch.quantization.prepare_qat来实现，它会插入伪量化模块。 在步骤(4）中，您可以开始“微调”模型，然后将其转换为完全量化的版本(步骤 5）。 要将微调模型转换为量化模型，可以调用torch.quantization.convert函数(在本例中，仅对特征提取器进行量化）。 Note 由于随机初始化，您的结果可能与本教程中显示的结果不同。 ＃注意 quantize = False model = models.resnet18(pretrained = True，progress = True，quantize = False）num_ftrs = model.fc.in_features ＃步骤 1 model.train(）model.fuse_model(）＃步骤 2 model_ft = create_combined_model(model）model_ft [0] .qconfig = torch.quantization.default_qat_qconfig＃使用默认 QAT 配置＃步骤 3 model_ft = torch.quantization.prepare_qat (model_ft，inplace = True） 优化模型 在当前教程中，整个模型都经过了微调。 通常，这将导致更高的精度。 但是，由于此处使用的训练集很小，最终导致我们过度适应了训练集。 步骤 4.微调模型 for param in model_ft.parameters(): param.requires_grad = True model_ft.to(device) # We can fine-tune on GPU if available criterion = nn.CrossEntropyLoss() # Note that we are training everything, so the learning rate is lower # Notice the smaller learning rate optimizer_ft = optim.SGD(model_ft.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.1) # Decay LR by a factor of 0.3 every several epochs exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.3) model_ft_tuned = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25, device=device) 步骤 5.转换为量化模型 from torch.quantization import convert model_ft_tuned.cpu() model_quantized_and_trained = convert(model_ft_tuned, inplace=False) 让我们看看量化模型在几张图像上的表现 visualize_model(model_quantized_and_trained) plt.ioff() plt.tight_layout() plt.show() 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"47.html":{"url":"47.html","title":"(实验）BERT 上的动态量化","keywords":"","body":"(实验）BERT 上的动态量化 原文： https://pytorch.org/tutorials/intermediate/dynamic_quantization_bert_tutorial.html 小费 为了充分利用本教程，我们建议使用此 Colab 版本。 这将使您可以尝试以下信息。 作者：黄建宇 被审核： Raghuraman Krishnamoorthi 由编辑：林 ess 琳 介绍 在本教程中，我们将动态量化应用在 BERT 模型上，紧跟 HuggingFace Transformers 示例中的 BERT 模型。 通过这一循序渐进的过程，我们将演示如何将 BERT 等众所周知的最新模型转换为动态量化模型。 BERT，或者说 Transformers 的双向嵌入表示法，是一种预训练语言表示法的新方法，可以在许多流行的自然语言处理(NLP）任务(例如问题解答，文本分类， 和别的。 可以在此处找到。 PyTorch 中的动态量化支持将权重模型的浮点模型转换为具有静态 int8 或 float16 数据类型的量化模型，并为激活提供动态量化。 当权重量化为 int8 时，激活(每批）动态量化为 int8。 在 PyTorch 中，我们有 torch.quantization.quantize_dynamic API ，它用仅动态权重的量化版本替换了指定的模块，并输出了量化模型。 我们在通用语言理解评估基准(GLUE）中演示了 Microsoft Research Paraphrase 语料库(MRPC）任务的准确性和推理性能结果。 MRPC(Dolan 和 Brockett，2005 年）是从在线新闻源中自动提取的句子对的语料库，带有人工注释，说明句子中的句子在语义上是否等效。 由于班级不平衡(正向为 68％，负向为 32％），我们遵循常规做法并报告 F1 得分。 MRPC 是用于语言对分类的常见 NLP 任务，如下所示。 1.设定 1.1 安装 PyTorch 和 HuggingFace 变压器 要开始本教程，首先请遵循 PyTorch (此处）和 HuggingFace Github Repo (此处）中的安装说明。 此外，我们还将安装 scikit-learn 软件包，因为我们将重复使用其内置的 F1 分数计算帮助器功能。 pip install sklearn pip install transformers 由于我们将使用 PyTorch 的实验部分，因此建议安装最新版本的 Torch 和 Torchvision。 您可以在此处找到有关本地安装的最新说明。 例如，要在 Mac 上安装： yes y | pip uninstall torch tochvision yes y | pip install --pre torch -f https://download.pytorch.org/whl/nightly/cu101/torch_nightly.html 1.2 导入必要的模块 在这一步中，我们将导入本教程所需的 Python 模块。 from __future__ import absolute_import, division, print_function import logging import numpy as np import os import random import sys import time import torch from argparse import Namespace from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset) from tqdm import tqdm from transformers import (BertConfig, BertForSequenceClassification, BertTokenizer,) from transformers import glue_compute_metrics as compute_metrics from transformers import glue_output_modes as output_modes from transformers import glue_processors as processors from transformers import glue_convert_examples_to_features as convert_examples_to_features # Setup logging logger = logging.getLogger(__name__) logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s - %(message)s', datefmt = '%m/%d/%Y %H:%M:%S', level = logging.WARN) logging.getLogger(\"transformers.modeling_utils\").setLevel( logging.WARN) # Reduce logging print(torch.__version__) 我们设置线程数以比较 FP32 和 INT8 性能之间的单线程性能。 在本教程的最后，用户可以通过使用右侧并行后端构建 PyTorch 来设置其他线程数量。 torch.set_num_threads(1) print(torch.__config__.parallel_info()) 1.3 了解助手功能 帮助器功能内置在转换器库中。 我们主要使用以下辅助函数：一个用于将文本示例转换为特征向量的函数； 另一个用于测量预测结果的 F1 分数。 gum_convert_examples_to_features 函数将文本转换为输入特征： 标记输入序列； 在开头插入[CLS]； 在第一句和第二句之间并在最后插入[SEP]； 生成令牌类型 ID，以指示令牌是属于第一序列还是第二序列。 gum_compute_metrics 函数的计算指标为 F1 得分，可以将其解释为精度和召回率的加权平均值，其中 F1 得分在 1 和最差处达到最佳值 得分为 0。精度和召回率对 F1 得分的相对贡献相等。 F1 分数的公式为： 1.4 下载数据集 在运行 MRPC 任务之前，我们通过运行此脚本并下载 GLUE 数据并将其解压缩到目录glue_data中。 python download_glue_data.py --data_dir='glue_data' --tasks='MRPC' 2.微调 BERT 模型 BERT 的精神是预训练语言表示形式，然后以最小的任务相关参数对各种任务上的深层双向表示形式进行微调，并获得最新的结果。 在本教程中，我们将专注于对预训练的 BERT 模型进行微调，以对 MRPC 任务上的语义等效句子对进行分类。 要为 MRPC 任务微调预训练的 BERT 模型(HuggingFace 变压器中的bert-base-uncased模型），可以按照示例中的命令进行操作： export GLUE_DIR=./glue_data export TASK_NAME=MRPC export OUT_DIR=./$TASK_NAME/ python ./run_glue.py \\ --model_type bert \\ --model_name_or_path bert-base-uncased \\ --task_name $TASK_NAME \\ --do_train \\ --do_eval \\ --do_lower_case \\ --data_dir $GLUE_DIR/$TASK_NAME \\ --max_seq_length 128 \\ --per_gpu_eval_batch_size=8 \\ --per_gpu_train_batch_size=8 \\ --learning_rate 2e-5 \\ --num_train_epochs 3.0 \\ --save_steps 100000 \\ --output_dir $OUT_DIR 我们在此处为 MRPC 任务提供了经过微调的 BERT 模型。 为了节省时间，您可以将模型文件(〜400 MB）直接下载到本地文件夹$OUT_DIR中。 2.1 设置全局配置 在这里，我们设置了全局配置，用于评估动态量化前后的微调 BERT 模型。 configs = Namespace() # The output directory for the fine-tuned model, $OUT_DIR. configs.output_dir = \"./MRPC/\" # The data directory for the MRPC task in the GLUE benchmark, $GLUE_DIR/$TASK_NAME. configs.data_dir = \"./glue_data/MRPC\" # The model name or path for the pre-trained model. configs.model_name_or_path = \"bert-base-uncased\" # The maximum length of an input sequence configs.max_seq_length = 128 # Prepare GLUE task. configs.task_name = \"MRPC\".lower() configs.processor = processors[configs.task_name]() configs.output_mode = output_modes[configs.task_name] configs.label_list = configs.processor.get_labels() configs.model_type = \"bert\".lower() configs.do_lower_case = True # Set the device, batch size, topology, and caching flags. configs.device = \"cpu\" configs.per_gpu_eval_batch_size = 8 configs.n_gpu = 0 configs.local_rank = -1 configs.overwrite_cache = False # Set random seed for reproducibility. def set_seed(seed): random.seed(seed) np.random.seed(seed) torch.manual_seed(seed) set_seed(42) 2.2 加载微调的 BERT 模型 我们从configs.output_dir加载标记器和经过微调的 BERT 序列分类器模型(FP32）。 tokenizer = BertTokenizer.from_pretrained( configs.output_dir, do_lower_case=configs.do_lower_case) model = BertForSequenceClassification.from_pretrained(configs.output_dir) model.to(configs.device) 2.3 定义标记化和评估功能 我们重用了 Huggingface 中的标记化和评估函数。 # coding=utf-8 # Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team. # Copyright (c) 2018, NVIDIA CORPORATION. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. def evaluate(args, model, tokenizer, prefix=\"\"): # Loop to handle MNLI double evaluation (matched, mis-matched) eval_task_names = (\"mnli\", \"mnli-mm\") if args.task_name == \"mnli\" else (args.task_name,) eval_outputs_dirs = (args.output_dir, args.output_dir + '-MM') if args.task_name == \"mnli\" else (args.output_dir,) results = {} for eval_task, eval_output_dir in zip(eval_task_names, eval_outputs_dirs): eval_dataset = load_and_cache_examples(args, eval_task, tokenizer, evaluate=True) if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]: os.makedirs(eval_output_dir) args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu) # Note that DistributedSampler samples randomly eval_sampler = SequentialSampler(eval_dataset) if args.local_rank == -1 else DistributedSampler(eval_dataset) eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size) # multi-gpu eval if args.n_gpu > 1: model = torch.nn.DataParallel(model) # Eval! logger.info(\"***** Running evaluation {} *****\".format(prefix)) logger.info(\" Num examples = %d\", len(eval_dataset)) logger.info(\" Batch size = %d\", args.eval_batch_size) eval_loss = 0.0 nb_eval_steps = 0 preds = None out_label_ids = None for batch in tqdm(eval_dataloader, desc=\"Evaluating\"): model.eval() batch = tuple(t.to(args.device) for t in batch) with torch.no_grad(): inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[3]} if args.model_type != 'distilbert': inputs['token_type_ids'] = batch[2] if args.model_type in ['bert', 'xlnet'] else None # XLM, DistilBERT and RoBERTa don't use segment_ids outputs = model(**inputs) tmp_eval_loss, logits = outputs[:2] eval_loss += tmp_eval_loss.mean().item() nb_eval_steps += 1 if preds is None: preds = logits.detach().cpu().numpy() out_label_ids = inputs['labels'].detach().cpu().numpy() else: preds = np.append(preds, logits.detach().cpu().numpy(), axis=0) out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0) eval_loss = eval_loss / nb_eval_steps if args.output_mode == \"classification\": preds = np.argmax(preds, axis=1) elif args.output_mode == \"regression\": preds = np.squeeze(preds) result = compute_metrics(eval_task, preds, out_label_ids) results.update(result) output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\") with open(output_eval_file, \"w\") as writer: logger.info(\"***** Eval results {} *****\".format(prefix)) for key in sorted(result.keys()): logger.info(\" %s = %s\", key, str(result[key])) writer.write(\"%s = %s\\n\" % (key, str(result[key]))) return results def load_and_cache_examples(args, task, tokenizer, evaluate=False): if args.local_rank not in [-1, 0] and not evaluate: torch.distributed.barrier() # Make sure only the first process in distributed training process the dataset, and the others will use the cache processor = processors[task]() output_mode = output_modes[task] # Load data features from cache or dataset file cached_features_file = os.path.join(args.data_dir, 'cached_{}_{}_{}_{}'.format( 'dev' if evaluate else 'train', list(filter(None, args.model_name_or_path.split('/'))).pop(), str(args.max_seq_length), str(task))) if os.path.exists(cached_features_file) and not args.overwrite_cache: logger.info(\"Loading features from cached file %s\", cached_features_file) features = torch.load(cached_features_file) else: logger.info(\"Creating features from dataset file at %s\", args.data_dir) label_list = processor.get_labels() if task in ['mnli', 'mnli-mm'] and args.model_type in ['roberta']: # HACK(label indices are swapped in RoBERTa pretrained model) label_list[1], label_list[2] = label_list[2], label_list[1] examples = processor.get_dev_examples(args.data_dir) if evaluate else processor.get_train_examples(args.data_dir) features = convert_examples_to_features(examples, tokenizer, label_list=label_list, max_length=args.max_seq_length, output_mode=output_mode, pad_on_left=bool(args.model_type in ['xlnet']), # pad on the left for xlnet pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0], pad_token_segment_id=4 if args.model_type in ['xlnet'] else 0, ) if args.local_rank in [-1, 0]: logger.info(\"Saving features into cached file %s\", cached_features_file) torch.save(features, cached_features_file) if args.local_rank == 0 and not evaluate: torch.distributed.barrier() # Make sure only the first process in distributed training process the dataset, and the others will use the cache # Convert to Tensors and build dataset all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long) all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long) all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long) if output_mode == \"classification\": all_labels = torch.tensor([f.label for f in features], dtype=torch.long) elif output_mode == \"regression\": all_labels = torch.tensor([f.label for f in features], dtype=torch.float) dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels) return dataset 3.应用动态量化 我们在模型上调用torch.quantization.quantize_dynamic，将动态量化应用于 HuggingFace BERT 模型。 特别， 我们指定要对模型中的 torch.nn.Linear 模块进行量化； 我们指定希望将权重转换为量化的 int8 值。 quantized_model = torch.quantization.quantize_dynamic( model, {torch.nn.Linear}, dtype=torch.qint8 ) print(quantized_model) 3.1 检查型号 我们首先检查一下模型尺寸。 我们可以看到模型大小显着减少(FP32 总大小：438 MB； INT8 总大小：181 MB）： def print_size_of_model(model): torch.save(model.state_dict(), \"temp.p\") print('Size (MB):', os.path.getsize(\"temp.p\")/1e6) os.remove('temp.p') print_size_of_model(model) print_size_of_model(quantized_model) 本教程中使用的 BERT 模型(bert-base-uncased）的词汇量 V 为 30522。在嵌入量为 768 的情况下，单词嵌入表的总大小为〜4(字节/ FP32） 30522 768 = 90 MB 。 因此，借助量化，非嵌入表部分的模型大小从 350 MB(FP32 模型）减少到 90 MB(INT8 模型）。 3.2 评估推理的准确性和时间 接下来，我们比较一下动态量化后原始 FP32 模型和 INT8 模型之间的推断时间以及评估精度。 def time_model_evaluation(model, configs, tokenizer): eval_start_time = time.time() result = evaluate(configs, model, tokenizer, prefix=\"\") eval_end_time = time.time() eval_duration_time = eval_end_time - eval_start_time print(result) print(\"Evaluate total time (seconds): {0:.1f}\".format(eval_duration_time)) # Evaluate the original FP32 BERT model time_model_evaluation(model, configs, tokenizer) # Evaluate the INT8 BERT model after the dynamic quantization time_model_evaluation(quantized_model, configs, tokenizer) 在 MacBook Pro 上本地运行此程序，无需进行量化，推理(对于 MRPC 数据集中的所有 408 个示例）大约需要 160 秒，而进行量化则只需大约 90 秒。 我们总结了在 Macbook Pro 上运行量化 BERT 模型推断的结果，如下所示： | Prec | F1 score | Model Size | 1 thread | 4 threads | | FP32 | 0.9019 | 438 MB | 160 sec | 85 sec | | INT8 | 0.8953 | 181 MB | 90 sec | 46 sec | 在 MRPC 任务的微调 BERT 模型上应用训练后动态量化后，我们的 F1 分数准确性为 0.6％。 作为比较，在的最新论文(表 1）中，通过应用训练后动态量化，可以达到 0.8788；通过应用量化感知训练，可以达到 0.8956。 主要区别在于我们在 PyTorch 中支持非对称量化，而该论文仅支持对称量化。 请注意，在本教程中，为了进行单线程比较，我们将线程数设置为 1。 对于这些量化的 INT8 运算符，我们还支持运算内并行化。 用户现在可以通过torch.set_num_threads(N)设置多线程(N是内部运算并行线程的数量）。 启用帧内并行支持的一项初步要求是使用正确的后端(例如 OpenMP，Native 或 TBB）构建 PyTorch。 您可以使用torch.__config__.parallel_info()检查并行化设置。 在使用 PyTorch 和本机后端进行并行化的同一台 MacBook Pro 上，我们可以获得大约 46 秒的时间来处理 MRPC 数据集的评估。 3.3 序列化量化模型 我们可以序列化并保存量化模型，以备将来使用。 quantized_output_dir = configs.output_dir + \"quantized/\" if not os.path.exists(quantized_output_dir): os.makedirs(quantized_output_dir) quantized_model.save_pretrained(quantized_output_dir) 结论 在本教程中，我们演示了如何演示如何将 BERT 等著名的最新 NLP 模型转换为动态量化模型。 动态量化可以减小模型的大小，而对准确性的影响有限。 谢谢阅读！ 与往常一样，我们欢迎您提供任何反馈，因此，如果有任何问题，请在此处创建一个问题。 参考文献 [1] J.Devlin，M。Chang，K。Lee 和 K. Toutanova， BERT：用于语言理解的深度双向变压器的预训练(2018）。 [2] HuggingFace 变压器。 [3] O. Zafrir，G。Boudoukh，P。Izsak 和 M. Wasserblat(2019 年）。 Q8BERT：量化的 8 位 BERT 。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"48.html":{"url":"48.html","title":"修剪教程","keywords":"","body":"修剪教程 原文： https://pytorch.org/tutorials/intermediate/pruning_tutorial.html 注意 单击此处的下载完整的示例代码 作者： Michela Paganini 最新的深度学习技术依赖于难以部署的过度参数化模型。 相反，已知生物神经网络使用有效的稀疏连通性。 为了减少内存，电池和硬件消耗，同时又不牺牲精度，在设备上部署轻量级模型并通过私有设备内计算来确保私密性，确定通过减少模型中参数数量来压缩模型的最佳技术很重要。 在研究方面，修剪用于研究参数过度配置和参数不足网络之间学习动态的差异，以研究幸运稀疏子网络和初始化(“ 彩票”）作为破坏性对象的作用。 神经结构搜索技术等等。 在本教程中，您将学习如何使用torch.nn.utils.prune稀疏神经网络，以及如何扩展它以实现自己的自定义修剪技术。 要求 \"torch&gt;=1.4.0a0+8e8a5e0\" import torch from torch import nn import torch.nn.utils.prune as prune import torch.nn.functional as F 建立模型 在本教程中，我们使用 LeCun 等人，1998 年的 LeNet 体系结构。 device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") class LeNet(nn.Module): def __init__(self): super(LeNet, self).__init__() # 1 input image channel, 6 output channels, 3x3 square conv kernel self.conv1 = nn.Conv2d(1, 6, 3) self.conv2 = nn.Conv2d(6, 16, 3) self.fc1 = nn.Linear(16 * 5 * 5, 120) # 5x5 image dimension self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = x.view(-1, int(x.nelement() / x.shape[0])) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x model = LeNet().to(device=device) 检查模块 让我们检查一下 LeNet 模型中的(未经修剪的）conv1层。 目前它将包含两个参数weight和bias，并且没有缓冲区。 module = model.conv1 print(list(module.named_parameters())) 出： [('weight', Parameter containing: tensor([[[[ 0.3161, -0.2212, 0.0417], [ 0.2488, 0.2415, 0.2071], [-0.2412, -0.2400, -0.2016]]], [[[ 0.0419, 0.3322, -0.2106], [ 0.1776, -0.1845, -0.3134], [-0.0708, 0.1921, 0.3095]]], [[[-0.2070, 0.0723, 0.2876], [ 0.2209, 0.2077, 0.2369], [ 0.2108, 0.0861, -0.2279]]], [[[-0.2799, -0.1527, -0.0388], [-0.2043, 0.1220, 0.1032], [-0.0755, 0.1281, 0.1077]]], [[[ 0.2035, 0.2245, -0.1129], [ 0.3257, -0.0385, -0.0115], [-0.3146, -0.2145, -0.1947]]], [[[-0.1426, 0.2370, -0.1089], [-0.2491, 0.1282, 0.1067], [ 0.2159, -0.1725, 0.0723]]]], device='cuda:0', requires_grad=True)), ('bias', Parameter containing: tensor([-0.1214, -0.0749, -0.2656, -0.1519, -0.1021, 0.1425], device='cuda:0', requires_grad=True))] print(list(module.named_buffers())) Out: [] 修剪模块 要修剪模块(在此示例中，为 LeNet 架构的conv1层），请首先从torch.nn.utils.prune中可用的那些技术中选择一种修剪技术(或通过子类化BasePruningMethod实现您自己的）。 然后，指定模块和该模块中要修剪的参数的名称。 最后，使用所选修剪技术所需的适当关键字参数，指定修剪参数。 在此示例中，我们将在conv1层中名为weight的参数中随机修剪 30％的连接。 模块作为第一个参数传递给函数； name使用其字符串标识符在该模块内标识参数； amount表示与修剪的连接百分比(如果它是介于 0 和 1 之间的浮点数），或者表示与修剪的连接的绝对数量(如果它是非负整数）。 prune.random_unstructured(module, name=\"weight\", amount=0.3) 修剪是通过从参数中删除weight并将其替换为名为weight_orig的新参数(即，将\"_orig\"附加到初始参数name）来进行的。 weight_orig存储未修剪的张量版本。 bias未修剪，因此它将保持完整。 print(list(module.named_parameters())) Out: [('bias', Parameter containing: tensor([-0.1214, -0.0749, -0.2656, -0.1519, -0.1021, 0.1425], device='cuda:0', requires_grad=True)), ('weight_orig', Parameter containing: tensor([[[[ 0.3161, -0.2212, 0.0417], [ 0.2488, 0.2415, 0.2071], [-0.2412, -0.2400, -0.2016]]], [[[ 0.0419, 0.3322, -0.2106], [ 0.1776, -0.1845, -0.3134], [-0.0708, 0.1921, 0.3095]]], [[[-0.2070, 0.0723, 0.2876], [ 0.2209, 0.2077, 0.2369], [ 0.2108, 0.0861, -0.2279]]], [[[-0.2799, -0.1527, -0.0388], [-0.2043, 0.1220, 0.1032], [-0.0755, 0.1281, 0.1077]]], [[[ 0.2035, 0.2245, -0.1129], [ 0.3257, -0.0385, -0.0115], [-0.3146, -0.2145, -0.1947]]], [[[-0.1426, 0.2370, -0.1089], [-0.2491, 0.1282, 0.1067], [ 0.2159, -0.1725, 0.0723]]]], device='cuda:0', requires_grad=True))] 通过以上选择的修剪技术生成的修剪掩码将保存为名为weight_mask的模块缓冲区(即，将\"_mask\"附加到初始参数name）。 print(list(module.named_buffers())) Out: [('weight_mask', tensor([[[[0., 1., 0.], [1., 0., 0.], [1., 1., 1.]]], [[[1., 0., 1.], [1., 1., 0.], [1., 0., 1.]]], [[[1., 0., 0.], [0., 1., 1.], [1., 1., 1.]]], [[[1., 0., 0.], [1., 1., 1.], [1., 1., 1.]]], [[[1., 0., 1.], [1., 1., 1.], [0., 1., 1.]]], [[[1., 1., 1.], [1., 1., 0.], [1., 1., 0.]]]], device='cuda:0'))] 为了使前向通过不更改即可工作，需要存在weight属性。 torch.nn.utils.prune中实现的修剪技术计算权重的修剪版本(通过将掩码与原始参数组合）并将其存储在属性weight中。 注意，这不再是module的参数，现在只是一个属性。 print(module.weight) Out: tensor([[[[ 0.0000, -0.2212, 0.0000], [ 0.2488, 0.0000, 0.0000], [-0.2412, -0.2400, -0.2016]]], [[[ 0.0419, 0.0000, -0.2106], [ 0.1776, -0.1845, -0.0000], [-0.0708, 0.0000, 0.3095]]], [[[-0.2070, 0.0000, 0.0000], [ 0.0000, 0.2077, 0.2369], [ 0.2108, 0.0861, -0.2279]]], [[[-0.2799, -0.0000, -0.0000], [-0.2043, 0.1220, 0.1032], [-0.0755, 0.1281, 0.1077]]], [[[ 0.2035, 0.0000, -0.1129], [ 0.3257, -0.0385, -0.0115], [-0.0000, -0.2145, -0.1947]]], [[[-0.1426, 0.2370, -0.1089], [-0.2491, 0.1282, 0.0000], [ 0.2159, -0.1725, 0.0000]]]], device='cuda:0', grad_fn=) 最后，使用 PyTorch 的forward_pre_hooks在每次向前传递之前应用修剪。 具体来说，当修剪module时(如我们在此处所做的那样），它将为与之关联的每个参数获取forward_pre_hook进行修剪。 在这种情况下，由于到目前为止我们只修剪了名称为weight的原始参数，因此只会出现一个钩子。 print(module._forward_pre_hooks) Out: OrderedDict([(0, )]) 为了完整起见，我们现在也可以修剪bias，以查看module的参数，缓冲区，挂钩和属性如何变化。 仅出于尝试另一种修剪技术的目的，在此我们按 L1 范数修剪偏差中的 3 个最小条目，如l1_unstructured修剪功能中所实现的。 prune.l1_unstructured(module, name=\"bias\", amount=3) 现在，我们希望命名的参数同时包含weight_orig(从前）和bias_orig。 缓冲区将包括weight_mask和bias_mask。 两个张量的修剪版本将作为模块属性存在，并且该模块现在将具有两个forward_pre_hooks。 print(list(module.named_parameters())) Out: [('weight_orig', Parameter containing: tensor([[[[ 0.3161, -0.2212, 0.0417], [ 0.2488, 0.2415, 0.2071], [-0.2412, -0.2400, -0.2016]]], [[[ 0.0419, 0.3322, -0.2106], [ 0.1776, -0.1845, -0.3134], [-0.0708, 0.1921, 0.3095]]], [[[-0.2070, 0.0723, 0.2876], [ 0.2209, 0.2077, 0.2369], [ 0.2108, 0.0861, -0.2279]]], [[[-0.2799, -0.1527, -0.0388], [-0.2043, 0.1220, 0.1032], [-0.0755, 0.1281, 0.1077]]], [[[ 0.2035, 0.2245, -0.1129], [ 0.3257, -0.0385, -0.0115], [-0.3146, -0.2145, -0.1947]]], [[[-0.1426, 0.2370, -0.1089], [-0.2491, 0.1282, 0.1067], [ 0.2159, -0.1725, 0.0723]]]], device='cuda:0', requires_grad=True)), ('bias_orig', Parameter containing: tensor([-0.1214, -0.0749, -0.2656, -0.1519, -0.1021, 0.1425], device='cuda:0', requires_grad=True))] print(list(module.named_buffers())) Out: [('weight_mask', tensor([[[[0., 1., 0.], [1., 0., 0.], [1., 1., 1.]]], [[[1., 0., 1.], [1., 1., 0.], [1., 0., 1.]]], [[[1., 0., 0.], [0., 1., 1.], [1., 1., 1.]]], [[[1., 0., 0.], [1., 1., 1.], [1., 1., 1.]]], [[[1., 0., 1.], [1., 1., 1.], [0., 1., 1.]]], [[[1., 1., 1.], [1., 1., 0.], [1., 1., 0.]]]], device='cuda:0')), ('bias_mask', tensor([0., 0., 1., 1., 0., 1.], device='cuda:0'))] print(module.bias) Out: tensor([-0.0000, -0.0000, -0.2656, -0.1519, -0.0000, 0.1425], device='cuda:0', grad_fn=) print(module._forward_pre_hooks) Out: OrderedDict([(0, ), (1, )]) 迭代修剪 一个模块中的同一参数可以被多次修剪，各种修剪调用的效果等于串联应用的各种蒙版的组合。 PruningContainer的compute_mask方法可处理新遮罩与旧遮罩的组合。 例如，假设我们现在要进一步修剪module.weight，这一次是使用沿着张量的第 0 轴的结构化修剪(第 0 轴对应于卷积层的输出通道，并且conv1的维数为 6） ，基于渠道的 L2 规范。 这可以通过ln_structured和n=2和dim=0功能来实现。 prune.ln_structured(module, name=\"weight\", amount=0.5, n=2, dim=0) # As we can verify, this will zero out all the connections corresponding to # 50% (3 out of 6) of the channels, while preserving the action of the # previous mask. print(module.weight) Out: tensor([[[[ 0.0000, -0.2212, 0.0000], [ 0.2488, 0.0000, 0.0000], [-0.2412, -0.2400, -0.2016]]], [[[ 0.0000, 0.0000, -0.0000], [ 0.0000, -0.0000, -0.0000], [-0.0000, 0.0000, 0.0000]]], [[[-0.2070, 0.0000, 0.0000], [ 0.0000, 0.2077, 0.2369], [ 0.2108, 0.0861, -0.2279]]], [[[-0.0000, -0.0000, -0.0000], [-0.0000, 0.0000, 0.0000], [-0.0000, 0.0000, 0.0000]]], [[[ 0.2035, 0.0000, -0.1129], [ 0.3257, -0.0385, -0.0115], [-0.0000, -0.2145, -0.1947]]], [[[-0.0000, 0.0000, -0.0000], [-0.0000, 0.0000, 0.0000], [ 0.0000, -0.0000, 0.0000]]]], device='cuda:0', grad_fn=) 现在，对应的钩子将为torch.nn.utils.prune.PruningContainer类型，并将存储应用于weight参数的修剪历史。 for hook in module._forward_pre_hooks.values(): if hook._tensor_name == \"weight\": # select out the correct hook break print(list(hook)) # pruning history in the container Out: [, ] 序列化修剪的模型 所有相关的张量，包括掩码缓冲区和用于计算修剪的张量的原始参数，都存储在模型的state_dict中，因此可以根据需要轻松地序列化和保存。 print(model.state_dict().keys()) Out: odict_keys(['conv1.weight_orig', 'conv1.bias_orig', 'conv1.weight_mask', 'conv1.bias_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']) 删除修剪重新参数化 要使修剪永久化，请删除weight_orig和weight_mask的重新参数化，然后删除forward_pre_hook，我们可以使用torch.nn.utils.prune的remove功能。 请注意，这不会撤消修剪，好像从未发生过。 它只是通过将参数weight重新分配为模型参数(修剪后的版本）来使其永久不变。 删除重新参数化之前： print(list(module.named_parameters())) Out: [('weight_orig', Parameter containing: tensor([[[[ 0.3161, -0.2212, 0.0417], [ 0.2488, 0.2415, 0.2071], [-0.2412, -0.2400, -0.2016]]], [[[ 0.0419, 0.3322, -0.2106], [ 0.1776, -0.1845, -0.3134], [-0.0708, 0.1921, 0.3095]]], [[[-0.2070, 0.0723, 0.2876], [ 0.2209, 0.2077, 0.2369], [ 0.2108, 0.0861, -0.2279]]], [[[-0.2799, -0.1527, -0.0388], [-0.2043, 0.1220, 0.1032], [-0.0755, 0.1281, 0.1077]]], [[[ 0.2035, 0.2245, -0.1129], [ 0.3257, -0.0385, -0.0115], [-0.3146, -0.2145, -0.1947]]], [[[-0.1426, 0.2370, -0.1089], [-0.2491, 0.1282, 0.1067], [ 0.2159, -0.1725, 0.0723]]]], device='cuda:0', requires_grad=True)), ('bias_orig', Parameter containing: tensor([-0.1214, -0.0749, -0.2656, -0.1519, -0.1021, 0.1425], device='cuda:0', requires_grad=True))] print(list(module.named_buffers())) Out: [('weight_mask', tensor([[[[0., 1., 0.], [1., 0., 0.], [1., 1., 1.]]], [[[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]], [[[1., 0., 0.], [0., 1., 1.], [1., 1., 1.]]], [[[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]], [[[1., 0., 1.], [1., 1., 1.], [0., 1., 1.]]], [[[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]]], device='cuda:0')), ('bias_mask', tensor([0., 0., 1., 1., 0., 1.], device='cuda:0'))] print(module.weight) Out: tensor([[[[ 0.0000, -0.2212, 0.0000], [ 0.2488, 0.0000, 0.0000], [-0.2412, -0.2400, -0.2016]]], [[[ 0.0000, 0.0000, -0.0000], [ 0.0000, -0.0000, -0.0000], [-0.0000, 0.0000, 0.0000]]], [[[-0.2070, 0.0000, 0.0000], [ 0.0000, 0.2077, 0.2369], [ 0.2108, 0.0861, -0.2279]]], [[[-0.0000, -0.0000, -0.0000], [-0.0000, 0.0000, 0.0000], [-0.0000, 0.0000, 0.0000]]], [[[ 0.2035, 0.0000, -0.1129], [ 0.3257, -0.0385, -0.0115], [-0.0000, -0.2145, -0.1947]]], [[[-0.0000, 0.0000, -0.0000], [-0.0000, 0.0000, 0.0000], [ 0.0000, -0.0000, 0.0000]]]], device='cuda:0', grad_fn=) 删除重新参数化后： prune.remove(module, 'weight') print(list(module.named_parameters())) Out: [('bias_orig', Parameter containing: tensor([-0.1214, -0.0749, -0.2656, -0.1519, -0.1021, 0.1425], device='cuda:0', requires_grad=True)), ('weight', Parameter containing: tensor([[[[ 0.0000, -0.2212, 0.0000], [ 0.2488, 0.0000, 0.0000], [-0.2412, -0.2400, -0.2016]]], [[[ 0.0000, 0.0000, -0.0000], [ 0.0000, -0.0000, -0.0000], [-0.0000, 0.0000, 0.0000]]], [[[-0.2070, 0.0000, 0.0000], [ 0.0000, 0.2077, 0.2369], [ 0.2108, 0.0861, -0.2279]]], [[[-0.0000, -0.0000, -0.0000], [-0.0000, 0.0000, 0.0000], [-0.0000, 0.0000, 0.0000]]], [[[ 0.2035, 0.0000, -0.1129], [ 0.3257, -0.0385, -0.0115], [-0.0000, -0.2145, -0.1947]]], [[[-0.0000, 0.0000, -0.0000], [-0.0000, 0.0000, 0.0000], [ 0.0000, -0.0000, 0.0000]]]], device='cuda:0', requires_grad=True))] print(list(module.named_buffers())) Out: [('bias_mask', tensor([0., 0., 1., 1., 0., 1.], device='cuda:0'))] 修剪模型中的多个参数 通过指定所需的修剪技术和参数，我们可以轻松地修剪网络中的多个张量，也许根据它们的类型，如在本示例中将看到的那样。 new_model = LeNet() for name, module in new_model.named_modules(): # prune 20% of connections in all 2D-conv layers if isinstance(module, torch.nn.Conv2d): prune.l1_unstructured(module, name='weight', amount=0.2) # prune 40% of connections in all linear layers elif isinstance(module, torch.nn.Linear): prune.l1_unstructured(module, name='weight', amount=0.4) print(dict(new_model.named_buffers()).keys()) # to verify that all masks exist Out: dict_keys(['conv1.weight_mask', 'conv2.weight_mask', 'fc1.weight_mask', 'fc2.weight_mask', 'fc3.weight_mask']) 全球修剪 到目前为止，我们仅研究了通常被称为“局部”修剪的方法，即通过比较每个条目的统计信息(权重，激活度，梯度等）来逐一修剪模型中的张量的做法。 到该张量中的其他条目。 但是，一种常见且可能更强大的技术是通过删除(例如）删除整个模型中最低的 20％的连接，而不是删除每一层中最低的 20％的连接来一次修剪模型。 这很可能导致每个层的修剪百分比不同。 让我们看看如何使用torch.nn.utils.prune中的global_unstructured进行操作。 model = LeNet() parameters_to_prune = ( (model.conv1, 'weight'), (model.conv2, 'weight'), (model.fc1, 'weight'), (model.fc2, 'weight'), (model.fc3, 'weight'), ) prune.global_unstructured( parameters_to_prune, pruning_method=prune.L1Unstructured, amount=0.2, ) 现在，我们可以检查在每个修剪参数中引起的稀疏性，该稀疏性将不等于每层中的 20％。 但是，全球稀疏度将(大约）为 20％。 print( \"Sparsity in conv1.weight: {:.2f}%\".format( 100\\. * float(torch.sum(model.conv1.weight == 0)) / float(model.conv1.weight.nelement()) ) ) print( \"Sparsity in conv2.weight: {:.2f}%\".format( 100\\. * float(torch.sum(model.conv2.weight == 0)) / float(model.conv2.weight.nelement()) ) ) print( \"Sparsity in fc1.weight: {:.2f}%\".format( 100\\. * float(torch.sum(model.fc1.weight == 0)) / float(model.fc1.weight.nelement()) ) ) print( \"Sparsity in fc2.weight: {:.2f}%\".format( 100\\. * float(torch.sum(model.fc2.weight == 0)) / float(model.fc2.weight.nelement()) ) ) print( \"Sparsity in fc3.weight: {:.2f}%\".format( 100\\. * float(torch.sum(model.fc3.weight == 0)) / float(model.fc3.weight.nelement()) ) ) print( \"Global sparsity: {:.2f}%\".format( 100\\. * float( torch.sum(model.conv1.weight == 0) + torch.sum(model.conv2.weight == 0) + torch.sum(model.fc1.weight == 0) + torch.sum(model.fc2.weight == 0) + torch.sum(model.fc3.weight == 0) ) / float( model.conv1.weight.nelement() + model.conv2.weight.nelement() + model.fc1.weight.nelement() + model.fc2.weight.nelement() + model.fc3.weight.nelement() ) ) ) Out: Sparsity in conv1.weight: 7.41% Sparsity in conv2.weight: 9.49% Sparsity in fc1.weight: 22.00% Sparsity in fc2.weight: 12.28% Sparsity in fc3.weight: 9.76% Global sparsity: 20.00% 使用自定义修剪功能扩展torch.nn.utils.prune 要实现自己的修剪功能，您可以通过继承BasePruningMethod基类来扩展nn.utils.prune模块，这与所有其他修剪方法一样。 基类为您实现以下方法：__call__，apply_mask，apply，prune和remove。 除了某些特殊情况外，您不必为新的修剪技术重新实现这些方法。 但是，您将必须实现__init__(构造函数）和compute_mask(有关如何根据修剪技术的逻辑为给定张量计算掩码的说明）。 另外，您将必须指定此技术实现的修剪类型(支持的选项为global，structured和unstructured）。 需要确定在迭代应用修剪的情况下如何组合蒙版。 换句话说，当修剪预修剪的参数时，当前的修剪技术应作用于参数的未修剪部分。 指定PRUNING_TYPE将使PruningContainer(处理修剪蒙版的迭代应用）正确识别要修剪的参数。 例如，假设您要实施一种修剪技术，以修剪张量中的所有其他条目(或者-如果先前已修剪过张量，则在张量的其余未修剪部分中）。 这将是PRUNING_TYPE='unstructured'，因为它作用于层中的单个连接，而不作用于整个单元/通道('structured'），或作用于不同的参数('global'）。 class FooBarPruningMethod(prune.BasePruningMethod): \"\"\"Prune every other entry in a tensor \"\"\" PRUNING_TYPE = 'unstructured' def compute_mask(self, t, default_mask): mask = default_mask.clone() mask.view(-1)[::2] = 0 return mask 现在，要将其应用于nn.Module中的参数，还应该提供一个简单的函数来实例化该方法并将其应用。 def foobar_unstructured(module, name): \"\"\"Prunes tensor corresponding to parameter called `name` in `module` by removing every other entry in the tensors. Modifies module in place (and also return the modified module) by: 1) adding a named buffer called `name+'_mask'` corresponding to the binary mask applied to the parameter `name` by the pruning method. The parameter `name` is replaced by its pruned version, while the original (unpruned) parameter is stored in a new parameter named `name+'_orig'`. Args: module (nn.Module): module containing the tensor to prune name (string): parameter name within `module` on which pruning will act. Returns: module (nn.Module): modified (i.e. pruned) version of the input module Examples: >>> m = nn.Linear(3, 4) >>> foobar_unstructured(m, name='bias') \"\"\" FooBarPruningMethod.apply(module, name) return module 试试吧！ model = LeNet() foobar_unstructured(model.fc3, name='bias') print(model.fc3.bias_mask) Out: tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1.]) 脚本的总运行时间：(0 分钟 0.146 秒） Download Python source code: pruning_tutorial.py Download Jupyter notebook: pruning_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"50.html":{"url":"50.html","title":"使用 PyTorch C ++前端","keywords":"","body":"使用 PyTorch C ++前端 原文： https://pytorch.org/tutorials/advanced/cpp_frontend.html PyTorch C ++前端是 PyTorch 机器学习框架的纯 C ++接口。 虽然 PyTorch 的主要接口自然是 Python，但此 Python API 位于大量的 C ++代码库之上，提供基本的数据结构和功能，例如张量和自动微分。 C ++前端公开了纯 C ++ 11 API，该 API 使用机器学习训练和推理所需的工具扩展了此基础 C ++代码库。 这包括用于神经网络建模的通用组件的内置集合； 使用自定义模块扩展此集合的 API； 一个流行的优化算法库，例如随机梯度下降； 具有 API 的并行数据加载器，用于定义和加载数据集； 序列化例程等。 本教程将引导您完成使用 C ++前端训练模型的端到端示例。 具体来说，我们将训练 DCGAN (一种生成模型），以生成 MNIST 数字的图像。 虽然从概念上讲是一个简单的示例，但它足以使您对 PyTorch C ++前端有个大概的了解，并可以满足训练更复杂模型的胃口。 我们将从一些鼓舞人心的词开始，说明您为什么要使用 C ++前端，然后直接深入定义和训练我们的模型。 小费 观看来自 CppCon 2018 的闪电演讲，获得有关 C ++前端的快速(幽默）演示。 Tip 本笔记概述了 C ++前端的组件和设计原理。 Tip 有关 PyTorch C ++生态系统的文档，请访问 https://pytorch.org/cppdocs 。 您可以在此处找到高级描述以及 API 级文档。 动机 在我们开始 GAN 和 MNIST 数字的激动人心的旅程之前，让我们退后一步，讨论为什么您要使用 C ++前端而不是 Python。 我们(PyTorch 团队）创建了 C ++前端，以便能够在无法使用 Python 或根本不适合该工具的环境中进行研究。 此类环境的示例包括： 低延迟系统：您可能希望在具有高每秒帧数和低延迟要求的纯 C ++游戏引擎中进行强化学习研究。 与 Python 库相比，使用纯 C ++库更适合这种环境。 由于 Python 解释器的缓慢性，Python 可能根本无法处理。 高度多线程环境：由于全局解释器锁定(GIL），Python 一次不能运行多个系统线程。 并行处理是一种替代方法，但可扩展性不强，并且存在很多缺点。 C ++没有这样的约束，线程易于使用和创建。 需要重型并行化的模型，例如深层神经进化中使用的模型，可以从中受益。 现有的 C ++代码库：您可能是现有 C ++应用程序的所有者，其工作范围从后端服务器中的网页服务到照片编辑软件中的 3D 图形渲染，并且希望将机器学习方法集成到您的系统中。 C ++前端使您可以继续使用 C ++，并避免在 Python 和 C ++之间来回绑定的麻烦，同时保留了传统 PyTorch(Python）体验的大部分灵活性和直观性。 C ++前端无意与 Python 前端竞争。 它是对它的补充。 我们知道研究人员和工程师都喜欢 PyTorch，因为它具有简单，灵活和直观的 API。 我们的目标是确保您可以在所有可能的环境(包括上述环境）中利用这些核心设计原则。 如果这些情况之一很好地描述了您的用例，或者您只是感兴趣或好奇，请在以下段落中继续研究 C ++前端。 Tip C ++前端试图提供一个与 Python 前端尽可能接近的 API。 如果您对 Python 前端有丰富的经验，并且问过自己“我如何使用 C ++前端 X？”，请像在 Python 中那样编写代码，并且大多数情况下，相同的函数和方法都可以在 C ++中使用。 就像在 Python 中一样(只记得用双冒号替换点）。 编写基本应用程序 首先，编写一个最小的 C ++应用程序，以验证我们是否在同一页面上了解我们的设置和构建环境。 首先，您需要获取 LibTorch 发行版的副本-我们现成的 zip 归档文件，其中打包了使用 C ++前端所需的所有相关标头，库和 CMake 构建文件。 LibTorch 发行版可在 PyTorch 网站上下载，适用于 Linux，MacOS 和 Windows。 本教程的其余部分将假定基本的 Ubuntu Linux 环境，但是您也可以在 MacOS 或 Windows 上随意进行学习。 Tip 关于安装 PyTorch 的 C ++发行版的注释更详细地描述了以下步骤。 Tip 在 Windows 上，调试和发行版本不兼容 ABI。 如果您打算以调试模式构建项目，请尝试使用 LibTorch 的调试版本。 另外，请确保在下面的cmake --build .行中指定正确的配置。 第一步是通过从 PyTorch 网站获取的链接在本地下载 LibTorch 发行版。 对于普通的 Ubuntu Linux 环境，这意味着运行： # If you need e.g. CUDA 9.0 support, please replace \"cpu\" with \"cu90\" in the URL below. wget https://download.pytorch.org/libtorch/nightly/cpu/libtorch-shared-with-deps-latest.zip unzip libtorch-shared-with-deps-latest.zip 接下来，让我们编写一个名为dcgan.cpp的小型 C ++文件，其中包含torch/torch.h，现在只需打印出三乘三的标识矩阵即可： #include #include int main() { torch::Tensor tensor = torch::eye(3); std::cout 要在以后构建这个小应用程序以及我们完整的训练脚本，我们将使用以下CMakeLists.txt文件： cmake_minimum_required(VERSION 3.0 FATAL_ERROR) project(dcgan) find_package(Torch REQUIRED) add_executable(dcgan dcgan.cpp) target_link_libraries(dcgan \"${TORCH_LIBRARIES}\") set_property(TARGET dcgan PROPERTY CXX_STANDARD 14) 注意 虽然 CMake 是 LibTorch 的推荐构建系统，但这并不是硬性要求。 您还可以使用 Visual Studio 项目文件，QMake，普通 Makefile 或您认为合适的任何其他构建环境。 但是，我们不为此提供现成的支持。 在上面的 CMake 文件中记下第 4 行：find_package(Torch REQUIRED)。 这指示 CMake 查找 LibTorch 库的构建配置。 为了使 CMake 知道在哪里找到这些文件，调用cmake时必须设置CMAKE_PREFIX_PATH。 在执行此操作之前，让我们就dcgan应用程序的以下目录结构达成一致： dcgan/ CMakeLists.txt dcgan.cpp 此外，我将指向未压缩的 LibTorch 分布的路径称为/path/to/libtorch。 请注意，此必须是绝对路径。 特别是，将CMAKE_PREFIX_PATH设置为../../libtorch之类的内容会以意想不到的方式中断。 而是写$PWD/../../libtorch以获取相应的绝对路径。 现在，我们准备构建我们的应用程序： root@fa350df05ecf:/home# mkdir build root@fa350df05ecf:/home# cd build root@fa350df05ecf:/home/build# cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch .. -- The C compiler identification is GNU 5.4.0 -- The CXX compiler identification is GNU 5.4.0 -- Check for working C compiler: /usr/bin/cc -- Check for working C compiler: /usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Detecting C compile features -- Detecting C compile features - done -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Looking for pthread.h -- Looking for pthread.h - found -- Looking for pthread_create -- Looking for pthread_create - not found -- Looking for pthread_create in pthreads -- Looking for pthread_create in pthreads - not found -- Looking for pthread_create in pthread -- Looking for pthread_create in pthread - found -- Found Threads: TRUE -- Found torch: /path/to/libtorch/lib/libtorch.so -- Configuring done -- Generating done -- Build files have been written to: /home/build root@fa350df05ecf:/home/build# cmake --build . --config Release Scanning dependencies of target dcgan [ 50%] Building CXX object CMakeFiles/dcgan.dir/dcgan.cpp.o [100%] Linking CXX executable dcgan [100%] Built target dcgan 上面，我们首先在dcgan目录内创建一个build文件夹，进入该文件夹，运行cmake命令以生成必要的 build(Make）文件，最后通过运行cmake --build . --config Release成功编译该项目。 现在我们准备执行最小的二进制文件并完成有关基本项目配置的这一部分： root@fa350df05ecf:/home/build# ./dcgan 1 0 0 0 1 0 0 0 1 [ Variable[CPUFloatType]{3,3} ] 在我看来就像一个身份矩阵！ 定义神经网络模型 现在我们已经配置了基本环境，我们可以深入研究本教程中更有趣的部分。 首先，我们将讨论如何在 C ++前端中定义模块并与之交互。 我们将从基本的小规模示例模块开始，然后使用 C ++前端提供的广泛的内置模块库来实现完整的 GAN。 模块 API 基础 与 Python 界面一致，基于 C ++前端的神经网络由称为模块的可重用构建块组成。 有一个基础模块类，所有其他模块都从该基础类派生。 在 Python 中，此类为torch.nn.Module，在 C ++中为torch::nn::Module。 除了实现模块封装的算法的forward()方法之外，模块通常还包含以下三种子对象中的任何一种：参数，缓冲区和子模块。 参数和缓冲区以张量的形式存储状态。 参数记录渐变，而缓冲区不记录。 参数通常是神经网络的可训练权重。 缓冲区的示例包括批量标准化的均值和方差。 为了重用特定的逻辑和状态块，PyTorch API 允许嵌套模块。 嵌套模块称为子模块。 必须显式注册参数，缓冲区和子模块。 注册后，可以使用parameters()或buffers()之类的方法来检索整个(嵌套）模块层次结构中所有参数的容器。 类似地，使用to(...)之类的方法，例如 to(torch::kCUDA)将所有参数和缓冲区从 CPU 移到 CUDA 内存，在整个模块层次结构上工作。 定义模块和注册参数 为了将这些词写成代码，让我们考虑一下用 Python 界面编写的简单模块： import torch class Net(torch.nn.Module): def __init__(self, N, M): super(Net, self).__init__() self.W = torch.nn.Parameter(torch.randn(N, M)) self.b = torch.nn.Parameter(torch.randn(M)) def forward(self, input): return torch.addmm(self.b, input, self.W) 在 C ++中，它看起来像这样： #include struct Net : torch::nn::Module { Net(int64_t N, int64_t M) { W = register_parameter(\"W\", torch::randn({N, M})); b = register_parameter(\"b\", torch::randn(M)); } torch::Tensor forward(torch::Tensor input) { return torch::addmm(b, input, W); } torch::Tensor W, b; }; 就像在 Python 中一样，我们定义了一个名为Net的类(为简单起见，这里是struct而不是class），然后从模块基类派生它。 在构造函数内部，我们使用torch::randn创建张量，就像在 Python 中使用torch.randn一样。 一个有趣的区别是我们如何注册参数。 在 Python 中，我们用torch.nn.Parameter类包装了张量，而在 C ++中，我们不得不通过register_parameter方法传递张量。 这样做的原因是 Python API 可以检测到属性为torch.nn.Parameter类型并自动注册此类张量。 在 C ++中，反射非常有限，因此提供了一种更传统(且魔术性较小）的方法。 注册子模块并遍历模块层次结构 同样，我们可以注册参数，也可以注册子模块。 在 Python 中，将子模块分配为模块的属性时，会自动检测并注册这些子模块： class Net(torch.nn.Module): def __init__(self, N, M): super(Net, self).__init__() # Registered as a submodule behind the scenes self.linear = torch.nn.Linear(N, M) self.another_bias = torch.nn.Parameter(torch.rand(M)) def forward(self, input): return self.linear(input) + self.another_bias 例如，这允许使用parameters()方法来递归访问模块层次结构中的所有参数： >>> net = Net(4, 5) >>> print(list(net.parameters())) [Parameter containing: tensor([0.0808, 0.8613, 0.2017, 0.5206, 0.5353], requires_grad=True), Parameter containing: tensor([[-0.3740, -0.0976, -0.4786, -0.4928], [-0.1434, 0.4713, 0.1735, -0.3293], [-0.3467, -0.3858, 0.1980, 0.1986], [-0.1975, 0.4278, -0.1831, -0.2709], [ 0.3730, 0.4307, 0.3236, -0.0629]], requires_grad=True), Parameter containing: tensor([ 0.2038, 0.4638, -0.2023, 0.1230, -0.0516], requires_grad=True)] 要在 C ++中注册子模块，请使用恰当命名的register_module()方法注册类似torch::nn::Linear的模块： struct Net : torch::nn::Module { Net(int64_t N, int64_t M) : linear(register_module(\"linear\", torch::nn::Linear(N, M))) { another_bias = register_parameter(\"b\", torch::randn(M)); } torch::Tensor forward(torch::Tensor input) { return linear(input) + another_bias; } torch::nn::Linear linear; torch::Tensor another_bias; }; Tip 您可以在torch::nn命名空间的文档中中找到可用的内置模块的完整列表，例如torch::nn::Linear，torch::nn::Dropout或torch::nn::Conv2d。 关于上述代码的一个微妙之处是，为什么在构造函数的初始值设定项列表中创建子模块，而在构造函数的主体内部创建参数的原因。 这是有充分的理由的，我们将在下面有关 C ++前端的所有权模型的部分中对此进行介绍。 但是，最终结果是，就像 Python 中一样，我们可以递归访问模块树的参数。 调用parameters()将返回std::vector&lt;torch::Tensor&gt;，我们可以对其进行迭代： int main() { Net net(4, 5); for (const auto& p : net.parameters()) { std::cout 打印： root@fa350df05ecf:/home/build# ./dcgan 0.0345 1.4456 -0.6313 -0.3585 -0.4008 [ Variable[CPUFloatType]{5} ] -0.1647 0.2891 0.0527 -0.0354 0.3084 0.2025 0.0343 0.1824 -0.4630 -0.2862 0.2500 -0.0420 0.3679 -0.1482 -0.0460 0.1967 0.2132 -0.1992 0.4257 0.0739 [ Variable[CPUFloatType]{5,4} ] 0.01 * 3.6861 -10.1166 -45.0333 7.9983 -20.0705 [ Variable[CPUFloatType]{5} ] 具有三个参数，就像在 Python 中一样。 为了也查看这些参数的名称，C ++ API 提供了named_parameters()方法，该方法返回OrderedDict就像在 Python 中一样： Net net(4, 5); for (const auto& pair : net.named_parameters()) { std::cout 我们可以再次执行以查看输出： root@fa350df05ecf:/home/build# make && ./dcgan 11:13:48 Scanning dependencies of target dcgan [ 50%] Building CXX object CMakeFiles/dcgan.dir/dcgan.cpp.o [100%] Linking CXX executable dcgan [100%] Built target dcgan b: -0.1863 -0.8611 -0.1228 1.3269 0.9858 [ Variable[CPUFloatType]{5} ] linear.weight: 0.0339 0.2484 0.2035 -0.2103 -0.0715 -0.2975 -0.4350 -0.1878 -0.3616 0.1050 -0.4982 0.0335 -0.1605 0.4963 0.4099 -0.2883 0.1818 -0.3447 -0.1501 -0.0215 [ Variable[CPUFloatType]{5,4} ] linear.bias: -0.0250 0.0408 0.3756 -0.2149 -0.3636 [ Variable[CPUFloatType]{5} ] Note torch::nn::Module的文档包含在模块层次结构上运行的方法的完整列表。 在转发模式下运行网络 要使用 C ++执行网络，我们只需调用我们自己定义的forward()方法： int main() { Net net(4, 5); std::cout 打印类似： root@fa350df05ecf:/home/build# ./dcgan 0.8559 1.1572 2.1069 -0.1247 0.8060 0.8559 1.1572 2.1069 -0.1247 0.8060 [ Variable[CPUFloatType]{2,5} ] 模块所有权 至此，我们知道了如何使用 C ++定义模块，注册参数，注册子模块，通过parameters()之类的方法遍历模块层次结构并最终运行模块的forward()方法。 尽管在 C ++ API 中还有很多方法，类和主题需要使用，但我将为您提供完整菜单的文档。 我们将在稍后实现 DCGAN 模型和端到端训练管道的过程中，涉及更多概念。 在我们这样做之前，让我简要地谈谈 C ++前端为torch::nn::Module的子类提供的所有权模型。 在本次讨论中，所有权模型是指模块的存储和传递方式-确定特定模块实例的所有者或所有者。 在 Python 中，对象始终是动态分配的(在堆上），并具有引用语义。 这是非常容易使用且易于理解的。 实际上，在 Python 中，您可以很大程度上忽略对象的位置以及如何引用它们，而将精力集中在完成事情上。 C ++是一种较低级的语言，它在此领域提供了更多选择。 这增加了复杂性，并严重影响了 C ++前端的设计和人体工程学。 特别是，对于 C ++前端中的模块，我们可以选择使用或值语义或参考语义。 第一种情况是最简单的，并且在到目前为止的示例中已进行了展示：模块对象分配在堆栈上，并在传递给函数时可以复制，移动(使用std::move）或通过引用或指针获取： struct Net : torch::nn::Module { }; void a(Net net) { } void b(Net& net) { } void c(Net* net) { } int main() { Net net; a(net); a(std::move(net)); b(net); c(&net); } 对于第二种情况-参考语义-我们可以使用std::shared_ptr。 引用语义的优势在于，就像在 Python 中一样，它减少了思考如何将模块传递给函数以及如何声明参数的认知开销(假设您在任何地方都使用shared_ptr）。 struct Net : torch::nn::Module {}; void a(std::shared_ptr net) { } int main() { auto net = std::make_shared(); a(net); } 根据我们的经验，来自动态语言的研究人员非常喜欢引用语义而不是值语义，尽管后者比 C ++更“原生”。 同样重要的是要注意，torch::nn::Module的设计要与 Python API 的人体工程学保持紧密联系，因此要依靠共享所有权。 例如，采用我们先前的Net定义(此处为简称）： struct Net : torch::nn::Module { Net(int64_t N, int64_t M) : linear(register_module(\"linear\", torch::nn::Linear(N, M))) { } torch::nn::Linear linear; }; 为了使用linear子模块，我们想将其直接存储在我们的类中。 但是，我们还希望模块基类了解并有权访问此子模块。 为此，它必须存储对此子模块的引用。 至此，我们已经达到了共享所有权的需要。 torch::nn::Module类和具体的Net类都需要引用该子模块。 因此，基类将模块存储为shared_ptr，因此具体类也必须存储。 可是等等！ 在以上代码中我没有看到任何关于shared_ptr的提示！ 这是为什么？ 好吧，因为std::shared_ptr&lt;MyModule&gt;实在令人难受。 为了保持研究人员的生产力，我们提出了一个精心设计的方案，以隐藏shared_ptr的提法-通常保留给值语义的好处-同时保留参考语义。 要了解它是如何工作的，我们可以看一下核心库中torch::nn::Linear模块的简化定义(完整定义为，在此处）： struct LinearImpl : torch::nn::Module { LinearImpl(int64_t in, int64_t out); Tensor forward(const Tensor& input); Tensor weight, bias; }; TORCH_MODULE(Linear); 简而言之：该模块不是Linear，而是LinearImpl。 然后，宏TORCH_MODULE定义了实际的Linear类。 这个“生成的”类实际上是std::shared_ptr&lt;LinearImpl&gt;的包装。 它是一个包装器，而不是简单的 typedef，因此，除其他事项外，构造函数仍可按预期工作，即，您仍然可以编写torch::nn::Linear(3, 4)而不是std::make_shared&lt;LinearImpl&gt;(3, 4)。 我们将由宏创建的类称为模块持有人。 与(共享）指针一样，您可以使用箭头运算符(例如model-&gt;forward(...)）访问基础对象。 最终结果是一个所有权模型，该所有权模型非常类似于 Python API。 引用语义成为默认语义，但是没有额外输入std::shared_ptr或std::make_shared。 对于我们的Net，使用模块持有人 API 如下所示： struct NetImpl : torch::nn::Module {}; TORCH_MODULE(Net); void a(Net net) { } int main() { Net net; a(net); } 这里有一个微妙的问题值得一提。 默认构造的std::shared_ptr为“空”，即包含空指针。 什么是默认构造的Linear或Net？ 好吧，这是一个棘手的选择。 我们可以说它应该是一个空(null）std::shared_ptr&lt;LinearImpl&gt;。 但是，请记住Linear(3, 4)与std::make_shared&lt;LinearImpl&gt;(3, 4)相同。 这意味着如果我们已确定Linear linear;应该为空指针，则将无法构造不采用任何构造函数参数或都不使用所有缺省构造函数的模块。 因此，在当前的 API 中，默认构造的模块持有人(如Linear()）将调用基础模块的默认构造函数(LinearImpl()）。 如果基础模块没有默认构造函数，则会出现编译器错误。 要构造空持有人，可以将nullptr传递给持有人的构造函数。 实际上，这意味着您可以使用如先前所示的子模块，在初始化程序列表中注册并构造该模块： struct Net : torch::nn::Module { Net(int64_t N, int64_t M) : linear(register_module(\"linear\", torch::nn::Linear(N, M))) { } torch::nn::Linear linear; }; 或者，您可以先使用空指针构造持有人，然后在构造函数中为其分配值(Pythonistas 更熟悉）： struct Net : torch::nn::Module { Net(int64_t N, int64_t M) { linear = register_module(\"linear\", torch::nn::Linear(N, M)); } torch::nn::Linear linear{nullptr}; // construct an empty holder }; 结论：您应该使用哪种所有权模型–哪种语义？ C ++前端的 API 最能支持模块所有者提供的所有权模型。 这种机制的唯一缺点是在模块声明下方多了一行样板。 也就是说，最简单的模型仍然是 C ++模块简介中显示的值语义模型。 对于小的，简单的脚本，您也可以摆脱它。 但是，由于技术原因，您迟早会发现它并不总是受支持。 例如，序列化 API(torch::save和torch::load）仅支持模块支架(或普通shared_ptr）。 因此，推荐使用模块持有人 API 和 C ++前端定义模块，此后我们将在本教程中使用此 API。 定义 DCGAN 模块 现在，我们有必要的背景和简介来定义我们要在本文中解决的机器学习任务的模块。 回顾一下：我们的任务是从 MNIST 数据集生成数字图像。 我们想使用生成对抗网络(GAN）解决此任务。 特别是，我们将使用 DCGAN 体系结构-这是同类中最早的也是最简单的一种，但是完全可以完成此任务。 Tip 您可以在存储库中找到本教程中提供的完整源代码。 什么是 GAN aGAN？ GAN 由两个不同的神经网络模型组成：生成器和鉴别器。 生成器从噪声分布中接收样本，其目的是将每个噪声样本转换为类似于目标分布的图像(在我们的情况下为 MNIST 数据集）。 鉴别器又从 MNIST 数据集接收实际图像，或从生成器接收假图像。 要求发出一个概率来判断特定图像的真实程度(接近1）或伪造(接近0）。 来自鉴别器的关于由发生器产生的图像如何真实的反馈被用来训练发生器。 鉴别器对真实性有多好的反馈将用于优化鉴别器。 从理论上讲，生成器和鉴别器之间的微妙平衡使它们串联起来得到改善，从而导致生成器生成与目标分布无法区分的图像，从而使鉴别器(那时）的敏锐眼睛冒出了散发0.5的真实和真实可能性。 假图片。 对我们来说，最终结果是一台接收噪声作为输入并生成数字逼真的图像作为其输出的机器。 发电机模块 我们首先定义生成器模块，该模块由一系列转置的 2D 卷积，批处理归一化和 ReLU 激活单元组成。 我们在定义自己的模块的forward()方法中显式地(在功能上）在模块之间传递输入： struct DCGANGeneratorImpl : nn::Module { DCGANGeneratorImpl(int kNoiseSize) : conv1(nn::ConvTranspose2dOptions(kNoiseSize, 256, 4) .bias(false)), batch_norm1(256), conv2(nn::ConvTranspose2dOptions(256, 128, 3) .stride(2) .padding(1) .bias(false)), batch_norm2(128), conv3(nn::ConvTranspose2dOptions(128, 64, 4) .stride(2) .padding(1) .bias(false)), batch_norm3(64), conv4(nn::ConvTranspose2dOptions(64, 1, 4) .stride(2) .padding(1) .bias(false)) { // register_module() is needed if we want to use the parameters() method later on register_module(\"conv1\", conv1); register_module(\"conv2\", conv2); register_module(\"conv3\", conv3); register_module(\"conv4\", conv4); register_module(\"batch_norm1\", batch_norm1); register_module(\"batch_norm2\", batch_norm2); register_module(\"batch_norm3\", batch_norm3); } torch::Tensor forward(torch::Tensor x) { x = torch::relu(batch_norm1(conv1(x))); x = torch::relu(batch_norm2(conv2(x))); x = torch::relu(batch_norm3(conv3(x))); x = torch::tanh(conv4(x)); return x; } nn::ConvTranspose2d conv1, conv2, conv3, conv4; nn::BatchNorm2d batch_norm1, batch_norm2, batch_norm3; }; TORCH_MODULE(DCGANGenerator); DCGANGenerator generator(kNoiseSize); 现在我们可以在DCGANGenerator上调用forward()将噪声样本映射到图像。 选择的特定模块，例如nn::ConvTranspose2d和nn::BatchNorm2d，遵循前面概述的结构。 kNoiseSize常数确定输入噪声矢量的大小，并将其设置为100。 当然，超参数是通过研究生的血统发现的。 注意 在超参数的发现中，没有研究生受到伤害。 他们定期喂给 Soylent。 Note 简要介绍如何将选项传递给 C ++前端中的Conv2d等内置模块：每个模块都有一些必需的选项，例如BatchNorm2d的功能数量。 如果您只需要配置所需的选项，则可以将它们直接传递给模块的构造函数，例如BatchNorm2d(128)或Dropout(0.5)或Conv2d(8, 4, 2)(用于输入通道数，输出通道数和内核大小）。 但是，如果需要修改其他通常默认设置的选项，例如Conv2d的bias，则需要构造并传递选项对象。 C ++前端中的每个模块都有一个关联的选项结构，称为ModuleOptions，其中Module是模块的名称，例如Linear的LinearOptions。 这就是我们上面的Conv2d模块的工作。 鉴别模块 鉴别器类似地是卷积，批归一化和激活的序列。 但是，卷积现在是常规的卷积，而不是转置的卷积，我们使用 alpha 值为 0.2 的泄漏 ReLU 代替了普通的 ReLU。 同样，最后的激活变为 Sigmoid，将值压缩到 0 到 1 之间。然后，我们可以将这些压缩后的值解释为鉴别器分配给真实图像的概率。 为了构建鉴别器，我们将尝试不同的方法：顺序模块。 像在 Python 中一样，PyTorch 在此提供了两种用于模型定义的 API：一种功能，其中的输入通过连续的函数传递(例如，生成器模块示例），而另一种面向对象的，其中我们构建了顺序模块 包含整个模型作为子模块。 使用顺序，鉴别符将如下所示： nn::Sequential discriminator( // Layer 1 nn::Conv2d( nn::Conv2dOptions(1, 64, 4).stride(2).padding(1).bias(false)), nn::LeakyReLU(nn::LeakyReLUOptions().negative_slope(0.2)), // Layer 2 nn::Conv2d( nn::Conv2dOptions(64, 128, 4).stride(2).padding(1).bias(false)), nn::BatchNorm2d(128), nn::LeakyReLU(nn::LeakyReLUOptions().negative_slope(0.2)), // Layer 3 nn::Conv2d( nn::Conv2dOptions(128, 256, 4).stride(2).padding(1).bias(false)), nn::BatchNorm2d(256), nn::LeakyReLU(nn::LeakyReLUOptions().negative_slope(0.2)), // Layer 4 nn::Conv2d( nn::Conv2dOptions(256, 1, 3).stride(1).padding(0).bias(false)), nn::Sigmoid()); Tip Sequential模块仅执行功能组合。 第一个子模块的输出成为第二个子模块的输入，第三个子模块的输出成为第四个子模块的输入，依此类推。 加载数据中 现在我们已经定义了生成器和鉴别器模型，我们需要一些可以用来训练这些模型的数据。 与 Python 一样，C ++前端也具有强大的并行数据加载器。 该数据加载器可以从数据集中读取批次数据(您可以定义自己），并提供许多配置旋钮。 Note 尽管 Python 数据加载器使用多重处理，但 C ++数据加载器实际上是多线程的，不会启动任何新进程。 数据加载器是 C ++前端data API 的一部分，该 API 包含在torch::data::名称空间中。 该 API 由几个不同的组件组成： 数据加载器类， 用于定义数据集的 API， 用于定义转换的 API，可以将其应用于数据集， 用于定义采样器的 API，该采样器会生成用于对数据集建立索引的索引， 现有数据集，变换和采样器的库。 对于本教程，我们可以使用 C ++前端附带的MNIST数据集。 让我们为此实例化一个torch::data::datasets::MNIST，并应用两个转换：首先，我们对图像进行归一化，以使其在-1至+1的范围内(从0到1的原始范围）。 其次，我们应用Stack 归类，它采用一批张量并将它们沿第一维堆叠为单个张量： auto dataset = torch::data::datasets::MNIST(\"./mnist\") .map(torch::data::transforms::Normalize<>(0.5, 0.5)) .map(torch::data::transforms::Stack<>()); 请注意，相对于执行训练二进制文件的位置，MNIST 数据集应位于./mnist目录中。 您可以使用此脚本下载 MNIST 数据集。 接下来，我们创建一个数据加载器并将其传递给此数据集。 为了创建一个新的数据加载器，我们使用torch::data::make_data_loader，它返回正确类型的std::unique_ptr(取决于数据集的类型，采样器的类型以及其他一些实现细节）： auto data_loader = torch::data::make_data_loader(std::move(dataset)); 数据加载器确实提供了很多选项。 您可以在处检查全套。 例如，为了加快数据加载速度，我们可以增加工作人员的数量。 默认数字为零，这表示将使用主线程。 如果将workers设置为2，将产生两个线程并发加载数据。 我们还应该将批次大小从其默认值1增大到更合理的值，例如64(kBatchSize的值）。 因此，让我们创建一个DataLoaderOptions对象并设置适当的属性： auto data_loader = torch::data::make_data_loader( std::move(dataset), torch::data::DataLoaderOptions().batch_size(kBatchSize).workers(2)); 现在，我们可以编写一个循环来加载批量数据，目前我们仅将其打印到控制台： for (torch::data::Example<>& batch : *data_loader) { std::cout () 在这种情况下，数据加载器返回的类型为torch::data::Example。 此类型是一种简单的结构，其中的data字段用于数据，而target字段用于标签。 因为我们之前应用了Stack归类，所以数据加载器仅返回一个这样的示例。 如果我们未应用排序规则，则数据加载器将改为生成std::vector&lt;torch::data::Example&lt;&gt;&gt;，批处理中每个示例包含一个元素。 如果重新生成并运行此代码，则应看到类似以下内容的内容： root@fa350df05ecf:/home/build# make Scanning dependencies of target dcgan [ 50%] Building CXX object CMakeFiles/dcgan.dir/dcgan.cpp.o [100%] Linking CXX executable dcgan [100%] Built target dcgan root@fa350df05ecf:/home/build# make [100%] Built target dcgan root@fa350df05ecf:/home/build# ./dcgan Batch size: 64 | Labels: 5 2 6 7 2 1 6 7 0 1 6 2 3 6 9 1 8 4 0 6 5 3 3 0 4 6 6 6 4 0 8 6 0 6 9 2 4 0 2 8 6 3 3 2 9 2 0 1 4 2 3 4 8 2 9 9 3 5 8 0 0 7 9 9 Batch size: 64 | Labels: 2 2 4 7 1 2 8 8 6 9 0 2 2 9 3 6 1 3 8 0 4 4 8 8 8 9 2 6 4 7 1 5 0 9 7 5 4 3 5 4 1 2 8 0 7 1 9 6 1 6 5 3 4 4 1 2 3 2 3 5 0 1 6 2 Batch size: 64 | Labels: 4 5 4 2 1 4 8 3 8 3 6 1 5 4 3 6 2 2 5 1 3 1 5 0 8 2 1 5 3 2 4 4 5 9 7 2 8 9 2 0 6 7 4 3 8 3 5 8 8 3 0 5 8 0 8 7 8 5 5 6 1 7 8 0 Batch size: 64 | Labels: 3 3 7 1 4 1 6 1 0 3 6 4 0 2 5 4 0 4 2 8 1 9 6 5 1 6 3 2 8 9 2 3 8 7 4 5 9 6 0 8 3 0 0 6 4 8 2 5 4 1 8 3 7 8 0 0 8 9 6 7 2 1 4 7 Batch size: 64 | Labels: 3 0 5 5 9 8 3 9 8 9 5 9 5 0 4 1 2 7 7 2 0 0 5 4 8 7 7 6 1 0 7 9 3 0 6 3 2 6 2 7 6 3 3 4 0 5 8 8 9 1 9 2 1 9 4 4 9 2 4 6 2 9 4 0 Batch size: 64 | Labels: 9 6 7 5 3 5 9 0 8 6 6 7 8 2 1 9 8 8 1 1 8 2 0 7 1 4 1 6 7 5 1 7 7 4 0 3 2 9 0 6 6 3 4 4 8 1 2 8 6 9 2 0 3 1 2 8 5 6 4 8 5 8 6 2 Batch size: 64 | Labels: 9 3 0 3 6 5 1 8 6 0 1 9 9 1 6 1 7 7 4 4 4 7 8 8 6 7 8 2 6 0 4 6 8 2 5 3 9 8 4 0 9 9 3 7 0 5 8 2 4 5 6 2 8 2 5 3 7 1 9 1 8 2 2 7 Batch size: 64 | Labels: 9 1 9 2 7 2 6 0 8 6 8 7 7 4 8 6 1 1 6 8 5 7 9 1 3 2 0 5 1 7 3 1 6 1 0 8 6 0 8 1 0 5 4 9 3 8 5 8 4 8 0 1 2 6 2 4 2 7 7 3 7 4 5 3 Batch size: 64 | Labels: 8 8 3 1 8 6 4 2 9 5 8 0 2 8 6 6 7 0 9 8 3 8 7 1 6 6 2 7 7 4 5 5 2 1 7 9 5 4 9 1 0 3 1 9 3 9 8 8 5 3 7 5 3 6 8 9 4 2 0 1 2 5 4 7 Batch size: 64 | Labels: 9 2 7 0 8 4 4 2 7 5 0 0 6 2 0 5 9 5 9 8 8 9 3 5 7 5 4 7 3 0 5 7 6 5 7 1 6 2 8 7 6 3 2 6 5 6 1 2 7 7 0 0 5 9 0 0 9 1 7 8 3 2 9 4 Batch size: 64 | Labels: 7 6 5 7 7 5 2 2 4 9 9 4 8 7 4 8 9 4 5 7 1 2 6 9 8 5 1 2 3 6 7 8 1 1 3 9 8 7 9 5 0 8 5 1 8 7 2 6 5 1 2 0 9 7 4 0 9 0 4 6 0 0 8 6 ... 这意味着我们能够成功地从 MNIST 数据集中加载数据。 编写训练循环 现在，让我们完成示例的算法部分，并实现生成器和鉴别器之间的精妙舞蹈。 首先，我们将创建两个优化器，一个用于生成器，一个用于区分器。 我们使用的优化程序实现了 Adam 算法： torch::optim::Adam generator_optimizer( generator->parameters(), torch::optim::AdamOptions(2e-4).beta1(0.5)); torch::optim::Adam discriminator_optimizer( discriminator->parameters(), torch::optim::AdamOptions(5e-4).beta1(0.5)); Note 在撰写本文时，C ++前端提供了实现 Adagrad，Adam，LBBFG，RMSprop 和 SGD 的优化器。 文档具有最新列表。 接下来，我们需要更新我们的训练循环。 我们将添加一个外部循环以在每个时期耗尽数据加载器，然后编写 GAN 训练代码： for (int64_t epoch = 1; epoch & batch : *data_loader) { // Train discriminator with real images. discriminator->zero_grad(); torch::Tensor real_images = batch.data; torch::Tensor real_labels = torch::empty(batch.data.size(0)).uniform_(0.8, 1.0); torch::Tensor real_output = discriminator->forward(real_images); torch::Tensor d_loss_real = torch::binary_cross_entropy(real_output, real_labels); d_loss_real.backward(); // Train discriminator with fake images. torch::Tensor noise = torch::randn({batch.data.size(0), kNoiseSize, 1, 1}); torch::Tensor fake_images = generator->forward(noise); torch::Tensor fake_labels = torch::zeros(batch.data.size(0)); torch::Tensor fake_output = discriminator->forward(fake_images.detach()); torch::Tensor d_loss_fake = torch::binary_cross_entropy(fake_output, fake_labels); d_loss_fake.backward(); torch::Tensor d_loss = d_loss_real + d_loss_fake; discriminator_optimizer.step(); // Train generator. generator->zero_grad(); fake_labels.fill_(1); fake_output = discriminator->forward(fake_images); torch::Tensor g_loss = torch::binary_cross_entropy(fake_output, fake_labels); g_loss.backward(); generator_optimizer.step(); std::printf( \"\\r[%2ld/%2ld][%3ld/%3ld] D_loss: %.4f | G_loss: %.4f\", epoch, kNumberOfEpochs, ++batch_index, batches_per_epoch, d_loss.item(), g_loss.item()); } } 上面，我们首先在真实图像上评估鉴别器，为此应为其分配较高的概率。 为此，我们使用torch::empty(batch.data.size(0)).uniform_(0.8, 1.0)作为目标概率。 Note 我们选择均匀分布在 0.8 到 1.0 之间的随机值，而不是各处的 1.0，以使鉴别器训练更加可靠。 此技巧称为标签平滑。 在评估鉴别器之前，我们将其参数的梯度归零。 计算完损耗后，我们通过调用d_loss.backward()计算新的梯度来在网络中反向传播。 我们对虚假图像重复此步骤。 我们不使用数据集中的图像，而是让生成器通过为它提供一批随机噪声来为此创建伪造图像。 然后，我们将这些伪造图像转发给鉴别器。 这次，我们希望鉴别器发出低概率，最好是全零。 一旦计算了一批真实图像和一批伪造图像的鉴别器损耗，我们就可以一步一步地进行鉴别器的优化程序，以更新其参数。 为了训练生成器，我们再次首先将其梯度归零，然后在伪图像上重新评估鉴别器。 但是，这一次，我们希望鉴别器将概率分配为非常接近的概率，这将表明生成器可以生成使鉴别器认为它们实际上是真实的图像(来自数据集）。 为此，我们用全部填充fake_labels张量。 最后，我们逐步使用生成器的优化器来更新其参数。 现在，我们应该准备在 CPU 上训练我们的模型。 我们还没有任何代码可以捕获状态或示例输出，但是我们稍后会添加。 现在，让我们观察一下我们的模型正在做某事 –我们稍后将根据生成的图像来验证这是否有意义。 重建和运行应打印如下内容： root@3c0711f20896:/home/build# make && ./dcgan Scanning dependencies of target dcgan [ 50%] Building CXX object CMakeFiles/dcgan.dir/dcgan.cpp.o [100%] Linking CXX executable dcgan [100%] Built target dcga [ 1/10][100/938] D_loss: 0.6876 | G_loss: 4.1304 [ 1/10][200/938] D_loss: 0.3776 | G_loss: 4.3101 [ 1/10][300/938] D_loss: 0.3652 | G_loss: 4.6626 [ 1/10][400/938] D_loss: 0.8057 | G_loss: 2.2795 [ 1/10][500/938] D_loss: 0.3531 | G_loss: 4.4452 [ 1/10][600/938] D_loss: 0.3501 | G_loss: 5.0811 [ 1/10][700/938] D_loss: 0.3581 | G_loss: 4.5623 [ 1/10][800/938] D_loss: 0.6423 | G_loss: 1.7385 [ 1/10][900/938] D_loss: 0.3592 | G_loss: 4.7333 [ 2/10][100/938] D_loss: 0.4660 | G_loss: 2.5242 [ 2/10][200/938] D_loss: 0.6364 | G_loss: 2.0886 [ 2/10][300/938] D_loss: 0.3717 | G_loss: 3.8103 [ 2/10][400/938] D_loss: 1.0201 | G_loss: 1.3544 [ 2/10][500/938] D_loss: 0.4522 | G_loss: 2.6545 ... 移至 GPU 尽管我们当前的脚本可以在 CPU 上正常运行，但是我们都知道卷积在 GPU 上要快得多。 让我们快速讨论如何将训练转移到 GPU 上。 为此，我们需要做两件事：将 GPU 设备规范传递给我们分配给自己的张量，并通过to()方法将所有其他张量明确复制到 C ++前端中所有张量和模块上。 实现这两者的最简单方法是在训练脚本的顶层创建torch::Device的实例，然后将该设备传递给诸如torch::zeros和to()方法之类的张量工厂函数。 我们可以从使用 CPU 设备开始： // Place this somewhere at the top of your training script. torch::Device device(torch::kCPU); 新的张量分配，例如 torch::Tensor fake_labels = torch::zeros(batch.data.size(0)); 应该更新为以device作为最后一个参数： torch::Tensor fake_labels = torch::zeros(batch.data.size(0), device); 对于那些不在我们手中的张量，例如来自 MNIST 数据集的张量，我们必须插入显式的to()调用。 这表示 torch::Tensor real_images = batch.data; 变成 torch::Tensor real_images = batch.data.to(device); 并且我们的模型参数也应该移到正确的设备上： generator->to(device); discriminator->to(device); Note 如果张量已经存在于提供给to()的设备上，则该调用为空操作。 没有多余的副本。 至此，我们已经使之前的 CPU 驻留代码更加明确。 但是，现在将设备更改为 CUDA 设备也非常容易： torch::Device device(torch::kCUDA) 现在，所有张量都将驻留在 GPU 上，并调用快速 CUDA 内核进行所有操作，而无需我们更改任何下游代码。 如果我们想指定一个特定的设备索引，则可以将其作为第二个参数传递给Device构造函数。 如果我们希望不同的张量驻留在不同的设备上，则可以传递单独的设备实例(例如，一个在 CUDA 设备 0 上，另一个在 CUDA 设备 1 上）。 我们甚至可以动态地进行此配置，这通常对于使我们的训练脚本更具可移植性很有用： torch::Device device = torch::kCPU; if (torch::cuda::is_available()) { std::cout 甚至 torch::Device device(torch::cuda::is_available() ? torch::kCUDA : torch::kCPU); 检查点和恢复训练状态 我们应该对训练脚本进行的最后扩充是定期保存模型参数的状态，优化器的状态以及一些生成的图像样本。 如果我们的计算机在训练过程中崩溃，则前两个将使我们能够恢复训练状态。 对于长期的训练课程，这是绝对必要的。 幸运的是，C ++前端提供了一个 API，用于对模型和优化器状态以及单个张量进行序列化和反序列化。 为此的核心 API 是torch::save(thing,filename)和torch::load(thing,filename)，其中thing可以是torch::nn::Module子类或优化程序实例，例如我们在训练脚本中拥有的Adam对象。 让我们更新训练循环，以一定间隔检查模型和优化器状态： if (batch_index % kCheckpointEvery == 0) { // Checkpoint the model and optimizer state. torch::save(generator, \"generator-checkpoint.pt\"); torch::save(generator_optimizer, \"generator-optimizer-checkpoint.pt\"); torch::save(discriminator, \"discriminator-checkpoint.pt\"); torch::save(discriminator_optimizer, \"discriminator-optimizer-checkpoint.pt\"); // Sample the generator and save the images. torch::Tensor samples = generator->forward(torch::randn({8, kNoiseSize, 1, 1}, device)); torch::save((samples + 1.0) / 2.0, torch::str(\"dcgan-sample-\", checkpoint_counter, \".pt\")); std::cout checkpoint \" 其中kCheckpointEvery是设置为类似于100之类的整数，以便每批100都进行检查，而checkpoint_counter是每次创建检查点时都会增加的计数器。 要恢复训练状态，可以在创建所有模型和优化器之后但在训练循环之前添加如下代码： torch::optim::Adam generator_optimizer( generator->parameters(), torch::optim::AdamOptions(2e-4).beta1(0.5)); torch::optim::Adam discriminator_optimizer( discriminator->parameters(), torch::optim::AdamOptions(2e-4).beta1(0.5)); if (kRestoreFromCheckpoint) { torch::load(generator, \"generator-checkpoint.pt\"); torch::load(generator_optimizer, \"generator-optimizer-checkpoint.pt\"); torch::load(discriminator, \"discriminator-checkpoint.pt\"); torch::load( discriminator_optimizer, \"discriminator-optimizer-checkpoint.pt\"); } int64_t checkpoint_counter = 0; for (int64_t epoch = 1; epoch & batch : *data_loader) { 检查生成的图像 我们的训练脚本现已完成。 我们准备在 CPU 或 GPU 上训练 GAN。 为了检查我们训练过程的中间输出，为此我们添加了将代码样本定期保存到\"dcgan-sample-xxx.pt\"文件的代码，我们可以编写一个小的 Python 脚本来加载张量并使用 matplotlib 显示它们： from __future__ import print_function from __future__ import unicode_literals import argparse import matplotlib.pyplot as plt import torch parser = argparse.ArgumentParser() parser.add_argument(\"-i\", \"--sample-file\", required=True) parser.add_argument(\"-o\", \"--out-file\", default=\"out.png\") parser.add_argument(\"-d\", \"--dimension\", type=int, default=3) options = parser.parse_args() module = torch.jit.load(options.sample_file) images = list(module.parameters())[0] for index in range(options.dimension * options.dimension): image = images[index].detach().cpu().reshape(28, 28).mul(255).to(torch.uint8) array = image.numpy() axis = plt.subplot(options.dimension, options.dimension, 1 + index) plt.imshow(array, cmap=\"gray\") axis.get_xaxis().set_visible(False) axis.get_yaxis().set_visible(False) plt.savefig(options.out_file) print(\"Saved \", options.out_file) 现在，让我们训练模型约 30 个纪元： root@3c0711f20896:/home/build# make && ./dcgan 10:17:57 Scanning dependencies of target dcgan [ 50%] Building CXX object CMakeFiles/dcgan.dir/dcgan.cpp.o [100%] Linking CXX executable dcgan [100%] Built target dcgan CUDA is available! Training on GPU. [ 1/30][200/938] D_loss: 0.4953 | G_loss: 4.0195 -> checkpoint 1 [ 1/30][400/938] D_loss: 0.3610 | G_loss: 4.8148 -> checkpoint 2 [ 1/30][600/938] D_loss: 0.4072 | G_loss: 4.36760 -> checkpoint 3 [ 1/30][800/938] D_loss: 0.4444 | G_loss: 4.0250 -> checkpoint 4 [ 2/30][200/938] D_loss: 0.3761 | G_loss: 3.8790 -> checkpoint 5 [ 2/30][400/938] D_loss: 0.3977 | G_loss: 3.3315 ... -> checkpoint 120 [30/30][938/938] D_loss: 0.3610 | G_loss: 3.8084 并在图中显示图像： root@3c0711f20896:/home/build# python display.py -i dcgan-sample-100.pt Saved out.png 应该看起来像这样： 数字！ 万岁！ 现在，事情就在您的球场上：您可以改进模型以使数字看起来更好吗？ 结论 希望本教程为您提供了 PyTorch C ++前端的摘要。 像 PyTorch 这样的机器学习库必然具有非常广泛的 API。 因此，有许多概念我们没有时间或空间来讨论。 但是，我建议您尝试使用该 API，并在遇到问题时查阅我们的文档，尤其是库 API 部分。 另外，请记住，只要我们能够做到，就可以期望 C ++前端遵循 Python 前端的设计和语义，因此您可以利用这一事实来提高学习率。 Tip You can find the full source code presented in this tutorial in this repository. 与往常一样，如果您遇到任何问题或疑问，可以使用我们的论坛或 GitHub 问题进行联系。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"52.html":{"url":"52.html","title":"通过示例学习 PyTorch","keywords":"","body":"通过示例学习 PyTorch 原文： https://pytorch.org/tutorials/beginner/pytorch_with_examples.html 作者：贾斯汀·约翰逊 本教程通过独立的示例介绍 PyTorch 的基本概念。 PyTorch 的核心是提供两个主要功能： n 维张量，类似于 numpy，但可以在 GPU 上运行 自动区分以构建和训练神经网络 我们将使用完全连接的 ReLU 网络作为我们的运行示例。 该网络将具有单个隐藏层，并且将通过最小化网络输出与真实输出之间的欧几里德距离来进行梯度下降训练，以适应随机数据。 注意 您可以在本页的末尾浏览各个示例。 目录 张量 Warm-up：numpy PyTorch：张量 自动分级 PyTorch：张量和自定等级 PyTorch：定义新的 autograd 功能 nn 模块 PyTorch：nn PyTorch：优化 PyTorch：自定义 nn 模块 PyTorch：控制流+权重共享 范例 张量 自动分级 nn 模块 张量 Warm-up：numpy 在介绍 PyTorch 之前，我们将首先使用 numpy 实现网络。 Numpy 提供了一个 n 维数组对象，以及许多用于操纵这些数组的函数。 Numpy 是用于科学计算的通用框架。 它对计算图，深度学习或梯度一无所知。 但是，我们可以使用 numpy 操作手动实现通过网络的前向和后向传递，从而轻松地使用 numpy 使两层网络适合随机数据： # -*- coding: utf-8 -*- import numpy as np # N is batch size; D_in is input dimension; # H is hidden dimension; D_out is output dimension. N, D_in, H, D_out = 64, 1000, 100, 10 # Create random input and output data x = np.random.randn(N, D_in) y = np.random.randn(N, D_out) # Randomly initialize weights w1 = np.random.randn(D_in, H) w2 = np.random.randn(H, D_out) learning_rate = 1e-6 for t in range(500): # Forward pass: compute predicted y h = x.dot(w1) h_relu = np.maximum(h, 0) y_pred = h_relu.dot(w2) # Compute and print loss loss = np.square(y_pred - y).sum() print(t, loss) # Backprop to compute gradients of w1 and w2 with respect to loss grad_y_pred = 2.0 * (y_pred - y) grad_w2 = h_relu.T.dot(grad_y_pred) grad_h_relu = grad_y_pred.dot(w2.T) grad_h = grad_h_relu.copy() grad_h[h PyTorch：张量 Numpy 是一个很棒的框架，但是它不能利用 GPU 来加速其数值计算。 对于现代深度神经网络，GPU 通常会提供 50 倍或更高的加速，因此遗憾的是，numpy 不足以实现现代深度学习。 在这里，我们介绍最基本的 PyTorch 概念：张量。 PyTorch 张量在概念上与 numpy 数组相同：张量是 n 维数组，而 PyTorch 提供了许多在这些张量上运行的功能。 在幕后，张量可以跟踪计算图和渐变，但它们也可用作科学计算的通用工具。 与 numpy 不同，PyTorch 张量可以利用 GPU 加速其数字计算。 要在 GPU 上运行 PyTorch Tensor，只需要将其转换为新的数据类型。 在这里，我们使用 PyTorch 张量使两层网络适合随机数据。 像上面的 numpy 示例一样，我们需要手动实现通过网络的正向和反向传递： # -*- coding: utf-8 -*- import torch dtype = torch.float device = torch.device(\"cpu\") # device = torch.device(\"cuda:0\") # Uncomment this to run on GPU # N is batch size; D_in is input dimension; # H is hidden dimension; D_out is output dimension. N, D_in, H, D_out = 64, 1000, 100, 10 # Create random input and output data x = torch.randn(N, D_in, device=device, dtype=dtype) y = torch.randn(N, D_out, device=device, dtype=dtype) # Randomly initialize weights w1 = torch.randn(D_in, H, device=device, dtype=dtype) w2 = torch.randn(H, D_out, device=device, dtype=dtype) learning_rate = 1e-6 for t in range(500): # Forward pass: compute predicted y h = x.mm(w1) h_relu = h.clamp(min=0) y_pred = h_relu.mm(w2) # Compute and print loss loss = (y_pred - y).pow(2).sum().item() if t % 100 == 99: print(t, loss) # Backprop to compute gradients of w1 and w2 with respect to loss grad_y_pred = 2.0 * (y_pred - y) grad_w2 = h_relu.t().mm(grad_y_pred) grad_h_relu = grad_y_pred.mm(w2.t()) grad_h = grad_h_relu.clone() grad_h[h 自动分级 PyTorch：张量和自定等级 在以上示例中，我们必须手动实现神经网络的正向和反向传递。 对于小型的两层网络，手动实施反向传递并不是什么大问题，但是对于大型的复杂网络而言，可以很快变得非常麻烦。 幸运的是，我们可以使用自动微分来自动计算神经网络中的反向传递。 PyTorch 中的 autograd 软件包正是提供了此功能。 使用 autograd 时，网络的正向传递将定义计算图； 图中的节点为张量，边为从输入张量生成输出张量的函数。 然后通过该图进行反向传播，可以轻松计算梯度。 这听起来很复杂，在实践中非常简单。 每个张量代表计算图中的一个节点。 如果x是具有x.requires_grad=True的张量，则x.grad是另一个张量，其保持x相对于某个标量值的梯度。 在这里，我们使用 PyTorch 张量和 autograd 来实现我们的两层网络。 现在我们不再需要手动通过网络实现反向传递： # -*- coding: utf-8 -*- import torch dtype = torch.float device = torch.device(\"cpu\") # device = torch.device(\"cuda:0\") # Uncomment this to run on GPU # N is batch size; D_in is input dimension; # H is hidden dimension; D_out is output dimension. N, D_in, H, D_out = 64, 1000, 100, 10 # Create random Tensors to hold input and outputs. # Setting requires_grad=False indicates that we do not need to compute gradients # with respect to these Tensors during the backward pass. x = torch.randn(N, D_in, device=device, dtype=dtype) y = torch.randn(N, D_out, device=device, dtype=dtype) # Create random Tensors for weights. # Setting requires_grad=True indicates that we want to compute gradients with # respect to these Tensors during the backward pass. w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True) w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True) learning_rate = 1e-6 for t in range(500): # Forward pass: compute predicted y using operations on Tensors; these # are exactly the same operations we used to compute the forward pass using # Tensors, but we do not need to keep references to intermediate values since # we are not implementing the backward pass by hand. y_pred = x.mm(w1).clamp(min=0).mm(w2) # Compute and print loss using operations on Tensors. # Now loss is a Tensor of shape (1,) # loss.item() gets the scalar value held in the loss. loss = (y_pred - y).pow(2).sum() if t % 100 == 99: print(t, loss.item()) # Use autograd to compute the backward pass. This call will compute the # gradient of loss with respect to all Tensors with requires_grad=True. # After this call w1.grad and w2.grad will be Tensors holding the gradient # of the loss with respect to w1 and w2 respectively. loss.backward() # Manually update weights using gradient descent. Wrap in torch.no_grad() # because weights have requires_grad=True, but we don't need to track this # in autograd. # An alternative way is to operate on weight.data and weight.grad.data. # Recall that tensor.data gives a tensor that shares the storage with # tensor, but doesn't track history. # You can also use torch.optim.SGD to achieve this. with torch.no_grad(): w1 -= learning_rate * w1.grad w2 -= learning_rate * w2.grad # Manually zero the gradients after updating weights w1.grad.zero_() w2.grad.zero_() PyTorch：定义新的 autograd 功能 在幕后，每个原始的 autograd 运算符实际上都是在 Tensor 上运行的两个函数。 正向函数从输入张量计算输出张量。 向后函数接收相对于某个标量值的输出张量的梯度，并计算相对于相同标量值的输入张量的梯度。 在 PyTorch 中，我们可以通过定义torch.autograd.Function的子类并实现forward和backward函数来轻松定义自己的 autograd 运算符。 然后，我们可以通过构造实例并像调用函数一样调用新的 autograd 运算符，并传递包含输入数据的张量。 在此示例中，我们定义了自己的自定义 autograd 函数来执行 ReLU 非线性，并使用它来实现我们的两层网络： # -*- coding: utf-8 -*- import torch class MyReLU(torch.autograd.Function): \"\"\" We can implement our own custom autograd Functions by subclassing torch.autograd.Function and implementing the forward and backward passes which operate on Tensors. \"\"\" @staticmethod def forward(ctx, input): \"\"\" In the forward pass we receive a Tensor containing the input and return a Tensor containing the output. ctx is a context object that can be used to stash information for backward computation. You can cache arbitrary objects for use in the backward pass using the ctx.save_for_backward method. \"\"\" ctx.save_for_backward(input) return input.clamp(min=0) @staticmethod def backward(ctx, grad_output): \"\"\" In the backward pass we receive a Tensor containing the gradient of the loss with respect to the output, and we need to compute the gradient of the loss with respect to the input. \"\"\" input, = ctx.saved_tensors grad_input = grad_output.clone() grad_input[input nn 模块 PyTorch：nn 计算图和 autograd 是定义复杂运算符并自动采用导数的非常强大的范例。 但是对于大型神经网络，原始的 autograd 可能会有点太低了。 在构建神经网络时，我们经常想到将计算安排在层中，其中某些层具有可学习的参数，这些参数将在学习期间进行优化。 在 TensorFlow 中，像 Keras ， TensorFlow-Slim 和 TFLearn 之类的软件包在原始计算图上提供了更高层次的抽象，可用于构建神经网络。 在 PyTorch 中，nn包也达到了相同的目的。 nn包定义了一组模块，它们大致等效于神经网络层。 模块接收输入张量并计算输出张量，但也可以保持内部状态，例如包含可学习参数的张量。 nn程序包还定义了一组有用的损失函数，这些函数通常在训练神经网络时使用。 在此示例中，我们使用nn包来实现我们的两层网络： # -*- coding: utf-8 -*- import torch # N is batch size; D_in is input dimension; # H is hidden dimension; D_out is output dimension. N, D_in, H, D_out = 64, 1000, 100, 10 # Create random Tensors to hold inputs and outputs x = torch.randn(N, D_in) y = torch.randn(N, D_out) # Use the nn package to define our model as a sequence of layers. nn.Sequential # is a Module which contains other Modules, and applies them in sequence to # produce its output. Each Linear Module computes output from input using a # linear function, and holds internal Tensors for its weight and bias. model = torch.nn.Sequential( torch.nn.Linear(D_in, H), torch.nn.ReLU(), torch.nn.Linear(H, D_out), ) # The nn package also contains definitions of popular loss functions; in this # case we will use Mean Squared Error (MSE) as our loss function. loss_fn = torch.nn.MSELoss(reduction='sum') learning_rate = 1e-4 for t in range(500): # Forward pass: compute predicted y by passing x to the model. Module objects # override the __call__ operator so you can call them like functions. When # doing so you pass a Tensor of input data to the Module and it produces # a Tensor of output data. y_pred = model(x) # Compute and print loss. We pass Tensors containing the predicted and true # values of y, and the loss function returns a Tensor containing the # loss. loss = loss_fn(y_pred, y) if t % 100 == 99: print(t, loss.item()) # Zero the gradients before running the backward pass. model.zero_grad() # Backward pass: compute gradient of the loss with respect to all the learnable # parameters of the model. Internally, the parameters of each Module are stored # in Tensors with requires_grad=True, so this call will compute gradients for # all learnable parameters in the model. loss.backward() # Update the weights using gradient descent. Each parameter is a Tensor, so # we can access its gradients like we did before. with torch.no_grad(): for param in model.parameters(): param -= learning_rate * param.grad PyTorch：优化 到目前为止，我们通过手动更改持有可学习参数的张量(使用torch.no_grad()或.data来避免在自动分级中跟踪历史记录）来更新模型的权重。 对于像随机梯度下降这样的简单优化算法而言，这并不是一个巨大的负担，但是在实践中，我们经常使用更复杂的优化器(例如 AdaGrad，RMSProp，Adam 等）来训练神经网络。 PyTorch 中的optim软件包抽象了优化算法的思想，并提供了常用优化算法的实现。 在此示例中，我们将使用nn包像以前一样定义我们的模型，但是我们将使用optim包提供的 Adam 算法优化模型： # -*- coding: utf-8 -*- import torch # N is batch size; D_in is input dimension; # H is hidden dimension; D_out is output dimension. N, D_in, H, D_out = 64, 1000, 100, 10 # Create random Tensors to hold inputs and outputs x = torch.randn(N, D_in) y = torch.randn(N, D_out) # Use the nn package to define our model and loss function. model = torch.nn.Sequential( torch.nn.Linear(D_in, H), torch.nn.ReLU(), torch.nn.Linear(H, D_out), ) loss_fn = torch.nn.MSELoss(reduction='sum') # Use the optim package to define an Optimizer that will update the weights of # the model for us. Here we will use Adam; the optim package contains many other # optimization algoriths. The first argument to the Adam constructor tells the # optimizer which Tensors it should update. learning_rate = 1e-4 optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) for t in range(500): # Forward pass: compute predicted y by passing x to the model. y_pred = model(x) # Compute and print loss. loss = loss_fn(y_pred, y) if t % 100 == 99: print(t, loss.item()) # Before the backward pass, use the optimizer object to zero all of the # gradients for the variables it will update (which are the learnable # weights of the model). This is because by default, gradients are # accumulated in buffers( i.e, not overwritten) whenever .backward() # is called. Checkout docs of torch.autograd.backward for more details. optimizer.zero_grad() # Backward pass: compute gradient of the loss with respect to model # parameters loss.backward() # Calling the step function on an Optimizer makes an update to its # parameters optimizer.step() PyTorch：自定义 nn 模块 有时，您将需要指定比一系列现有模块更复杂的模型。 对于这些情况，您可以通过子类化nn.Module并定义一个forward来定义自己的模块，该模块使用其他模块或在 Tensors 上的其他自动转换操作来接收输入 Tensors 并生成输出 Tensors。 在此示例中，我们将两层网络实现为自定义的 Module 子类： # -*- coding: utf-8 -*- import torch class TwoLayerNet(torch.nn.Module): def __init__(self, D_in, H, D_out): \"\"\" In the constructor we instantiate two nn.Linear modules and assign them as member variables. \"\"\" super(TwoLayerNet, self).__init__() self.linear1 = torch.nn.Linear(D_in, H) self.linear2 = torch.nn.Linear(H, D_out) def forward(self, x): \"\"\" In the forward function we accept a Tensor of input data and we must return a Tensor of output data. We can use Modules defined in the constructor as well as arbitrary operators on Tensors. \"\"\" h_relu = self.linear1(x).clamp(min=0) y_pred = self.linear2(h_relu) return y_pred # N is batch size; D_in is input dimension; # H is hidden dimension; D_out is output dimension. N, D_in, H, D_out = 64, 1000, 100, 10 # Create random Tensors to hold inputs and outputs x = torch.randn(N, D_in) y = torch.randn(N, D_out) # Construct our model by instantiating the class defined above model = TwoLayerNet(D_in, H, D_out) # Construct our loss function and an Optimizer. The call to model.parameters() # in the SGD constructor will contain the learnable parameters of the two # nn.Linear modules which are members of the model. criterion = torch.nn.MSELoss(reduction='sum') optimizer = torch.optim.SGD(model.parameters(), lr=1e-4) for t in range(500): # Forward pass: Compute predicted y by passing x to the model y_pred = model(x) # Compute and print loss loss = criterion(y_pred, y) if t % 100 == 99: print(t, loss.item()) # Zero gradients, perform a backward pass, and update the weights. optimizer.zero_grad() loss.backward() optimizer.step() PyTorch：控制流+权重共享 作为动态图和权重共享的示例，我们实现了一个非常奇怪的模型：一个完全连接的 ReLU 网络，该网络在每个前向传递中选择 1 到 4 之间的随机数，并使用那么多隐藏层，多次重复使用相同的权重 计算最里面的隐藏层。 对于此模型，我们可以使用常规的 Python 流控制来实现循环，并且可以通过在定义前向传递时简单地多次重复使用同一模块来实现最内层之间的权重共享。 我们可以轻松地将此模型实现为 Module 子类： # -*- coding: utf-8 -*- import random import torch class DynamicNet(torch.nn.Module): def __init__(self, D_in, H, D_out): \"\"\" In the constructor we construct three nn.Linear instances that we will use in the forward pass. \"\"\" super(DynamicNet, self).__init__() self.input_linear = torch.nn.Linear(D_in, H) self.middle_linear = torch.nn.Linear(H, H) self.output_linear = torch.nn.Linear(H, D_out) def forward(self, x): \"\"\" For the forward pass of the model, we randomly choose either 0, 1, 2, or 3 and reuse the middle_linear Module that many times to compute hidden layer representations. Since each forward pass builds a dynamic computation graph, we can use normal Python control-flow operators like loops or conditional statements when defining the forward pass of the model. Here we also see that it is perfectly safe to reuse the same Module many times when defining a computational graph. This is a big improvement from Lua Torch, where each Module could be used only once. \"\"\" h_relu = self.input_linear(x).clamp(min=0) for _ in range(random.randint(0, 3)): h_relu = self.middle_linear(h_relu).clamp(min=0) y_pred = self.output_linear(h_relu) return y_pred # N is batch size; D_in is input dimension; # H is hidden dimension; D_out is output dimension. N, D_in, H, D_out = 64, 1000, 100, 10 # Create random Tensors to hold inputs and outputs x = torch.randn(N, D_in) y = torch.randn(N, D_out) # Construct our model by instantiating the class defined above model = DynamicNet(D_in, H, D_out) # Construct our loss function and an Optimizer. Training this strange model with # vanilla stochastic gradient descent is tough, so we use momentum criterion = torch.nn.MSELoss(reduction='sum') optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9) for t in range(500): # Forward pass: Compute predicted y by passing x to the model y_pred = model(x) # Compute and print loss loss = criterion(y_pred, y) if t % 100 == 99: print(t, loss.item()) # Zero gradients, perform a backward pass, and update the weights. optimizer.zero_grad() loss.backward() optimizer.step() 范例 您可以在此处浏览以上示例。 张量 Warm-up：numpy PyTorch：张量 自动分级 PyTorch：张量和自定等级 PyTorch：定义新的 autograd 函数 TensorFlow：静态图 nn 模块 PyTorch：nn PyTorch：优化 PyTorch：自定义 nn 模块 PyTorch：控制流+权重共享 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"53.html":{"url":"53.html","title":"torch.nn 到底是什么？","keywords":"","body":"torch.nn 到底是什么？ 原文： https://pytorch.org/tutorials/beginner/nn_tutorial.html 注意 单击此处的下载完整的示例代码 作者：杰里米·霍华德(Jeremy Howard）， fast.ai 。 感谢 Rachel Thomas 和 Francisco Ingham。 我们建议将本教程作为笔记本而不是脚本来运行。 要下载笔记本(.ipynb）文件，请单击页面顶部的链接。 PyTorch 提供设计优雅的模块和类 torch.nn ， torch.optim ， Dataset 和 DataLoader 来帮助您创建和训练神经网络。 为了充分利用它们的功能并针对您的问题对其进行自定义，您需要真正地了解他们的工作。 为了建立这种理解，我们将首先在 MNIST 数据集上训练基本神经网络，而无需使用这些模型的任何功能； 我们最初只会使用最基本的 PyTorch 张量功能。 然后，我们将一次从torch.nn，torch.optim，Dataset或DataLoader中逐个添加一个功能，确切地显示每个功能，以及如何使代码更简洁或更灵活。 本教程假定您已经安装了 PyTorch，并且熟悉张量操作的基础知识。 (如果您熟悉 Numpy 数组操作，将会发现此处使用的 PyTorch 张量操作几乎相同）。 MNIST 数据设置 我们将使用经典的 MNIST 数据集，该数据集由手绘数字的黑白图像组成(介于 0 到 9 之间）。 我们将使用 pathlib 处理路径(Python 3 标准库的一部分），并使用请求下载数据集。 我们只会在使用模块时才导入它们，因此您可以确切地看到正在使用模块的每个细节。 from pathlib import Path import requests DATA_PATH = Path(\"data\") PATH = DATA_PATH / \"mnist\" PATH.mkdir(parents=True, exist_ok=True) URL = \"http://deeplearning.net/data/mnist/\" FILENAME = \"mnist.pkl.gz\" if not (PATH / FILENAME).exists(): content = requests.get(URL + FILENAME).content (PATH / FILENAME).open(\"wb\").write(content) 该数据集为 numpy 数组格式，并已使用 pickle(一种用于序列化数据的 python 特定格式）存储。 import pickle import gzip with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\") 每个图像为 28 x 28，并存储被拍平长度为 784(= 28x28）的向量。 让我们来看一个； 我们需要先将其重塑为 2d。 from matplotlib import pyplot import numpy as np pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\") print(x_train.shape) 出： (50000, 784) PyTorch 使用torch.tensor而不是 numpy 数组，因此我们需要转换数据。 import torch x_train, y_train, x_valid, y_valid = map( torch.tensor, (x_train, y_train, x_valid, y_valid) ) n, c = x_train.shape x_train, x_train.shape, y_train.min(), y_train.max() print(x_train, y_train) print(x_train.shape) print(y_train.min(), y_train.max()) Out: tensor([[0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], ..., [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.]]) tensor([5, 0, 4, ..., 8, 4, 8]) torch.Size([50000, 784]) tensor(0) tensor(9) 从零开始的神经网络(无 torch.nn） 首先，我们仅使用 PyTorch 张量操作创建模型。 我们假设您已经熟悉神经网络的基础知识。 (如果您不是，则可以在 course.fast.ai 中学习它们）。 PyTorch 提供了创建随机或零填充张量的方法，我们将使用它们来为简单的线性模型创建权重和偏差。 这些只是常规张量，还有一个非常特殊的附加值：我们告诉 PyTorch 它们需要梯度。 这使 PyTorch 记录了在张量上完成的所有操作，因此它可以在反向传播时自动地计算梯度！ 对于权重，我们在初始化之后设置requires_grad ，因为我们不希望该步骤包含在梯度中。 (请注意，PyTorch 中的尾随_表示该操作是就地执行的。） Note 我们在这里用 Xavier 初始化(通过乘以 1 / sqrt(n））来初始化权重。 import math weights = torch.randn(784, 10) / math.sqrt(784) weights.requires_grad_() bias = torch.zeros(10, requires_grad=True) 由于 PyTorch 具有自动计算梯度的功能，我们可以将任何标准的 Python 函数(或可调用对象）用作模型！ 因此，让我们编写一个简单的矩阵乘法和广播加法来创建一个简单的线性模型。 我们还需要激活函数，因此我们将编写并使用 $log_softmax$ 。 请记住：尽管 PyTorch 提供了许多预先编写的损失函数，激活函数等，但是您可以使用纯 Python 轻松编写自己的函数。 PyTorch 甚至会自动为您的函数创建快速 GPU 或矢量化的 CPU 代码。 def log_softmax(x): return x - x.exp().sum(-1).log().unsqueeze(-1) def model(xb): return log_softmax(xb @ weights + bias) 在上面，@代表点积运算。 我们将对一批数据(在这种情况下为 64 张图像）调用函数。 这是一个前向传播。 请注意，由于我们从随机权重开始，因此在这一阶段，我们的预测不会比随机预测更好。 bs = 64 # batch size xb = x_train[0:bs] # a mini-batch from x preds = model(xb) # predictions preds[0], preds.shape print(preds[0], preds.shape) Out: tensor([-2.0790, -2.6699, -2.2096, -1.6754, -1.7844, -2.8664, -2.2463, -2.7637, -3.0813, -2.6712], grad_fn=) torch.Size([64, 10]) 如您所见，preds张量不仅包含张量值，还包含梯度函数。 稍后我们将使用它进行反向传播。 让我们实现负对数似然作为损失函数(同样，我们只能使用标准 Python）： def nll(input, target): return -input[range(target.shape[0]), target].mean() loss_func = nll 让我们用随机模型来检查损失，以便我们以后看向后传播后是否可以改善。 yb = y_train[0:bs] print(loss_func(preds, yb)) Out: tensor(2.3076, grad_fn=) 我们还实现一个函数来计算模型的准确性。 对于每个预测，如果具有最大值的索引与目标值匹配，则该预测是正确的。 def accuracy(out, yb): preds = torch.argmax(out, dim=1) return (preds == yb).float().mean() 让我们检查一下随机模型的准确性，以便我们可以看出随着损失的增加，准确性是否有所提高。 print(accuracy(preds, yb)) Out: tensor(0.1250) 现在，我们可以运行一个训练循环。 对于每次迭代，我们将： 选择一个小批量数据(大小为bs） 使用模型进行预测 计算损失 loss.backward()更新模型的梯度，在这种情况下为weights和bias。 现在，我们使用这些梯度来更新权重和偏差。 我们在torch.no_grad()上下文管理器中执行此操作，因为我们不希望在下一步的梯度计算中记录这些操作。 您可以在上阅读有关 PyTorch 的 Autograd 如何记录操作的更多信息。 然后，将梯度设置为零，以便为下一个循环做好准备。 否则，我们的梯度会记录所有已发生操作的运行记录(即loss.backward() 将梯度添加到已存储的内容中，而不是替换它们）。 小费 您可以使用标准的 python 调试器逐步浏览 PyTorch 代码，从而可以在每一步检查各种变量值。 取消注释以下set_trace()即可尝试。 from IPython.core.debugger import set_trace lr = 0.5 # learning rate epochs = 2 # how many epochs to train for for epoch in range(epochs): for i in range((n - 1) // bs + 1): # set_trace() start_i = i * bs end_i = start_i + bs xb = x_train[start_i:end_i] yb = y_train[start_i:end_i] pred = model(xb) loss = loss_func(pred, yb) loss.backward() with torch.no_grad(): weights -= weights.grad * lr bias -= bias.grad * lr weights.grad.zero_() bias.grad.zero_() 就是这样：我们完全从头开始创建并训练了一个最小的神经网络(在这种情况下，是逻辑回归，因为我们没有隐藏的层）！ 让我们检查损失和准确性，并将其与我们之前获得的进行比较。 我们希望损失会减少，准确性会增加，而且确实如此。 print(loss_func(model(xb), yb), accuracy(model(xb), yb)) Out: tensor(0.0799, grad_fn=) tensor(1.) 使用 torch.nn.functional 现在，我们将重构代码，使其与以前相同，只是我们将开始利用 PyTorch 的nn类使其更加简洁和灵活。 从这里开始的每一步，我们都应该使代码中的一个或多个：更短，更易理解和/或更灵活。 第一步也是最简单的步骤，就是用torch.nn.functional(通常按照惯例将其导入到名称空间F中）替换我们的手写激活和损失函数，从而缩短代码长度。 该模块包含torch.nn库中的所有函数(而该库的其他部分包含类）。 除了广泛的损失和激活函数外，您还会在这里找到一些合适的函数来创建神经网络，例如池化函数。 (还有一些用于进行卷积，线性图层等的函数，但是正如我们将看到的那样，通常可以使用库的其他部分来更好地处理这些函数。） 如果您使用的是负对数似然损失和 log softmax 激活，那么 Pytorch 会提供将两者结合的单个函数F.cross_entropy。 因此，我们甚至可以从模型中删除激活函数。 import torch.nn.functional as F loss_func = F.cross_entropy def model(xb): return xb @ weights + bias 请注意，我们不再在model函数中调用log_softmax。 让我们确认我们的损失和准确性与以前相同： print(loss_func(model(xb), yb), accuracy(model(xb), yb)) Out: tensor(0.0799, grad_fn=) tensor(1.) 使用 nn.Module 进行重构 接下来，我们将使用nn.Module和nn.Parameter进行更清晰，更简洁的训练循环。 我们将nn.Module子类化(它本身是一个类并且能够跟踪状态）。 在这种情况下，我们要创建一个类，该类包含前进步骤的权重，偏差和方法。 nn.Module具有许多我们将要使用的属性和方法(例如.parameters()和.zero_grad()）。 Note nn.Module(大写 M）是 PyTorch 的特定概念，也是我们将经常使用的一个类。 nn.Module不要与(小写m）模块的 Python 概念混淆，该模块是可以导入的 Python 代码文件。 from torch import nn class Mnist_Logistic(nn.Module): def __init__(self): super().__init__() self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784)) self.bias = nn.Parameter(torch.zeros(10)) def forward(self, xb): return xb @ self.weights + self.bias 由于我们现在使用的是对象而不是仅使用函数，因此我们首先必须实例化模型： model = Mnist_Logistic() 现在我们可以像以前一样计算损失。 请注意，nn.Module对象的使用就像它们是函数一样(即，它们是可调用的），但是在后台 Pytorch 会自动调用我们的forward方法。 print(loss_func(model(xb), yb)) Out: tensor(2.4205, grad_fn=) 以前，在我们的训练循环中，我们必须按名称更新每个参数的值，并手动将每个参数的 grads 分别归零，如下所示： with torch.no_grad(): weights -= weights.grad * lr bias -= bias.grad * lr weights.grad.zero_() bias.grad.zero_() 现在我们可以利用 model.parameters(）和 model.zero_grad(）(它们都由 PyTorch 为nn.Module定义）来使这些步骤更简洁，并且更不会出现忘记某些参数的错误，特别是在 我们有一个更复杂的模型： with torch.no_grad(): for p in model.parameters(): p -= p.grad * lr model.zero_grad() 我们将把小的训练循环包装在fit函数中，以便稍后再运行。 def fit(): for epoch in range(epochs): for i in range((n - 1) // bs + 1): start_i = i * bs end_i = start_i + bs xb = x_train[start_i:end_i] yb = y_train[start_i:end_i] pred = model(xb) loss = loss_func(pred, yb) loss.backward() with torch.no_grad(): for p in model.parameters(): p -= p.grad * lr model.zero_grad() fit() 让我们仔细检查一下我们的损失是否下降了： print(loss_func(model(xb), yb)) Out: tensor(0.0796, grad_fn=) 使用 nn.Linear 重构 我们继续重构我们的代码。 代替手动定义和初始化self.weights和self.bias并计算xb @ self.weights + self.bias，我们将对线性层使用 Pytorch 类 nn.Linear ，这将为我们完成所有工作。 Pytorch 具有许多类型的预定义层，可以大大简化我们的代码，并且通常也可以使其速度更快。 class Mnist_Logistic(nn.Module): def __init__(self): super().__init__() self.lin = nn.Linear(784, 10) def forward(self, xb): return self.lin(xb) 我们用与以前相同的方式实例化模型并计算损失： model = Mnist_Logistic() print(loss_func(model(xb), yb)) Out: tensor(2.3077, grad_fn=) 我们仍然可以使用与以前相同的fit方法。 fit() print(loss_func(model(xb), yb)) Out: tensor(0.0824, grad_fn=) 使用优化重构 Pytorch 还提供了一个包含各种优化算法的软件包torch.optim。 我们可以使用优化器中的step方法采取向前的步骤，而不是手动更新每个参数。 这就是我们将要替换之前手动编码的优化步骤： with torch.no_grad(): for p in model.parameters(): p -= p.grad * lr model.zero_grad() 我们只需使用下面的代替： opt.step() opt.zero_grad() (optim.zero_grad()将梯度重置为 0，我们需要在计算下一个小批量的梯度之前调用它。） from torch import optim 我们将定义一个小函数来创建模型和优化器，以便将来再次使用。 def get_model(): model = Mnist_Logistic() return model, optim.SGD(model.parameters(), lr=lr) model, opt = get_model() print(loss_func(model(xb), yb)) for epoch in range(epochs): for i in range((n - 1) // bs + 1): start_i = i * bs end_i = start_i + bs xb = x_train[start_i:end_i] yb = y_train[start_i:end_i] pred = model(xb) loss = loss_func(pred, yb) loss.backward() opt.step() opt.zero_grad() print(loss_func(model(xb), yb)) Out: tensor(2.2542, grad_fn=) tensor(0.0811, grad_fn=) 使用数据集进行重构 PyTorch 有一个抽象的 Dataset 类。 数据集可以是具有__len__函数(由 Python 的标准len函数调用）和具有__getitem__函数作为对其进行索引的一种方法。 本教程演示了一个不错的示例，该示例创建一个自定义FacialLandmarkDataset类作为Dataset的子类。 PyTorch 的 TensorDataset 是一个数据集包装张量。 通过定义索引的长度和方式，这也为我们提供了沿张量的一维进行迭代，索引和切片的方法。 这将使我们在训练的同一行中更容易访问自变量和因变量。 from torch.utils.data import TensorDataset x_train和y_train都可以合并为一个TensorDataset，这将更易于迭代和切片。 train_ds = TensorDataset(x_train, y_train) 以前，我们不得不分别遍历 x 和 y 值的迷你批处理： xb = x_train[start_i:end_i] yb = y_train[start_i:end_i] 现在，我们可以将两个步骤一起执行： xb,yb = train_ds[i*bs : i*bs+bs] model, opt = get_model() for epoch in range(epochs): for i in range((n - 1) // bs + 1): xb, yb = train_ds[i * bs: i * bs + bs] pred = model(xb) loss = loss_func(pred, yb) loss.backward() opt.step() opt.zero_grad() print(loss_func(model(xb), yb)) Out: tensor(0.0819, grad_fn=) 使用 DataLoader 进行重构 Pytorch 的DataLoader负责批次管理。 您可以从任何Dataset创建一个DataLoader。 DataLoader使迭代迭代变得更加容易。 不必使用train_ds[i*bs : i*bs+bs]，DataLoader 会自动为我们提供每个小批量。 from torch.utils.data import DataLoader train_ds = TensorDataset(x_train, y_train) train_dl = DataLoader(train_ds, batch_size=bs) 以前，我们的循环遍历批处理(xb，yb），如下所示： for i in range((n-1)//bs + 1): xb,yb = train_ds[i*bs : i*bs+bs] pred = model(xb) 现在，我们的循环更加简洁了，因为(xb，yb）是从数据加载器自动加载的： for xb,yb in train_dl: pred = model(xb) model, opt = get_model() for epoch in range(epochs): for xb, yb in train_dl: pred = model(xb) loss = loss_func(pred, yb) loss.backward() opt.step() opt.zero_grad() print(loss_func(model(xb), yb)) Out: tensor(0.0822, grad_fn=) 得益于 Pytorch 的nn.Module，nn.Parameter，Dataset和DataLoader，我们的训练循环现在变得更小，更容易理解。 现在，让我们尝试添加在实践中创建有效模型所需的基本功能。 添加验证 在第 1 部分中，我们只是试图建立一个合理的训练循环以用于我们的训练数据。 实际上，您总是也应该具有验证集，以便识别您是否过度拟合。 打乱训练数据顺序对于防止批次与过度拟合之间的相关性很重要。 另一方面，无论我们是否打乱验证集，验证损失都是相同的。 由于打乱顺序需要花费更多时间，因此打乱验证集数据顺序没有任何意义。 我们将验证集的批次大小设为训练集的两倍。 这是因为验证集不需要反向传播，因此占用的内存更少(不需要存储渐变）。 我们利用这一优势来使用更大的批量，并更快地计算损失。 train_ds = TensorDataset(x_train, y_train) train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True) valid_ds = TensorDataset(x_valid, y_valid) valid_dl = DataLoader(valid_ds, batch_size=bs * 2) 我们将在每个 epoch 结束时计算并打印验证损失。 (请注意，我们总是在训练之前调用model.train()，并在推断之前调用model.eval()，因为诸如nn.BatchNorm2d和nn.Dropout之类的图层会使用它们，以确保这些不同阶段的行为正确。） model, opt = get_model() for epoch in range(epochs): model.train() for xb, yb in train_dl: pred = model(xb) loss = loss_func(pred, yb) loss.backward() opt.step() opt.zero_grad() model.eval() with torch.no_grad(): valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl) print(epoch, valid_loss / len(valid_dl)) Out: 0 tensor(0.2903) 1 tensor(0.3343) 创建 fit(）和 get_data(） 现在，我们将自己进行一些重构。 由于我们经历了两次相似的过程来计算训练集和验证集的损失，因此我们将其设为自己的函数loss_batch，该函数可计算一批损失。 我们将优化器传入训练集中，并使用它执行反向传播。 对于验证集，我们没有通过优化程序，因此该方法不会执行反向传播。 def loss_batch(model, loss_func, xb, yb, opt=None): loss = loss_func(model(xb), yb) if opt is not None: loss.backward() opt.step() opt.zero_grad() return loss.item(), len(xb) fit运行必要的操作来训练我们的模型，并计算每个时期的训练和验证损失。 import numpy as np def fit(epochs, model, loss_func, opt, train_dl, valid_dl): for epoch in range(epochs): model.train() for xb, yb in train_dl: loss_batch(model, loss_func, xb, yb, opt) model.eval() with torch.no_grad(): losses, nums = zip( *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl] ) val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums) print(epoch, val_loss) get_data返回用于训练和验证集的数据加载器。 def get_data(train_ds, valid_ds, bs): return ( DataLoader(train_ds, batch_size=bs, shuffle=True), DataLoader(valid_ds, batch_size=bs * 2), ) 现在，我们获取数据加载器和拟合模型的整个过程可以在 3 行代码中运行： train_dl, valid_dl = get_data(train_ds, valid_ds, bs) model, opt = get_model() fit(epochs, model, loss_func, opt, train_dl, valid_dl) Out: 0 0.34931180425286296 1 0.28620736759901044 您可以使用这些基本的 3 行代码来训练各种各样的模型。 让我们看看是否可以使用它们来训练卷积神经网络(CNN）！ 切换到 CNN 现在，我们将构建具有三个卷积层的神经网络。 由于上一节中的所有函数都不包含任何有关模型组合的内容，因此我们将能够使用它们来训练 CNN，而无需进行任何修改。 我们将使用 Pytorch 的预定义 Conv2d 类作为我们的卷积层。 我们定义具有 3 个卷积层的 CNN。 每个卷积后跟一个 ReLU。 最后，我们执行平均池化。 (请注意，view是 numpy 的reshape的 PyTorch 版本） class Mnist_CNN(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1) self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1) self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1) def forward(self, xb): xb = xb.view(-1, 1, 28, 28) xb = F.relu(self.conv1(xb)) xb = F.relu(self.conv2(xb)) xb = F.relu(self.conv3(xb)) xb = F.avg_pool2d(xb, 4) return xb.view(-1, xb.size(1)) lr = 0.1 动量是随机梯度下降的一种变体，它也考虑了以前的更新，通常可以加快训练速度。 model = Mnist_CNN() opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9) fit(epochs, model, loss_func, opt, train_dl, valid_dl) Out: 0 0.33537127304077147 1 0.24059089585542678 nn.Sequential torch.nn还有另一个灵活的类，可以用来简化我们的代码： Sequential 。 Sequential对象以顺序方式运行其中包含的每个模块。 这是编写神经网络的一种简单方法。 要利用此优势，我们需要能够从给定的函数轻松定义自定义层。 例如，PyTorch 没有视图图层，我们需要为网络创建一个图层。 Lambda将创建一个层，然后在使用Sequential定义网络时可以使用该层。 class Lambda(nn.Module): def __init__(self, func): super().__init__() self.func = func def forward(self, x): return self.func(x) def preprocess(x): return x.view(-1, 1, 28, 28) 用Sequential创建的模型很简单： model = nn.Sequential( Lambda(preprocess), nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(), nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(), nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), nn.ReLU(), nn.AvgPool2d(4), Lambda(lambda x: x.view(x.size(0), -1)), ) opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9) fit(epochs, model, loss_func, opt, train_dl, valid_dl) Out: 0 0.4098783682346344 1 0.2799181687355041 包装 DataLoader 虽然我们的 CNN 网络很简洁，但是它只能在 MNIST 数据集上面有效，因为 MNIST 数据集假设输入为 28 * 28 长向量 MNIST 数据集假设 CNN 的最终网格尺寸为 4 * 4(这是因为 我们使用的平均池化卷积核的大小） 让我们摆脱这两个假设，因此我们的模型需要适用于任何 2d 单通道图像。 首先，我们可以删除初始的 Lambda 层，但将数据预处理移至生成器中： def preprocess(x, y): return x.view(-1, 1, 28, 28), y class WrappedDataLoader: def __init__(self, dl, func): self.dl = dl self.func = func def __len__(self): return len(self.dl) def __iter__(self): batches = iter(self.dl) for b in batches: yield (self.func(*b)) train_dl, valid_dl = get_data(train_ds, valid_ds, bs) train_dl = WrappedDataLoader(train_dl, preprocess) valid_dl = WrappedDataLoader(valid_dl, preprocess) 接下来，我们可以将nn.AvgPool2d替换为nn.AdaptiveAvgPool2d，这使我们可以定义所需的输出张量的大小，而不是所需的输入张量的大小。 结果，我们的模型将适用于任何大小的输入。 model = nn.Sequential( nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(), nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(), nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d(1), Lambda(lambda x: x.view(x.size(0), -1)), ) opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9) 试试看： fit(epochs, model, loss_func, opt, train_dl, valid_dl) Out: 0 0.34252993125915526 1 0.28579100420475007 使用您的 GPU 如果您足够幸运地能够使用具有 CUDA 功能的 GPU(您可以从大多数云提供商处以每小时$ 0.50 的价格租用一个 GPU），则可以使用它来加速代码。 首先检查您的 GPU 是否在 Pytorch 中正常工作： print(torch.cuda.is_available()) Out: True 然后为其创建一个设备对象： dev = torch.device( \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") 让我们更新preprocess，将批次移至 GPU： def preprocess(x, y): return x.view(-1, 1, 28, 28).to(dev), y.to(dev) train_dl, valid_dl = get_data(train_ds, valid_ds, bs) train_dl = WrappedDataLoader(train_dl, preprocess) valid_dl = WrappedDataLoader(valid_dl, preprocess) 最后，我们可以将模型移至 GPU。 model.to(dev) opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9) 您应该发现它现在运行得更快： fit(epochs, model, loss_func, opt, train_dl, valid_dl) Out: 0 0.1909765040397644 1 0.180943009185791 总结思想 现在，我们有了一个通用的数据管道和训练循环，您可以将其用于使用 Pytorch 训练多种类型的模型。 要了解现在可以轻松进行模型训练，请查看 mnist_sample 示例笔记本。 当然，您需要添加很多内容，例如数据增强，超参数调整，监控训练，转移学习等。 这些功能在 fastai 库中可用，该库是使用本教程中所示的相同设计方法开发的，为希望进一步推广模型的从业人员提供了自然的下一步。 我们承诺在本教程开始时将通过示例分别说明torch.nn，torch.optim，Dataset和DataLoader。 因此，让我们总结一下我们所看到的： torch.nn Module：创建一个类似函数行为功能的，但可以包含状态(例如神经网络层权重）的可调用对象。它知道它包含的Parameter，并且可以将其所有梯度归零，通过其循环进行权重更新等 。 Parameter：张量的包装器，它告诉Module具有在反向传播期间需要更新的权重。仅更新具有 require_grad 属性集的张量 functional：一个模块(通常按照常规导入到F名称空间中），包含激活函数，损失函数等。以及卷积和线性层之类的无状态版本。 torch.optim：包含其中SGD之类的优化程序，这些优化程序可以在反向传播期间更新权重参数 Dataset：一个具有__len__和__getitem__的抽象接口对象，包括 Pytorch 提供的类，例如TensorDataset DataLoader：获取任何Dataset并创建一个迭代器，该迭代器返回批量数据。 脚本的总运行时间：(1 分钟 7.131 秒） Download Python source code: nn_tutorial.py Download Jupyter notebook: nn_tutorial.ipynb 由狮身人面像画廊生成的画廊 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-26 23:01:04 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"56.html":{"url":"56.html","title":"自动毕业力学","keywords":"","body":"自动毕业力学 原文： https://pytorch.org/docs/stable/notes/autograd.html 本说明将概述 autograd 的工作方式并记录操作。 不一定要完全了解所有这些内容，但我们建议您熟悉它，因为它可以帮助您编写更高效，更简洁的程序，并可以帮助您进行调试。 从向后排除子图 每个张量都有一个标志：requires_grad，允许从梯度计算中细粒度地排除子图，并可以提高效率。 requires_grad 如果某个操作的单个输入需要进行渐变，则其输出也将需要进行渐变。 相反，仅当所有输入都不需要渐变时，输出才不需要。 在所有张量都不要求渐变的子图中，永远不会执行向后计算。 >>> x = torch.randn(5, 5) # requires_grad=False by default >>> y = torch.randn(5, 5) # requires_grad=False by default >>> z = torch.randn((5, 5), requires_grad=True) >>> a = x + y >>> a.requires_grad False >>> b = a + z >>> b.requires_grad True 当您要冻结部分模型，或者事先知道您将不使用渐变色时，此功能特别有用。 一些参数。 例如，如果您想微调预训练的 CNN，只需在冻结的基数中切换requires_grad标志，就不会保存任何中间缓冲区，直到计算到达最后一层，仿射变换将使用权重为 需要梯度，网络的输出也将需要它们。 model = torchvision.models.resnet18(pretrained=True) for param in model.parameters(): param.requires_grad = False # Replace the last fully-connected layer # Parameters of newly constructed modules have requires_grad=True by default model.fc = nn.Linear(512, 100) # Optimize only the classifier optimizer = optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9) autograd 如何编码历史 Autograd 是反向自动分化系统。 从概念上讲，autograd 会记录一个图形，记录执行操作时创建数据的所有操作，从而为您提供一个有向无环图，其叶子为输入张量，根为输出张量。 通过从根到叶跟踪该图，您可以使用链式规则自动计算梯度。 在内部，autograd 将该图表示为Function对象(真正的表达式）的图，可以将其apply()编辑以计算评估图的结果。 在计算前向通过时，autograd 同时执行请求的计算，并建立一个表示表示计算梯度的函数的图形(每个 torch.Tensor 的.grad_fn属性是该图形的入口）。 完成前向遍历后，我们在后向遍历中评估此图以计算梯度。 需要注意的重要一点是，每次迭代都会从头开始重新创建图形，这正是允许使用任意 Python 控制流语句的原因，它可以在每次迭代时更改图形的整体形状和大小。 在开始训练之前，您不必编码所有可能的路径-跑步就是您的与众不同。 使用 autograd 进行就地操作 在 autograd 中支持就地操作很困难，并且在大多数情况下，我们不鼓励使用它们。 Autograd 积极的缓冲区释放和重用使其非常高效，就地操作实际上很少显着降低内存使用量的情况很少。 除非您在高内存压力下进行操作，否则可能永远不需要使用它们。 限制就地操作的适用性的主要原因有两个： 就地操作可能会覆盖计算梯度所需的值。 实际上，每个就地操作都需要实现来重写计算图。 异地版本仅分配新对象并保留对旧图形的引用，而就地操作则需要更改表示此操作的Function的所有输入的创建者。 这可能很棘手，特别是如果有许多张量引用相同的存储(例如通过索引或转置创建的），并且如果修改后的输入的存储被任何其他Tensor引用，则就地函数实际上会引发错误。 就地正确性检查 每个张量都有一个版本计数器，每次在任何操作中被标记为脏时，该计数器都会增加。 当函数保存任何张量以供向后时，也会保存其包含 Tensor 的版本计数器。 访问self.saved_tensors后，将对其进行检查，如果该值大于保存的值，则会引发错误。 这样可以确保，如果您使用的是就地函数并且没有看到任何错误，则可以确保计算出的梯度是正确的。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"57.html":{"url":"57.html","title":"广播语义","keywords":"","body":"广播语义 原文： https://pytorch.org/docs/stable/notes/broadcasting.html 许多 PyTorch 操作都支持NumPy Broadcasting Semantics。 简而言之，如果 PyTorch 操作支持广播，则其 Tensor 参数可以自动扩展为相等大小(无需复制数据）。 一般语义 如果满足以下规则，则两个张量是“可广播的”： 每个张量具有至少一个维度。 从尾随尺寸开始迭代尺寸尺寸时，尺寸尺寸必须相等，其中之一为 1，或者不存在其中之一。 例如： >>> x=torch.empty(5,7,3) >>> y=torch.empty(5,7,3) # same shapes are always broadcastable (i.e. the above rules always hold) >>> x=torch.empty((0,)) >>> y=torch.empty(2,2) # x and y are not broadcastable, because x does not have at least 1 dimension # can line up trailing dimensions >>> x=torch.empty(5,3,4,1) >>> y=torch.empty( 3,1,1) # x and y are broadcastable. # 1st trailing dimension: both have size 1 # 2nd trailing dimension: y has size 1 # 3rd trailing dimension: x size == y size # 4th trailing dimension: y dimension doesn't exist # but: >>> x=torch.empty(5,2,4,1) >>> y=torch.empty( 3,1,1) # x and y are not broadcastable, because in the 3rd trailing dimension 2 != 3 如果两个张量x和y是“可广播的”，则所得张量大小的计算如下： 如果x和y的维数不相等，则在张量的维数前面加 1，以使其长度相等。 然后，对于每个尺寸尺寸，所得尺寸尺寸是该尺寸上x和y尺寸的最大值。 For Example: # can line up trailing dimensions to make reading easier >>> x=torch.empty(5,1,4,1) >>> y=torch.empty( 3,1,1) >>> (x+y).size() torch.Size([5, 3, 4, 1]) # but not necessary: >>> x=torch.empty(1) >>> y=torch.empty(3,1,7) >>> (x+y).size() torch.Size([3, 1, 7]) >>> x=torch.empty(5,2,4,1) >>> y=torch.empty(3,1,1) >>> (x+y).size() RuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1 就地语义 一个复杂之处在于，就地操作不允许就地张量由于广播而改变形状。 For Example: >>> x=torch.empty(5,3,4,1) >>> y=torch.empty(3,1,1) >>> (x.add_(y)).size() torch.Size([5, 3, 4, 1]) # but: >>> x=torch.empty(1,3,1) >>> y=torch.empty(3,1,7) >>> (x.add_(y)).size() RuntimeError: The expanded size of the tensor (1) must match the existing size (7) at non-singleton dimension 2. 向后兼容 只要每个张量中的元素数量相等，以前的 PyTorch 版本都可以在具有不同形状的张量上执行某些逐点函数。 然后，通过将每个张量视为一维来执行逐点操作。 PyTorch 现在支持广播，并且“一维”按点行为被认为已弃用，并且在张量不可广播但具有相同数量元素的情况下会生成 Python 警告。 注意，在两个张量不具有相同形状但可广播且具有相同元素数量的情况下，广播的引入会导致向后不兼容的更改。 例如： >>> torch.add(torch.ones(4,1), torch.randn(4)) 以前会产生一个具有大小：torch.Size([4,1]）的张量，但现在会产生一个具有以下大小：torch.Size([4,4]）的张量。 为了帮助确定代码中可能存在广播引入的向后不兼容的情况，可以将 torch.utils.backcompat.broadcast_warning.enabled 设置为 True ，这将生成一个 python 在这种情况下发出警告。 For Example: >>> torch.utils.backcompat.broadcast_warning.enabled=True >>> torch.add(torch.ones(4,1), torch.ones(4)) __main__:1: UserWarning: self and other do not have the same shape, but are broadcastable, and have the same number of elements. Changing behavior in a backwards incompatible manner to broadcasting rather than viewing as 1-dimensional. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"58.html":{"url":"58.html","title":"CPU 线程和 TorchScript 推断","keywords":"","body":"CPU 线程和 TorchScript 推断 原文： https://pytorch.org/docs/stable/notes/cpu_threading_torchscript_inference.html PyTorch 允许在 TorchScript 模型推断期间使用多个 CPU 线程。 下图显示了在典型应用程序中可以找到的不同级别的并行性： 一个或多个推理线程在给定的输入上执行模型的前向传递。 每个推理线程都调用一个 JIT 解释器，该解释器逐一执行内联模型的操作。 模型可以利用fork TorchScript 原语来启动异步任务。 一次分叉多个操作将导致并行执行任务。 fork运算符返回一个future对象，该对象可用于以后进行同步，例如： @torch.jit.script def compute_z(x): return torch.mm(x, self.w_z) @torch.jit.script def forward(x): # launch compute_z asynchronously: fut = torch.jit._fork(compute_z, x) # execute the next operation in parallel to compute_z: y = torch.mm(x, self.w_y) # wait for the result of compute_z: z = torch.jit._wait(fut) return y + z PyTorch 使用单个线程池实现操作间的并行性，该线程池由应用程序过程中分叉的所有推理任务共享。 除了操作间并行性之外，PyTorch 还可以在操作内部利用多个线程(操作内并行性）。 在许多情况下，这可能很有用，包括大张量上的元素操作，卷积，GEMM，嵌入查找等。 构建选项 PyTorch 使用内部的 ATen 库来实现操作。 除此之外，PyTorch 还可以通过支持 MKL 和 MKL-DNN 等外部库来构建，以加快 CPU 的计算速度。 ATen，MKL 和 MKL-DNN 支持操作内并行，并依靠以下并行库来实现它： OpenMP -广泛用于外部库中的标准(和库，通常随编译器一起提供）； TBB -针对基于任务的并行性和并发环境优化的更新并行化库。 过去，OpenMP 已被许多库使用。 以相对容易使用和支持基于循环的并行性和其他原语而闻名。 同时，OpenMP 与该应用程序使用的其他线程库之间的良好互操作性并不为人所知。 特别是，OpenMP 不保证在应用程序中将使用单个每个进程的内部操作线程池。 相反，两个不同的互操作线程将可能使用不同的 OpenMP 线程池进行互操作。 这可能会导致应用程序使用大量线程。 TBB 在外部库中使用的程度较小，但同时针对并发环境进行了优化。 PyTorch 的 TBB 后端保证了应用程序中运行的所有操作都使用一个单独的，按进程的单个进程内线程池。 根据使用情况，可能会发现一个或另一个并行化库在其应用程序中是更好的选择。 PyTorch 允许通过以下构建选项来选择构建时 ATen 和其他库使用的并行化后端： | 图书馆 | 构建选项 | 价值观 | 笔记 | | --- | --- | --- | --- | | en | ATEN_THREADING | OMP(默认），TBB | | | MKL | MKL_THREADING | (相同） | 要启用 MKL，请使用BLAS=MKL | | MKL-DNN | MKLDNN_THREADING | (same) | 要启用 MKL-DNN，请使用USE_MKLDNN=1 | 强烈建议不要在一个内部版本中混用 OpenMP 和 TBB。 以上任何TBB值都需要USE_TBB=1构建设置(默认值：OFF）。 OpenMP 并行性需要单独的设置USE_OPENMP=1(默认值：ON）。 运行时 API 以下 API 用于控制线程设置： | 并行类型 | 设定值 | Notes | | --- | --- | --- | | 互操作并行 | at::set_num_interop_threads和at::get_num_interop_threads(C ++）set_num_interop_threads和get_num_interop_threads(Python， torch 模块） | set*功能只能在启动期间，实际操作员运行之前被调用一次；默认线程数：CPU 内核数。 | | 帧内并行 | at::set_num_threads，at::get_num_threads(C ++）set_num_threads，get_num_threads(Python， torch 模块）环境变量：OMP_NUM_THREADS和MKL_NUM_THREADS | 对于操作内并行设置，at::set_num_threads，torch.set_num_threads始终优先于环境变量，MKL_NUM_THREADS变量优先于OMP_NUM_THREADS。 注意 parallel_info实用程序可打印有关线程设置的信息，并可用于调试。 在 Python 中，也可以通过torch.__config__.parallel_info()调用获得类似的输出。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"59.html":{"url":"59.html","title":"CUDA 语义","keywords":"","body":"CUDA 语义 原文： https://pytorch.org/docs/stable/notes/cuda.html torch.cuda 用于设置和运行 CUDA 操作。 它跟踪当前选择的 GPU，默认情况下，您分配的所有 CUDA 张量将在该设备上创建。 可以使用 torch.cuda.device 上下文管理器更改所选设备。 但是，一旦分配了张量，就可以对它进行操作，而与所选设备无关，并且结果将始终与张量放在同一设备上。 默认情况下，除 copy_() 和其他具有类似复制功能的方法(例如 to() 和 [cuda() 。 除非您启用对等内存访问，否则尝试在分布在不同设备上的张量上启动 ops 都会引发错误。 在下面，您可以找到一个小例子，展示了这一点： cuda = torch.device('cuda') # Default CUDA device cuda0 = torch.device('cuda:0') cuda2 = torch.device('cuda:2') # GPU 2 (these are 0-indexed) x = torch.tensor([1., 2.], device=cuda0) # x.device is device(type='cuda', index=0) y = torch.tensor([1., 2.]).cuda() # y.device is device(type='cuda', index=0) with torch.cuda.device(1): # allocates a tensor on GPU 1 a = torch.tensor([1., 2.], device=cuda) # transfers a tensor from CPU to GPU 1 b = torch.tensor([1., 2.]).cuda() # a.device and b.device are device(type='cuda', index=1) # You can also use ``Tensor.to`` to transfer a tensor: b2 = torch.tensor([1., 2.]).to(device=cuda) # b.device and b2.device are device(type='cuda', index=1) c = a + b # c.device is device(type='cuda', index=1) z = x + y # z.device is device(type='cuda', index=0) # even within a context, you can specify the device # (or give a GPU index to the .cuda call) d = torch.randn(2, device=cuda2) e = torch.randn(2).to(cuda2) f = torch.randn(2).cuda(cuda2) # d.device, e.device, and f.device are all device(type='cuda', index=2) 异步执行 默认情况下，GPU 操作是异步的。 当您调用使用 GPU 的函数时，的操作会排队到特定的设备，但不一定要等到以后执行。 这使我们能够并行执行更多计算，包括在 CPU 或其他 GPU 上的操作。 通常，调用者看不到异步计算的效果，因为(1）每个设备按照它们排队的顺序执行操作，并且(2）当在 CPU 和 GPU 之间或两个 GPU 之间复制数据时，PyTorch 自动执行必要的同步。 因此，计算将像每个操作都同步执行一样进行。 您可以通过设置环境变量CUDA_LAUNCH_BLOCKING=1来强制进行同步计算。 当 GPU 上发生错误时，这很方便。 (对于异步执行，直到实际执行该操作后才报告这种错误，因此堆栈跟踪不会显示请求的位置。） 异步计算的结果是没有同步的时间测量不准确。 要获得精确的测量结果，应在测量之前致电 torch.cuda.synchronize() ，或使用 torch.cuda.Event 记录时间，如下所示： start_event = torch.cuda.Event(enable_timing=True) end_event = torch.cuda.Event(enable_timing=True) start_event.record() # Run some things here end_event.record() torch.cuda.synchronize() # Wait for the events to be recorded! elapsed_time_ms = start_event.elapsed_time(end_event) 作为例外， to() 和 copy_() 等几个函数都允许使用显式non_blocking参数，该参数使调用者在不需要时绕过同步。 另一个例外是 CUDA 流，如下所述。 CUDA 流 CUDA 流是属于特定设备的线性执行序列。 通常，您无需显式创建一个：默认情况下，每个设备使用其自己的“默认”流。 每个流内部的操作都按照创建顺序进行序列化，但是来自不同流的操作可以以任何相对顺序并发执行，除非显式同步功能(例如 synchronize() 或 wait_stream())。 例如，以下代码不正确： cuda = torch.device('cuda') s = torch.cuda.Stream() # Create a new stream. A = torch.empty((100, 100), device=cuda).normal_(0.0, 1.0) with torch.cuda.stream(s): # sum() may start execution before normal_() finishes! B = torch.sum(A) 如上所述，当“当前流”为默认流时，PyTorch 会在数据四处移动时自动执行必要的同步。 但是，使用非默认流时，用户有责任确保正确的同步。 内存管理 PyTorch 使用缓存内存分配器来加速内存分配。 这允许快速的内存重新分配而无需设备同步。 但是，分配器管理的未使用内存仍将显示为nvidia-smi中使用的内存。 您可以使用 memory_allocated() 和 max_memory_allocated() 来监视张量占用的内存，并使用 memory_reserved() 和 max_memory_reserved() 监视由缓存分配器管理的内存总量。 调用 empty_cache() 会从 PyTorch 释放所有未使用的缓存内存，以便其他 GPU 应用程序可以使用它们。 但是，张量占用的 GPU 内存不会被释放，因此不会增加可用于 PyTorch 的 GPU 内存量。 对于更高级的用户，我们通过 memory_stats() 提供更全面的内存基准测试。 我们还提供了通过 memory_snapshot() 捕获内存分配器状态的完整快照的功能，它可以帮助您了解代码所产生的基础分配模式。 cuFFT 计划缓存 对于每个 CUDA 设备，使用 cuFFT 计划的 LRU 缓存来加速在具有相同配置的相同几何形状的 CUDA 张量上重复运行 FFT 方法(例如 torch.fft())。 由于某些 cuFFT 计划可能会分配 GPU 内存，因此这些缓存具有最大容量。 您可以使用以下 API 控制和查询当前设备的缓存的属性： torch.backends.cuda.cufft_plan_cache.max_size给出了缓存的容量(在 CUDA 10 及更高版本上，默认值为 4096；在较旧 CUDA 版本上，默认值为 1023）。 设置该值将直接修改容量。 torch.backends.cuda.cufft_plan_cache.size给出当前驻留在缓存中的计划数量。 torch.backends.cuda.cufft_plan_cache.clear()清除缓存。 要控制和查询非默认设备的计划缓存，您可以使用torch.device对象或设备索引为torch.backends.cuda.cufft_plan_cache对象建立索引，并访问上述属性之一。 例如，要设置设备1的缓存容量，可以写入torch.backends.cuda.cufft_plan_cache[1].max_size = 10。 最佳实务 与设备无关的代码 由于 PyTorch 的结构，您可能需要显式编写与设备无关的代码(CPU 或 GPU）； 一个例子可能是创建一个新的张量作为循环神经网络的初始隐藏状态。 第一步是确定是否应使用 GPU。 一种常见的模式是与 is_available() 结合使用 Python 的argparse模块读取用户参数，并具有可用于禁用 CUDA 的标志。 在下面，args.device产生一个torch.device对象，该对象可用于将张量移动到 CPU 或 CUDA。 import argparse import torch parser = argparse.ArgumentParser(description='PyTorch Example') parser.add_argument('--disable-cuda', action='store_true', help='Disable CUDA') args = parser.parse_args() args.device = None if not args.disable_cuda and torch.cuda.is_available(): args.device = torch.device('cuda') else: args.device = torch.device('cpu') 现在我们有了args.device，我们可以使用它在所需设备上创建张量。 x = torch.empty((8, 42), device=args.device) net = Network().to(device=args.device) 在许多情况下可以使用它来生成设备不可知代码。 以下是使用数据加载器时的示例： cuda0 = torch.device('cuda:0') # CUDA GPU 0 for i, x in enumerate(train_loader): x = x.to(cuda0) 在系统上使用多个 GPU 时，可以使用CUDA_VISIBLE_DEVICES环境标志来管理 PyTorch 可以使用哪些 GPU。 如上所述，要手动控制在哪个 GPU 上创建张量，最佳实践是使用 torch.cuda.device 上下文管理器。 print(\"Outside device is 0\") # On device 0 (default in most scenarios) with torch.cuda.device(1): print(\"Inside device is 1\") # On device 1 print(\"Outside device is still 0\") # On device 0 如果您具有张量，并且想在同一设备上创建相同类型的新张量，则可以使用torch.Tensor.new_*方法(请参见 torch.Tensor)。 前面提到的torch.*工厂函数 (Creation Ops)取决于当前 GPU 上下文和您传入的属性参数，torch.Tensor.new_*方法保留设备和张量的其他属性。 这是在创建模块时的推荐做法，在这些模块中，在前向传递期间需要在内部创建新的张量。 cuda = torch.device('cuda') x_cpu = torch.empty(2) x_gpu = torch.empty(2, device=cuda) x_cpu_long = torch.empty(2, dtype=torch.int64) y_cpu = x_cpu.new_full([3, 2], fill_value=0.3) print(y_cpu) tensor([[ 0.3000, 0.3000], [ 0.3000, 0.3000], [ 0.3000, 0.3000]]) y_gpu = x_gpu.new_full([3, 2], fill_value=-5) print(y_gpu) tensor([[-5.0000, -5.0000], [-5.0000, -5.0000], [-5.0000, -5.0000]], device='cuda:0') y_cpu_long = x_cpu_long.new_tensor([[1, 2, 3]]) print(y_cpu_long) tensor([[ 1, 2, 3]]) 如果要创建与其他张量相同类型和大小的张量，并用一个或零填充，请提供 ones_like() 或 zeros_like() 作为方便的助手 函数(还保留张量的torch.device和torch.dtype）。 x_cpu = torch.empty(2, 3) x_gpu = torch.empty(2, 3) y_cpu = torch.ones_like(x_cpu) y_gpu = torch.zeros_like(x_gpu) 使用固定的内存缓冲区 主机到 GPU 副本源自固定(页面锁定）内存时，速度要快得多。 CPU 张量和存储公开了 pin_memory() 方法，该方法返回对象的副本，并将数据放在固定的区域中。 此外，一旦固定张量或存储，就可以使用异步 GPU 副本。 只需将附加的non_blocking=True参数传递给 to() 或 cuda() 调用。 这可用于将数据传输与计算重叠。 通过将pin_memory=True传递给其构造函数，可以使 DataLoader 返回放置在固定内存中的批处理。 使用 nn.DataParallel 代替并行处理 大多数涉及批处理输入和多个 GPU 的用例应默认使用 DataParallel 来利用多个 GPU。 即使使用 GIL，单个 Python 进程也可以使多个 GPU 饱和。 从 0.1.9 版开始，可能无法充分利用大量 GPU(8+）。 但是，这是一个正在积极开发的已知问题。 与往常一样，测试您的用例。 使用 multiprocessing 的 CUDA 模型有很多警告； 除非注意要完全满足数据处理要求，否则您的程序可能会出现错误或不确定的行为。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:39:43 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"60.html":{"url":"60.html","title":"分布式 Autograd 设计","keywords":"","body":"分布式 Autograd 设计 原文： https://pytorch.org/docs/stable/notes/distributed_autograd.html 警告 分布式 RPC 框架是实验性的，随时可能更改。 本说明将介绍分布式自动分级的详细设计，并逐步介绍其内部。 在继续之前，请确保您熟悉 Autograd 机械手和分布式 RPC 框架。 背景 假设您有两个节点，并且在两个节点之间划分了一个非常简单的模型。 可以使用 torch.distributed.rpc 如下实现： import torch import torch.distributed.rpc as rpc def my_add(t1, t2): return torch.add(t1, t2) # On worker 0: t1 = torch.rand((3, 3), requires_grad=True) t2 = torch.rand((3, 3), requires_grad=True) # Perform some computation remotely. t3 = rpc.rpc_sync(\"worker1\", my_add, args=(t1, t2)) # Perform some computation locally based on remote result. t4 = torch.rand((3, 3), requires_grad=True) t5 = torch.mul(t3, t4) # Compute some loss. loss = t5.sum() 分布式 autograd 背后的主要动机是使用我们已经计算并记录所有需要梯度的张量的合适梯度的loss在这样的分布式模型上运行向后传递。 正向通过过程中的自动分级记录 PyTorch 在正向传递过程中会构建自动分级图，该图用于执行向后传递。 有关更多详细信息，请参见 autograd 如何编码历史记录。 对于分布式 autograd，我们需要在正向传递过程中跟踪所有 RPC，以确保正确执行向后传递。 为此，我们在执行 RPC 时将send和recv函数附加到自动缩放图。 send函数附加到 RPC 的源，并且其输出边指向 RPC 输入张量的 autograd 函数。 从目的地接收反向传递期间此功能的输入，作为适当的recv功能的输出。 recv函数附加到 RPC 的目标，并且使用输入张量从在目标上执行的运算符检索其输入。 在向后传递过程中，此函数的输出梯度将发送到源节点并发送到适当的send函数。 每个send-recv对都分配有一个全局唯一的autograd_message_id，以唯一地标识该对。 这对于在反向传递期间在远程节点上查找对应的功能很有用。 对于 RRef ，每当我们调用 torch.distributed.rpc.RRef.to_here() 时，我们都会为所涉及的张量附加一个适当的send-recv对。 举例来说，这就是我们上面示例中的 autograd 图的样子(为简单起见，排除了 t5.sum(））： 分布式 Autograd 上下文 每个使用分布式 autograd 的正向和反向传递都分配有唯一的 torch.distributed.autograd.context ，并且此上下文具有全局唯一的autograd_context_id。 根据需要在每个节点上创建此上下文。 此上下文具有以下目的： 运行分布式后向遍历的多个节点可能会在同一张量上累积梯度，因此，在我们有机会运行优化器之前，张量的.grad字段将具有来自各种分布式后向遍历的梯度。 这类似于在本地多次调用 torch.autograd.backward() 。 为了提供一种为每个后退通道分离梯度的方法，对于每个后退通道，梯度会累积在 torch.distributed.autograd.context 中。 在前向传递过程中，我们在这种情况下为每个自动分级传递存储send和recv函数。 这样可以确保我们保留对 autograd 图中适当节点的引用，以使其保持活动状态。 除此之外，在向后传递过程中很容易查找适当的send和recv功能。 通常，我们还使用此上下文为每个分布式 autograd pass 存储一些元数据。 从用户的角度来看，自动分级上下文的设置如下： import torch.distributed.autograd as dist_autograd with dist_autograd.context() as context_id: loss = model.forward() dist_autograd.backward(loss) 分布式后向通行证 在本节中，我们概述了在分布式后向传递过程中准确计算依赖项的挑战，并描述了一些关于如何执行分布式后向传递的算法(需要权衡）。 计算依赖 考虑以下代码在单台计算机上运行 import torch a = torch.rand((3, 3), requires_grad=True) b = torch.rand((3, 3), requires_grad=True) c = torch.rand((3, 3), requires_grad=True) d = a + b e = b * c d.sum.().backward() 这就是上面代码的 autograd 图形： autograd 引擎作为向后传递的一部分执行的第一步是计算 autograd 图中每个节点的依赖项数量。 这有助于 autograd 引擎知道何时可以执行图中的节点。 add(1)和mul(0)括号中的数字表示依赖项的数量。 如您所见，这意味着在向后传递期间，add节点需要 1 个输入，mul节点不需要任何输入(换句话说，不需要执行）。 本地 autograd 引擎通过遍历根节点中的图来计算这些依赖性(在这种情况下为d）。 autograd 图中的某些节点可能无法在向后传递中执行的事实对分布式 autograd 提出了挑战。 考虑使用 RPC 的这段代码。 import torch import torch.distributed.rpc as rpc a = torch.rand((3, 3), requires_grad=True) b = torch.rand((3, 3), requires_grad=True) c = torch.rand((3, 3), requires_grad=True) d = rpc.rpc_sync(\"worker1\", torch.add, args=(a, b)) e = rpc.rpc_sync(\"worker1\", torch.mul, args=(b, c)) loss = d.sum() 上面的代码的相关自动分级图为： 计算此分布式 autograd 图的依赖项更具挑战性，并且需要一些开销(无论是在计算还是在网络通信方面）。 对于性能敏感的应用程序，我们可以通过假设每个send和recv函数在反向传递中都是有效的(大多数应用程序不执行未使用的 RPC）来避免很多开销。 这简化了分布式 autograd 算法，并且效率更高，但代价是应用程序需要意识到这些限制。 该算法称为 FAST 模式算法，下面将对其进行详细说明。 在一般情况下，可能不需要每个send和recv函数都有效作为反向传递的一部分。 为了解决这个问题，我们还有一个 SMART 模式算法，将在后面的部分中进行介绍。 快速模式算法 该算法的关键假设是，当我们运行向后传递时，每个send函数的相关性均为 1。 换句话说，我们假设将从另一个节点接收到 RPC 上的渐变。 算法如下： 我们从具有向后遍历的根的工作程序开始(所有根必须是本地的）。 查找当前分布式 Autograd 上下文的所有send功能。 从提供的根目录和我们检索到的所有send函数开始，本地计算依赖项。 计算依赖关系后，使用提供的根启动本地 autograd 引擎。 当 autograd 引擎执行recv功能时，recv功能会通过 RPC 将输入梯度发送到适当的工作程序。 每个recv函数都知道目标工作者 ID，因为它被记录为正向传递的一部分。 recv功能还将autograd_context_id和autograd_message_id发送到远程主机。 当在远程主机上收到此请求时，我们使用autograd_context_id和autograd_message_id查找适当的send功能。 如果这是工作人员第一次收到对给定autograd_context_id的请求，则它将如上面的第 1-3 点所述在本地计算依赖性。 然后，将在 6 中检索到的send函数排队以便在该工作者的本地 autograd 引擎上执行。 最后，我们不是在张量的.grad字段上累积梯度，而是根据分布式自学背景分别累积梯度。 梯度存储在Dict[Tensor, Tensor]中，基本上是从 Tensor 到其相关梯度的映射，可以使用 get_gradients() API 检索此映射。 例如，具有分布式 autograd 的完整代码如下： import torch import torch.distributed.autograd as dist_autograd import torch.distributed.rpc as rpc def my_add(t1, t2): return torch.add(t1, t2) # On worker 0: # Setup the autograd context. with dist_autograd.context() as context_id: t1 = torch.rand((3, 3), requires_grad=True) t2 = torch.rand((3, 3), requires_grad=True) # Perform some computation remotely. t3 = rpc.rpc_sync(\"worker1\", my_add, args=(t1, t2)) # Perform some computation locally based on remote result. t4 = torch.rand((3, 3), requires_grad=True) t5 = torch.mul(t3, t4) # Compute some loss. loss = t5.sum() # Run the backward pass. dist_autograd.backward([loss]) # Retrieve the gradients from the context. dist_autograd.get_gradients(context_id) 具有依赖关系的分布式 autograd 图如下所示： 应用于以上示例的 FAST 模式算法如下： 在Worker 0上，我们从根loss和send1开始计算依赖关系。 结果，send1的依赖性为 1，mul对Worker 0的依赖性为 1。 现在，我们在Worker 0上启动本地 autograd 引擎。 我们首先执行mul函数，将其输出在 autograd 上下文中累积为t4的梯度。 然后，我们执行recv2，它将梯度发送到Worker 1。 由于这是Worker 1第一次听到有关此反向传递的信息，因此它将开始依赖性计算并适当地标记send2，add和recv1的依赖性。 接下来，将send2排队在Worker 1的本地 autograd 引擎上，该引擎依次执行add和recv1。 当执行recv1时，它将梯度发送到Worker 0。 由于Worker 0已经计算了此向后传递的依赖性，因此它仅排队并在本地执行send1。 最后，t1，t2和t4的梯度会累积在分布式 Autograd 上下文中。 SMART 模式算法 该算法的完整细节仍在研究中，但是对于一般概念，您可以参考 RFC 中的分布式 Autograd Algorithm Smart 模式部分。 分布式优化器 DistributedOptimizer 的操作如下： 获取要优化的远程参数列表 (RRef)。 这些也可以是包装在本地RRef中的本地参数。 将 Optimizer 类作为本地优化器，以在所有不同的RRef所有者上运行。 分布式优化器在每个工作程序节点上创建本地Optimizer的实例，并将其保存RRef。 当调用 torch.distributed.optim.DistributedOptimizer.step() 时，分布式优化器使用 RPC 在适当的远程工作器上远程执行所有本地优化器。 如果多个并发的分布式优化器正在更新工作器上的相同参数，则这些更新将通过锁序列化。 简单的端到端示例 综上所述，以下是使用分布式 autograd 和分布式优化器的简单的端到端示例。 如果将代码放入名为“ dist_autograd_simple.py”的文件中，则可以使用命令MASTER_ADDR=\"localhost\" MASTER_PORT=29500 python dist_autograd_simple.py运行该代码： import multiprocessing as mp import torch import torch.distributed.autograd as dist_autograd from torch.distributed import rpc from torch import optim from torch.distributed.optim import DistributedOptimizer def random_tensor(): return torch.rand((3, 3), requires_grad=True) def _run_process(rank, dst_rank, world_size): name = \"worker{}\".format(rank) dst_name = \"worker{}\".format(dst_rank) # Initialize RPC. rpc.init_rpc( name=name, rank=rank, world_size=world_size ) # Use a distributed autograd context. with dist_autograd.context() as context_id: # Forward pass (create references on remote nodes). rref1 = rpc.remote(dst_name, random_tensor) rref2 = rpc.remote(dst_name, random_tensor) loss = rref1.to_here() + rref2.to_here() # Backward pass (run distributed autograd). dist_autograd.backward([loss.sum()]) # Build DistributedOptimizer. dist_optim = DistributedOptimizer( optim.SGD, [rref1, rref2], lr=0.05, ) # Run the distributed optimizer step. dist_optim.step() def run_process(rank, dst_rank, world_size): _run_process(rank, dst_rank, world_size) rpc.shutdown() processes = [] # Run world_size workers. world_size = 2 for i in range(world_size): p = mp.Process(target=run_process, args=(i, (i + 1) % 2, world_size)) p.start() processes.append(p) for p in processes: p.join() 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:39:43 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"61.html":{"url":"61.html","title":"扩展 PyTorch","keywords":"","body":"扩展 PyTorch 原文： https://pytorch.org/docs/stable/notes/extending.html 在本说明中，我们将介绍扩展 torch.nn ， torch.autograd 以及使用我们的 C 库编写自定义 C 扩展的方法。 扩展 torch.autograd 向 autograd 添加操作需要为每个操作实现一个新的 Function 子类。 回想一下 Function 是 autograd 用于计算结果和梯度并编码操作历史的工具。 每个新功能都需要您实现 2 种方法： forward() -执行该操作的代码。 如果指定默认值，它可以根据需要选择任意数量的参数，其中一些参数是可选的。 此处接受各种 Python 对象。 跟踪历史记录的Tensor自变量(即使用requires_grad=True的自变量）将被转换为在调用之前不跟踪历史的自变量，并且它们的使用将被记录在图形中。 请注意，此逻辑不会遍历列表/字典/任何其他数据结构，而只会考虑直接作为调用参数的Tensor。 您可以返回单个Tensor输出，或者如果有多个输出，则返回Tensor的tuple。 另外，请参考 Function 的文档，以找到仅可从 forward() 调用的有用方法的描述。 backward() -梯度公式。 将给与Tensor参数一样多的参数，每个参数代表梯度 w.r.t。 该输出。 它应该返回与输入一样多的Tensor，每个输入都包含梯度 w.r.t。 其相应的输入。 如果您的输入不需要梯度(needs_input_grad是布尔值的元组，指示每个输入是否需要梯度计算），或者是非Tensor对象，则可以返回python:None。 另外，如果您为 forward() 设置了可选参数，则返回的梯度可能比输入的梯度多，只要它们都是python:None。 注意 用户有责任正确使用前向 ctx 中的特殊功能，以确保新的 Function 与Autograd Engine一起正常工作。 保存正向输入或输出以供稍后在向后使用时，必须使用 save_for_backward() 。 mark_dirty() 必须用于标记任何由正向功能修改的输入。 mark_non_differentiable() 必须用于告知发动机输出是否不可微。 您可以在下面找到 torch.nn 中Linear功能的代码，并附带以下注释： # Inherit from Function class LinearFunction(Function): # Note that both forward and backward are @staticmethods @staticmethod # bias is an optional argument def forward(ctx, input, weight, bias=None): ctx.save_for_backward(input, weight, bias) output = input.mm(weight.t()) if bias is not None: output += bias.unsqueeze(0).expand_as(output) return output # This function has only a single output, so it gets only one gradient @staticmethod def backward(ctx, grad_output): # This is a pattern that is very convenient - at the top of backward # unpack saved_tensors and initialize all gradients w.r.t. inputs to # None. Thanks to the fact that additional trailing Nones are # ignored, the return statement is simple even when the function has # optional inputs. input, weight, bias = ctx.saved_tensors grad_input = grad_weight = grad_bias = None # These needs_input_grad checks are optional and there only to # improve efficiency. If you want to make your code simpler, you can # skip them. Returning gradients for inputs that don't require it is # not an error. if ctx.needs_input_grad[0]: grad_input = grad_output.mm(weight) if ctx.needs_input_grad[1]: grad_weight = grad_output.t().mm(input) if bias is not None and ctx.needs_input_grad[2]: grad_bias = grad_output.sum(0) return grad_input, grad_weight, grad_bias 现在，为了使使用这些自定义操作更容易，我们建议为它们的apply方法加上别名： linear = LinearFunction.apply 在这里，我们给出了一个由非 Tensor 参数参数化的函数的附加示例： class MulConstant(Function): @staticmethod def forward(ctx, tensor, constant): # ctx is a context object that can be used to stash information # for backward computation ctx.constant = constant return tensor * constant @staticmethod def backward(ctx, grad_output): # We return as many input gradients as there were arguments. # Gradients of non-Tensor arguments to forward must be None. return grad_output * ctx.constant, None Note backward的输入，即grad_output，也可以是跟踪历史的张量。 因此，如果backward通过可区分的操作实现(例如，调用另一个自定义function），则高阶导数将起作用。 您可能想检查实现的向后方法是否实际计算了函数的派生类。 通过与使用较小有限差分的数值近似进行比较，可以实现： from torch.autograd import gradcheck # gradcheck takes a tuple of tensors as input, check if your gradient # evaluated with these tensors are close enough to numerical # approximations and returns True if they all verify this condition. input = (torch.randn(20,20,dtype=torch.double,requires_grad=True), torch.randn(30,20,dtype=torch.double,requires_grad=True)) test = gradcheck(linear, input, eps=1e-6, atol=1e-4) print(test) 有关有限差分梯度比较的更多详细信息，请参见数字梯度检查。 扩展 torch.nn nn 导出两种接口-模块及其功能版本。 您可以通过两种方式对其进行扩展，但是我们建议对所有层使用模块，这些模块可容纳任何参数或缓冲区，并建议使用功能形式的无参数操作，例如激活函数，缓冲池等。 上面的部分已经完全介绍了添加操作的功能版本。 添加 Module 由于 nn 大量利用了 autograd ，因此添加新的 Module 需要实现执行该操作的 Function 并可以计算梯度。 从现在开始，假设我们要实现Linear模块，并且已经实现了如上清单所示的功能。 只需很少的代码即可添加。 现在，需要实现两个功能： __init__(可选）-接受参数，例如内核大小，功能数量等，并初始化参数和缓冲区。 forward() -实例化 Function 并使用它执行操作。 它与上面显示的功能包装非常相似。 这是可以实现Linear模块的方式： class Linear(nn.Module): def __init__(self, input_features, output_features, bias=True): super(Linear, self).__init__() self.input_features = input_features self.output_features = output_features # nn.Parameter is a special kind of Tensor, that will get # automatically registered as Module's parameter once it's assigned # as an attribute. Parameters and buffers need to be registered, or # they won't appear in .parameters() (doesn't apply to buffers), and # won't be converted when e.g. .cuda() is called. You can use # .register_buffer() to register buffers. # nn.Parameters require gradients by default. self.weight = nn.Parameter(torch.Tensor(output_features, input_features)) if bias: self.bias = nn.Parameter(torch.Tensor(output_features)) else: # You should always register all possible parameters, but the # optional ones can be None if you want. self.register_parameter('bias', None) # Not a very smart way to initialize weights self.weight.data.uniform_(-0.1, 0.1) if bias is not None: self.bias.data.uniform_(-0.1, 0.1) def forward(self, input): # See the autograd section for explanation of what happens here. return LinearFunction.apply(input, self.weight, self.bias) def extra_repr(self): # (Optional)Set the extra information about this module. You can test # it by printing an object of this class. return 'in_features={}, out_features={}, bias={}'.format( self.in_features, self.out_features, self.bias is not None ) 编写自定义 C ++扩展 有关详细说明和示例，请参见 PyTorch 教程。 可在 torch.utils.cpp_extension 上找到文档。 编写自定义 C 扩展 可以在此 GitHub 存储库上找到示例。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:54:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"62.html":{"url":"62.html","title":"经常问的问题","keywords":"","body":"经常问的问题 原文： https://pytorch.org/docs/stable/notes/faq.html 我的模型报告“ CUDA 运行时错误(2）：内存不足” 如错误消息所暗示，您的 GPU 内存已用完。 由于我们经常在 PyTorch 中处理大量数据，因此小错误可能会迅速导致您的程序用尽所有 GPU； 幸运的是，这些情况下的修复程序通常很简单。 以下是一些常见的检查事项： 不要在整个训练循环中累积历史记录。 默认情况下，涉及需要渐变的变量的计算将保留历史记录。 这意味着您应避免在计算中使用此类变量，这些变量将不受训练循环的影响，例如在跟踪统计信息时。 相反，您应该分离变量或访问其基础数据。 有时，可微变量发生时可能不是很明显。 考虑以下训练循环(从源删节）： total_loss = 0 for i in range(10000): optimizer.zero_grad() output = model(input) loss = criterion(output) loss.backward() optimizer.step() total_loss += loss 在这里，total_loss会在您的训练循环中累积历史记录，因为loss是具有自动分级历史记录的可微变量。 您可以改写 total_loss + = float(loss）来解决此问题。 此问题的其他实例： 1 。 不要使用不需要的张量和变量。 如果将 Tensor 或 Variable 分配给本地，Python 将不会取消分配，直到本地超出范围。 您可以使用del x释放此参考。 同样，如果将 Tensor 或 Variable 分配给对象的成员变量，则在对象超出范围之前它不会释放。 如果不使用不需要的临时存储，则将获得最佳的内存使用率。 当地人的范围可能会超出您的预期。 例如： for i in range(5): intermediate = f(input[i]) result += g(intermediate) output = h(result) return output 这里，即使h正在执行，intermediate仍保持活动状态，因为它的作用域超出了循环的结尾。 要提早释放它，使用完后应del intermediate。 不要对太大的序列运行 RNN。 通过 RNN 反向传播所需的内存量与 RNN 输入的长度成线性比例； 因此，如果您尝试向 RNN 输入过长的序列，则会耗尽内存。 这种现象的技术术语是到时间的反向传播，关于如何实现截断 BPTT 的参考很​​多，包括字语言模型示例； 截断由本论坛帖子中所述的repackage功能处理。 请勿使用太大的线性图层。 线性层nn.Linear(m, n)使用内存：也就是说，权重的内存要求与要素数量成正比关系。 以这种方式穿透内存非常容易(请记住，您至少需要权重大小的两倍，因为您还需要存储渐变。） 我的 GPU 内存未正确释放 PyTorch 使用缓存内存分配器来加速内存分配。 因此，nvidia-smi中显示的值通常不能反映真实的内存使用情况。 有关 GPU 内存管理的更多详细信息，请参见内存管理。 如果即使在退出 Python 后仍没有释放 GPU 内存，则很可能某些 Python 子进程仍然存在。 您可以通过ps -elf | grep python找到它们，然后使用kill -9 [pid]手动将其杀死。 我的数据加载器工作人员返回相同的随机数 您可能会使用其他库在数据集中生成随机数。 例如，当通过fork启动工作程序子流程时，NumPy 的 RNG 被复制。 请参阅 torch.utils.data.DataLoader 的文档，以了解如何通过worker_init_fn选项在工人中正确设置随机种子。 我的经常性网络无法使用数据并行性 在 Module 与 DataParallel 或 data_parallel() 中使用pack sequence -&gt; recurrent network -&gt; unpack sequence模式是很微妙的。 每个设备上每个forward()的输入仅是整个输入的一部分。 由于默认情况下，拆包操作 torch.nn.utils.rnn.pad_packed_sequence() 仅填充其看到的最长输入，即该特定设备上的最长输入，因此，将结果汇总在一起时会发生大小不匹配的情况。 因此，您可以改而利用 pad_packed_sequence() 的total_length自变量来确保forward()调用相同长度的返回序列。 例如，您可以编写： from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence class MyModule(nn.Module): # ... __init__, other methods, etc. # padded_input is of shape [B x T x *] (batch_first mode) and contains # the sequences sorted by lengths # B is the batch size # T is max sequence length def forward(self, padded_input, input_lengths): total_length = padded_input.size(1) # get the max sequence length packed_input = pack_padded_sequence(padded_input, input_lengths, batch_first=True) packed_output, _ = self.my_lstm(packed_input) output, _ = pad_packed_sequence(packed_output, batch_first=True, total_length=total_length) return output m = MyModule().cuda() dp_m = nn.DataParallel(m) 此外，当批处理尺寸为1(即batch_first=False）且数据平行时，需要格外小心。 在这种情况下，pack_padded_sequence padding_input的第一个参数的形状将为[T x B x *]，并且应沿昏暗1分散，而第二个参数input_lengths的形状将为[B]，并且应沿昏暗[[Gate] 0。 将需要额外的代码来操纵张量形状。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"63.html":{"url":"63.html","title":"大规模部署的功能","keywords":"","body":"大规模部署的功能 原文： https://pytorch.org/docs/stable/notes/large_scale_deployments.html 整个机队的运营商配置文件 API 使用记录 将元数据附加到已保存的 TorchScript 模型中 构建环境注意事项 通用扩展点 本说明讨论了一些扩展点和技巧，这些扩展点和技巧在较大的系统中运行 PyTorch 或在较大的组织中使用 PyTorch 操作多个系统时可能有用。 它不涉及将模型部署到生产中的主题。 检查 torch.jit 或相应的教程之一。 该注释假定您是从组织中的源代码构建 PyTorch 的，或者能够静态链接使用 PyTorch 时要加载的其他代码。 因此，许多钩子都公开为 C ++ API，可以在集中式位置(例如， 在静态初始化代码中。 整个机队的运营商配置文件 PyTorch 带有torch.autograd.profiler，能够测量各个操作员根据需要花费的时间。 可以使用相同的机制对运行 PyTorch 的任何进程进行“始终在线”测量。 收集有关在给定进程中或在整个机器组中运行的 PyTorch 工作负载的信息可能很有用。 可以使用torch::autograd::profiler::pushCallback添加用于任何操作员调用的新回调。 挂钩将使用描述调用上下文的torch::autograd::profiler::RecordFunction结构调用(例如名称）。 如果启用，RecordFunction::inputs()包含表示为torch::IValue变量类型的函数的参数。 注意，输入日志记录相对昂贵，因此必须显式启用。 操作员回调还可以访问at::getThreadLocalDebugInfo()接口，该接口返回指向包含调试信息的结构的指针。 该调试信息应该与相应的at::setThreadLocalDebugInfo(debug_info)调用一起设置。 调试信息通过前向传播(包括异步fork任务）和后向传播进行传播，对于将有关执行环境的一些额外信息(例如，模型 ID）从应用程序的高层传递到操作员回调非常有用。 调用回调会增加一些开销，因此通常随机抽样操作员调用很有用。 可以在每个回调的基础上启用 torch :: autograd :: profiler :: setSamplingProbability 指定的全局采样率。 请注意，pushCallback和setSamplingProbability不是线程安全的，只有在没有运行 PyTorch 运算符时才能调用。 通常，在初始化过程中一次调用它们是一个好主意。 这是一个例子： // Called somewhere in the program beginning void init() { // Sample one in a hundred operator runs randomly torch::autograd::setSamplingProbability(0.01); pushCallback( &onFunctionEnter, &onFunctionExit, /* needs_inputs */ true, /* sampled */ true ); } void onFunctionEnter(const RecordFunction& fn) { std::cerr API 使用记录 在更广泛的生态系统中运行时(例如在托管的工作计划程序中），跟踪哪些二进制文件调用特定的 PyTorch API 通常很有用。 在几个重要的 API 点注入了简单的工具，这些工具会触发给定的回调。 由于通常在一次性 python 脚本中调用 PyTorch，因此对于每个 API 的给定进程，回调仅触发一次。 c10::SetAPIUsageHandler可用于注册 API 使用情况检测处理程序。 传递的参数将是“ api key”，用于标识使用的点，例如，用于 PyTorch 扩展名导入的python.import或触发 TorchScript 编译的torch.script.compile。 SetAPIUsageLogger([](const std::string& event_name) { std::cerr 开发人员注意：可以在代码中使用 C ++中的C10_LOG_API_USAGE_ONCE(\"my_api\")或 Python 中的torch._C._log_api_usage_once(\"my.api\")添加新的 API 触发点。 将元数据附加到已保存的 TorchScript 模型中 TorchScript 模块可以保存为存档文件，该文件将序列化的参数和模块代码捆绑为 TorchScript(请参见 torch.jit.save())。 将附加信息与模型捆绑在一起通常很方便，例如，模型生产者或辅助工件的描述。 可以通过将_extra_files参数传递给 torch.jit.save() 和torch::jit::load在存储过程中存储和检索任意二进制 Blob 来实现。 由于 TorchScript 文件是常规的 ZIP 存档，因此额外的信息将作为常规文件存储在存档的extra/目录中。 还有一个全局挂钩，可将其他文件附加到当前流程中生成的任何 TorchScript 存档中。 用生产者元数据标记模型可能很有用，类似于由数码相机产生的 JPEG 元数据。 用法示例如下所示： SetExportModuleExtraFilesHook([](const script::Module&) { script::ExtraFilesMap files; files[\"producer_info.json\"] = \"{\\\"user\\\": \\\"\" + getenv(\"USER\") + \"\\\"}\"; return files; }); 构建环境注意事项 TorchScript 的编译需要使用 python 的inspect.getsource调用，因此必须有权访问原始 python 文件。 在某些生产环境中，可能需要显式部署.py文件以及预编译的.pyc文件。 通用扩展点 PyTorch API 通常是松散耦合的，很容易用专用版本替换组件。 常见的扩展点包括： 使用 C ++实现的自定义运算符-有关更多详细信息，请参见教程。 自定义数据读取通常可以通过调用相应的 python 库直接集成。 torch.utils.data 的现有功能可以通过扩展 Dataset 或 IterableDataset 加以利用。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:39:43 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"64.html":{"url":"64.html","title":"并行处理最佳实践","keywords":"","body":"并行处理最佳实践 原文： https://pytorch.org/docs/stable/notes/multiprocessing.html torch.multiprocessing 是 Python python:multiprocessing模块的替代品。 它支持完全相同的操作，但是对其进行了扩展，以便所有通过python:multiprocessing.Queue发送的张量将其数据移至共享内存中，并且仅将句柄发送给另一个进程。 注意 将 Tensor 发送到另一个进程时，将共享 Tensor 数据。 如果 torch.Tensor.grad 不是None，则也将其共享。 将没有 torch.Tensor.grad 字段的 Tensor 发送到另一个进程后，它将创建一个特定于标准进程的.grad Tensor 不会自动在所有进程之间共享，这与 Tensor 的数据共享方式不同。 这允许实施各种训练方法，例如 Hogwild，A3C 或任何其他需要异步操作的方法。 并行处理中的 CUDA CUDA 运行时不支持fork启动方法。 但是，Python 2 中的python:multiprocessing只能使用fork创建子进程。 因此，需要 Python 3 和spawn或forkserver启动方法在子进程中使用 CUDA。 Note 可以通过使用multiprocessing.get_context(...)创建上下文或直接使用multiprocessing.set_start_method(...)来设置启动方法。 与 CPU 张量不同，只要接收过程保留张量的副本，就需要发送过程来保留原始张量。 它是在幕后实施的，但要求用户遵循最佳实践才能使程序正确运行。 例如，只要使用者进程具有对张量的引用，发送进程就必须保持活动状态，并且如果使用者进程通过致命信号异常退出，则引用计数无法保存您。 参见本部分。 另请参见：使用 nn.DataParallel 而不是并行处理 最佳做法和提示 避免和消除僵局 产生新进程时，很多事情都会出错，死锁的最常见原因是后台线程。 如果有任何持有锁的线程或导入模块的线程，并且调用了fork，则子进程很可能会处于损坏状态，并且将以不同的方式死锁或失败。 请注意，即使您不这样做，内置库的 Python 也会这样做-不需要比python:multiprocessing看起来更深。 python:multiprocessing.Queue实际上是一个非常复杂的类，它产生用于序列化，发送和接收对象的多个线程，它们也可能导致上述问题。 如果您遇到这种情况，请尝试使用SimpleQueue，它不使用任何其他线程。 我们正在努力为您提供便利，并确保不会发生这些僵局，但有些事情是我们无法控制的。 如果您有一段时间无法解决的问题，请尝试与论坛联系，我们将解决是否可以解决的问题。 重用通过队列传递的缓冲区 请记住，每次将 Tensor 放入python:multiprocessing.Queue时，都必须将其移到共享内存中。 如果已共享，则为空操作，否则将产生额外的内存副本，从而减慢整个过程。 即使您有一个将数据发送到单个进程的进程池，也要使它将缓冲区发送回去-这几乎是免费的，并且可以避免在发送下一批时复制。 异步多进程训练(例如 Hogwild） 使用 torch.multiprocessing ，可以异步训练模型，参数可以始终共享，也可以定期同步。 在第一种情况下，我们建议发送整个模型对象，而在后一种情况下，建议仅发送 state_dict() 。 我们建议使用python:multiprocessing.Queue在进程之间传递各种 PyTorch 对象。 例如 当使用fork start 方法时，它会继承共享内存中已经存在的张量和存储，但是，它非常容易出错，应谨慎使用，并且只有高级用户可以使用。 队列即使有时不是很优雅的解决方案，也可以在所有情况下正常工作。 警告 您应谨慎使用不受if __name__ == '__main__'约束的全局语句。 如果使用与fork不同的启动方法，则将在所有子过程中执行它们。 霍格威尔德 您可以在示例存储库中找到具体的 Hogwild 实现，但为了展示代码的整体结构，下面还有一个最小的示例： import torch.multiprocessing as mp from model import MyModel def train(model): # Construct data_loader, optimizer, etc. for data, labels in data_loader: optimizer.zero_grad() loss_fn(model(data), labels).backward() optimizer.step() # This will update the shared parameters if __name__ == '__main__': num_processes = 4 model = MyModel() # NOTE: this is required for the ``fork`` method to work model.share_memory() processes = [] for rank in range(num_processes): p = mp.Process(target=train, args=(model,)) p.start() processes.append(p) for p in processes: p.join() 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"65.html":{"url":"65.html","title":"重现性","keywords":"","body":"重现性 原文： https://pytorch.org/docs/stable/notes/randomness.html 在 PyTorch 发行版，单独的提交或不同的平台上，不能保证完全可重复的结果。 此外，即使在使用相同种子的情况下，结果也不必在 CPU 和 GPU 执行之间再现。 但是，为了使计算能够在一个特定平台和 PyTorch 版本上确定特定问题，需要采取几个步骤。 PyTorch 中涉及两个伪随机数生成器，您将需要手动对其进行播种以使运行可重复。 此外，您应确保代码所依赖的所有其他库以及使用随机数的库也使用固定种子。 torch 您可以使用 torch.manual_seed() 为所有设备(CPU 和 CUDA）播种 RNG： import torch torch.manual_seed(0) 有一些使用 CUDA 函数的 PyTorch 函数可能会导致不确定性。 此类 CUDA 函数的一类是原子运算，尤其是atomicAdd，其中不确定与相同值的并行加法顺序，对于浮点变量，其结果是方差的来源。 向前使用atomicAdd的 PyTorch 函数包括 torch.Tensor.index_add_() ， torch.Tensor.scatter_add_() ， torch.bincount() 。 许多操作都向后使用atomicAdd，特别是 torch.nn.functional.embedding_bag() ， torch.nn.functional.ctc_loss() 和许多形式的合并，填充和采样。 当前，没有简单的方法可以避免这些函数中的不确定性。 铜网 在 CuDNN 后端上运行时，必须设置另外两个选项： torch.backends.cudnn.deterministic = True torch.backends.cudnn.benchmark = False 警告 确定性模式可能会对性能产生影响，具体取决于您的模型。 这意味着，由于模型具有确定性，因此与模型不确定时相比，处理速度(即每秒处理的批次项目）可能会更低。 脾气暴躁的 如果您或您正在使用的任何库都依赖于 Numpy，则也应为 Numpy RNG 设置种子。 这可以通过以下方式完成： import numpy as np np.random.seed(0) 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"66.html":{"url":"66.html","title":"远程参考协议","keywords":"","body":"远程参考协议 原文： https://pytorch.org/docs/stable/notes/rref.html 警告 RRef API 是实验性的，随时可能更改。 本说明描述了远程引用协议的设计细节，并逐步介绍了不同情况下的消息流。 在继续之前，请确保您熟悉分布式 RPC 框架。 背景 RRef 代表远程参考。 它是位于本地或远程工作人员上的对象的引用，并且透明地在内部进行引用计数。 从概念上讲，它可以视为分布式共享指针。 应用程序可以通过调用 remote() 创建 RRef。 每个 RRef 都由 remote() 呼叫的被调用方工作者(即所有者）拥有，并且可以由多个用户使用。 所有者存储实际数据，并跟踪全局参考计数。 每个 RRef 可以由全局RRefId唯一标识，该全局RRefId在创建时在 remote() 调用的调用方上分配。 在所有者工作程序中，只有一个OwnerRRef实例包含真实数据，而在用户工作程序中，可以根据需要包含任意数量的UserRRefs，而UserRRef不保存数据。 所有者上的所有用法都将使用全局唯一的RRefId来检索唯一的OwnerRRef实例。 在 rpc_sync() ， rpc_async() 或 remote() 调用中将UserRRef用作参数或返回值时，将创建该UserRRef 将会根据更新的参考计数通知所有者。 如果全局没有UserRRef实例，并且所有者上也没有对OwnerRRef的引用，则OwnerRRef及其数据将被删除。 假设条件 RRef 协议的设计基于以下假设。 瞬态网络故障：RRef 设计旨在通过重试消息来处理瞬态网络故障。 节点崩溃或永久性网络分区超出了范围。 当这些事件发生时，该应用程序可能会关闭所有工作人员，还原到先前的检查点，然后恢复训练。 非幂等 UDF ：我们假设提供给 rpc_sync() ， rpc_async() 或 remote() 的用户功能(UDF） 不是幂等的，因此无法重试。 但是，内部 RRef 控制消息将成为幂等且可重试。 消息传递无序：我们不假定任何一对节点之间的消息传递顺序，因为发送者和接收者都使用多个线程。 无法保证首先处理哪个消息。 RRef 生命周期 该协议的目标是在适当的时候删除OwnerRRef。 删除OwnerRRef的正确时机是在没有活动UserRRef实例且用户代码也没有保存对OwnerRRef的引用的情况下。 棘手的部分是确定是否存在任何活动的UserRRef实例。 设计推理 用户可以在以下三种情况下获得UserRRef： 从所有者那里收到了UserRRef。 接收到另一个用户的UserRRef。 创建另一个工人拥有的新UserRRef。 情况 1 是最简单的，所有者将其 RRef 传递给用户，所有者调用 rpc_sync() ， rpc_async() 或 remote() 使用其 RRef 作为参数。 在这种情况下，将在用户上创建一个新的UserRRef。 由于所有者是调用者，因此可以轻松地在OwnerRRef上更新其本地引用计数。 唯一的要求是任何UserRRef必须在销毁时通知所有者。 因此，我们需要第一个保证： G1。 删除任何“ UserRRef”时，都会通知所有者。 由于邮件可能会延迟或出现乱序，因此我们还需要一项保证，以确保删除邮件不会过早处理。 如果 A 向 B 发送涉及 RRef 的消息，我们将 A 上的 RRef 称为父 RRef，将 B 上的 RRef 称为子 RRef。 G2。 在所有者确认子 RRef 之前，不会删除父 RRef。 在情况 2 和 3 中，所有者可能仅对 RRef 分支图有部分了解或根本不了解。 例如，可以在用户上构建 RRef，并且在所有者收到任何 RPC 调用之前，创建者用户可能已经与其他用户共享了 RRef，并且这些用户可以进一步共享 RRef。 一个不变性是，任何 RRef 的派生图始终都是一棵树，因为派生 RRef 总是在被调用方上创建一个新的UserRRef实例(除非被调用方是所有者），因此每个 RRef 都有一个父级。 所有者对树中任何UserRRef的视图分为三个阶段： 1) unknown -> 2) known -> 3) deleted. 所有者对整棵树的看法不断变化。 拥有者认为没有活动的UserRRef实例时，即删除OwnerRRef实例时，所有UserRRef实例都可能确实被删除或未知，因此所有者删除了其OwnerRRef实例。 危险的情况是某些分叉未知，而另一些被删除。 G2 简单地保证在拥有者知道其所有子级UserRRef实例之前，不能删除任何父级UserRRef。 但是，有可能在拥有者知道其父项UserRRef之前删除了子项UserRRef。 考虑下面的示例，其中OwnerRRef分支到 A，然后 A 分支到 Y，Y 分支到 Z： OwnerRRef -> A -> Y -> Z 如果所有者在处理所有来自 Z 的消息(包括删除消息）之前先处理来自 Y 的所有消息，那么所有者将在知道 Y 之前就知道 Z 的删除。但这不会造成任何问题。 因为，Y 的祖先中至少有一个还活着(在本例中为 A），这将阻止所有者删除OwnerRRef。 更具体地说，如果所有者不知道 Y，则由于 G2 而无法删除 A，并且所有者知道 A，因为所有者是 A 的父母。 如果在用户上创建 RRef，事情会变得有些棘手： OwnerRRef ^ | A -> Y -> Z 如果 Z 在UserRRef上调用 to_here() ，则所有者至少知道删除 Z 时的 A，否则， to_here() 不会结束。 如果 Z 没有调用 to_here() ，则所有者可能在从 A 和 Y 发送任何消息之前就已从 Z 接收了所有消息。在这种情况下，由于尚未获得OwnerRRef的真实数据 创建后，也没有要删除的内容。 就像 Z 根本不存在一样。 因此，仍然可以。 实作 G1 通过在UserRRef析构函数中发送删除消息来实现。 为了提供 G2 ，无论何时将父级UserRRef派生，都将其置于上下文中，并由新的ForkId对其进行索引。 仅当父级UserRRef从子级收到确认消息(ACK）时，才会从上下文中删除该父级UserRRef，并且只有当所有者确认后，该子级才会发出 ACK。 协议方案 现在，让我们讨论以上设计如何在四种情况下转换为协议。 用户与所有者共享 RRef 作为返回值 import torch import torch.distributed.rpc as rpc # on worker A rref = rpc.remote('B', torch.add, args=(torch.ones(2), 1)) # say the rref has RRefId 100 and ForkId 1 rref.to_here() 在这种情况下，在用户工作程序 A 上创建UserRRef，然后将其与远程消息一起传递给所有者工作程序 B，然后 B 创建OwnerRRef。 方法 remote() 立即返回，这意味着UserRRef可以在所有者了解之前被分叉/使用。 在所有者上，当接收到 remote() 调用时，它将创建OwnerRRef，并返回一个 ACK 来确认{100, 1}(RRefId，ForkId）。 仅在收到此 ACK 后，A 才能删除其UserRRef。 这涉及 G1 和 G2 。 G1 很明显。 对于 G2 而言，OwnerRRef是UserRRef的子级，并且UserRRef直到收到所有者的 ACK 才被删除。 上图显示了消息流，其中实心箭头包含用户功能，而虚线箭头是内置消息。 请注意，从 A 到 B 的前两个消息 (remote() 和 to_here())可以按任何顺序到达 B，但最终的删除消息仅在以下情况下发送： ： B 确认UserRRef {100, 1}(G2），并且 Python GC 同意删除本地UserRRef实例。 当 RRef 不再在范围内并且可以进行垃圾回收时，就会发生这种情况。 用户与所有者共享 RRef 作为参数 import torch import torch.distributed.rpc as rpc # on worker A and worker B def func(rref): pass # on worker A rref = rpc.remote('B', torch.add, args=(torch.ones(2), 1)) # say the rref has RRefId 100 and ForkId 1 rpc.rpc_async('B', func, args=(rref, )) 在这种情况下，在 A 上创建UserRRef后，A 会将其用作对 B 的后续 RPC 调用中的参数。A 将使UserRRef {100, 1}保持活动状态，直到收到 B 的确认 (G2 ， 而不是 RPC 调用的返回值）。 这是必要的，因为在接收到所有先前的消息之前，A 不应发出删除消息，否则，OwnerRRef可以在使用前删除，因为我们不能保证消息的传递顺序。 这是通过创建 RRef 的子项ForkId并将其保存在地图中，直到收到所有者确认该子项ForkId来完成的。 下图显示了消息流。 注意，UserRRef可以在功能完成甚至启动之前在 B 上删除。 但是，这是可以的，因为在 B 向子ForkId发送 ACK 时，它已经获取了OwnerRRef实例，这将防止它被过早删除。 所有者与用户共享 RRef 所有者对用户是最简单的情况，所有者可以在本地更新引用计数，并且不需要任何其他控制消息即可通知其他人。 关于 G2 ，因为父级是所有者，所以它与父级立即从所有者接收 ACK 相同。 import torch import torch.distributed.rpc as RRef, rpc # on worker B and worker C def func(rref): pass # on worker B, creating a local RRef rref = RRef(\"data\") # say the rref has RRefId 100 dist.rpc_async('C', func, args=(rref, )) 上图显示了消息流。 请注意，当在 rpc_async 调用之后OwnerRRef退出作用域时，将不会删除它，因为如果存在任何已知的派生，则内部会存在一个使它保持活动状态的映射，在这种情况下为UserRRef {100, 1}。 (G2 ) 用户与用户共享 RRef 这是最复杂的情​​况，其中调用者用户(父级UserRRef），被调用者用户(子级UserRRef）和所有者都需要参与。 import torch import torch.distributed.rpc as rpc # on worker A and worker C def func(rref): pass # on worker A rref = rpc.remote('B', torch.add, args=(torch.ones(2), 1)) # say the rref has RRefId 100 and ForkId 1 rpc.rpc_async('C', func, args=(rref, )) 当 C 从 A 接收到子项UserRRef时，它向所有者 B 发送一个派生请求。稍后，当 B 确认 C 上的UserRRef时，C 将并行执行两个操作：1）发送子项 ACK 到 A，然后 2）运行用户提供的功能。 在这段时间中，亲本(A）将保持其UserRRef {100, 1}存活以实现 G2 。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"67.html":{"url":"67.html","title":"序列化语义","keywords":"","body":"序列化语义 原文： https://pytorch.org/docs/stable/notes/serialization.html 最佳实务 推荐的模型保存方法 序列化和还原模型有两种主要方法。 第一个(推荐）仅保存和加载模型参数： torch.save(the_model.state_dict(), PATH) 然后再： the_model = TheModelClass(*args, **kwargs) the_model.load_state_dict(torch.load(PATH)) 第二个保存并加载整个模型： torch.save(the_model, PATH) Then later: the_model = torch.load(PATH) 但是，在这种情况下，序列化的数据将绑定到所使用的特定类和确切的目录结构，因此在其他项目中使用时或经过一些严重的重构后，序列化的数据可能会以各种方式中断。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"68.html":{"url":"68.html","title":"Windows 常见问题","keywords":"","body":"Windows 常见问题 原文： https://pytorch.org/docs/stable/notes/windows.html 从源头建造 包括可选组件 Windows PyTorch 支持两个组件：MKL 和 MAGMA。 以下是使用它们构建的步骤。 REM Make sure you have 7z and curl installed. REM Download MKL files curl https://s3.amazonaws.com/ossci-windows/mkl_2018.2.185.7z -k -O 7z x -aoa mkl_2018.2.185.7z -omkl REM Download MAGMA files REM cuda100/cuda101 is also available for `CUDA_PREFIX`. There are also 2.4.0 binaries for cuda80/cuda92. REM The configuration could be `debug` or `release` for 2.5.0\\. Only `release` is available for 2.4.0. set CUDA_PREFIX=cuda90 set CONFIG=release curl -k https://s3.amazonaws.com/ossci-windows/magma_2.5.0_%CUDA_PREFIX%_%CONFIG%.7z -o magma.7z 7z x -aoa magma.7z -omagma REM Setting essential environment variables set \"CMAKE_INCLUDE_PATH=%cd%\\\\mkl\\\\include\" set \"LIB=%cd%\\\\mkl\\\\lib;%LIB%\" set \"MAGMA_HOME=%cd%\\\\magma\" 加快 Windows 的 CUDA 构建 Visual Studio 当前不支持并行自定义任务。 或者，我们可以使用Ninja并行化 CUDA 构建任务。 只需输入几行代码即可使用它。 REM Let's install ninja first. pip install ninja REM Set it as the cmake generator set CMAKE_GENERATOR=Ninja 一键安装脚本 您可以看看这组脚本。 它将为您带路。 延期 CFFI 扩展 CFFI Extension 的支持是试验性的。 在 Windows 下启用它通常需要两个步骤。 首先，在Extension对象中指定其他libraries以使其在 Windows 上构建。 ffi = create_extension( '_ext.my_lib', headers=headers, sources=sources, define_macros=defines, relative_to=__file__, with_cuda=with_cuda, extra_compile_args=[\"-std=c99\"], libraries=['ATen', '_C'] # Append cuda libaries when necessary, like cudart ) 其次，这里是“ extern THCState *state;导致的外部符号状态无法解析”的工作场所 将源代码从 C 更改为 C ++。 下面列出了一个示例。 #include #include THCState *state = at::globalContext().thc_state; extern \"C\" int my_lib_add_forward_cuda(THCudaTensor *input1, THCudaTensor *input2, THCudaTensor *output) { if (!THCudaTensor_isSameSizeAs(state, input1, input2)) return 0; THCudaTensor_resizeAs(state, output, input1); THCudaTensor_cadd(state, output, input1, 1.0, input2); return 1; } extern \"C\" int my_lib_add_backward_cuda(THCudaTensor *grad_output, THCudaTensor *grad_input) { THCudaTensor_resizeAs(state, grad_input, grad_output); THCudaTensor_fill(state, grad_input, 1); return 1; } Cpp 扩展 与前一个扩展相比，这种扩展具有更好的支持。 但是，它仍然需要一些手动配置。 首先，您应该打开 x86_x64 VS 2017 的交叉工具命令提示符。 然后，您可以开始编译过程。 安装 在 Win-32 频道中找不到软件包。 Solving environment: failed PackagesNotFoundError: The following packages are not available from current channels: - pytorch Current channels: - https://conda.anaconda.org/pytorch/win-32 - https://conda.anaconda.org/pytorch/noarch - https://repo.continuum.io/pkgs/main/win-32 - https://repo.continuum.io/pkgs/main/noarch - https://repo.continuum.io/pkgs/free/win-32 - https://repo.continuum.io/pkgs/free/noarch - https://repo.continuum.io/pkgs/r/win-32 - https://repo.continuum.io/pkgs/r/noarch - https://repo.continuum.io/pkgs/pro/win-32 - https://repo.continuum.io/pkgs/pro/noarch - https://repo.continuum.io/pkgs/msys2/win-32 - https://repo.continuum.io/pkgs/msys2/noarch PyTorch 在 32 位系统上不起作用。 请使用 Windows 和 Python 64 位版本。 为什么 Windows 没有 Python 2 软件包？ 因为它不够稳定。 在我们正式发布之前，有一些问题需要解决。 您可以自己构建。 导入错误 from torch._C import * ImportError: DLL load failed: The specified module could not be found. 该问题是由于缺少基本文件引起的。 实际上，除了 VC2017 可再发行和一些 mkl 库，我们几乎包含了 PyTorch 的 conda 软件包所需的所有基本文件。 您可以通过键入以下命令来解决此问题。 conda install -c peterjc123 vc vs2017_runtime conda install mkl_fft intel_openmp numpy mkl 至于 wheel 软件包，由于我们没有打包一些库和 VS2017 可再发行文件，因此请确保手动安装它们。 可以下载 VS 2017 可再发行安装程序。 而且您还应该注意安装 Numpy。 确保它使用 MKL 而不是 OpenBLAS。 您可以输入以下命令。 pip install numpy mkl intel-openmp mkl_fft 另一个可能的原因可能是您使用的是没有 NVIDIA 显卡的 GPU 版本。 请用 CPU 之一替换您的 GPU 软件包。 from torch._C import * ImportError: DLL load failed: The operating system cannot run %1. 这实际上是 Anaconda 的上游问题。 当您使用 conda-forge 频道初始化环境时，就会出现此问题。 您可以通过此命令修复 intel-openmp 库。 conda install -c defaults intel-openmp -f 用法(并行处理） 没有 if 子句保护的并行处理错误 RuntimeError: An attempt has been made to start a new process before the current process has finished its bootstrapping phase. This probably means that you are not using fork to start your child processes and you have forgotten to use the proper idiom in the main module: if __name__ == '__main__': freeze_support() ... The \"freeze_support()\" line can be omitted if the program is not going to be frozen to produce an executable. multiprocessing的实现在 Windows 上有所不同，Windows 使用spawn代替fork。 因此，我们必须用 if 子句包装代码，以防止代码多次执行。 将代码重构为以下结构。 import torch def main() for i, data in enumerate(dataloader): # do something here if __name__ == '__main__': main() 并行处理错误“管道破裂” ForkingPickler(file, protocol).dump(obj) BrokenPipeError: [Errno 32] Broken pipe 当子进程在父进程完成发送数据之前结束时，就会发生此问题。 您的代码可能有问题。 您可以通过将 DataLoader 的num_worker减小为零来调试代码，然后查看问题是否仍然存在。 并行处理错误“驱动程序关闭” Couldn’t open shared file mapping: , error code: at torch\\lib\\TH\\THAllocator.c:154 [windows] driver shut down 请更新您的图形驱动程序。 如果这种情况持续存在，则可能是图形卡太旧或计算量太大。 请根据此帖子更新 TDR 设置。 CUDA IPC 操作 THCudaCheck FAIL file=torch\\csrc\\generic\\StorageSharing.cpp line=252 error=63 : OS call failed or operation not supported on this OS Windows 不支持它们。 像对 CUDA 张量执行并行处理之类的操作无法成功，有两种选择。 1.不要使用multiprocessing。 将 DataLoader 的num_worker设置为零。 2.改为共享 CPU 张量。 确保自定义DataSet返回 CPU 张量。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"69.html":{"url":"69.html","title":"XLA 设备上的 PyTorch","keywords":"","body":"XLA 设备上的 PyTorch 原文： http://pytorch.org/xla/ PyTorch 使用 torch_xla 软件包在 XPU 设备(如 TPU）上运行。 本文档介绍了如何在这些设备上运行模型。 创建 XLA 张量 PyTorch / XLA 向 PyTorch 添加了新的xla设备类型。 此设备类型的工作方式与其他 PyTorch 设备类型一样。 例如，以下是创建和打印 XLA 张量的方法： import torch import torch_xla import torch_xla.core.xla_model as xm t = torch.randn(2, 2, device=xm.xla_device()) print(t.device) print(t) 此代码应该看起来很熟悉。 PyTorch / XLA 使用与常规 PyTorch 相同的界面，但有一些附加功能。 导入torch_xla会初始化 PyTorch / XLA，xm.xla_device()会返回当前的 XLA 设备。 根据您的环境，这可能是 CPU 或 TPU。 XLA 张量是 PyTorch 张量 可以像 CPU 或 CUDA 张量一样在 XLA 张量上执行 PyTorch 操作。 例如，可以将 XLA 张量添加在一起： t0 = torch.randn(2, 2, device=xm.xla_device()) t1 = torch.randn(2, 2, device=xm.xla_device()) print(t0 + t1) 或乘以矩阵： print(t0.mm(t1)) 或与神经网络模块一起使用： l_in = torch.randn(10, device=xm.xla_device()) linear = torch.nn.Linear(10, 20).to(xm.xla_device()) l_out = linear(l_in) print(l_out) 与其他设备类型一样，XLA 张量仅可与同一设备上的其他 XLA 张量一起使用。 所以代码像 l_in = torch.randn(10, device=xm.xla_device()) linear = torch.nn.Linear(10, 20) l_out = linear(l_in) print(l_out) # Input tensor is not an XLA tensor: torch.FloatTensor 由于 torch.nn.Linear 模块在 CPU 上，因此将引发错误。 在 XLA 设备上运行模型 建立新的 PyTorch 网络或转换现有网络以在 XLA 设备上运行仅需要几行 XLA 专用代码。 以下代码片段突出显示了在单个设备，具有 XLA 并行处理功能的多个设备或具有 XLA 多线程的多个线程上运行时的这些行。 在单个 XLA 设备上运行 以下代码片段显示了单个 XLA 设备上的网络训练： import torch_xla.core.xla_model as xm device = xm.xla_device() model = MNIST().train().to(device) loss_fn = nn.NLLLoss() optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum) for data, target in train_loader: optimizer.zero_grad() data = data.to(device) target = target.to(device) output = model(data) loss = loss_fn(output, target) loss.backward() xm.optimizer_step(optimizer, barrier=True) 此代码段突出显示了切换模型以在 XLA 上运行非常容易。 模型定义，数据加载器，优化器和训练循环可在任何设备上运行。 唯一的 XLA 特定代码是几行代码，这些代码获取 XLA 设备并以屏障进入优化程序。 在每次训练迭代结束时调用xm.optimizer_step(optimizer, barrier=True)都会使 XLA 执行其当前图形并更新模型的参数。 有关 XLA 如何创建图形和运行操作的更多信息，请参见 XLA Tensor Deep Dive 。 在具有并行处理功能的多个 XLA 设备上运行 通过在多个 XLA 设备上运行，PyTorch / XLA 可以轻松加速训练。 以下代码段显示了如何： import torch_xla.core.xla_model as xm import torch_xla.distributed.parallel_loader as pl import torch_xla.distributed.xla_multiprocessing as xmp def _mp_fn(index): device = xm.xla_device() para_loader = pl.ParallelLoader(train_loader, [device]) model = MNIST().train().to(device) loss_fn = nn.NLLLoss() optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum) for data, target in para_loader.per_device_loader(device): optimizer.zero_grad() output = model(data) loss = loss_fn(output, target) loss.backward() xm.optimizer_step(optimizer) if __name__ == '__main__': xmp.spawn(_mp_fn, args=()) 此多设备代码段和先前的单设备代码段之间存在三个区别： xmp.spawn()创建分别运行 XLA 设备的进程。 ParallelLoader将训练数据加载到每个设备上。 xm.optimizer_step(optimizer)不再需要障碍。 ParallelLoader 自动创建用于评估图形的 XLA 障碍。 模型定义，优化器定义和训练循环保持不变。 请参阅完整的并行处理示例，以获取更多关于在具有并行处理功能的多个 XLA 设备上训练网络的信息。 通过多线程在多个 XLA 设备上运行 使用进程(请参见上文）在多个 XLA 设备上运行比使用线程更可取。 但是，如果您想使用线程，则 PyTorch / XLA 具有DataParallel接口。 以下代码片段显示了具有多个线程的相同网络训练： import torch_xla.core.xla_model as xm import torch_xla.distributed.data_parallel as dp devices = xm.get_xla_supported_devices() model_parallel = dp.DataParallel(MNIST, device_ids=devices) def train_loop_fn(model, loader, device, context): loss_fn = nn.NLLLoss() optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum) model.train() for _, (data, target) in loader: optimizer.zero_grad() output = model(data) loss = loss_fn(output, target) loss.backward() xm.optimizer_step(optimizer) for epoch in range(1, num_epochs + 1): model_parallel(train_loop_fn, train_loader) 多线程和并行处理代码之间的唯一区别是： 使用xm.get_xla_supported_devices()在同一过程中获取多个设备。 该模型包装在dp.DataParallel中，并通过了训练循环和数据加载器。 有关在多 XLA 设备上使用多线程训练网络的更多信息，请参见完整的多线程示例。 XLA Tensor 深潜 使用 XLA 张量和设备仅需要更改几行代码。 但是，即使 XLA 张量的行为很像 CPU 和 CUDA 张量，其内部结构也不同。 本节描述了 XLA 张量独特的原因。 XLA 张量是懒惰的 CPU 和 CUDA 张量立即启动操作或急切启动。 另一方面，XLA 张量是惰性。 他们将操作记录在图形中，直到需要结果为止。 这样推迟执行，XLA 可以对其进行优化。 例如，多个单独操作的图形可能会融合为一个优化操作。 懒惰执行通常对调用者不可见。 当在 XLA 设备和 CPU 之间复制数据时，PyTorch / XLA 自动构建图形，将它们发送到 XLA 设备，并进行同步。 采取优化程序步骤时插入屏障会显式同步 CPU 和 XLA 设备。 XLA 张量和 bFloat16 当在 TPU 上运行时，PyTorch / XLA 可以使用 bfloat16 数据类型。 实际上，PyTorch / XLA 在 TPU 上处理浮点类型(torch.float和torch.double）的方式有所不同。 此行为由XLA_USE_BF16环境变量控制： 默认情况下，TPU 上的torch.float和torch.double均为torch.float。 如果设置了XLA_USE_BF16，则 TPU 上的torch.float和torch.double均为bfloat16。 TPU 上的 XLA 张量将始终报告其 PyTorch 数据类型，而不管其使用的实际数据类型是什么。 这种转换是自动且不透明的。 如果将 TPU 上的 XLA 张量移回 CPU，它将从其实际数据类型转换为其 PyTorch 数据类型。 内存布局 XLA 张量的内部数据表示对于用户而言是不透明的。 它们不公开其存储，并且它们总是看起来是连续的，这与 CPU 和 CUDA 张量不同。 这使 XLA 可以调整张量的内存布局以获得更好的性能。 将 XLA 张量移入和移出 CPU XLA 张量可以从 CPU 移到 XLA 设备，也可以从 XLA 设备移到 CPU。 如果移动了视图，则其视图的数据将被复制到另一台设备，并且不会保留视图关系。 换句话说，将数据复制到另一设备后，它与先前的设备或其上的任何张量都没有关系。 保存和加载 XLA 张量 在保存之前，应将 XLA 张量移至 CPU，如以下代码段所示： import torch import torch_xla import torch_xla.core.xla_model as xm device = xm.xla_device() t0 = torch.randn(2, 2, device=device) t1 = torch.randn(2, 2, device=device) tensors = (t0.cpu(), t1.cpu()) torch.save(tensors, 'tensors.pt') tensors = torch.load('tensors.pt') t0 = tensors[0].to(device) t1 = tensors[1].to(device) 这使您可以将加载的张量放置在任何可用设备上。 根据以上有关将 XLA 张量移至 CPU 的说明，使用视图时必须格外小心。 建议不要在保存张量并将其移至目标设备后重新创建视图，而不必保存视图。 可以直接保存 XLA 张量，但不建议这样做。 XLA 张量始终会加载回保存它们的设备，如果该设备不可用，加载将会失败。 与所有 PyTorch 一样，PyTorch / XLA 正在积极开发中，这种行为将来可能会改变。 进一步阅读 其他文档可在 PyTorch / XLA 存储库中找到。 在此处可以找到在 TPU 上运行网络的更多示例。 PyTorch / XLA API xla_model torch_xla.core.xla_model.xla_device(n=None, devkind=None)¶ 返回 XLA 设备的给定实例。 参数 n (python：int ， 可选）–要返回的特定实例(普通）。 如果指定，将返回特定的 XLA 设备实例。 否则，将返回 devkind 的第一个设备。 devkind (字符串... ， 可选）–如果指定，则为 TPU ，中的一个 GPU 或 CPU (当前未实现“ GPU” XLA 设备）。 退货 具有所请求实例的torch设备。 torch_xla.core.xla_model.get_xla_supported_devices(devkind=None, max_devices=None)¶ 返回给定类型的受支持设备的列表。 Parameters devkind (string...__, optional) – If specified, one of TPU, GPU or CPU (the ‘GPU’ XLA device is currently not implemented). max_devices (python：int ， 可选）–此类设备的最大返回数量。 Returns 设备字符串列表。 torch_xla.core.xla_model.xrt_world_size(defval=1)¶ 检索参与复制的设备数。 Parameters defval (python：int ， 可选）–如果没有可用的复制信息，则返回默认值。 默认值：1 Returns 参与复制的设备数。 torch_xla.core.xla_model.get_ordinal(defval=0)¶ 检索当前进程的复制序号。 序数范围从 0 到 xrt_world_size(）减 1。 Parameters defval (python：int ， 可选）–如果没有可用的复制信息，则返回默认值。 默认值：0 Returns 当前进程的复制序号。 torch_xla.core.xla_model.is_master_ordinal()¶ 检查当前进程是否为主序(0）。 Returns 一个布尔值，指示当前进程是否是主序。 torch_xla.core.xla_model.optimizer_step(optimizer, barrier=False, optimizer_args={})¶ 运行提供的优化器步骤并发出 XLA 设备步骤计算。 Parameters 优化器(torch.Optimizer）–需要调用其 step(）函数的torch.optim器实例。 step(）函数将使用名为 optimizer_args 的参数调用。 屏障 (bool ， 可选）–是否应在此 API 中发布 XLA 张量屏障。 如果使用 PyTorch XLA ParallelLoader 或 DataParallel 支持，则不需要这样做，因为 XLA 数据加载器迭代器 next(）调用会发出屏障。 默认值：False optimizer_args (dict ， 可选）–为 optimizer.step(）调用的命名参数字典。 Returns Optimizer.step(）调用返回的值相同。 Distributed class torch_xla.distributed.parallel_loader.ParallelLoader(loader, devices, batchdim=0, fixed_batch_size=False, loader_prefetch_size=8, device_prefetch_size=4)¶ 使用背景数据上传包装现有的 PyTorch DataLoader。 Parameters 加载器(torch.utils.data.DataLoader）–要包装的 PyTorch DataLoader。 设备(torch设备…）–必须将数据发送到的设备列表。 加载器返回的第 i 个样本将发送到 devices [i％len(devices）] 。 batchdim (python：int ， 可选）–保留批大小的尺寸。 默认值：0 fixed_batch_size (bool ， 可选）–确保发送给设备的所有批次大小均相同。 一旦发现不匹配的批处理大小，原始的加载程序迭代就会停止。 默认值：False loader_prefetch_size (python：int ， 可选）–线程从[[ loader ，由工作线程处理，这些工作线程会将数据上传到设备。 默认值：8 device_prefetch_size (python：int ， 可选）–每个设备队列的最大大小，工作线程在其中存放张量， 已经发送到设备。 默认值：4 per_device_loader(device)¶ 检索给定设备的加载程序对象。 Parameters 设备(torch设备）–正在请求设备整个装载程序。 Returns 设备的数据加载器。 class torch_xla.distributed.data_parallel.DataParallel(network, device_ids=None)¶ 使用线程以复制模式启用模型网络的执行。 Parameters 网络(torch.nn.Module或可调用）–模型的网络。 torch.nn.Module 的子类，或者是返回 torch.nn.Module 子类的可调用对象。 device_ids (字符串…或torch.device…）–应在其上进行复制的设备的列表。 如果列表为空，则网络将在 PyTorch CPU 设备上运行。 __call__(loop_fn, loader, fixed_batch_size=False, batchdim=0)¶ 进行一次 EPOCH 训练/测试。 Parameters loop_fn (可调用的）–在分配给参与复制的每个设备的每个线程上调用的函数。 该函数将使用 def loop_fn(model，device_loader，device，context）签名来调用。 其中模型是传递到 DataParallel 构造器的每个设备网络。 device_loader 是 ParallelLoader ，它将为当前设备返回样本。 上下文是每个线程/设备上下文，具有 DataParallel 对象的生存期，并且 loop_fn 可以使用它来存储需要 在不同的 EPOCH 中保持一致。 fixed_batch_size (bool ， 可选）–参数传递给 ParallelLoader 构造函数。 默认值：False batchdim (python：int ， 可选）–由加载器返回的样本尺寸 批量大小。 默认值：0 Returns 每个设备上 loop_fn 返回的值的列表。 torch_xla.distributed.xla_multiprocessing.spawn(fn, args=(), nprocs=None, join=True, daemon=False)¶ 启用基于并行处理的复制。 Parameters fn –参与复制的每个设备要调用的功能。 将调用该函数，第一个参数是复制中进程的全局索引，然后是 args 中传递的参数。 args - fn 的参数。 nprocs –复制的进程/设备数。 目前，如果指定，则可以为 1 或最大设备数。 join –呼叫是否应等待生成的进程完成而阻塞。 守护程序 –产生的进程是否应设置守护程序标志(请参阅 Python 并行处理 API）。 Returns torch.multiprocessing.spawn API 返回的同一对象。 实用程序 class torch_xla.utils.utils.SampleGenerator(data, sample_count)¶ 迭代器，它返回给定输入数据的多个样本。 可以代替 PyTorch DataLoader 生成合成数据。 Parameters 数据 –在每个迭代器步骤应返回的数据。 sample_count –要返回的数据个样本的最大数量。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"71.html":{"url":"71.html","title":"PyTorch C ++ API","keywords":"","body":"PyTorch C ++ API 原文： https://pytorch.org/cppdocs/ 这些页面提供了 PyTorch C ++ API 公共部分的文档。 该 API 大致可分为五个部分： ATen ：所有其他基础都建立在其上的基础张量和数学运算库； Autograd ：具有自动微分的增强 ATen； C ++前端：用于训练和评估机器学习模型的高级构造； TorchScript ：TorchScript JIT 编译器和解释器的接口； C ++扩展：一种使用自定义 C ++和 CUDA 例程扩展 Python API 的方法。 这些构建模块一起构成了一个可用于张量计算和动态神经网络的研究和生产就绪的 C ++库，其中特别强调 GPU 加速以及快速的 CPU 性能。 目前，Facebook 正在研究和生产中使用它。 我们期待欢迎更多的 PyTorch C ++ API 用户。 警告 目前，应将 C ++ API 视为“测试版”稳定性。 我们可能会对后端进行重大更改，以改进 API，或者在为 PyTorch 提供 Python 接口(这是我们最稳定和最受支持的接口）时使用。 en ATen 从根本上讲是一个张量库，在 PyTorch 中几乎所有其他 Python 和 C ++接口都在其上构建。 它提供了一个核心Tensor类，在该类上定义了数百种操作。 这些操作大多数都具有 CPU 和 GPU 实现，Tensor类将根据其类型向其动态调度。 使用 ATen 的一个小示例如下所示： #include at::Tensor a = at::ones({2, 2}, at::kInt); at::Tensor b = at::randn({2, 2}); auto c = a + b.to(at::kInt); 此Tensor类和 ATen 中的所有其他符号在at::命名空间中找到，在这里记录在中。 自动毕业 我们所称的 autograd 是 PyTorch C ++ API 的一部分，这些部分通过涉及自动区分的功能扩展了 ATen Tensor类。 autograd 系统在张量上记录操作，以形成 autograd 图。 在该图中的叶变量上调用backwards()，可通过跨越 autograd 图的函数和张量网络执行反向模式微分，最终产生梯度。 以下示例提供了该界面的外观： #include #include torch::Tensor a = torch::ones({2, 2}, torch::requires_grad()); torch::Tensor b = torch::randn({2, 2}); auto c = a + b; c.backward(); // a.grad() will now hold the gradient of c w.r.t. a. 默认情况下，ATen 中的at::Tensor类不可区分。 若要增加 autograd API 提供的张量的可微性，必须使用 torch :: 命名空间中的张量工厂函数，而不是位于::: 命名空间中的。 例如，使用在:: ones 创建的张量将是不可微的，而使用 Torch :: ones 创建的张量将是可微的。 C ++前端 PyTorch C ++前端为神经网络以及一般的机器学习研究和生产用例提供了一个高级的纯 C ++建模接口，在设计和提供的功能上很大程度上遵循了 Python API。 C ++前端包括以下内容： 通过分层模块系统(例如torch.nn.Module）定义机器学习模型的接口； 用于最常见建模目的的预先存在模块的“标准库”(例如卷积，RNN，批处理规范化等）； 优化 API，包括流行的优化器(例如 SGD，Adam，RMSprop 等）的实现； 一种表示数据集和数据管道的方法，包括在许多 CPU 内核上并行加载数据的功能； 用于存储和加载训练检查点的序列化格式(例如torch.utils.data.DataLoader）； 将模型自动并行化到多个 GPU(例如torch.nn.parallel.DataParallel）； 支持代码，可以使用 pybind11 轻松将 C ++模型绑定到 Python； 入口指向 TorchScript JIT 编译器； 有用的实用程序，可促进与 ATen 和 Autograd API 的接口。 有关 C ++前端的详细说明，请参见本文档的。 与 C ++前端相关的 torch :: 命名空间的相关部分包括 torch :: nn ， torch :: optim 和 [torch :: data ， torch :: serialize ， torch :: jit 和 torch :: python 。 C ++前端的示例可以在该存储库的中找到，该存储库正在持续不断地扩展。 注意 除非有特殊原因要专门限制自己使用 ATen 或 Autograd API，否则 C ++前端是 PyTorch C ++生态系统的推荐入口点。 尽管它仍处于测试阶段，因为我们收集了您的用户反馈，但与 ATen 和 Autograd API 相比，它提供了更多的功能和更好的稳定性保证。 torch脚本 TorchScript 是 PyTorch 模型的表示形式，可以由 TorchScript 编译器理解，编译和序列化。 从根本上说，TorchScript 本身就是一种编程语言。 它是使用 PyTorch API 的 Python 的子集。 TorchScript 的 C ++接口包含三个主要功能： 一种用于加载和执行 Python 中定义的序列化 TorchScript 模型的机制； 用于定义自定义运算符的 API，用于扩展 TorchScript 标准运算库； 从 C ++实时编译 TorchScript 程序。 如果您想尽可能地在 Python 中定义模型，但是随后将它们导出到 C ++进行生产环境和无 Python 推断，第一种机制可能对您很感兴趣。 您可以通过以下此链接找到有关此内容的更多信息。 第二个 API 涉及您想使用自定义运算符扩展 TorchScript 的场景，可以类似地在推理过程中从 C ++对其进行序列化和调用。 最后， torch :: jit :: compile 函数可用于直接从 C ++访问 TorchScript 编译器。 C ++扩展 C ++扩展提供了一种简单而强大的方法来访问上述所有接口，以扩展 PyTorch 的常规 Python 用例。 C ++扩展最常用于在 C ++或 CUDA 中实现自定义运算符，以加快对原始 PyTorch 设置的研究。 C ++扩展 API 不会向 PyTorch C ++ API 添加任何新功能。 相反，它提供了与 Python setuptool 以及 JIT 编译机制的集成，该机制允许从 Python 访问 ATen，autograd 和其他 C ++ API。 要了解有关 C ++扩展 API 的更多信息，请参见本教程的。 内容 安装 PyTorch 的 C ++发行版 最小示例 支持 C ++前端 说明 端到端示例 哲学 安装 库 API 类层次结构 文件层次结构 完整 API 笔记 常见问题解答 Tensor 基础 Tensor Creation API 指数和表格 索引 模块索引 搜索页 致谢 PyTorch C ++领域的此文档网站已由 Exhale 项目启用，并且其维护者 svenevs 投入了大量时间和精力。 我们感谢 Stephen 的工作以及他对 PyTorch C ++文档的帮助。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"72.html":{"url":"72.html","title":"PyTorch Java API","keywords":"","body":"PyTorch Java API 原文： https://pytorch.org/javadoc/ 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:23:53 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"74.html":{"url":"74.html","title":"torch","keywords":"","body":"torch 原文： https://pytorch.org/docs/stable/torch.html torch程序包包含多维张量的数据结构，并定义了这些数据的数学运算。 此外，它提供了许多实用程序，可用于有效地序列化张量和任意类型，以及其他有用的实用程序。 它具有 CUDA 对应项，使您能够在具有计算能力> = 3.0 的 NVIDIA GPU 上运行张量计算。 张量 torch.is_tensor(obj)¶ 如果 obj 是 PyTorch 张量，则返回 True。 参数 obj (对象）–要测试的对象 torch.is_storage(obj)¶ 如果 obj 是 PyTorch 存储对象，则返回 True。 Parameters obj (Object) – Object to test torch.is_floating_point(input) -> (bool)¶ 如果input的数据类型是浮点数据类型，即torch.float64，torch.float32和torch.float16之一，则返回 True。 Parameters 输入 (tensor)–要测试的 PyTorch 张量 torch.set_default_dtype(d)¶ 将默认浮点 dtype 设置为d。 该类型将用作 torch.tensor() 中类型推断的默认浮点类型。 默认浮点 dtype 最初为torch.float32。 Parameters d (torch.dtype)–浮点 dtype，使其成为默认值 例： >>> torch.tensor([1.2, 3]).dtype # initial default for floating point is torch.float32 torch.float32 >>> torch.set_default_dtype(torch.float64) >>> torch.tensor([1.2, 3]).dtype # a new floating point tensor torch.float64 torch.get_default_dtype() → torch.dtype¶ 获取当前的默认浮点数 torch.dtype 。 Example: >>> torch.get_default_dtype() # initial default for floating point is torch.float32 torch.float32 >>> torch.set_default_dtype(torch.float64) >>> torch.get_default_dtype() # default is now changed to torch.float64 torch.float64 >>> torch.set_default_tensor_type(torch.FloatTensor) # setting tensor type also affects this >>> torch.get_default_dtype() # changed to torch.float32, the dtype for torch.FloatTensor torch.float32 torch.set_default_tensor_type(t)¶ 将默认的torch.Tensor类型设置为浮点张量类型t。 该类型还将用作 torch.tensor() 中类型推断的默认浮点类型。 默认的浮点张量类型最初为torch.FloatTensor。 Parameters t (python：type 或 字符串）–浮点张量类型或其名称 Example: >>> torch.tensor([1.2, 3]).dtype # initial default for floating point is torch.float32 torch.float32 >>> torch.set_default_tensor_type(torch.DoubleTensor) >>> torch.tensor([1.2, 3]).dtype # a new floating point tensor torch.float64 torch.numel(input) → int¶ 返回input张量中的元素总数。 Parameters 输入 (tensor)–输入张量。 Example: >>> a = torch.randn(1, 2, 3, 4, 5) >>> torch.numel(a) 120 >>> a = torch.zeros(4,4) >>> torch.numel(a) 16 torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)¶ 设置打印选项。 从 NumPy 无耻地拿走的物品 Parameters precision –浮点输出的精度位数(默认= 4）。 阈值 –触发汇总而不是完整的 repr 的数组元素总数(默认= 1000）。 edgeitems -每个维的开始和结束处摘要中数组项目的数量(默认= 3）。 线宽 –用于插入换行符的每行字符数(默认= 80）。 阈值矩阵将忽略此参数。 配置文件 – Sane 默认用于漂亮的打印。 可以使用以上任何选项覆盖。 (默认，短，完整中的任何一种） sci_mode –启用(真）或禁用(假）科学计数法。 如果指定了 None(默认），则该值由 _Formatter 定义 torch.set_flush_denormal(mode) → bool¶ 禁用 CPU 上的非正常浮​​点数。 如果您的系统支持刷新非正规数并且已成功配置刷新非正规模式，则返回True。 set_flush_denormal() 仅在支持 SSE3 的 x86 架构上受支持。 Parameters 模式 (bool )–控制是否启用冲洗非正常模式 Example: >>> torch.set_flush_denormal(True) True >>> torch.tensor([1e-323], dtype=torch.float64) tensor([ 0.], dtype=torch.float64) >>> torch.set_flush_denormal(False) True >>> torch.tensor([1e-323], dtype=torch.float64) tensor(9.88131e-324 * [ 1.0000], dtype=torch.float64) 创作行动 注意 随机抽样创建操作列在随机抽样下，包括： torch.rand() torch.rand_like() torch.randn() torch.randn_like() torch.randint() torch.randint_like() torch.randperm() 您也可以将 torch.empty() 与输入一起使用 位随机抽样方法来创建 torch.Tensor ，并从更广泛的分布范围内采样值。 torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False) → Tensor¶ 用data构造一个张量。 警告 torch.tensor() 始终复制data。 如果您具有张量data并希望避免复制，请使用 torch.Tensor.requires_grad_() 或 torch.Tensor.detach() 。 如果您有 NumPy ndarray并想避免复制，请使用 torch.as_tensor() 。 Warning 当数据是张量 x 时， torch.tensor() 从传递的任何数据中读出“数据”，并构造一个叶子变量。 因此，torch.tensor(x)等同于x.clone().detach()，torch.tensor(x, requires_grad=True)等同于x.clone().detach().requires_grad_(True)。 建议使用clone()和detach()的等效项。 Parameters 数据 (array_like )–张量的初始数据。 可以是列表，元组，NumPy ndarray，标量和其他类型。 dtype (torch.dtype ，可选）–返回张量的所需数据类型。 默认值：如果None，则从data推断数据类型。 设备 (torch.device ，可选）–返回张量的所需设备。 默认值：如果None，则使用当前设备作为默认张量类型(请参见 torch.set_default_tensor_type())。 device将是用于 CPU 张量类型的 CPU，并且是用于 CUDA 张量类型的当前 CUDA 设备。 require_grad (bool ， 可选）–如果 autograd 应该在返回的张量上记录操作。 默认值：False。 pin_memory (bool ， 可选）–如果设置，返回的张量将分配在固定的内存中。 仅适用于 CPU 张量。 默认值：False。 Example: >>> torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]]) tensor([[ 0.1000, 1.2000], [ 2.2000, 3.1000], [ 4.9000, 5.2000]]) >>> torch.tensor([0, 1]) # Type inference on data tensor([ 0, 1]) >>> torch.tensor([[0.11111, 0.222222, 0.3333333]], dtype=torch.float64, device=torch.device('cuda:0')) # creates a torch.cuda.DoubleTensor tensor([[ 0.1111, 0.2222, 0.3333]], dtype=torch.float64, device='cuda:0') >>> torch.tensor(3.14159) # Create a scalar (zero-dimensional tensor) tensor(3.1416) >>> torch.tensor([]) # Create an empty tensor (of size (0,)) tensor([]) torch.sparse_coo_tensor(indices, values, size=None, dtype=None, device=None, requires_grad=False) → Tensor¶ 在给定values和给定values的情况下，以非零元素构造 COO(rdinate）格式的稀疏张量。 稀疏张量可以是而不是，在那种情况下，索引中有重复的坐标，并且该索引处的值是所有重复值条目的总和： torch.sparse 。 Parameters 索引 (array_like )–张量的初始数据。 可以是列表，元组，NumPy ndarray，标量和其他类型。 将在内部强制转换为torch.LongTensor。 索引是矩阵中非零值的坐标，因此应为二维，其中第一维是张量维数，第二维是非零值数。 值 (array_like )–张量的初始值。 可以是列表，元组，NumPy ndarray，标量和其他类型。 大小(列表，元组或torch.Size，可选）–稀疏张量的大小。 如果未提供，则将推断大小为足以容纳所有非零元素的最小大小。 dtype (torch.dtype ，可选）–返回张量的所需数据类型。 默认值：如果为 None，则从values推断数据类型。 设备 (torch.device ，可选）–返回张量的所需设备。 默认值：如果为 None，则使用当前设备作为默认张量类型(请参见 torch.set_default_tensor_type())。 device将是用于 CPU 张量类型的 CPU，是用于 CUDA 张量类型的当前 CUDA 设备。 requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> i = torch.tensor([[0, 1, 1], [2, 0, 2]]) >>> v = torch.tensor([3, 4, 5], dtype=torch.float32) >>> torch.sparse_coo_tensor(i, v, [2, 4]) tensor(indices=tensor([[0, 1, 1], [2, 0, 2]]), values=tensor([3., 4., 5.]), size=(2, 4), nnz=3, layout=torch.sparse_coo) >>> torch.sparse_coo_tensor(i, v) # Shape inference tensor(indices=tensor([[0, 1, 1], [2, 0, 2]]), values=tensor([3., 4., 5.]), size=(2, 3), nnz=3, layout=torch.sparse_coo) >>> torch.sparse_coo_tensor(i, v, [2, 4], dtype=torch.float64, device=torch.device('cuda:0')) tensor(indices=tensor([[0, 1, 1], [2, 0, 2]]), values=tensor([3., 4., 5.]), device='cuda:0', size=(2, 4), nnz=3, dtype=torch.float64, layout=torch.sparse_coo) # Create an empty sparse tensor with the following invariants: # 1\\. sparse_dim + dense_dim = len(SparseTensor.shape) # 2\\. SparseTensor._indices().shape = (sparse_dim, nnz) # 3\\. SparseTensor._values().shape = (nnz, SparseTensor.shape[sparse_dim:]) # # For instance, to create an empty sparse tensor with nnz = 0, dense_dim = 0 and # sparse_dim = 1 (hence indices is a 2D tensor of shape = (1, 0)) >>> S = torch.sparse_coo_tensor(torch.empty([1, 0]), [], [1]) tensor(indices=tensor([], size=(1, 0)), values=tensor([], size=(0,)), size=(1,), nnz=0, layout=torch.sparse_coo) # and to create an empty sparse tensor with nnz = 0, dense_dim = 1 and # sparse_dim = 1 >>> S = torch.sparse_coo_tensor(torch.empty([1, 0]), torch.empty([0, 2]), [1, 2]) tensor(indices=tensor([], size=(1, 0)), values=tensor([], size=(0, 2)), size=(1, 2), nnz=0, layout=torch.sparse_coo) torch.as_tensor(data, dtype=None, device=None) → Tensor¶ 将数据转换为torch。张量。 如果数据已经是具有相同 dtype 和设备的张量，则不会执行任何复制，否则将使用新的张量。 如果数据张量具有requires_grad=True，则返回保留计算图的计算图。 同样，如果数据是对应的 dtype 的ndarray，并且设备是 cpu，则不会执行任何复制。 Parameters data (array_like) – Initial data for the tensor. Can be a list, tuple, NumPy ndarray, scalar, and other types. dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, infers data type from data. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. Example: >>> a = numpy.array([1, 2, 3]) >>> t = torch.as_tensor(a) >>> t tensor([ 1, 2, 3]) >>> t[0] = -1 >>> a array([-1, 2, 3]) >>> a = numpy.array([1, 2, 3]) >>> t = torch.as_tensor(a, device=torch.device('cuda')) >>> t tensor([ 1, 2, 3]) >>> t[0] = -1 >>> a array([1, 2, 3]) torch.as_strided(input, size, stride, storage_offset=0) → Tensor¶ 创建具有指定size，stride和storage_offset的现有炬管 input的视图。 Warning 创建的张量中的一个以上元素可以引用单个存储位置。 结果，就地操作(尤其是矢量化的操作）可能会导致错误的行为。 如果需要写张量，请先克隆它们。 许多 PyTorch 函数可返回张量视图，并在此函数内部实现。 这些功能，例如 torch.Tensor.expand() ，更易于阅读，因此更可取。 Parameters input (Tensor) – the input tensor. 大小(元组 或 python：ints )–输出张量的形状 跨度(元组 或 python：ints )–输出张量的跨度 storage_offset (python：int ， 可选）–输出张量的基础存储中的偏移量 Example: >>> x = torch.randn(3, 3) >>> x tensor([[ 0.9039, 0.6291, 1.0795], [ 0.1586, 2.1939, -0.4900], [-0.1909, -0.7503, 1.9355]]) >>> t = torch.as_strided(x, (2, 2), (1, 2)) >>> t tensor([[0.9039, 1.0795], [0.6291, 0.1586]]) >>> t = torch.as_strided(x, (2, 2), (1, 2), 1) tensor([[0.6291, 0.1586], [1.0795, 2.1939]]) torch.from_numpy(ndarray) → Tensor¶ 从numpy.ndarray创建 Tensor 。 返回的张量和ndarray共享相同的内存。 对张量的修改将反映在ndarray中，反之亦然。 返回的张量不可调整大小。 当前它接受具有numpy.float64，numpy.float32，numpy.float16，numpy.int64，numpy.int32，numpy.int16，numpy.int8，numpy.uint8和numpy.bool d 类型的ndarray。 Example: >>> a = numpy.array([1, 2, 3]) >>> t = torch.from_numpy(a) >>> t tensor([ 1, 2, 3]) >>> t[0] = -1 >>> a array([-1, 2, 3]) torch.zeros(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor¶ 返回一个由标量值 0 填充的张量，其形状由变量参数size定义。 Parameters 大小 (python：int ... )–定义输出张量形状的整数序列。 可以是可变数量的参数，也可以是列表或元组之类的集合。 输出 (tensor ， 可选）–输出张量。 dtype (torch.dtype ，可选）–返回张量的所需数据类型。 默认值：如果None使用全局默认值(请参见 torch.set_default_tensor_type())。 布局 (torch.layout ，可选）–返回的 Tensor 所需的布局。 默认值：torch.strided。 device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.zeros(2, 3) tensor([[ 0., 0., 0.], [ 0., 0., 0.]]) >>> torch.zeros(5) tensor([ 0., 0., 0., 0., 0.]) torch.zeros_like(input, dtype=None, layout=None, device=None, requires_grad=False) → Tensor¶ 返回一个由标量值 0 填充的张量，其大小与input相同。 torch.zeros_like(input)等效于torch.zeros(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)。 Warning 从 0.4 开始，此功能不支持out关键字。 作为替代，旧的torch.zeros_like(input, out=output)等效于torch.zeros(input.size(), out=output)。 Parameters 输入 (tensor)– input的大小将确定输出张量的大小。 dtype (torch.dtype ，可选）–返回的 Tensor 的所需数据类型。 默认值：如果为None，则默认为input的 dtype。 布局 (torch.layout ，可选）–返回张量的所需布局。 默认值：如果为None，则默认为input的布局。 设备 (torch.device ，可选）–返回张量的所需设备。 默认值：如果为None，则默认为input的设备。 requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> input = torch.empty(2, 3) >>> torch.zeros_like(input) tensor([[ 0., 0., 0.], [ 0., 0., 0.]]) torch.ones(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor¶ 返回一个由标量值 1 填充的张量，其形状由变量自变量size定义。 Parameters size (python:int...) – a sequence of integers defining the shape of the output tensor. Can be a variable number of arguments or a collection like a list or tuple. out (Tensor, optional) – the output tensor. dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.ones(2, 3) tensor([[ 1., 1., 1.], [ 1., 1., 1.]]) >>> torch.ones(5) tensor([ 1., 1., 1., 1., 1.]) torch.ones_like(input, dtype=None, layout=None, device=None, requires_grad=False) → Tensor¶ 返回一个由标量值 1 填充的张量，其大小与input相同。 torch.ones_like(input)等效于torch.ones(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)。 Warning 从 0.4 开始，此功能不支持out关键字。 作为替代，旧的torch.ones_like(input, out=output)等效于torch.ones(input.size(), out=output)。 Parameters input (Tensor) – the size of input will determine size of the output tensor. dtype (torch.dtype, optional) – the desired data type of returned Tensor. Default: if None, defaults to the dtype of input. layout (torch.layout, optional) – the desired layout of returned tensor. Default: if None, defaults to the layout of input. device (torch.device, optional) – the desired device of returned tensor. Default: if None, defaults to the device of input. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> input = torch.empty(2, 3) >>> torch.ones_like(input) tensor([[ 1., 1., 1.], [ 1., 1., 1.]]) torch.arange(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor¶ 返回大小为的一维张量，该值具有从开始开始具有公共差step的间隔[start, end)的值。 请注意，与end比较时，非整数step会出现浮点舍入错误； 为了避免不一致，在这种情况下，建议在end中添加一个小的ε。 Parameters 起始(编号）–点集的起始值。 默认值：0。 结束(编号）–点集的结束值 步骤(编号）–每对相邻点之间的间隙。 默认值：1。 out (Tensor, optional) – the output tensor. dtype (torch.dtype ，可选）–返回张量的所需数据类型。 默认值：如果None使用全局默认值(请参阅 torch.set_default_tensor_type())。 如果未提供 dtype ，则从其他输入参数推断数据类型。 如果开始，结束或停止中的任何一个是浮点，则推断 dtype 为默认 dtype，请参见[ get_default_dtype() 。 否则，将 dtype 推断为 torch.int64 。 layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.arange(5) tensor([ 0, 1, 2, 3, 4]) >>> torch.arange(1, 4) tensor([ 1, 2, 3]) >>> torch.arange(1, 2.5, 0.5) tensor([ 1.0000, 1.5000, 2.0000]) torch.range(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor¶ 在步骤step中返回大小为的一维张量，其值从start到end。 阶跃是张量中两个值之间的差距。 Warning 不推荐使用此功能，而推荐使用 torch.arange() 。 Parameters start (python：float )–点集的起始值。 默认值：0。 end (python：float )–点集的结束值 步骤 (python：float )–每对相邻点之间的间隙。 默认值：1。 out (Tensor, optional) – the output tensor. dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). If dtype is not given, infer the data type from the other input arguments. If any of start, end, or stop are floating-point, the dtype is inferred to be the default dtype, see get_default_dtype(). Otherwise, the dtype is inferred to be torch.int64. layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.range(1, 4) tensor([ 1., 2., 3., 4.]) >>> torch.range(1, 4, 0.5) tensor([ 1.0000, 1.5000, 2.0000, 2.5000, 3.0000, 3.5000, 4.0000]) torch.linspace(start, end, steps=100, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor¶ 返回start和end之间等距点的steps的一维张量。 输出张量为steps大小的 1-D。 Parameters 开始 (python：float )–点集的起始值 end (python:float) – the ending value for the set of points 步骤 (python：int )–在start和end之间采样的点数。 默认值：100。 out (Tensor, optional) – the output tensor. dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.linspace(3, 10, steps=5) tensor([ 3.0000, 4.7500, 6.5000, 8.2500, 10.0000]) >>> torch.linspace(-10, 10, steps=5) tensor([-10., -5., 0., 5., 10.]) >>> torch.linspace(start=-10, end=10, steps=5) tensor([-10., -5., 0., 5., 10.]) >>> torch.linspace(start=-10, end=10, steps=1) tensor([-10.]) torch.logspace(start, end, steps=100, base=10.0, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor¶ 返回与和之间的底数base对数间隔的steps点的一维张量。 The output tensor is 1-D of size steps. Parameters start (python:float) – the starting value for the set of points end (python:float) – the ending value for the set of points steps (python:int) – number of points to sample between start and end. Default: 100. 基数 (python：float )–对数函数的基数。 默认值：10.0。 out (Tensor, optional) – the output tensor. dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.logspace(start=-10, end=10, steps=5) tensor([ 1.0000e-10, 1.0000e-05, 1.0000e+00, 1.0000e+05, 1.0000e+10]) >>> torch.logspace(start=0.1, end=1.0, steps=5) tensor([ 1.2589, 2.1135, 3.5481, 5.9566, 10.0000]) >>> torch.logspace(start=0.1, end=1.0, steps=1) tensor([1.2589]) >>> torch.logspace(start=2, end=2, steps=1, base=2) tensor([4.0]) torch.eye(n, m=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor¶ 返回一个二维张量，对角线上有一个，其他位置为零。 Parameters n (python：int )–行数 m (python：int ， 可选）–默认为n的列数 out (Tensor, optional) – the output tensor. dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. 退货 二维张量，对角线上有一个，其他位置为零 返回类型 张量 Example: >>> torch.eye(3) tensor([[ 1., 0., 0.], [ 0., 1., 0.], [ 0., 0., 1.]]) torch.empty(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False) → Tensor¶ 返回填充有未初始化数据的张量。 张量的形状由变量参数size定义。 Parameters size (python:int...) – a sequence of integers defining the shape of the output tensor. Can be a variable number of arguments or a collection like a list or tuple. out (Tensor, optional) – the output tensor. dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. pin_memory (bool__, optional) – If set, returned tensor would be allocated in the pinned memory. Works only for CPU tensors. Default: False. Example: >>> torch.empty(2, 3) tensor(1.00000e-08 * [[ 6.3984, 0.0000, 0.0000], [ 0.0000, 0.0000, 0.0000]]) torch.empty_like(input, dtype=None, layout=None, device=None, requires_grad=False) → Tensor¶ 返回与input相同大小的未初始化张量。 torch.empty_like(input)等效于torch.empty(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)。 Parameters input (Tensor) – the size of input will determine size of the output tensor. dtype (torch.dtype, optional) – the desired data type of returned Tensor. Default: if None, defaults to the dtype of input. layout (torch.layout, optional) – the desired layout of returned tensor. Default: if None, defaults to the layout of input. device (torch.device, optional) – the desired device of returned tensor. Default: if None, defaults to the device of input. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.empty((2,3), dtype=torch.int64) tensor([[ 9.4064e+13, 2.8000e+01, 9.3493e+13], [ 7.5751e+18, 7.1428e+18, 7.5955e+18]]) torch.empty_strided(size, stride, dtype=None, layout=None, device=None, requires_grad=False, pin_memory=False) → Tensor¶ 返回填充有未初始化数据的张量。 张量的形状和步幅分别由变量参数size和stride定义。 torch.empty_strided(size, stride)等同于torch.empty(size).as_strided(size, stride)。 Warning 创建的张量中的一个以上元素可以引用单个存储位置。 结果，就地操作(尤其是矢量化的操作）可能会导致错误的行为。 如果需要写张量，请先克隆它们。 Parameters 大小(python：ints 的元组）–输出张量的形状 跨度(python：ints 的元组）–输出张量的跨度 dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. pin_memory (bool__, optional) – If set, returned tensor would be allocated in the pinned memory. Works only for CPU tensors. Default: False. Example: >>> a = torch.empty_strided((2, 3), (1, 2)) >>> a tensor([[8.9683e-44, 4.4842e-44, 5.1239e+07], [0.0000e+00, 0.0000e+00, 3.0705e-41]]) >>> a.stride() (1, 2) >>> a.size() torch.Size([2, 3]) torch.full(size, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor¶ 返回大小为size的张量，其中填充了fill_value。 Parameters 大小 (python：int ... )–定义输出张量形状的整数列表，元组或torch.Size。 fill_value –用来填充输出张量的数字。 out (Tensor, optional) – the output tensor. dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.full((2, 3), 3.141592) tensor([[ 3.1416, 3.1416, 3.1416], [ 3.1416, 3.1416, 3.1416]]) torch.full_like(input, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor¶ 返回与填充有fill_value的input大小相同的张量。 torch.full_like(input, fill_value)等同于torch.full(input.size(), fill_value, dtype=input.dtype, layout=input.layout, device=input.device)。 Parameters input (Tensor) – the size of input will determine size of the output tensor. fill_value – the number to fill the output tensor with. dtype (torch.dtype, optional) – the desired data type of returned Tensor. Default: if None, defaults to the dtype of input. layout (torch.layout, optional) – the desired layout of returned tensor. Default: if None, defaults to the layout of input. device (torch.device, optional) – the desired device of returned tensor. Default: if None, defaults to the device of input. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. torch.quantize_per_tensor(input, scale, zero_point, dtype) → Tensor¶ 将浮点张量转换为具有给定比例和零点的量化张量。 Parameters 输入 (tensor)–浮点张量进行量化 标度 (python：float )–适用于量化公式的标度 zero_point (python：int )–映射为浮点零的整数值偏移 dtype (torch.dtype)–返回张量的所需数据类型。 必须是量化的 dtypes 之一：torch.quint8，torch.qint8和torch.qint32 Returns 新量化的张量 Return type Tensor Example: >>> torch.quantize_per_tensor(torch.tensor([-1.0, 0.0, 1.0, 2.0]), 0.1, 10, torch.quint8) tensor([-1., 0., 1., 2.], size=(4,), dtype=torch.quint8, quantization_scheme=torch.per_tensor_affine, scale=0.1, zero_point=10) >>> torch.quantize_per_tensor(torch.tensor([-1.0, 0.0, 1.0, 2.0]), 0.1, 10, torch.quint8).int_repr() tensor([ 0, 10, 20, 30], dtype=torch.uint8) torch.quantize_per_channel(input, scales, zero_points, axis, dtype) → Tensor¶ 将浮点张量转换为具有给定比例和零点的每通道量化张量。 Parameters input (Tensor) – float tensor to quantize 秤 (tensor)–要使用的一维浮标秤，尺寸应匹配input.size(axis) zero_points (python：int )–要使用的整数 1D 张量偏移量，大小应与input.size(axis)相匹配 轴 (python：int )–应用每个通道量化的维度 dtype (torch.dtype) – the desired data type of returned tensor. Has to be one of the quantized dtypes: torch.quint8, torch.qint8, torch.qint32 Returns A newly quantized tensor Return type Tensor Example: >>> x = torch.tensor([[-1.0, 0.0], [1.0, 2.0]]) >>> torch.quantize_per_channel(x, torch.tensor([0.1, 0.01]), torch.tensor([10, 0]), 0, torch.quint8) tensor([[-1., 0.], [ 1., 2.]], size=(2, 2), dtype=torch.quint8, quantization_scheme=torch.per_channel_affine, scale=tensor([0.1000, 0.0100], dtype=torch.float64), zero_point=tensor([10, 0]), axis=0) >>> torch.quantize_per_channel(x, torch.tensor([0.1, 0.01]), torch.tensor([10, 0]), 0, torch.quint8).int_repr() tensor([[ 0, 10], [100, 200]], dtype=torch.uint8) 索引，切片，联接，操作变更 torch.cat(tensors, dim=0, out=None) → Tensor¶ 在给定维度上连接seq张量的给定序列。 所有张量必须具有相同的形状(在连接维中除外）或为空。 torch.cat() 可以看作是 torch.split() 和 torch.chunk() 的逆运算。 通过示例可以更好地理解 torch.cat() 。 Parameters 张量(张量序列）–同一类型的任何 python 张量序列。 提供的非空张量必须具有相同的形状，但猫的尺寸除外。 暗淡的 (python：int ， 可选）–张量级联的尺寸 out (Tensor, optional) – the output tensor. Example: >>> x = torch.randn(2, 3) >>> x tensor([[ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497]]) >>> torch.cat((x, x, x), 0) tensor([[ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497], [ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497], [ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497]]) >>> torch.cat((x, x, x), 1) tensor([[ 0.6580, -1.0969, -0.4614, 0.6580, -1.0969, -0.4614, 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497, -0.1034, -0.5790, 0.1497, -0.1034, -0.5790, 0.1497]]) torch.chunk(input, chunks, dim=0) → List of Tensors¶ 将张量拆分为特定数量的块。 如果沿给定维度dim的张量大小不能被chunks整除，则最后一块将较小。 Parameters 输入 (tensor)–要分割的张量 块 (python：int )–要返回的块数 暗淡的 (python：int )–沿其张量分裂的尺寸 torch.gather(input, dim, index, out=None, sparse_grad=False) → Tensor¶ 沿昏暗指定的轴收集值。 对于 3-D 张量，输出指定为： out[i][j][k] = input[index[i][j][k]][j][k] # if dim == 0 out[i][j][k] = input[i][index[i][j][k]][k] # if dim == 1 out[i][j][k] = input[i][j][index[i][j][k]] # if dim == 2 如果input是大小为和dim = i的 n 维张量，则index必须是大小为的-维张量，其中和out具有相同的大小 大小为index。 Parameters 输入 (tensor)–源张量 暗淡的 (python：int )–沿其索引的轴 索引 (LongTensor )–要收集的元素的索引 输出 (tensor ， 可选）–目标张量 sparse_grad (bool ， 可选）–如果True，则梯度 w.r.t. input将是一个稀疏张量。 Example: >>> t = torch.tensor([[1,2],[3,4]]) >>> torch.gather(t, 1, torch.tensor([[0,0],[1,0]])) tensor([[ 1, 1], [ 4, 3]]) torch.index_select(input, dim, index, out=None) → Tensor¶ 返回一个新张量，该张量使用index LongTensor 中的index中的条目沿维度dim索引input张量。 返回的张量具有与原始张量(input）相同的维数。 dim的尺寸与index的长度相同； 其他尺寸与原始张量中的尺寸相同。 Note 返回的张量不与原始张量使用相同的存储空间而不是。 如果out的形状与预期的形状不同，我们将默默地将其更改为正确的形状，并在必要时重新分配基础存储。 Parameters input (Tensor) – the input tensor. 暗淡的 (python：int )–我们索引的维度 索引 (LongTensor )–包含要索引的索引的一维张量 out (Tensor, optional) – the output tensor. Example: >>> x = torch.randn(3, 4) >>> x tensor([[ 0.1427, 0.0231, -0.5414, -1.0009], [-0.4664, 0.2647, -0.1228, -1.1068], [-1.1734, -0.6571, 0.7230, -0.6004]]) >>> indices = torch.tensor([0, 2]) >>> torch.index_select(x, 0, indices) tensor([[ 0.1427, 0.0231, -0.5414, -1.0009], [-1.1734, -0.6571, 0.7230, -0.6004]]) >>> torch.index_select(x, 1, indices) tensor([[ 0.1427, -0.5414], [-0.4664, -0.1228], [-1.1734, 0.7230]]) torch.masked_select(input, mask, out=None) → Tensor¶ 返回一个新的一维张量，该张量根据布尔值掩码mask为其 BoolTensor 索引input张量。 mask张量和input张量的形状不需要匹配，但它们必须是可广播的。 Note 返回的张量是否而不是使用与原始张量相同的存储 Parameters input (Tensor) – the input tensor. 掩码 (ByteTensor )–包含二进制掩码的张量，以使用 out (Tensor, optional) – the output tensor. Example: >>> x = torch.randn(3, 4) >>> x tensor([[ 0.3552, -2.3825, -0.8297, 0.3477], [-1.2035, 1.2252, 0.5002, 0.6248], [ 0.1307, -2.0608, 0.1244, 2.0139]]) >>> mask = x.ge(0.5) >>> mask tensor([[False, False, False, False], [False, True, True, True], [False, False, False, True]]) >>> torch.masked_select(x, mask) tensor([ 1.2252, 0.5002, 0.6248, 2.0139]) torch.narrow(input, dim, start, length) → Tensor¶ 返回一个新的张量，该张量是input张量的缩小版本。 尺寸dim从start输入到start + length。 返回的张量和input张量共享相同的基础存储。 Parameters 输入 (tensor)–张量变窄 暗淡的 (python：int )–缩小范围 开始 (python：int )–起始尺寸 长度 (python：int )–到最终尺寸的距离 Example: >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) >>> torch.narrow(x, 0, 0, 2) tensor([[ 1, 2, 3], [ 4, 5, 6]]) >>> torch.narrow(x, 1, 1, 2) tensor([[ 2, 3], [ 5, 6], [ 8, 9]]) torch.nonzero(input, *, out=None, as_tuple=False) → LongTensor or tuple of LongTensors¶ Note torch.nonzero(..., as_tuple=False) (默认值）返回一个二维张量，其中每一行都是非零值的索引。 torch.nonzero(..., as_tuple=True) 返回一维索引张量的元组，允许进行高级索引，因此x[x.nonzero(as_tuple=True)]给出张量x的所有非零值。 在返回的元组中，每个索引张量都包含特定维度的非零索引。 有关这两种行为的更多详细信息，请参见下文。 当 as_tuple 为“ False”(默认）时： 返回一个张量，该张量包含input所有非零元素的索引。 结果中的每一行都包含input中非零元素的索引。 结果按字典顺序排序，最后一个索引更改最快(C 样式）。 如果input具有尺寸，则所得索引张量out的大小为，其中是input张量中非零元素的总数。 当 as_tuple 为“ True” 时： 返回一维张量的元组，在input中每个维度一个张量，每个张量包含input所有非零元素的索引(在该维度中）。 如果input具有尺寸，则生成的元组包含大小的张量，其中是input张量中非零元素的总数。 作为一种特殊情况，当input具有零维和非零标量值时，会将其视为具有一个元素的一维张量。 Parameters input (Tensor) – the input tensor. out (LongTensor ， 可选）–包含索引的输出张量 Returns 如果as_tuple为False，则包含索引的输出张量。 如果as_tuple为True，则每个维度都有一个 1-D 张量，其中包含沿着该维度的每个非零元素的索引。 Return type LongTensor 或 LongTensor 的元组 Example: >>> torch.nonzero(torch.tensor([1, 1, 1, 0, 1])) tensor([[ 0], [ 1], [ 2], [ 4]]) >>> torch.nonzero(torch.tensor([[0.6, 0.0, 0.0, 0.0], [0.0, 0.4, 0.0, 0.0], [0.0, 0.0, 1.2, 0.0], [0.0, 0.0, 0.0,-0.4]])) tensor([[ 0, 0], [ 1, 1], [ 2, 2], [ 3, 3]]) >>> torch.nonzero(torch.tensor([1, 1, 1, 0, 1]), as_tuple=True) (tensor([0, 1, 2, 4]),) >>> torch.nonzero(torch.tensor([[0.6, 0.0, 0.0, 0.0], [0.0, 0.4, 0.0, 0.0], [0.0, 0.0, 1.2, 0.0], [0.0, 0.0, 0.0,-0.4]]), as_tuple=True) (tensor([0, 1, 2, 3]), tensor([0, 1, 2, 3])) >>> torch.nonzero(torch.tensor(5), as_tuple=True) (tensor([0]),) torch.reshape(input, shape) → Tensor¶ 返回具有与input相同的数据和元素数量，但具有指定形状的张量。 如果可能，返回的张量将是input的视图。 否则，它将是副本。 连续输入和具有兼容步幅的输入可以在不复制的情况下进行重塑，但是您不应该依赖复制与查看行为。 当可以返回视图时，请参见 torch.Tensor.view() 。 单个尺寸可能为-1，在这种情况下，它是根据input中的其余尺寸和元素数量推断出来的。 Parameters 输入 (tensor)–要重塑的张量 形状 (python：ints 的元组）–新形状 Example: >>> a = torch.arange(4.) >>> torch.reshape(a, (2, 2)) tensor([[ 0., 1.], [ 2., 3.]]) >>> b = torch.tensor([[0, 1], [2, 3]]) >>> torch.reshape(b, (-1,)) tensor([ 0, 1, 2, 3]) torch.split(tensor, split_size_or_sections, dim=0)¶ 将张量拆分为多个块。 如果split_size_or_sections是整数类型，则 tensor 将被拆分为大小相等的块(如果可能）。 如果沿给定维度dim的张量大小不能被split_size整除，则最后一个块将较小。 如果split_size_or_sections是列表，则根据split_size_or_sections将 tensor 拆分为dim，大小为dim。 Parameters 张量 (tensor)–张量分裂。 split_size_or_sections (python：int ）或 ( 列表 ( python ：int ））–单个块的大小或每个块的大小列表 暗淡的 (python：int )–沿其张量分裂的尺寸。 torch.squeeze(input, dim=None, out=None) → Tensor¶ 返回一个张量，其中所有尺寸为 1 的input尺寸均被删除。 例如，如果输入的形状为：，则张量中的张量将为：。 给定dim时，仅在给定尺寸上执行挤压操作。 如果输入的形状为：，squeeze(input, 0)保持张量不变，但是squeeze(input, 1)会将张量压缩为形状。 Note 返回的张量与输入张量共享存储，因此更改一个张量的内容将更改另一个张量的内容。 Parameters input (Tensor) – the input tensor. 暗淡的 (python：int ， 可选）–如果给定，则仅在此维度上压缩输入 out (Tensor, optional) – the output tensor. Example: >>> x = torch.zeros(2, 1, 2, 1, 2) >>> x.size() torch.Size([2, 1, 2, 1, 2]) >>> y = torch.squeeze(x) >>> y.size() torch.Size([2, 2, 2]) >>> y = torch.squeeze(x, 0) >>> y.size() torch.Size([2, 1, 2, 1, 2]) >>> y = torch.squeeze(x, 1) >>> y.size() torch.Size([2, 2, 1, 2]) torch.stack(tensors, dim=0, out=None) → Tensor¶ 将张量的序列沿新维度连接起来。 所有张量都必须具有相同的大小。 Parameters 张量(张量序列）–连接的张量序列 暗淡的 (python：int )–插入的尺寸。 必须介于 0 和级联张量的维数之间(含） out (Tensor, optional) – the output tensor. torch.t(input) → Tensor¶ 期望input为 将按原样返回 0-D 和 1-D 张量，并且可以将 2-D 张量视为transpose(input, 0, 1)的简写函数。 Parameters input (Tensor) – the input tensor. Example: >>> x = torch.randn(()) >>> x tensor(0.1995) >>> torch.t(x) tensor(0.1995) >>> x = torch.randn(3) >>> x tensor([ 2.4320, -0.4608, 0.7702]) >>> torch.t(x) tensor([.2.4320,.-0.4608,..0.7702]) >>> x = torch.randn(2, 3) >>> x tensor([[ 0.4875, 0.9158, -0.5872], [ 0.3938, -0.6929, 0.6932]]) >>> torch.t(x) tensor([[ 0.4875, 0.3938], [ 0.9158, -0.6929], [-0.5872, 0.6932]]) torch.take(input, index) → Tensor¶ 返回给定索引处带有input元素的新张量。 将输入张量视为视为一维张量。 结果采用与索引相同的形状。 Parameters input (Tensor) – the input tensor. 索引 (LongTensor )–张量索引 Example: >>> src = torch.tensor([[4, 3, 5], [6, 7, 8]]) >>> torch.take(src, torch.tensor([0, 2, 5])) tensor([ 4, 5, 8]) torch.transpose(input, dim0, dim1) → Tensor¶ 返回一个张量，该张量是input的转置版本。 给定的尺寸dim0和dim1被交换。 产生的out张量与input张量共享其基础存储，因此更改一个内容将更改另一个内容。 Parameters input (Tensor) – the input tensor. dim0 (python：int )–要转置的第一个维度 dim1 (python：int )–要转置的第二维 Example: >>> x = torch.randn(2, 3) >>> x tensor([[ 1.0028, -0.9893, 0.5809], [-0.1669, 0.7299, 0.4942]]) >>> torch.transpose(x, 0, 1) tensor([[ 1.0028, -0.1669], [-0.9893, 0.7299], [ 0.5809, 0.4942]]) torch.unbind(input, dim=0) → seq¶ 删除张量尺寸。 返回给定维度上所有切片的元组，已经没有它。 Parameters 输入 (tensor)–要解除绑定的张量 暗淡的 (python：int )–要移除的尺寸 Example: >>> torch.unbind(torch.tensor([[1, 2, 3], >>> [4, 5, 6], >>> [7, 8, 9]])) (tensor([1, 2, 3]), tensor([4, 5, 6]), tensor([7, 8, 9])) torch.unsqueeze(input, dim, out=None) → Tensor¶ 返回在指定位置插入的尺寸为 1 的新张量。 返回的张量与此张量共享相同的基础数据。 可以使用[-input.dim() - 1, input.dim() + 1)范围内的dim值。 负的dim对应于dim = dim + input.dim() + 1处应用的 unsqueeze() 。 Parameters input (Tensor) – the input tensor. 暗淡的 (python：int )–插入单例尺寸的索引 out (Tensor, optional) – the output tensor. Example: >>> x = torch.tensor([1, 2, 3, 4]) >>> torch.unsqueeze(x, 0) tensor([[ 1, 2, 3, 4]]) >>> torch.unsqueeze(x, 1) tensor([[ 1], [ 2], [ 3], [ 4]]) torch.where()¶ torch.where(condition, x, y) → Tensor 返回从x或y中选择的元素的张量，具体取决于condition。 该操作定义为： Note 张量condition，x和y必须是可广播的。 Parameters 条件 (BoolTensor)–当为 True(非零）时，产生 x，否则产生 y x (tensor)–在condition为True的索引处选择的值 y (tensor)–在condition为False的索引处选择的值 Returns 形状张量等于condition，x，y的广播形状 Return type Tensor Example: >>> x = torch.randn(3, 2) >>> y = torch.ones(3, 2) >>> x tensor([[-0.4620, 0.3139], [ 0.3898, -0.7197], [ 0.0478, -0.1657]]) >>> torch.where(x > 0, x, y) tensor([[ 1.0000, 0.3139], [ 0.3898, 1.0000], [ 0.0478, 1.0000]]) torch.where(condition) → tuple of LongTensor torch.where(condition)与torch.nonzero(condition, as_tuple=True)相同。 Note 另请参见 torch.nonzero() 。 发电机 class torch._C.Generator(device='cpu') → Generator¶ 创建并返回一个生成器对象，该对象管理产生伪随机数的算法的状态。 在许多就地随机采样函数中用作关键字参数。 Parameters 设备(torch.device，可选）–生成器所需的设备。 Returns 一个 torch.Generator 对象。 Return type 生成器 Example: >>> g_cpu = torch.Generator() >>> g_cuda = torch.Generator(device='cuda') device¶ Generator.device->设备 获取生成器的当前设备。 Example: >>> g_cpu = torch.Generator() >>> g_cpu.device device(type='cpu') get_state() → Tensor¶ 返回生成器状态为torch.ByteTensor。 Returns 一个torch.ByteTensor，其中包含将生成器还原到特定时间点的所有必要位。 Return type Tensor Example: >>> g_cpu = torch.Generator() >>> g_cpu.get_state() initial_seed() → int¶ 返回用于生成随机数的初始种子。 Example: >>> g_cpu = torch.Generator() >>> g_cpu.initial_seed() 2147483647 manual_seed(seed) → Generator¶ 设置用于生成随机数的种子。 返回一个torch.生成器对象。 建议设置一个大种子，即一个具有 0 和 1 位平衡的数字。 避免在种子中包含许多 0 位。 Parameters 种子 (python：int )–所需的种子。 Returns An torch.Generator object. Return type Generator Example: >>> g_cpu = torch.Generator() >>> g_cpu.manual_seed(2147483647) seed() → int¶ 从 std :: random_device 或当前时间获取不确定的随机数，并将其用作生成器的种子。 Example: >>> g_cpu = torch.Generator() >>> g_cpu.seed() 1516516984916 set_state(new_state) → void¶ 设置生成器状态。 Parameters new_state (Torch.ByteTensor )–所需状态。 Example: >>> g_cpu = torch.Generator() >>> g_cpu_other = torch.Generator() >>> g_cpu.set_state(g_cpu_other.get_state()) 随机抽样 torch.seed()¶ 将用于生成随机数的种子设置为不确定的随机数。 返回用于播种 RNG 的 64 位数字。 torch.manual_seed(seed)¶ 设置用于生成随机数的种子。 返回一个torch.生成器对象。 Parameters seed (python:int) – The desired seed. torch.initial_seed()¶ 返回长为 Python long 的用于生成随机数的初始种子。 torch.get_rng_state()¶ 以 torch.ByteTensor 的形式返回随机数生成器状态。 torch.set_rng_state(new_state)¶ 设置随机数生成器状态。 Parameters new_state (torch.ByteTensor )–所需状态 torch.default_generator Returns the default CPU torch.Generator¶ torch.bernoulli(input, *, generator=None, out=None) → Tensor¶ 从伯努利分布中提取二进制随机数(0 或 1）。 input张量应为包含用于绘制二进制随机数的概率的张量。 因此，input中的所有值都必须在以下范围内：。 输出张量的元素将根据input中给出的概率值绘制一个值。 返回的out张量仅具有值 0 或 1，并且具有与input相同的形状。 out可以具有整数dtype，但是input必须具有浮点dtype。 Parameters 输入 (tensor)–伯努利分布的概率值的输入张量 生成器(torch.Generator，可选）–用于采样的伪随机数生成器 out (Tensor, optional) – the output tensor. Example: >>> a = torch.empty(3, 3).uniform_(0, 1) # generate a uniform random matrix with range [0, 1] >>> a tensor([[ 0.1737, 0.0950, 0.3609], [ 0.7148, 0.0289, 0.2676], [ 0.9456, 0.8937, 0.7202]]) >>> torch.bernoulli(a) tensor([[ 1., 0., 0.], [ 0., 0., 0.], [ 1., 1., 1.]]) >>> a = torch.ones(3, 3) # probability of drawing \"1\" is 1 >>> torch.bernoulli(a) tensor([[ 1., 1., 1.], [ 1., 1., 1.], [ 1., 1., 1.]]) >>> a = torch.zeros(3, 3) # probability of drawing \"1\" is 0 >>> torch.bernoulli(a) tensor([[ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]]) torch.multinomial(input, num_samples, replacement=False, *, generator=None, out=None) → LongTensor¶ 返回一个张量，其中每行包含num_samples索引，这些索引是从位于张量input的相应行中的多项式概率分布中采样的。 Note input的行不需要加总为 1(在这种情况下，我们将这些值用作权重），但必须为非负数，有限且总和为非零。 根据每个样本的采样时间，索引从左到右排序(第一个样本放在第一列中）。 如果input是向量，则out是大小num_samples的向量。 如果input是具有 m 行的矩阵，则out是形状的矩阵。 如果替换为True，则抽取样本进行替换。 如果没有，则它们将被替换而不会被绘制，这意味着当为一行绘制样本索引时，无法为该行再次绘制它。 Note 如果绘制时不进行替换，则num_samples必须小于input中非零元素的数目(如果是矩阵，则必须小于input每行中非零元素的最小数目）。 Parameters 输入 (tensor)–包含概率的输入张量 num_samples (python：int )–要绘制的样本数 替换 (bool ， 可选）–是否使用替换绘制 generator (torch.Generator, optional) – a pseudorandom number generator for sampling out (Tensor, optional) – the output tensor. Example: >>> weights = torch.tensor([0, 10, 3, 0], dtype=torch.float) # create a tensor of weights >>> torch.multinomial(weights, 2) tensor([1, 2]) >>> torch.multinomial(weights, 4) # ERROR! RuntimeError: invalid argument 2: invalid multinomial distribution (with replacement=False, not enough non-negative category to sample) at ../aten/src/TH/generic/THTensorRandom.cpp:320 >>> torch.multinomial(weights, 4, replacement=True) tensor([ 2, 1, 1, 1]) torch.normal()¶ torch.normal(mean, std, *, generator=None, out=None) → Tensor 返回从均值和标准差给出的独立正态分布中得出的随机数张量。 mean 是一个张量，每个输出元素的正态分布均值 std 是一个张量，每个输出元素的正态分布的标准偏差 mean 和 std 的形状不需要匹配，但是每个张量中元素的总数必须相同。 Note 当形状不匹配时，将 mean 的形状用作返回的输出张量的形状 Parameters 均值 (tensor)–每个元素均值的张量 std (tensor)–每个元素的标准偏差张量 generator (torch.Generator, optional) – a pseudorandom number generator for sampling out (Tensor, optional) – the output tensor. Example: >>> torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1)) tensor([ 1.0425, 3.5672, 2.7969, 4.2925, 4.7229, 6.2134, 8.0505, 8.1408, 9.0563, 10.0566]) torch.normal(mean=0.0, std, out=None) → Tensor 与上面的功能相似，但均值在所有绘制的元素之间共享。 Parameters 平均值 (python：float ， 可选）–所有分布的平均值 std (Tensor) – the tensor of per-element standard deviations out (Tensor, optional) – the output tensor. Example: >>> torch.normal(mean=0.5, std=torch.arange(1., 6.)) tensor([-1.2793, -1.0732, -2.0687, 5.1177, -1.2303]) torch.normal(mean, std=1.0, out=None) → Tensor 与上面的函数相似，但是标准偏差在所有绘制的元素之间共享。 Parameters mean (Tensor) – the tensor of per-element means std (python：float ， 可选）–所有发行版的标准差 out (tensor ， 可选）–输出张量 Example: >>> torch.normal(mean=torch.arange(1., 6.)) tensor([ 1.1552, 2.6148, 2.6535, 5.8318, 4.2361]) torch.normal(mean, std, size, *, out=None) → Tensor 与上述功能相似，但均值和标准差在所有绘制的元素之间共享。 所得张量的大小由size给出。 Parameters 平均值 (python：float )–所有分布的平均值 std (python：float )–所有分布的标准偏差 大小 (python：int ... )–定义输出张量形状的整数序列。 out (Tensor, optional) – the output tensor. Example: >>> torch.normal(2, 3, size=(1, 4)) tensor([[-1.3987, -1.9544, 3.6048, 0.7909]]) torch.rand(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor¶ 从区间返回均匀分布的随机张量 张量的形状由变量参数size定义。 Parameters size (python:int...) – a sequence of integers defining the shape of the output tensor. Can be a variable number of arguments or a collection like a list or tuple. out (Tensor, optional) – the output tensor. dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.rand(4) tensor([ 0.5204, 0.2503, 0.3525, 0.5673]) >>> torch.rand(2, 3) tensor([[ 0.8237, 0.5781, 0.6879], [ 0.3816, 0.7249, 0.0998]]) torch.rand_like(input, dtype=None, layout=None, device=None, requires_grad=False) → Tensor¶ 返回与input大小相同的张量，该张量由间隔上均匀分布的随机数填充。 torch.rand_like(input)等效于torch.rand(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)。 Parameters input (Tensor) – the size of input will determine size of the output tensor. dtype (torch.dtype, optional) – the desired data type of returned Tensor. Default: if None, defaults to the dtype of input. layout (torch.layout, optional) – the desired layout of returned tensor. Default: if None, defaults to the layout of input. device (torch.device, optional) – the desired device of returned tensor. Default: if None, defaults to the device of input. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. torch.randint(low=0, high, size, *, generator=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor¶ 返回一个由在low(包括）和high(不包括）之间均匀生成的随机整数填充的张量。 The shape of the tensor is defined by the variable argument size. Parameters 低 (python：int ， 可选）–从分布中得出的最低整数。 默认值：0 高 (python：int )–从分布中得出的最高整数之上一个。 大小(元组）–定义输出张量形状的元组。 generator (torch.Generator, optional) – a pseudorandom number generator for sampling out (Tensor, optional) – the output tensor. dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.randint(3, 5, (3,)) tensor([4, 3, 4]) >>> torch.randint(10, (2, 2)) tensor([[0, 2], [5, 5]]) >>> torch.randint(3, 10, (2, 2)) tensor([[4, 5], [6, 7]]) torch.randint_like(input, low=0, high, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor¶ 返回具有与张量input相同形状的张量，其中填充了在low(包括）和high(排除）之间均匀生成的随机整数。 Parameters input (Tensor) – the size of input will determine size of the output tensor. low (python:int__, optional) – Lowest integer to be drawn from the distribution. Default: 0. high (python:int) – One above the highest integer to be drawn from the distribution. dtype (torch.dtype, optional) – the desired data type of returned Tensor. Default: if None, defaults to the dtype of input. layout (torch.layout, optional) – the desired layout of returned tensor. Default: if None, defaults to the layout of input. device (torch.device, optional) – the desired device of returned tensor. Default: if None, defaults to the device of input. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. torch.randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor¶ 从平均值为 0 ，方差为 1 的正态分布中返回一个填充有随机数的张量(也称为标准正态分布）。 The shape of the tensor is defined by the variable argument size. Parameters size (python:int...) – a sequence of integers defining the shape of the output tensor. Can be a variable number of arguments or a collection like a list or tuple. out (Tensor, optional) – the output tensor. dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.randn(4) tensor([-2.1436, 0.9966, 2.3426, -0.6366]) >>> torch.randn(2, 3) tensor([[ 1.5954, 2.8929, -1.0923], [ 1.1719, -0.4709, -0.1996]]) torch.randn_like(input, dtype=None, layout=None, device=None, requires_grad=False) → Tensor¶ 返回一个与input相同大小的张量，该张量由均值 0 和方差 1 的正态分布的随机数填充。torch.randn_like(input)等效于torch.randn(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)。 Parameters input (Tensor) – the size of input will determine size of the output tensor. dtype (torch.dtype, optional) – the desired data type of returned Tensor. Default: if None, defaults to the dtype of input. layout (torch.layout, optional) – the desired layout of returned tensor. Default: if None, defaults to the layout of input. device (torch.device, optional) – the desired device of returned tensor. Default: if None, defaults to the device of input. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. torch.randperm(n, out=None, dtype=torch.int64, layout=torch.strided, device=None, requires_grad=False) → LongTensor¶ 返回从0到n - 1的整数的随机排列。 Parameters n (python：int )–上限(不包括） out (Tensor, optional) – the output tensor. dtype (torch.dtype ，可选）–返回张量的所需数据类型。 默认值：torch.int64。 layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.randperm(4) tensor([2, 1, 0, 3]) 就地随机抽样 在 Tensor 上还定义了一些就地随机采样函数。 单击以查看其文档： torch.Tensor.bernoulli_() - torch.bernoulli() 的就地版本 torch.Tensor.cauchy_() -从柯西分布中得出的数字 torch.Tensor.exponential_() -从指数分布中得出的数字 torch.Tensor.geometric_() -从几何分布中绘制的元素 torch.Tensor.log_normal_() -来自对数正态分布的样本 torch.Tensor.normal_() - torch.normal() 的就地版本 torch.Tensor.random_() -从离散均匀分布中采样的数字 torch.Tensor.uniform_() -从连续均匀分布中采样的数字 准随机抽样 class torch.quasirandom.SobolEngine(dimension, scramble=False, seed=None)¶ torch.quasirandom.SobolEngine 是用于生成(加扰）Sobol 序列的引擎。 Sobol 序列是低差异准随机序列的一个示例。 用于 Sobol 序列的引擎的这种实现方式能够对最大维度为 1111 的序列进行采样。它使用方向编号生成这些序列，并且这些编号已从此处改编而来。 参考文献 Art B. Owen。 争夺 Sobol 和 Niederreiter-Xing 点。 复杂性杂志，14(4）：466-489，1998 年 12 月。 I. M. Sobol。 立方体中点的分布和积分的准确评估。 嗯 Vychisl。 垫。 我在。 Phys。，7：784-802，1967。 Parameters 尺寸 (Int )–要绘制的序列的尺寸 扰乱 (bool ， 可选）–将其设置为True将产生扰乱的 Sobol 序列。 加扰能够产生更好的 Sobol 序列。 默认值：False。 种子 (Int ， 可选）–这是加扰的种子。 如果指定，则将随机数生成器的种子设置为此。 否则，它将使用随机种子。 默认值：None 例子： >>> soboleng = torch.quasirandom.SobolEngine(dimension=5) >>> soboleng.draw(3) tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000], [0.7500, 0.2500, 0.7500, 0.2500, 0.7500], [0.2500, 0.7500, 0.2500, 0.7500, 0.2500]]) draw(n=1, out=None, dtype=torch.float32)¶ 从 Sobol 序列中绘制n点序列的功能。 请注意，样本取决于先前的样本。 结果的大小为。 Parameters n (Int ， 可选）–绘制点序列的长度。 默认值：1 out (tensor ， 可选）–输出张量 dtype (torch.dtype，可选）–返回的张量的所需数据类型。 默认值：torch.float32 fast_forward(n)¶ 通过n步骤快速前进SobolEngine状态的功能。 这等效于不使用样本绘制n样本。 Parameters n (Int )–快进的步数。 reset()¶ 将SobolEngine重置为基本状态的功能。 序列化 torch.save(obj, f, pickle_module=, pickle_protocol=2, _use_new_zipfile_serialization=False)¶ 将对象保存到磁盘文件。 另请参见：推荐的模型保存方法 Parameters obj –保存的对象 f –类似于文件的对象(必须实现写入和刷新）或包含文件名的字符串 pickle_module –用于腌制元数据和对象的模块 pickle_protocol –可以指定为覆盖默认协议 Warning 如果使用的是 Python 2，则 torch.save() 不支持StringIO.StringIO作为有效的类似文件的对象。 这是因为 write 方法应返回写入的字节数； StringIO.write()不这样做。 请改用io.BytesIO之类的东西。 例 >>> # Save to file >>> x = torch.tensor([0, 1, 2, 3, 4]) >>> torch.save(x, 'tensor.pt') >>> # Save to io.BytesIO buffer >>> buffer = io.BytesIO() >>> torch.save(x, buffer) torch.load(f, map_location=None, pickle_module=, **pickle_load_args)¶ 从文件加载用 torch.save() 保存的对象。 torch.load() 使用 Python 的解开工具，但会特别处理位于张量之下的存储。 它们首先在 CPU 上反序列化，然后移到保存它们的设备上。 如果失败(例如，因为运行时系统没有某些设备），则会引发异常。 但是，可以使用map_location参数将存储动态重新映射到一组备用设备。 如果map_location是可调用的，则将为每个序列化存储调用一次，并带有两个参数：storage 和 location。 storage 参数将是驻留在 CPU 上的存储的初始反序列化。 每个序列化存储都有一个与之关联的位置标签，该标签标识了从中进行保存的设备，该标签是传递给map_location的第二个参数。 内置位置标签是用于 CPU 张量的'cpu'和用于 CUDA 张量的'cuda:device_id'(例如'cuda:2'）。 map_location应该返回None或存储。 如果map_location返回存储，它将用作最终反序列化的对象，已经移至正确的设备。 否则， torch.load() 将退回到默认行为，就像未指定map_location一样。 如果map_location是 torch.device 对象或与设备标签冲突的字符串，则它指示应加载所有张量的位置。 否则，如果map_location是字典，它将用于将文件(键）中出现的位置标签重新映射到指定将存储位置(值）放置的位置标签。 用户扩展可以使用torch.serialization.register_package()注册自己的位置标签以及标记和反序列化方法。 Parameters f –类似于文件的对象(必须实现read()，：methreadline，：methtell和：methseek）或包含文件名的字符串 map_location –函数， torch.device ，字符串或指定如何重新映射存储位置的字典 pickle_module –用于解开元数据和对象的模块(必须与用于序列化文件的pickle_module匹配） pickle_load_args –(仅适用于 Python 3）可选关键字参数传递给pickle_module.load()和pickle_module.Unpickler()，例如errors=...。 Note 当您在包含 GPU 张量的文件上调用 torch.load() 时，这些张量将默认加载到 GPU。 您可以先调用torch.load(.., map_location='cpu')，然后再调用load_state_dict()，以避免在加载模型检查点时 GPU RAM 激增。 Note 默认情况下，我们将字节字符串解码为utf-8。 这是为了避免在 Python 3 中加载 Python 2 保存的文件时出现常见错误情况UnicodeDecodeError: 'ascii' codec can't decode byte 0x...。如果此默认设置不正确，则可以使用额外的encoding关键字参数来指定应如何加载这些对象，例如encoding='latin1'使用latin1编码将它们解码为字符串，encoding='bytes'将它们保留为字节数组，以后可以使用byte_array.decode(...)进行解码。 Example >>> torch.load('tensors.pt') # Load all tensors onto the CPU >>> torch.load('tensors.pt', map_location=torch.device('cpu')) # Load all tensors onto the CPU, using a function >>> torch.load('tensors.pt', map_location=lambda storage, loc: storage) # Load all tensors onto GPU 1 >>> torch.load('tensors.pt', map_location=lambda storage, loc: storage.cuda(1)) # Map tensors from GPU 1 to GPU 0 >>> torch.load('tensors.pt', map_location={'cuda:1':'cuda:0'}) # Load tensor from io.BytesIO object >>> with open('tensor.pt', 'rb') as f: buffer = io.BytesIO(f.read()) >>> torch.load(buffer) # Load a module with 'ascii' encoding for unpickling >>> torch.load('module.pt', encoding='ascii') 平行性 torch.get_num_threads() → int¶ 返回用于并行化 CPU 操作的线程数 torch.set_num_threads(int)¶ 设置用于 CPU 上的内部运算并行的线程数。 警告：为确保使用正确的线程数，必须在运行 eager，JIT 或 autograd 代码之前调用 set_num_threads。 torch.get_num_interop_threads() → int¶ 返回用于 CPU 上的互操作并行的线程数(例如，在 JIT 解释器中） torch.set_num_interop_threads(int)¶ 设置用于 CPU 上的互操作并行性(例如，在 JIT 解释器中）的线程数。 警告：只能在一次操作间并行工作开始之前(例如 JIT 执行）调用一次。 局部禁用梯度计算 上下文管理器torch.no_grad()，torch.enable_grad()和torch.set_grad_enabled()有助于局部禁用和启用梯度计算。 有关其用法的更多详细信息，请参见局部禁用梯度计算。 这些上下文管理器是线程本地的，因此如果您使用threading模块等将工作发送到另一个线程，它们将无法工作。 Examples: >>> x = torch.zeros(1, requires_grad=True) >>> with torch.no_grad(): ... y = x * 2 >>> y.requires_grad False >>> is_train = False >>> with torch.set_grad_enabled(is_train): ... y = x * 2 >>> y.requires_grad False >>> torch.set_grad_enabled(True) # this can also be used as a function >>> y = x * 2 >>> y.requires_grad True >>> torch.set_grad_enabled(False) >>> y = x * 2 >>> y.requires_grad False 数学运算 逐点操作 torch.abs(input, out=None) → Tensor¶ 计算给定input张量的按元素的绝对值。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> torch.abs(torch.tensor([-1, -2, 3])) tensor([ 1, 2, 3]) torch.acos(input, out=None) → Tensor¶ 返回带有input元素的反余弦的新张量。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([ 0.3348, -0.5889, 0.2005, -0.1584]) >>> torch.acos(a) tensor([ 1.2294, 2.2004, 1.3690, 1.7298]) torch.add()¶ torch.add(input, other, out=None) 将标量other添加到输入input的每个元素中，并返回一个新的结果张量。 如果input的类型为 FloatTensor 或 DoubleTensor，则other必须为实数，否则应为整数。 Parameters input (Tensor) – the input tensor. 值(编号）–要添加到input每个元素的编号 Keyword Arguments out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([ 0.0202, 1.0985, 1.3506, -0.6056]) >>> torch.add(a, 20) tensor([ 20.0202, 21.0985, 21.3506, 19.3944]) torch.add(input, alpha=1, other, out=None) 张量other的每个元素乘以标量alpha，然后加到张量input的每个元素上。 返回结果张量。 input和other的形状必须是可广播的。 如果other的类型为 FloatTensor 或 DoubleTensor，则alpha必须为实数，否则应为整数。 Parameters 输入 (tensor)–第一个输入张量 alpha (数字）– other的标量乘法器 其他 (tensor)–第二个输入张量 Keyword Arguments out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([-0.9732, -0.3497, 0.6245, 0.4022]) >>> b = torch.randn(4, 1) >>> b tensor([[ 0.3743], [-1.7724], [-0.5811], [-0.8017]]) >>> torch.add(a, 10, b) tensor([[ 2.7695, 3.3930, 4.3672, 4.1450], [-18.6971, -18.0736, -17.0994, -17.3216], [ -6.7845, -6.1610, -5.1868, -5.4090], [ -8.9902, -8.3667, -7.3925, -7.6147]]) torch.addcdiv(input, value=1, tensor1, tensor2, out=None) → Tensor¶ 执行tensor1除以tensor2的元素，将结果乘以标量value并将其加到input上。 input，tensor1和tensor2的形状必须是可广播。 对于类型为 FloatTensor 或 DoubleTensor 的输入，value必须为实数，否则为整数。 Parameters 输入 (tensor)–要添加的张量 值(编号 ， 可选）– 的乘数 张量 1 (tensor)–分子张量 张量 2 (tensor)–分母张量 out (Tensor, optional) – the output tensor. Example: >>> t = torch.randn(1, 3) >>> t1 = torch.randn(3, 1) >>> t2 = torch.randn(1, 3) >>> torch.addcdiv(t, 0.1, t1, t2) tensor([[-0.2312, -3.6496, 0.1312], [-1.0428, 3.4292, -0.1030], [-0.5369, -0.9829, 0.0430]]) torch.addcmul(input, value=1, tensor1, tensor2, out=None) → Tensor¶ 对tensor1与tensor2进行元素逐项乘法，将结果与标量value相乘，然后将其与input相加。 tensor ，tensor1和tensor2的形状必须是可广播的。 For inputs of type FloatTensor or DoubleTensor, value must be a real number, otherwise an integer. Parameters input (Tensor) – the tensor to be added 值(编号 ， 可选）– 的乘数 张量 1 (tensor)–要相乘的张量 张量 2 (tensor)–要相乘的张量 out (Tensor, optional) – the output tensor. Example: >>> t = torch.randn(1, 3) >>> t1 = torch.randn(3, 1) >>> t2 = torch.randn(1, 3) >>> torch.addcmul(t, 0.1, t1, t2) tensor([[-0.8635, -0.6391, 1.6174], [-0.7617, -0.5879, 1.7388], [-0.8353, -0.6249, 1.6511]]) torch.angle(input, out=None) → Tensor¶ 计算给定input张量的元素方向角(以弧度为单位）。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> torch.angle(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j]))*180/3.14159 tensor([ 135., 135, -45]) torch.asin(input, out=None) → Tensor¶ 返回带有input元素的反正弦值的新张量。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([-0.5962, 1.4985, -0.4396, 1.4525]) >>> torch.asin(a) tensor([-0.6387, nan, -0.4552, nan]) torch.atan(input, out=None) → Tensor¶ 返回带有input元素的反正切的新张量。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([ 0.2341, 0.2539, -0.6256, -0.6448]) >>> torch.atan(a) tensor([ 0.2299, 0.2487, -0.5591, -0.5727]) torch.atan2(input, other, out=None) → Tensor¶ 考虑象限的元素逐级反正切。 返回一个新的张量，其矢量与矢量之间的弧度为符号角。 (请注意，第二个参数是 x 坐标，而第一个参数是 y 坐标。） input和other的形状必须是可广播的。 Parameters input (Tensor) – the first input tensor other (Tensor) – the second input tensor out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([ 0.9041, 0.0196, -0.3108, -2.4423]) >>> torch.atan2(a, torch.randn(4)) tensor([ 0.9833, 0.0811, -1.9743, -1.4151]) torch.bitwise_not(input, out=None) → Tensor¶ 计算给定输入张量的按位非。 输入张量必须是整数或布尔类型。 对于布尔张量，它计算逻辑非。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example >>> torch.bitwise_not(torch.tensor([-1, -2, 3], dtype=torch.int8)) tensor([ 0, 1, -4], dtype=torch.int8) torch.bitwise_xor(input, other, out=None) → Tensor¶ 计算input和other的按位 XOR。 输入张量必须是整数或布尔类型。 对于布尔张量，它计算逻辑 XOR。 Parameters 输入 –第一个输入张量 其他 –第二个输入张量 out (Tensor, optional) – the output tensor. Example >>> torch.bitwise_xor(torch.tensor([-1, -2, 3], dtype=torch.int8), torch.tensor([1, 0, 3], dtype=torch.int8)) tensor([-2, -2, 0], dtype=torch.int8) >>> torch.bitwise_xor(torch.tensor([True, True, False]), torch.tensor([False, True, False])) tensor([ True, False, False]) torch.ceil(input, out=None) → Tensor¶ 返回带有input元素的 ceil 的新张量，该元素大于或等于每个元素的最小整数。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([-0.6341, -1.4208, -1.0900, 0.5826]) >>> torch.ceil(a) tensor([-0., -1., -1., 1.]) torch.clamp(input, min, max, out=None) → Tensor¶ 将input中的所有元素限制在 [ min ， max ] 范围内，并返回结果张量： 如果input的类型为 FloatTensor 或 DoubleTensor ，则参数 min 和 max 必须为实数，否则为实数 应该是整数。 Parameters input (Tensor) – the input tensor. min (编号）–要钳制的范围的下限 最大(编号）–要钳位的范围的上限 out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([-1.7120, 0.1734, -0.0478, -0.0922]) >>> torch.clamp(a, min=-0.5, max=0.5) tensor([-0.5000, 0.1734, -0.0478, -0.0922]) torch.clamp(input, *, min, out=None) → Tensor 将input中的所有元素限制为大于或等于 min 。 如果input的类型为 FloatTensor 或 DoubleTensor ，则value应为实数，否则应为整数。 Parameters input (Tensor) – the input tensor. 值(编号）–输出中每个元素的最小值 out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([-0.0299, -2.3184, 2.1593, -0.8883]) >>> torch.clamp(a, min=0.5) tensor([ 0.5000, 0.5000, 2.1593, 0.5000]) torch.clamp(input, *, max, out=None) → Tensor 将input中的所有元素限制为小于或等于 max 。 If input is of type FloatTensor or DoubleTensor, value should be a real number, otherwise it should be an integer. Parameters input (Tensor) – the input tensor. 值(编号）–输出中每个元素的最大值 out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([ 0.7753, -0.4702, -0.4599, 1.1899]) >>> torch.clamp(a, max=0.5) tensor([ 0.5000, -0.4702, -0.4599, 0.5000]) torch.conj(input, out=None) → Tensor¶ 计算给定input张量的逐元素共轭。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> torch.conj(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j])) tensor([-1 - 1j, -2 - 2j, 3 + 3j]) torch.cos(input, out=None) → Tensor¶ 返回带有input元素的余弦的新张量。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([ 1.4309, 1.2706, -0.8562, 0.9796]) >>> torch.cos(a) tensor([ 0.1395, 0.2957, 0.6553, 0.5574]) torch.cosh(input, out=None) → Tensor¶ 返回具有input元素的双曲余弦的新张量。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([ 0.1632, 1.1835, -0.6979, -0.7325]) >>> torch.cosh(a) tensor([ 1.0133, 1.7860, 1.2536, 1.2805]) torch.div()¶ torch.div(input, other, out=None) → Tensor 将输入input的每个元素除以标量other，然后返回一个新的结果张量。 如果input和other的 torch.dtype 不同，则根据类型提升文档中所述的规则确定结果张量的 torch.dtype 。 ]。 如果指定了out，则结果必须是可转换为到指定输出张量的 torch.dtype 。 整数除以零会导致不确定的行为。 Parameters input (Tensor) – the input tensor. 其他(编号）–要划分为input每个元素的编号 Keyword Arguments out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(5) >>> a tensor([ 0.3810, 1.2774, -0.2972, -0.3719, 0.4637]) >>> torch.div(a, 0.5) tensor([ 0.7620, 2.5548, -0.5944, -0.7439, 0.9275]) torch.div(input, other, out=None) → Tensor 张量input的每个元素除以张量other的每个元素。 返回结果张量。 input和other的形状必须是可广播。 如果input和other的 torch.dtype 不同，则根据类型提升文档中描述的规则确定结果张量的 torch.dtype 。 ]。 如果指定了out，则结果必须是可转换为到指定输出张量的 torch.dtype 。 整数除以零会导致不确定的行为。 Parameters 输入 (tensor)–分子张量 其他 (tensor)–分母张量 Keyword Arguments out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4, 4) >>> a tensor([[-0.3711, -1.9353, -0.4605, -0.2917], [ 0.1815, -1.0111, 0.9805, -1.5923], [ 0.1062, 1.4581, 0.7759, -1.2344], [-0.1830, -0.0313, 1.1908, -1.4757]]) >>> b = torch.randn(4) >>> b tensor([ 0.8032, 0.2930, -0.8113, -0.2308]) >>> torch.div(a, b) tensor([[-0.4620, -6.6051, 0.5676, 1.2637], [ 0.2260, -3.4507, -1.2086, 6.8988], [ 0.1322, 4.9764, -0.9564, 5.3480], [-0.2278, -0.1068, -1.4678, 6.3936]]) torch.digamma(input, out=None) → Tensor¶ 计算输入上伽马函数的对数导数。 Parameters 输入 (tensor)–用于计算 digamma 函数的张量 Example: >>> a = torch.tensor([1, 0.5]) >>> torch.digamma(a) tensor([-0.5772, -1.9635]) torch.erf(input, out=None) → Tensor¶ 计算每个元素的误差函数。 错误函数定义如下： Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> torch.erf(torch.tensor([0, -1., 10.])) tensor([ 0.0000, -0.8427, 1.0000]) torch.erfc(input, out=None) → Tensor¶ 计算input的每个元素的互补误差函数。 互补误差函数定义如下： Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> torch.erfc(torch.tensor([0, -1., 10.])) tensor([ 1.0000, 1.8427, 0.0000]) torch.erfinv(input, out=None) → Tensor¶ 计算input的每个元素的反误差函数。 逆误差函数在范围内定义为： Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> torch.erfinv(torch.tensor([0, 0.5, -1.])) tensor([ 0.0000, 0.4769, -inf]) torch.exp(input, out=None) → Tensor¶ 返回具有输入张量input的元素指数的新张量。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> torch.exp(torch.tensor([0, math.log(2.)])) tensor([ 1., 2.]) torch.expm1(input, out=None) → Tensor¶ 返回一个新的张量，其元素的指数为input的负 1。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> torch.expm1(torch.tensor([0, math.log(2.)])) tensor([ 0., 1.]) torch.floor(input, out=None) → Tensor¶ 返回一个新的张量，该张量的元素为input的下限，即小于或等于每个元素的最大整数。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([-0.8166, 1.5308, -0.2530, -0.2091]) >>> torch.floor(a) tensor([-1., 1., -1., -1.]) torch.fmod(input, other, out=None) → Tensor¶ 计算除法元素的余数。 被除数和除数可以同时包含整数和浮点数。 其余部分与股息input具有相同的符号。 当other是张量时，input和other的形状必须是可广播的。 Parameters 输入 (tensor)–股息 其他 (tensor 或 python：float )–除数，可以是数字或整数 与股息形状相同的张量 out (Tensor, optional) – the output tensor. Example: >>> torch.fmod(torch.tensor([-3., -2, -1, 1, 2, 3]), 2) tensor([-1., -0., -1., 1., 0., 1.]) >>> torch.fmod(torch.tensor([1., 2, 3, 4, 5]), 1.5) tensor([ 1.0000, 0.5000, 0.0000, 1.0000, 0.5000]) torch.frac(input, out=None) → Tensor¶ 计算input中每个元素的分数部分。 Example: >>> torch.frac(torch.tensor([1, 2.5, -3.2])) tensor([ 0.0000, 0.5000, -0.2000]) torch.imag(input, out=None) → Tensor¶ 计算给定input张量的逐元素 imag 值。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> torch.imag(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j])) tensor([ 1, 2, -3]) torch.lerp(input, end, weight, out=None)¶ 根据标量或张量weight对两个张量start(由input给出）和end进行线性插值，并返回所得的out张量。 start和end的形状必须是可广播的。 如果weight是张量，则weight，start和end的形状必须是可广播的。 Parameters 输入 (tensor)–具有起点的张量 末端 (tensor)–具有终点的张量 权重 (python：float 或 tensor）–插值公式的权重 out (Tensor, optional) – the output tensor. Example: >>> start = torch.arange(1., 5.) >>> end = torch.empty(4).fill_(10) >>> start tensor([ 1., 2., 3., 4.]) >>> end tensor([ 10., 10., 10., 10.]) >>> torch.lerp(start, end, 0.5) tensor([ 5.5000, 6.0000, 6.5000, 7.0000]) >>> torch.lerp(start, end, torch.full_like(start, 0.5)) tensor([ 5.5000, 6.0000, 6.5000, 7.0000]) torch.lgamma(input, out=None) → Tensor¶ 计算input上伽马函数的对数。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.arange(0.5, 2, 0.5) >>> torch.lgamma(a) tensor([ 0.5724, 0.0000, -0.1208]) torch.log(input, out=None) → Tensor¶ 返回具有input元素的自然对数的新张量。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(5) >>> a tensor([-0.7168, -0.5471, -0.8933, -1.4428, -0.1190]) >>> torch.log(a) tensor([ nan, nan, nan, nan, nan]) torch.log10(input, out=None) → Tensor¶ 返回以input元素的底数为底的对数的新张量。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.rand(5) >>> a tensor([ 0.5224, 0.9354, 0.7257, 0.1301, 0.2251]) >>> torch.log10(a) tensor([-0.2820, -0.0290, -0.1392, -0.8857, -0.6476]) torch.log1p(input, out=None) → Tensor¶ 返回自然对数为(1 + input）的新张量。 Note 对于较小的input值，此功能比 torch.log() 更准确。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(5) >>> a tensor([-1.0090, -0.9923, 1.0249, -0.5372, 0.2492]) >>> torch.log1p(a) tensor([ nan, -4.8653, 0.7055, -0.7705, 0.2225]) torch.log2(input, out=None) → Tensor¶ 返回以input元素的底数为对数的新张量。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.rand(5) >>> a tensor([ 0.8419, 0.8003, 0.9971, 0.5287, 0.0490]) >>> torch.log2(a) tensor([-0.2483, -0.3213, -0.0042, -0.9196, -4.3504]) torch.logical_not(input, out=None) → Tensor¶ 计算给定输入张量的按元素逻辑非。 如果未指定，则输出张量将具有 bool dtype。 如果输入张量不是布尔张量，则将零视为False，将非零视为True。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> torch.logical_not(torch.tensor([True, False])) tensor([ False, True]) >>> torch.logical_not(torch.tensor([0, 1, -10], dtype=torch.int8)) tensor([ True, False, False]) >>> torch.logical_not(torch.tensor([0., 1.5, -10.], dtype=torch.double)) tensor([ True, False, False]) >>> torch.logical_not(torch.tensor([0., 1., -10.], dtype=torch.double), out=torch.empty(3, dtype=torch.int16)) tensor([1, 0, 0], dtype=torch.int16) torch.logical_xor(input, other, out=None) → Tensor¶ 计算给定输入张量的逐元素逻辑 XOR。 零被视为False，非零被视为True。 Parameters input (Tensor) – the input tensor. 其他 (tensor)–用于计算 XOR 的张量 out (Tensor, optional) – the output tensor. Example: >>> torch.logical_xor(torch.tensor([True, False, True]), torch.tensor([True, False, False])) tensor([ False, False, True]) >>> a = torch.tensor([0, 1, 10, 0], dtype=torch.int8) >>> b = torch.tensor([4, 0, 1, 0], dtype=torch.int8) >>> torch.logical_xor(a, b) tensor([ True, True, False, False]) >>> torch.logical_xor(a.double(), b.double()) tensor([ True, True, False, False]) >>> torch.logical_xor(a.double(), b) tensor([ True, True, False, False]) >>> torch.logical_xor(a, b, out=torch.empty(4, dtype=torch.bool)) tensor([ True, True, False, False]) torch.mul()¶ torch.mul(input, other, out=None) 将输入input的每个元素与标量other相乘，并返回一个新的结果张量。 如果input的类型为 FloatTensor 或 DoubleTensor ，则other应为实数，否则应为整数 Parameters {输入} – 值(数字）–要与input的每个元素相乘的数字 {out} – Example: >>> a = torch.randn(3) >>> a tensor([ 0.2015, -0.4255, 2.6087]) >>> torch.mul(a, 100) tensor([ 20.1494, -42.5491, 260.8663]) torch.mul(input, other, out=None) 张量input的每个元素乘以张量other的相应元素。 返回结果张量。 The shapes of input and other must be broadcastable. Parameters 输入 (tensor)–第一个被乘张量 其他 (tensor)–第二个被乘张量 out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4, 1) >>> a tensor([[ 1.1207], [-0.3137], [ 0.0700], [ 0.8378]]) >>> b = torch.randn(1, 4) >>> b tensor([[ 0.5146, 0.1216, -0.5244, 2.2382]]) >>> torch.mul(a, b) tensor([[ 0.5767, 0.1363, -0.5877, 2.5083], [-0.1614, -0.0382, 0.1645, -0.7021], [ 0.0360, 0.0085, -0.0367, 0.1567], [ 0.4312, 0.1019, -0.4394, 1.8753]]) torch.mvlgamma(input, p) → Tensor¶ 计算元素对数为维度的多元对数伽马函数 ([reference])，公式为 其中和是伽玛函数。 如果任何元素小于或等于，那么将引发错误。 Parameters 输入 (tensor)–用于计算多元对数伽马函数的张量 p (python：int )–尺寸数 Example: >>> a = torch.empty(2, 3).uniform_(1, 2) >>> a tensor([[1.6835, 1.8474, 1.1929], [1.0475, 1.7162, 1.4180]]) >>> torch.mvlgamma(a, 2) tensor([[0.3928, 0.4007, 0.7586], [1.0311, 0.3901, 0.5049]]) torch.neg(input, out=None) → Tensor¶ 返回带有input元素负数的新张量。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(5) >>> a tensor([ 0.0090, -0.2262, -0.0682, -0.2866, 0.3940]) >>> torch.neg(a) tensor([-0.0090, 0.2262, 0.0682, 0.2866, -0.3940]) torch.polygamma(n, input, out=None) → Tensor¶ 计算input上的 digamma 函数的导数。 被称为多伽玛函数的阶数。 Note 未实现此功能。 Parameters n (python：int )– polygamma 函数的顺序 input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example:: >>> a = torch.tensor([1, 0.5]) >>> torch.polygamma(1, a) tensor([1.64493, 4.9348]) torch.pow()¶ torch.pow(input, exponent, out=None) → Tensor 用exponent取input中每个元素的幂，并返回张量与结果。 exponent可以是单个float数字，也可以是具有与input相同元素数的张量。 当exponent为标量值时，应用的运算为： 当exponent是张量时，应用的运算是： 当exponent是张量时，input和exponent的形状必须是可广播的。 Parameters input (Tensor) – the input tensor. 指数 (python：float 或 tensor）–指数值 out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([ 0.4331, 1.2475, 0.6834, -0.2791]) >>> torch.pow(a, 2) tensor([ 0.1875, 1.5561, 0.4670, 0.0779]) >>> exp = torch.arange(1., 5.) >>> a = torch.arange(1., 5.) >>> a tensor([ 1., 2., 3., 4.]) >>> exp tensor([ 1., 2., 3., 4.]) >>> torch.pow(a, exp) tensor([ 1., 4., 27., 256.]) torch.pow(self, exponent, out=None) → Tensor self是标量float值，exponent是张量。 返回的张量out与exponent的形状相同 应用的操作是： Parameters 自我 (python：float )–幂运算的标量基值 指数 (tensor)–指数张量 out (Tensor, optional) – the output tensor. Example: >>> exp = torch.arange(1., 5.) >>> base = 2 >>> torch.pow(base, exp) tensor([ 2., 4., 8., 16.]) torch.real(input, out=None) → Tensor¶ 计算给定input张量的逐元素实数值。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> torch.real(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j])) tensor([ -1, -2, 3]) torch.reciprocal(input, out=None) → Tensor¶ 返回带有input元素倒数的新张量 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([-0.4595, -2.1219, -1.4314, 0.7298]) >>> torch.reciprocal(a) tensor([-2.1763, -0.4713, -0.6986, 1.3702]) torch.remainder(input, other, out=None) → Tensor¶ Computes the element-wise remainder of division. 除数和除数可以同时包含整数和浮点数。 其余部分与除数的符号相同。 When other is a tensor, the shapes of input and other must be broadcastable. Parameters input (Tensor) – the dividend 其他 (tensor 或 python：float )–除数可以是数字或张量 与股息形状相同 out (Tensor, optional) – the output tensor. Example: >>> torch.remainder(torch.tensor([-3., -2, -1, 1, 2, 3]), 2) tensor([ 1., 0., 1., 1., 0., 1.]) >>> torch.remainder(torch.tensor([1., 2, 3, 4, 5]), 1.5) tensor([ 1.0000, 0.5000, 0.0000, 1.0000, 0.5000]) 也可以看看 torch.fmod() ，它等效于 C 库函数fmod()来计算元素的除法余数。 torch.round(input, out=None) → Tensor¶ 返回一个新的张量，其中input的每个元素都舍入到最接近的整数。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([ 0.9920, 0.6077, 0.9734, -1.0362]) >>> torch.round(a) tensor([ 1., 1., 1., -1.]) torch.rsqrt(input, out=None) → Tensor¶ 返回带有input的每个元素的平方根的倒数的新张量。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([-0.0370, 0.2970, 1.5420, -0.9105]) >>> torch.rsqrt(a) tensor([ nan, 1.8351, 0.8053, nan]) torch.sigmoid(input, out=None) → Tensor¶ 返回具有input元素的 S 形的新张量。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([ 0.9213, 1.0887, -0.8858, -1.7683]) >>> torch.sigmoid(a) tensor([ 0.7153, 0.7481, 0.2920, 0.1458]) torch.sign(input, out=None) → Tensor¶ 返回带有input元素符号的新张量。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.tensor([0.7, -1.2, 0., 2.3]) >>> a tensor([ 0.7000, -1.2000, 0.0000, 2.3000]) >>> torch.sign(a) tensor([ 1., -1., 0., 1.]) torch.sin(input, out=None) → Tensor¶ 返回带有input元素正弦值的新张量。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([-0.5461, 0.1347, -2.7266, -0.2746]) >>> torch.sin(a) tensor([-0.5194, 0.1343, -0.4032, -0.2711]) torch.sinh(input, out=None) → Tensor¶ 返回具有input元素的双曲正弦值的新张量。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([ 0.5380, -0.8632, -0.1265, 0.9399]) >>> torch.sinh(a) tensor([ 0.5644, -0.9744, -0.1268, 1.0845]) torch.sqrt(input, out=None) → Tensor¶ 返回具有input元素平方根的新张量。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([-2.0755, 1.0226, 0.0831, 0.4806]) >>> torch.sqrt(a) tensor([ nan, 1.0112, 0.2883, 0.6933]) torch.tan(input, out=None) → Tensor¶ 返回带有input元素的切线的新张量。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([-1.2027, -1.7687, 0.4412, -1.3856]) >>> torch.tan(a) tensor([-2.5930, 4.9859, 0.4722, -5.3366]) torch.tanh(input, out=None) → Tensor¶ 返回具有input元素的双曲正切值的新张量。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([ 0.8986, -0.7279, 1.1745, 0.2611]) >>> torch.tanh(a) tensor([ 0.7156, -0.6218, 0.8257, 0.2553]) torch.trunc(input, out=None) → Tensor¶ 返回一个新的张量，该张量具有input元素的截断的整数值。 Parameters input (Tensor) – the input tensor. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([ 3.4742, 0.5466, -0.8008, -0.9079]) >>> torch.trunc(a) tensor([ 3., 0., -0., -0.]) 减少操作 torch.argmax()¶ torch.argmax(input) → LongTensor 返回input张量中所有元素的最大值的索引。 这是 torch.max() 返回的第二个值。 有关此方法的确切语义，请参见其文档。 Parameters input (Tensor) – the input tensor. Example: >>> a = torch.randn(4, 4) >>> a tensor([[ 1.3398, 0.2663, -0.2686, 0.2450], [-0.7401, -0.8805, -0.3402, -1.1936], [ 0.4907, -1.3948, -1.0691, -0.3132], [-1.6092, 0.5419, -0.2993, 0.3195]]) >>> torch.argmax(a) tensor(0) torch.argmax(input, dim, keepdim=False) → LongTensor 返回一个维度上张量最大值的索引。 This is the second value returned by torch.max(). See its documentation for the exact semantics of this method. Parameters input (Tensor) – the input tensor. 暗淡的 (python：int )–缩小的尺寸。 如果None，则返回扁平化输入的 argmax。 keepdim (bool )–输出张量是否保留dim。 忽略dim=None。 Example: >>> a = torch.randn(4, 4) >>> a tensor([[ 1.3398, 0.2663, -0.2686, 0.2450], [-0.7401, -0.8805, -0.3402, -1.1936], [ 0.4907, -1.3948, -1.0691, -0.3132], [-1.6092, 0.5419, -0.2993, 0.3195]]) >>> torch.argmax(a, dim=1) tensor([ 0, 2, 0, 1]) torch.argmin()¶ torch.argmin(input) → LongTensor 返回input张量中所有元素的最小值的索引。 这是 torch.min() 返回的第二个值。 有关此方法的确切语义，请参见其文档。 Parameters input (Tensor) – the input tensor. Example: >>> a = torch.randn(4, 4) >>> a tensor([[ 0.1139, 0.2254, -0.1381, 0.3687], [ 1.0100, -1.1975, -0.0102, -0.4732], [-0.9240, 0.1207, -0.7506, -1.0213], [ 1.7809, -1.2960, 0.9384, 0.1438]]) >>> torch.argmin(a) tensor(13) torch.argmin(input, dim, keepdim=False, out=None) → LongTensor 返回整个维度上张量的最小值的索引。 This is the second value returned by torch.min(). See its documentation for the exact semantics of this method. Parameters input (Tensor) – the input tensor. 暗淡的 (python：int )–缩小的尺寸。 如果None，则返回扁平化输入的 argmin。 keepdim (bool) – whether the output tensor has dim retained or not. Ignored if dim=None. Example: >>> a = torch.randn(4, 4) >>> a tensor([[ 0.1139, 0.2254, -0.1381, 0.3687], [ 1.0100, -1.1975, -0.0102, -0.4732], [-0.9240, 0.1207, -0.7506, -1.0213], [ 1.7809, -1.2960, 0.9384, 0.1438]]) >>> torch.argmin(a, dim=1) tensor([ 2, 1, 3, 1]) torch.dist(input, other, p=2) → Tensor¶ 返回(input-other）的 p 范数 The shapes of input and other must be broadcastable. Parameters input (Tensor) – the input tensor. 其他 (tensor)–右侧输入张量 p (python：float ， 可选）–要计算的范数 Example: >>> x = torch.randn(4) >>> x tensor([-1.5393, -0.8675, 0.5916, 1.6321]) >>> y = torch.randn(4) >>> y tensor([ 0.0967, -1.0511, 0.6295, 0.8360]) >>> torch.dist(x, y, 3.5) tensor(1.6727) >>> torch.dist(x, y, 3) tensor(1.6973) >>> torch.dist(x, y, 0) tensor(inf) >>> torch.dist(x, y, 1) tensor(2.6537) torch.logsumexp(input, dim, keepdim=False, out=None)¶ 返回给定维度dim中input张量的每一行的总指数对数。 该计算在数值上是稳定的。 对于由昏暗给出的总和指数和其他指数，结果为 如果keepdim为True，则输出张量的大小与input相同，但尺寸为dim的大小为 1。否则，压缩dim(请参见 torch.squeeze())，导致输出张量的尺寸减少 1(或len(dim)）。 Parameters input (Tensor) – the input tensor. 暗淡的 (python：int 或 python：ints 的元组）–要减小的尺寸。 keepdim (bool )–输出张量是否保留dim。 out (Tensor, optional) – the output tensor. Example:: >>> a = torch.randn(3, 3) >>> torch.logsumexp(a, 1) tensor([ 0.8442, 1.4322, 0.8711]) torch.mean()¶ torch.mean(input) → Tensor 返回input张量中所有元素的平均值。 Parameters input (Tensor) – the input tensor. Example: >>> a = torch.randn(1, 3) >>> a tensor([[ 0.2294, -0.5481, 1.3288]]) >>> torch.mean(a) tensor(0.3367) torch.mean(input, dim, keepdim=False, out=None) → Tensor 返回给定维度dim中input张量的每一行的平均值。 如果dim是尺寸列表，请缩小所有尺寸。 If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s). Parameters input (Tensor) – the input tensor. dim (python:int or tuple of python:ints) – the dimension or dimensions to reduce. keepdim (bool) – whether the output tensor has dim retained or not. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4, 4) >>> a tensor([[-0.3841, 0.6320, 0.4254, -0.7384], [-0.9644, 1.0131, -0.6549, -1.4279], [-0.2951, -1.3350, -0.7694, 0.5600], [ 1.0842, -0.9580, 0.3623, 0.2343]]) >>> torch.mean(a, 1) tensor([-0.0163, -0.5085, -0.4599, 0.1807]) >>> torch.mean(a, 1, True) tensor([[-0.0163], [-0.5085], [-0.4599], [ 0.1807]]) torch.median()¶ torch.median(input) → Tensor 返回input张量中所有元素的中值。 Parameters input (Tensor) – the input tensor. Example: >>> a = torch.randn(1, 3) >>> a tensor([[ 1.5219, -1.5212, 0.2202]]) >>> torch.median(a) tensor(0.2202) torch.median(input, dim=-1, keepdim=False, values=None, indices=None) -> (Tensor, LongTensor) 返回一个命名元组(values, indices)，其中values是在给定维度dim中input张量的每一行的中值。 indices是找到的每个中值的索引位置。 默认情况下，dim是input张量的最后一个尺寸。 如果keepdim为True，则输出张量的大小与input相同，只是尺寸为 1 的尺寸为dim。否则，将压缩dim(请参见 torch.squeeze())，导致输出张量的尺寸比input小 1。 Parameters input (Tensor) – the input tensor. 暗淡的 (python：int )–缩小的尺寸。 keepdim (bool) – whether the output tensor has dim retained or not. 值 (tensor ， 可选）–输出张量 索引 (tensor ， 可选）–输出索引张量 Example: >>> a = torch.randn(4, 5) >>> a tensor([[ 0.2505, -0.3982, -0.9948, 0.3518, -1.3131], [ 0.3180, -0.6993, 1.0436, 0.0438, 0.2270], [-0.2751, 0.7303, 0.2192, 0.3321, 0.2488], [ 1.0778, -1.9510, 0.7048, 0.4742, -0.7125]]) >>> torch.median(a, 1) torch.return_types.median(values=tensor([-0.3982, 0.2270, 0.2488, 0.4742]), indices=tensor([1, 4, 4, 3])) torch.mode(input, dim=-1, keepdim=False, values=None, indices=None) -> (Tensor, LongTensor)¶ 返回一个命名元组(values, indices)，其中values是给定维度dim中input张量的每一行的众数值，即该行中最常出现的值，而indices是索引位置 找到的每个模式值。 By default, dim is the last dimension of the input tensor. 如果keepdim为True，则输出张量的大小与input相同，只是尺寸为 1 的尺寸为dim。否则，将压缩dim(请参见 torch.squeeze())，导致输出张量的尺寸比input小 1。 Note 尚未为torch.cuda.Tensor定义此功能。 Parameters input (Tensor) – the input tensor. dim (python:int) – the dimension to reduce. keepdim (bool) – whether the output tensor has dim retained or not. values (Tensor, optional) – the output tensor indices (Tensor, optional) – the output index tensor Example: >>> a = torch.randint(10, (5,)) >>> a tensor([6, 5, 1, 0, 2]) >>> b = a + (torch.randn(50, 1) * 5).long() >>> torch.mode(b, 0) torch.return_types.mode(values=tensor([6, 5, 1, 0, 2]), indices=tensor([2, 2, 2, 2, 2])) torch.norm(input, p='fro', dim=None, keepdim=False, out=None, dtype=None)¶ 返回给定张量的矩阵范数或向量范数。 Parameters 输入 (tensor)–输入张量 p (python：int ， python：float ， inf ， -inf ， '来回 ， 'nuc' ， 可选）– 规范的顺序。 默认值：'fro'可以计算以下规范： | 奥德 | 矩阵范数 | 向量范数 | | --- | --- | --- | | 没有 | Frobenius 范数 | 2 范数 | | 来回 | Frobenius norm | – | | ‘nuc’ | 核规范 | – | | 其他 | 当 dim 为 None 时作为 vec 规范 | sum(abs(x） ord）(1./ord） | 暗淡的 (python：int ， 2 个元组的 python：ints ， 2 个列表 python：ints ， 可选）–如果为 int，则将计算向量范数，如果为 int 的 2 元组，则将计算矩阵范数。 如果值为 None，则在输入张量只有二维时将计算矩阵范数，而在输入张量只有一维时将计算向量范数。 如果输入张量具有两个以上的维，则矢量范数将应用于最后一个维。 keepdim (bool ， 可选）–输出张量是否保留dim。 如果dim = None和out = None则忽略。 默认值：False 输出 (tensor ， 可选）–输出张量。 如果dim = None和out = None则忽略。 dtype (torch.dtype ，可选）–返回张量的所需数据类型。 如果已指定，则在执行操作时将输入张量强制转换为：attr：“ dtype”。 默认值：无。 Example: >>> import torch >>> a = torch.arange(9, dtype= torch.float) - 4 >>> b = a.reshape((3, 3)) >>> torch.norm(a) tensor(7.7460) >>> torch.norm(b) tensor(7.7460) >>> torch.norm(a, float('inf')) tensor(4.) >>> torch.norm(b, float('inf')) tensor(4.) >>> c = torch.tensor([[ 1, 2, 3],[-1, 1, 4]] , dtype= torch.float) >>> torch.norm(c, dim=0) tensor([1.4142, 2.2361, 5.0000]) >>> torch.norm(c, dim=1) tensor([3.7417, 4.2426]) >>> torch.norm(c, p=1, dim=1) tensor([6., 6.]) >>> d = torch.arange(8, dtype= torch.float).reshape(2,2,2) >>> torch.norm(d, dim=(1,2)) tensor([ 3.7417, 11.2250]) >>> torch.norm(d[0, :, :]), torch.norm(d[1, :, :]) (tensor(3.7417), tensor(11.2250)) torch.prod()¶ torch.prod(input, dtype=None) → Tensor 返回input张量中所有元素的乘积。 Parameters input (Tensor) – the input tensor. dtype (torch.dtype ，可选）–返回张量的所需数据类型。 如果指定，则在执行操作之前将输入张量转换为dtype。 这对于防止数据类型溢出很有用。 默认值：无。 Example: >>> a = torch.randn(1, 3) >>> a tensor([[-0.8020, 0.5428, -1.5854]]) >>> torch.prod(a) tensor(0.6902) torch.prod(input, dim, keepdim=False, dtype=None) → Tensor 返回给定维度dim中input张量的每一行的乘积。 如果keepdim为True，则输出张量的大小与input相同，但尺寸为dim的大小为 1。否则，将压缩dim(请参见 torch.squeeze())，导致输出张量的尺寸比input小 1。 Parameters input (Tensor) – the input tensor. dim (python:int) – the dimension to reduce. keepdim (bool) – whether the output tensor has dim retained or not. dtype (torch.dtype, optional) – the desired data type of returned tensor. If specified, the input tensor is casted to dtype before the operation is performed. This is useful for preventing data type overflows. Default: None. Example: >>> a = torch.randn(4, 2) >>> a tensor([[ 0.5261, -0.3837], [ 1.1857, -0.2498], [-1.1646, 0.0705], [ 1.1131, -1.0629]]) >>> torch.prod(a, 1) tensor([-0.2018, -0.2962, -0.0821, -1.1831]) torch.std()¶ torch.std(input, unbiased=True) → Tensor 返回input张量中所有元素的标准偏差。 如果unbiased为False，则将通过有偏估计量计算标准偏差。 否则，将使用贝塞尔的更正。 Parameters input (Tensor) – the input tensor. 无偏 (bool )–是否使用无偏估计 Example: >>> a = torch.randn(1, 3) >>> a tensor([[-0.8166, -1.3802, -0.3560]]) >>> torch.std(a) tensor(0.5130) torch.std(input, dim, keepdim=False, unbiased=True, out=None) → Tensor 返回input张量的每一行在标准dim中的标准偏差。 如果dim是尺寸列表，请缩小所有尺寸。 If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s). If unbiased is False, then the standard-deviation will be calculated via the biased estimator. Otherwise, Bessel’s correction will be used. Parameters input (Tensor) – the input tensor. dim (python:int or tuple of python:ints) – the dimension or dimensions to reduce. keepdim (bool) – whether the output tensor has dim retained or not. unbiased (bool) – whether to use the unbiased estimation or not out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4, 4) >>> a tensor([[ 0.2035, 1.2959, 1.8101, -0.4644], [ 1.5027, -0.3270, 0.5905, 0.6538], [-1.5745, 1.3330, -0.5596, -0.6548], [ 0.1264, -0.5080, 1.6420, 0.1992]]) >>> torch.std(a, dim=1) tensor([ 1.0311, 0.7477, 1.2204, 0.9087]) torch.std_mean()¶ torch.std_mean(input, unbiased=True) -> (Tensor, Tensor) 返回input张量中所有元素的标准差和均值。 If unbiased is False, then the standard-deviation will be calculated via the biased estimator. Otherwise, Bessel’s correction will be used. Parameters input (Tensor) – the input tensor. unbiased (bool) – whether to use the unbiased estimation or not Example: >>> a = torch.randn(1, 3) >>> a tensor([[0.3364, 0.3591, 0.9462]]) >>> torch.std_mean(a) (tensor(0.3457), tensor(0.5472)) torch.std(input, dim, keepdim=False, unbiased=True) -> (Tensor, Tensor) 返回dim张量中input张量的每一行的标准偏差和均值。 如果dim是尺寸列表，请缩小所有尺寸。 If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s). If unbiased is False, then the standard-deviation will be calculated via the biased estimator. Otherwise, Bessel’s correction will be used. Parameters input (Tensor) – the input tensor. dim (python:int or tuple of python:ints) – the dimension or dimensions to reduce. keepdim (bool) – whether the output tensor has dim retained or not. unbiased (bool) – whether to use the unbiased estimation or not Example: >>> a = torch.randn(4, 4) >>> a tensor([[ 0.5648, -0.5984, -1.2676, -1.4471], [ 0.9267, 1.0612, 1.1050, -0.6014], [ 0.0154, 1.9301, 0.0125, -1.0904], [-1.9711, -0.7748, -1.3840, 0.5067]]) >>> torch.std_mean(a, 1) (tensor([0.9110, 0.8197, 1.2552, 1.0608]), tensor([-0.6871, 0.6229, 0.2169, -0.9058])) torch.sum()¶ torch.sum(input, dtype=None) → Tensor 返回input张量中所有元素的总和。 Parameters input (Tensor) – the input tensor. dtype (torch.dtype, optional) – the desired data type of returned tensor. If specified, the input tensor is casted to dtype before the operation is performed. This is useful for preventing data type overflows. Default: None. Example: >>> a = torch.randn(1, 3) >>> a tensor([[ 0.1133, -0.9567, 0.2958]]) >>> torch.sum(a) tensor(-0.5475) torch.sum(input, dim, keepdim=False, dtype=None) → Tensor 返回给定维度dim中input张量的每一行的总和。 如果dim是尺寸列表，请缩小所有尺寸。 If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s). Parameters input (Tensor) – the input tensor. dim (python:int or tuple of python:ints) – the dimension or dimensions to reduce. keepdim (bool) – whether the output tensor has dim retained or not. dtype (torch.dtype, optional) – the desired data type of returned tensor. If specified, the input tensor is casted to dtype before the operation is performed. This is useful for preventing data type overflows. Default: None. Example: >>> a = torch.randn(4, 4) >>> a tensor([[ 0.0569, -0.2475, 0.0737, -0.3429], [-0.2993, 0.9138, 0.9337, -1.6864], [ 0.1132, 0.7892, -0.1003, 0.5688], [ 0.3637, -0.9906, -0.4752, -1.5197]]) >>> torch.sum(a, 1) tensor([-0.4598, -0.1381, 1.3708, -2.6217]) >>> b = torch.arange(4 * 5 * 6).view(4, 5, 6) >>> torch.sum(b, (2, 1)) tensor([ 435., 1335., 2235., 3135.]) torch.unique(input, sorted=True, return_inverse=False, return_counts=False, dim=None)¶ 返回输入张量的唯一元素。 Note 此功能与 torch.unique_consecutive() 不同，因为该功能还消除了非连续的重复值。 Note 当前，在 CUDA 实现和 CPU 实现中，当指定 dim 时，无论 sort 参数如何， torch.unique 始终在开始时对张量进行排序。 排序可能会很慢，因此如果您的输入张量已被排序，建议使用 torch.unique_consecutive() 以避免排序。 Parameters input (Tensor) – the input tensor 排序的 (bool )–在返回为输出之前是否按升序对唯一元素进行排序。 return_inverse (bool )–是否还返回原始输入中元素在返回的唯一列表中所处位置的索引。 return_counts (bool )–是否还返回每个唯一元素的计数。 暗淡的 (python：int )–应用唯一尺寸。 如果None，则返回拼合输入的唯一性。 默认值：None Returns 一个张量或张量的元组包含 输出(tensor）：唯一标量元素的输出列表。 inverse_indices (tensor）：(可选）如果return_inverse为 True，将有一个额外的返回张量(形状与输入相同）表示原始输入中元素所在位置的索引 映射到输出中； 否则，此函数将仅返回单个张量。 计数为(tensor）：(可选）如果return_counts为 True，则将有一个额外的返回张量(与 output 或 output.size(dim）相同的形状，如果 dim 为 代表每个唯一值或张量的出现次数。 Return type (张量，张量(可选），张量(可选）） Example: >>> output = torch.unique(torch.tensor([1, 3, 2, 3], dtype=torch.long)) >>> output tensor([ 2, 3, 1]) >>> output, inverse_indices = torch.unique( torch.tensor([1, 3, 2, 3], dtype=torch.long), sorted=True, return_inverse=True) >>> output tensor([ 1, 2, 3]) >>> inverse_indices tensor([ 0, 2, 1, 2]) >>> output, inverse_indices = torch.unique( torch.tensor([[1, 3], [2, 3]], dtype=torch.long), sorted=True, return_inverse=True) >>> output tensor([ 1, 2, 3]) >>> inverse_indices tensor([[ 0, 2], [ 1, 2]]) torch.unique_consecutive(input, return_inverse=False, return_counts=False, dim=None)¶ 从每个连续的等效元素组中除去除第一个元素外的所有元素。 Note 在此功能仅消除连续重复值的意义上，此功能与 torch.unique() 不同。 此语义类似于 C ++中的 std :: unique 。 Parameters input (Tensor) – the input tensor return_inverse (bool) – Whether to also return the indices for where elements in the original input ended up in the returned unique list. return_counts (bool) – Whether to also return the counts for each unique element. dim (python:int) – the dimension to apply unique. If None, the unique of the flattened input is returned. default: None Returns A tensor or a tuple of tensors containing output (Tensor): the output list of unique scalar elements. inverse_indices (Tensor): (optional) if return_inverse is True, there will be an additional returned tensor (same shape as input) representing the indices for where elements in the original input map to in the output; otherwise, this function will only return a single tensor. counts (Tensor): (optional) if return_counts is True, there will be an additional returned tensor (same shape as output or output.size(dim), if dim was specified) representing the number of occurrences for each unique value or tensor. Return type (Tensor, Tensor (optional), Tensor (optional)) Example: >>> x = torch.tensor([1, 1, 2, 2, 3, 1, 1, 2]) >>> output = torch.unique_consecutive(x) >>> output tensor([1, 2, 3, 1, 2]) >>> output, inverse_indices = torch.unique_consecutive(x, return_inverse=True) >>> output tensor([1, 2, 3, 1, 2]) >>> inverse_indices tensor([0, 0, 1, 1, 2, 3, 3, 4]) >>> output, counts = torch.unique_consecutive(x, return_counts=True) >>> output tensor([1, 2, 3, 1, 2]) >>> counts tensor([2, 2, 1, 2, 1]) torch.var()¶ torch.var(input, unbiased=True) → Tensor 返回input张量中所有元素的方差。 如果unbiased为False，则将通过有偏估计量计算方差。 否则，将使用贝塞尔的更正。 Parameters input (Tensor) – the input tensor. unbiased (bool) – whether to use the unbiased estimation or not Example: >>> a = torch.randn(1, 3) >>> a tensor([[-0.3425, -1.2636, -0.4864]]) >>> torch.var(a) tensor(0.2455) torch.var(input, dim, keepdim=False, unbiased=True, out=None) → Tensor 返回给定维度dim中input张量的每一行的方差。 If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s). If unbiased is False, then the variance will be calculated via the biased estimator. Otherwise, Bessel’s correction will be used. Parameters input (Tensor) – the input tensor. dim (python:int or tuple of python:ints) – the dimension or dimensions to reduce. keepdim (bool) – whether the output tensor has dim retained or not. unbiased (bool) – whether to use the unbiased estimation or not out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4, 4) >>> a tensor([[-0.3567, 1.7385, -1.3042, 0.7423], [ 1.3436, -0.1015, -0.9834, -0.8438], [ 0.6056, 0.1089, -0.3112, -1.4085], [-0.7700, 0.6074, -0.1469, 0.7777]]) >>> torch.var(a, 1) tensor([ 1.7444, 1.1363, 0.7356, 0.5112]) torch.var_mean()¶ torch.var_mean(input, unbiased=True) -> (Tensor, Tensor) 返回input张量中所有元素的方差和均值。 If unbiased is False, then the variance will be calculated via the biased estimator. Otherwise, Bessel’s correction will be used. Parameters input (Tensor) – the input tensor. unbiased (bool) – whether to use the unbiased estimation or not Example: >>> a = torch.randn(1, 3) >>> a tensor([[0.0146, 0.4258, 0.2211]]) >>> torch.var_mean(a) (tensor(0.0423), tensor(0.2205)) torch.var_mean(input, dim, keepdim=False, unbiased=True) -> (Tensor, Tensor) 返回给定维度dim中input张量的每一行的方差和均值。 If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s). If unbiased is False, then the variance will be calculated via the biased estimator. Otherwise, Bessel’s correction will be used. Parameters input (Tensor) – the input tensor. dim (python:int or tuple of python:ints) – the dimension or dimensions to reduce. keepdim (bool) – whether the output tensor has dim retained or not. unbiased (bool) – whether to use the unbiased estimation or not Example: >>> a = torch.randn(4, 4) >>> a tensor([[-1.5650, 2.0415, -0.1024, -0.5790], [ 0.2325, -2.6145, -1.6428, -0.3537], [-0.2159, -1.1069, 1.2882, -1.3265], [-0.6706, -1.5893, 0.6827, 1.6727]]) >>> torch.var_mean(a, 1) (tensor([2.3174, 1.6403, 1.4092, 2.0791]), tensor([-0.0512, -1.0946, -0.3403, 0.0239])) 比较行动 torch.allclose(input, other, rtol=1e-05, atol=1e-08, equal_nan=False) → bool¶ 此函数检查input和other是否都满足以下条件： 对于input和other的所有元素，都是逐元素的。 此函数的行为类似于 numpy.allclose Parameters 输入 (tensor)–比较的第一个张量 其他 (tensor)–要比较的第二张量 atol (python：float ， 可选）–绝对公差。 默认值：1e-08 rtol (python：float ， 可选）–相对公差。 默认值：1e-05 equal_nan (bool ， 可选）–如果True，则将两个NaN s 相等。 默认值：False Example: >>> torch.allclose(torch.tensor([10000., 1e-07]), torch.tensor([10000.1, 1e-08])) False >>> torch.allclose(torch.tensor([10000., 1e-08]), torch.tensor([10000.1, 1e-09])) True >>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')])) False >>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]), equal_nan=True) True torch.argsort(input, dim=-1, descending=False, out=None) → LongTensor¶ 返回按值升序对给定维度上的张量排序的索引。 这是 torch.sort() 返回的第二个值。 有关此方法的确切语义，请参见其文档。 Parameters input (Tensor) – the input tensor. 暗淡的 (python：int ， 可选）–要排序的维度 降序 (bool ， 可选）–控制排序顺序(升序或降序） Example: >>> a = torch.randn(4, 4) >>> a tensor([[ 0.0785, 1.5267, -0.8521, 0.4065], [ 0.1598, 0.0788, -0.0745, -1.2700], [ 1.2208, 1.0722, -0.7064, 1.2564], [ 0.0669, -0.2318, -0.8229, -0.9280]]) >>> torch.argsort(a, dim=1) tensor([[2, 0, 3, 1], [3, 2, 1, 0], [2, 1, 0, 3], [3, 2, 1, 0]]) torch.eq(input, other, out=None) → Tensor¶ 计算按元素相等 第二个参数可以是数字或张量，其形状可以与第一个参数一起广播为的。 Parameters 输入 (tensor)–要比较的张量 其他 (tensor 或 python：float )–要比较的张量或值 输出 (tensor ， 可选）–输出张量。 必须是 ByteTensor Returns torch.BoolTensor在每个比较为真的位置包含一个真 Return type Tensor Example: >>> torch.eq(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[ 1, 0], [ 0, 1]], dtype=torch.uint8) torch.equal(input, other) → bool¶ 如果两个张量具有相同的大小和元素，则为True，否则为False。 Example: >>> torch.equal(torch.tensor([1, 2]), torch.tensor([1, 2])) True torch.ge(input, other, out=None) → Tensor¶ 逐元素计算。 The second argument can be a number or a tensor whose shape is broadcastable with the first argument. Parameters input (Tensor) – the tensor to compare other (Tensor or python:float) – the tensor or value to compare 输出 (tensor ， 可选）–输出张量必须为 BoolTensor Returns A torch.BoolTensor containing a True at each location where comparison is true Return type Tensor Example: >>> torch.ge(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[True, True], [False, True]]) torch.gt(input, other, out=None) → Tensor¶ 逐元素计算。 The second argument can be a number or a tensor whose shape is broadcastable with the first argument. Parameters input (Tensor) – the tensor to compare other (Tensor or python:float) – the tensor or value to compare out (Tensor, optional) – the output tensor that must be a BoolTensor Returns A torch.BoolTensor containing a True at each location where comparison is true Return type Tensor Example: >>> torch.gt(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[False, True], [False, False]]) torch.isfinite()¶ 返回带有布尔元素的新张量，布尔元素表示每个元素是否为有限。 Arguments: 张量(张量）：要检查的张量 Returns: 张量：A torch.Tensor with dtype torch.bool在有限元素的每个位置均包含 True，否则包含 False Example: &gt;&gt;&gt; torch.isfinite(torch.tensor([1, float('inf'), 2, float('-inf'), float('nan')])) tensor([True, False, True, False, False]) torch.isinf(tensor)¶ 返回带有布尔元素的新张量，该布尔元素表示每个元素是否为 +/- INF 。 Parameters 张量 (tensor)–要检查的张量 Returns A torch.Tensor with dtype torch.bool在 +/- INF 元素的每个位置均包含 True，否则包含 False Return type Tensor Example: >>> torch.isinf(torch.tensor([1, float('inf'), 2, float('-inf'), float('nan')])) tensor([False, True, False, True, False]) torch.isnan()¶ 返回带有布尔元素的新张量，布尔元素表示每个元素是否为 NaN 。 Parameters 输入 (tensor)–要检查的张量 Returns 在 NaN 元素的每个位置包含 True 的torch.BoolTensor。 Return type Tensor Example: >>> torch.isnan(torch.tensor([1, float('nan'), 2])) tensor([False, True, False]) torch.kthvalue(input, k, dim=None, keepdim=False, out=None) -> (Tensor, LongTensor)¶ 返回一个命名元组(values, indices)，其中values是在给定维度dim中input张量的每一行的第k个最小元素。 indices是找到的每个元素的索引位置。 如果未提供dim，则选择输入的最后尺寸。 如果keepdim为True，则values和indices张量与input的大小相同，但尺寸为dim的张量为 1。否则，dim会受到挤压 (参见 torch.squeeze())，导致values和indices张量的尺寸都比input张量小 1。 Parameters input (Tensor) – the input tensor. k (python：int )–第 k 个最小元素的 k 暗淡的 (python：int ， 可选）–沿第 k 个值查找尺寸 keepdim (bool) – whether the output tensor has dim retained or not. out (元组 ， 可选）–(Tensor，LongTensor）的输出元组可以可选地用作输出缓冲区 Example: >>> x = torch.arange(1., 6.) >>> x tensor([ 1., 2., 3., 4., 5.]) >>> torch.kthvalue(x, 4) torch.return_types.kthvalue(values=tensor(4.), indices=tensor(3)) >>> x=torch.arange(1.,7.).resize_(2,3) >>> x tensor([[ 1., 2., 3.], [ 4., 5., 6.]]) >>> torch.kthvalue(x, 2, 0, True) torch.return_types.kthvalue(values=tensor([[4., 5., 6.]]), indices=tensor([[1, 1, 1]])) torch.le(input, other, out=None) → Tensor¶ 逐元素计算。 The second argument can be a number or a tensor whose shape is broadcastable with the first argument. Parameters input (Tensor) – the tensor to compare other (Tensor or python:float) – the tensor or value to compare out (Tensor, optional) – the output tensor that must be a BoolTensor Returns A torch.BoolTensor containing a True at each location where comparison is true Return type Tensor Example: >>> torch.le(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[True, False], [True, True]]) torch.lt(input, other, out=None) → Tensor¶ 逐元素计算。 The second argument can be a number or a tensor whose shape is broadcastable with the first argument. Parameters input (Tensor) – the tensor to compare other (Tensor or python:float) – the tensor or value to compare out (Tensor, optional) – the output tensor that must be a BoolTensor Returns 在每个比较为真的位置处包含“真”的 Torch.BoolTensor Return type Tensor Example: >>> torch.lt(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[False, False], [True, False]]) torch.max()¶ torch.max(input) → Tensor 返回input张量中所有元素的最大值。 Parameters {input} – Example: >>> a = torch.randn(1, 3) >>> a tensor([[ 0.6763, 0.7445, -2.2369]]) >>> torch.max(a) tensor(0.7445) torch.max(input, dim, keepdim=False, out=None) -> (Tensor, LongTensor) 返回一个命名元组(values, indices)，其中values是在给定维度dim中input张量的每一行的最大值。 indices是找到的每个最大值(argmax）的索引位置。 如果keepdim为True，则输出张量的大小与input相同，只是尺寸为 1 的尺寸为dim。否则，将压缩dim(请参见 torch.squeeze())，导致输出张量的尺寸比input小 1。 Parameters {input} – {dim} – 默认 ({keepdim} )– False。 输出(元组 ， 可选）–两个输出张量的结果元组(max，max_indices） Example: >>> a = torch.randn(4, 4) >>> a tensor([[-1.2360, -0.2942, -0.1222, 0.8475], [ 1.1949, -1.1127, -2.2379, -0.6702], [ 1.5717, -0.9207, 0.1297, -1.8768], [-0.6172, 1.0036, -0.6060, -0.2432]]) >>> torch.max(a, 1) torch.return_types.max(values=tensor([0.8475, 1.1949, 1.5717, 1.0036]), indices=tensor([3, 0, 0, 1])) torch.max(input, other, out=None) → Tensor 将张量input的每个元素与张量other的对应元素进行比较，并获得逐个元素的最大值。 input和other的形状不需要匹配，但它们必须是可广播的。 Note 当形状不匹配时，返回的输出张量的形状遵循广播规则。 Parameters input (Tensor) – the input tensor. other (Tensor) – the second input tensor out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([ 0.2942, -0.7416, 0.2653, -0.1584]) >>> b = torch.randn(4) >>> b tensor([ 0.8722, -1.7421, -0.4141, -0.5055]) >>> torch.max(a, b) tensor([ 0.8722, -0.7416, 0.2653, -0.1584]) torch.min()¶ torch.min(input) → Tensor 返回input张量中所有元素的最小值。 Parameters {input} – Example: >>> a = torch.randn(1, 3) >>> a tensor([[ 0.6750, 1.0857, 1.7197]]) >>> torch.min(a) tensor(0.6750) torch.min(input, dim, keepdim=False, out=None) -> (Tensor, LongTensor) 返回一个命名元组(values, indices)，其中values是在给定维度dim中input张量的每一行的最小值。 indices是找到的每个最小值的索引位置(argmin）。 如果keepdim为True，则输出张量的大小与input相同，只是尺寸为 1 的尺寸为dim。否则，将压缩dim(请参见 torch.squeeze())，导致输出张量的尺寸比input小 1。 Parameters {input} – {dim} – {keepdim} – 输出(元组 ， 可选）–两个输出张量的元组(min，min_indices） Example: >>> a = torch.randn(4, 4) >>> a tensor([[-0.6248, 1.1334, -1.1899, -0.2803], [-1.4644, -0.2635, -0.3651, 0.6134], [ 0.2457, 0.0384, 1.0128, 0.7015], [-0.1153, 2.9849, 2.1458, 0.5788]]) >>> torch.min(a, 1) torch.return_types.min(values=tensor([-1.1899, -1.4644, 0.0384, -0.1153]), indices=tensor([2, 0, 1, 0])) torch.min(input, other, out=None) → Tensor 将张量input的每个元素与张量other的对应元素进行比较，并按元素取最小值。 返回结果张量。 The shapes of input and other don’t need to match, but they must be broadcastable. Note When the shapes do not match, the shape of the returned output tensor follows the broadcasting rules. Parameters input (Tensor) – the input tensor. other (Tensor) – the second input tensor out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4) >>> a tensor([ 0.8137, -1.1740, -0.6460, 0.6308]) >>> b = torch.randn(4) >>> b tensor([-0.1369, 0.1555, 0.4019, -0.1929]) >>> torch.min(a, b) tensor([-0.1369, -1.1740, -0.6460, -0.1929]) torch.ne(input, other, out=None) → Tensor¶ 逐元素计算。 The second argument can be a number or a tensor whose shape is broadcastable with the first argument. Parameters input (Tensor) – the tensor to compare other (Tensor or python:float) – the tensor or value to compare out (Tensor, optional) – the output tensor that must be a BoolTensor Returns torch.BoolTensor在比较为真的每个位置都包含“真”。 Return type Tensor Example: >>> torch.ne(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[False, True], [True, False]]) torch.sort(input, dim=-1, descending=False, out=None) -> (Tensor, LongTensor)¶ 沿给定维度按值升序对input张量的元素进行排序。 If dim is not given, the last dimension of the input is chosen. 如果descending为True，则元素将按值降序排序。 返回一个(值，索引）的命名元组，其中值是排序的值，索引是原始输入张量中元素的索引。 Parameters input (Tensor) – the input tensor. dim (python:int__, optional) – the dimension to sort along descending (bool__, optional) – controls the sorting order (ascending or descending) 输出(元组 ， 可选）–(张量， LongTensor )，可以选择将其用作输出缓冲区 Example: >>> x = torch.randn(3, 4) >>> sorted, indices = torch.sort(x) >>> sorted tensor([[-0.2162, 0.0608, 0.6719, 2.3332], [-0.5793, 0.0061, 0.6058, 0.9497], [-0.5071, 0.3343, 0.9553, 1.0960]]) >>> indices tensor([[ 1, 0, 2, 3], [ 3, 1, 0, 2], [ 0, 3, 1, 2]]) >>> sorted, indices = torch.sort(x, 0) >>> sorted tensor([[-0.5071, -0.2162, 0.6719, -0.5793], [ 0.0608, 0.0061, 0.9497, 0.3343], [ 0.6058, 0.9553, 1.0960, 2.3332]]) >>> indices tensor([[ 2, 0, 0, 1], [ 0, 1, 1, 2], [ 1, 2, 2, 0]]) torch.topk(input, k, dim=None, largest=True, sorted=True, out=None) -> (Tensor, LongTensor)¶ 返回沿给定维度的给定input张量的k最大元素。 If dim is not given, the last dimension of the input is chosen. 如果largest为False，则返回 k 个最小的元素。 返回(值，索引）的命名元组，其中索引是原始输入张量中元素的索引。 布尔选项sorted如果为True，将确保返回的 k 元素本身已排序 Parameters input (Tensor) – the input tensor. k (python：int )–“ top-k”中的 k dim (python:int__, optional) – the dimension to sort along 最大的 (bool ， 可选）–控制是返回最大还是最小元素 排序的 (bool ， 可选）–控制是否按排序顺序返回元素 out (元组 ， 可选）–可以选择提供(Tensor，LongTensor）的输出元组 缓冲区 Example: >>> x = torch.arange(1., 6.) >>> x tensor([ 1., 2., 3., 4., 5.]) >>> torch.topk(x, 3) torch.return_types.topk(values=tensor([5., 4., 3.]), indices=tensor([4, 3, 2])) 光谱操作 torch.fft(input, signal_ndim, normalized=False) → Tensor¶ 复数到复数离散傅立叶变换 此方法计算复数到复数离散傅里叶变换。 忽略批次尺寸，它将计算以下表达式： 其中 = signal_ndim是信号尺寸的数量，是信号尺寸的尺寸。 此方法支持signal_ndim指示的 1D，2D 和 3D 复数到复数转换。 input必须是张量，其最后一个尺寸为 2，代表复数的实部和虚部，并且至少应具有signal_ndim + 1个尺寸，并可以选择任意数量的前批尺寸。 如果normalized设置为True，则通过将结果除以来对结果进行归一化，以使运算符为一元。 将实部和虚部一起返回为input形状相同的一个张量。 此函数的反函数为 ifft() 。 Note 对于 CUDA 张量，LRU 缓存用于 cuFFT 计划，以加快在具有相同配置的相同几何形状的张量上重复运行 FFT 方法的速度。 有关如何监视和控制缓存的更多详细信息，请参见 cuFFT 计划缓存。 Warning 对于 CPU 张量，此方法当前仅适用于 MKL。 使用torch.backends.mkl.is_available()检查是否安装了 MKL。 Parameters 输入 (tensor)–至少signal_ndim + 1尺寸的输入张量 signal_ndim (python：int )–每个信号中的维数。 signal_ndim只能是 1、2 或 3 标准化的 (bool ， 可选）–控制是否返回标准化结果。 默认值：False Returns 包含复数到复数傅里叶变换结果的张量 Return type Tensor Example: >>> # unbatched 2D FFT >>> x = torch.randn(4, 3, 2) >>> torch.fft(x, 2) tensor([[[-0.0876, 1.7835], [-2.0399, -2.9754], [ 4.4773, -5.0119]], [[-1.5716, 2.7631], [-3.8846, 5.2652], [ 0.2046, -0.7088]], [[ 1.9938, -0.5901], [ 6.5637, 6.4556], [ 2.9865, 4.9318]], [[ 7.0193, 1.1742], [-1.3717, -2.1084], [ 2.0289, 2.9357]]]) >>> # batched 1D FFT >>> torch.fft(x, 1) tensor([[[ 1.8385, 1.2827], [-0.1831, 1.6593], [ 2.4243, 0.5367]], [[-0.9176, -1.5543], [-3.9943, -2.9860], [ 1.2838, -2.9420]], [[-0.8854, -0.6860], [ 2.4450, 0.0808], [ 1.3076, -0.5768]], [[-0.1231, 2.7411], [-0.3075, -1.7295], [-0.5384, -2.0299]]]) >>> # arbitrary number of batch dimensions, 2D FFT >>> x = torch.randn(3, 3, 5, 5, 2) >>> y = torch.fft(x, 2) >>> y.shape torch.Size([3, 3, 5, 5, 2]) torch.ifft(input, signal_ndim, normalized=False) → Tensor¶ 复数到逆离散傅立叶逆变换 此方法计算复杂到复杂的逆离散傅里叶变换。 忽略批次尺寸，它将计算以下表达式： where = signal_ndim is number of dimensions for the signal, and is the size of signal dimension . 参数规范几乎与 fft() 相同。 但是，如果将normalized设置为True，它将返回结果乘以的结果，从而成为一元运算符。 因此，要反转 fft() ，应为 fft() 设置normalized自变量。 Returns the real and the imaginary parts together as one tensor of the same shape of input. 此函数的反函数为 fft() 。 Note For CUDA tensors, an LRU cache is used for cuFFT plans to speed up repeatedly running FFT methods on tensors of same geometry with same configuration. See cuFFT plan cache for more details on how to monitor and control the cache. Warning For CPU tensors, this method is currently only available with MKL. Use torch.backends.mkl.is_available() to check if MKL is installed. Parameters input (Tensor) – the input tensor of at least signal_ndim + 1 dimensions signal_ndim (python:int) – the number of dimensions in each signal. signal_ndim can only be 1, 2 or 3 normalized (bool__, optional) – controls whether to return normalized results. Default: False Returns 包含复数到复数傅立叶逆变换结果的张量 Return type Tensor Example: >>> x = torch.randn(3, 3, 2) >>> x tensor([[[ 1.2766, 1.3680], [-0.8337, 2.0251], [ 0.9465, -1.4390]], [[-0.1890, 1.6010], [ 1.1034, -1.9230], [-0.9482, 1.0775]], [[-0.7708, -0.8176], [-0.1843, -0.2287], [-1.9034, -0.2196]]]) >>> y = torch.fft(x, 2) >>> torch.ifft(y, 2) # recover x tensor([[[ 1.2766, 1.3680], [-0.8337, 2.0251], [ 0.9465, -1.4390]], [[-0.1890, 1.6010], [ 1.1034, -1.9230], [-0.9482, 1.0775]], [[-0.7708, -0.8176], [-0.1843, -0.2287], [-1.9034, -0.2196]]]) torch.rfft(input, signal_ndim, normalized=False, onesided=True) → Tensor¶ 实数到复杂离散傅里叶变换 此方法计算实数到复杂的离散傅里叶变换。 它在数学上等效于 fft() ，只是输入和输出格式不同。 此方法支持 1D，2D 和 3D 实数到复杂的变换，由signal_ndim指示。 input必须是至少具有signal_ndim尺寸且可以选择任意数量的前导批尺寸的张量。 如果normalized设置为True，则通过将结果除以来标准化结果，以使运算符为 the，其中是信号维度的大小。 实数到复杂的傅立叶变换结果遵循共轭对称性： 其中索引算术是计算模量的相应尺寸的大小，是共轭算子， = signal_ndim。 onesided标志控制是否避免输出结果中的冗余。 如果设置为True(默认值），输出将不是形状的完全复杂结果，其中是input的形状，但是最后一个尺寸将是尺寸的一半 。 此函数的反函数为 irfft() 。 Note For CUDA tensors, an LRU cache is used for cuFFT plans to speed up repeatedly running FFT methods on tensors of same geometry with same configuration. See cuFFT plan cache for more details on how to monitor and control the cache. Warning For CPU tensors, this method is currently only available with MKL. Use torch.backends.mkl.is_available() to check if MKL is installed. Parameters 输入 (tensor)–至少signal_ndim尺寸的输入张量 signal_ndim (python:int) – the number of dimensions in each signal. signal_ndim can only be 1, 2 or 3 normalized (bool__, optional) – controls whether to return normalized results. Default: False 单面 (bool ， 可选）–控制是否返回一半结果以避免重复。 默认值：True Returns 包含实数到复数傅立叶变换结果的张量 Return type Tensor Example: >>> x = torch.randn(5, 5) >>> torch.rfft(x, 2).shape torch.Size([5, 3, 2]) >>> torch.rfft(x, 2, onesided=False).shape torch.Size([5, 5, 2]) torch.irfft(input, signal_ndim, normalized=False, onesided=True, signal_sizes=None) → Tensor¶ 复数到实数离散傅里叶逆变换 此方法计算复数到实数的离散傅里叶逆变换。 它在数学上等效于 ifft() ，只是输入和输出格式不同。 参数规范几乎与 ifft() 相同。 与 ifft() 相似，如果normalized设置为True，则通过将结果与相乘来对结果进行归一化，以使运算符为 ary，其中是信号的大小 尺寸。 Note 由于共轭对称性，input不需要包含完整的复数频率值。 大约一半的值就足够了，就像 rfft() 和rfft(signal, onesided=True)给出input的情况一样。 在这种情况下，请将此方法的onesided参数设置为True。 此外，原始信号形状信息有时会丢失，可以选择将signal_sizes设置为原始信号的大小(如果处于批处理模式，则没有批处理尺寸），以恢复正确的形状。 因此，要反转 rfft() ，应为 irfft() 设置normalized和onesided自变量，并且最好使用signal_sizes以避免大小 不匹配。 有关大小不匹配的情况，请参见下面的示例。 有关共轭对称性的详细信息，请参见 rfft() 。 此函数的反函数为 rfft() 。 Warning 通常，此函数的输入应包含遵循共轭对称性的值。 请注意，即使onesided为True，仍然经常需要在某些部分上保持对称。 当不满足此要求时， irfft() 的行为是不确定的。 由于 torch.autograd.gradcheck() 估计带有点扰动的数字雅可比行列式，因此 irfft() 几乎肯定会失败。 Note For CUDA tensors, an LRU cache is used for cuFFT plans to speed up repeatedly running FFT methods on tensors of same geometry with same configuration. See cuFFT plan cache for more details on how to monitor and control the cache. Warning For CPU tensors, this method is currently only available with MKL. Use torch.backends.mkl.is_available() to check if MKL is installed. Parameters input (Tensor) – the input tensor of at least signal_ndim + 1 dimensions signal_ndim (python:int) – the number of dimensions in each signal. signal_ndim can only be 1, 2 or 3 normalized (bool__, optional) – controls whether to return normalized results. Default: False 单面 (bool ， 可选）–控制input是否对半以避免冗余，例如通过 rfft() 。 默认值：True signal_sizes (列表或torch.Size，可选）–原始信号的大小(无批次尺寸）。 默认值：None Returns 包含复数到实数傅立叶逆变换结果的张量 Return type Tensor Example: >>> x = torch.randn(4, 4) >>> torch.rfft(x, 2, onesided=True).shape torch.Size([4, 3, 2]) >>> >>> # notice that with onesided=True, output size does not determine the original signal size >>> x = torch.randn(4, 5) >>> torch.rfft(x, 2, onesided=True).shape torch.Size([4, 3, 2]) >>> >>> # now we use the original shape to recover x >>> x tensor([[-0.8992, 0.6117, -1.6091, -0.4155, -0.8346], [-2.1596, -0.0853, 0.7232, 0.1941, -0.0789], [-2.0329, 1.1031, 0.6869, -0.5042, 0.9895], [-0.1884, 0.2858, -1.5831, 0.9917, -0.8356]]) >>> y = torch.rfft(x, 2, onesided=True) >>> torch.irfft(y, 2, onesided=True, signal_sizes=x.shape) # recover x tensor([[-0.8992, 0.6117, -1.6091, -0.4155, -0.8346], [-2.1596, -0.0853, 0.7232, 0.1941, -0.0789], [-2.0329, 1.1031, 0.6869, -0.5042, 0.9895], [-0.1884, 0.2858, -1.5831, 0.9917, -0.8356]]) torch.stft(input, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)¶ 短时傅立叶变换(STFT）。 忽略可选的批处理维，此方法将计算以下表达式： 其中是滑动窗口的索引，是的频率。 当onesided为默认值True时， input必须是一维时间序列或二维时间序列批次。 如果hop_length为None(默认值），则将其视为等于floor(n_fft / 4)。 如果win_length为None(默认值），则将其视为等于n_fft。 window可以是大小为win_length的一维张量，例如来自 torch.hann_window() 。 如果window为None(默认），则将其视为窗口中到处都有。 如果使用，则将window的两面填充长度n_fft，然后再进行应用。 如果center为True(默认值），则将在两边都填充input，以使第帧位于时间的中心。 否则，第帧在时间开始。 pad_mode确定当center为True时在input上使用的填充方法。 有关所有可用选项，请参见 torch.nn.functional.pad() 。 默认值为\"reflect\"。 如果onesided为True(默认值），则仅返回中的值，因为实数到复数傅里叶变换满足共轭对称性，即。 如果normalized为True(默认为False），则该函数返回归一化的 STFT 结果，即乘以。 将实部和虚部一起返回为一个大小为的张量，其中是可选的input批大小，是应用 STFT 的频率数，是总数 所使用的帧数，最后一维中的每一对代表一个复数，作为实部和虚部。 Warning 此功能在版本 0.4.1 更改了签名。 使用前一个签名进行调用可能会导致错误或返回错误的结果。 Parameters input (Tensor) – the input tensor n_fft (python：int )–傅立叶变换的大小 hop_length (python：int ， 可选）–相邻滑动窗口框架之间的距离。 默认值：None(等同于floor(n_fft / 4)） win_length (python：int ， 可选）–窗口框架和 STFT 过滤器的大小。 默认值：None(等同于n_fft） 窗口 (tensor ， 可选）–可选窗口功能。 默认值：None(被视为所有的窗口） 中心 (bool ， 可选）–是否在两侧都填充input以便第个帧位于 集中在时间上。 默认值：True pad_mode (字符串 ， 可选）–控制当center为True时使用的填充方法。 默认值：\"reflect\" 规范化的 (bool ， 可选）–控制是否返回规范化的 STFT 结果默认：False 单面 (bool ， 可选）–控制是否返回一半结果以避免冗余默认值：True Returns 包含 STFT 结果的张量具有上述形状 Return type Tensor torch.bartlett_window(window_length, periodic=True, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor¶ Bartlett 窗口功能。 其中是整个窗口的大小。 输入window_length是控制返回的窗口大小的正整数。 periodic标志确定返回的窗口是否从对称窗口中修剪掉最后一个重复值，并准备好用作具有 torch.stft() 之类的周期性窗口。 因此，如果periodic为真，则上式中的实际上为。 另外，我们总是torch.bartlett_window(L, periodic=True)等于torch.bartlett_window(L + 1, periodic=False)[:-1])。 Note 如果window_length ，则返回的窗口包含单个值 1。 Parameters window_length (python：int )–返回窗口的大小 周期性 (bool ， 可选）–如果为 True，则返回用作周期性函数的窗口。 如果为 False，则返回一个对称窗口。 dtype (torch.dtype ，可选）–返回张量的所需数据类型。 默认值：如果None使用全局默认值(请参见 torch.set_default_tensor_type())。 仅支持浮点类型。 布局 (torch.layout ，可选）–返回的窗口张量的所需布局。 仅支持torch.strided(密集布局）。 device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Returns 包含窗口的大小为的一维张量 Return type Tensor torch.blackman_window(window_length, periodic=True, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor¶ 布莱克曼窗口功能。 where is the full window size. 输入window_length是控制返回的窗口大小的正整数。 periodic标志确定返回的窗口是否从对称窗口中修剪掉最后一个重复值，并准备好用作具有 torch.stft() 之类的周期性窗口。 因此，如果periodic为真，则上式中的实际上为。 另外，我们总是torch.blackman_window(L, periodic=True)等于torch.blackman_window(L + 1, periodic=False)[:-1])。 Note If window_length , the returned window contains a single value 1. Parameters window_length (python:int) – the size of returned window periodic (bool__, optional) – If True, returns a window to be used as periodic function. If False, return a symmetric window. dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). Only floating point types are supported. layout (torch.layout, optional) – the desired layout of returned window tensor. Only torch.strided (dense layout) is supported. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Returns A 1-D tensor of size containing the window Return type Tensor torch.hamming_window(window_length, periodic=True, alpha=0.54, beta=0.46, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor¶ 汉明窗功能。 where is the full window size. 输入window_length是控制返回的窗口大小的正整数。 periodic标志确定返回的窗口是否从对称窗口中修剪掉最后一个重复值，并准备好用作具有 torch.stft() 之类的周期性窗口。 因此，如果periodic为真，则上式中的实际上为。 另外，我们总是torch.hamming_window(L, periodic=True)等于torch.hamming_window(L + 1, periodic=False)[:-1])。 Note If window_length , the returned window contains a single value 1. Note 这是 torch.hann_window() 的通用版本。 Parameters window_length (python:int) – the size of returned window periodic (bool__, optional) – If True, returns a window to be used as periodic function. If False, return a symmetric window. alpha (python：float ， 可选）–上式中的系数 beta (python：float ， 可选）–上式中的系数 dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). Only floating point types are supported. layout (torch.layout, optional) – the desired layout of returned window tensor. Only torch.strided (dense layout) is supported. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Returns A 1-D tensor of size containing the window Return type Tensor torch.hann_window(window_length, periodic=True, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor¶ 汉恩窗口功能。 where is the full window size. 输入window_length是控制返回的窗口大小的正整数。 periodic标志确定返回的窗口是否从对称窗口中修剪掉最后一个重复值，并准备好用作具有 torch.stft() 之类的周期性窗口。 因此，如果periodic为真，则上式中的实际上为。 另外，我们总是torch.hann_window(L, periodic=True)等于torch.hann_window(L + 1, periodic=False)[:-1])。 Note If window_length , the returned window contains a single value 1. Parameters window_length (python:int) – the size of returned window periodic (bool__, optional) – If True, returns a window to be used as periodic function. If False, return a symmetric window. dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). Only floating point types are supported. layout (torch.layout, optional) – the desired layout of returned window tensor. Only torch.strided (dense layout) is supported. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Returns A 1-D tensor of size containing the window Return type Tensor 其他作业 torch.bincount(input, weights=None, minlength=0) → Tensor¶ 计算非负整数数组中每个值的频率。 除非input为空，否则 bin 的数量(大小 1）比input中的最大值大一个，在这种情况下，结果是大小为 0 的张量。如果指定minlength，则 bin 的数量为 至少minlength为空，如果input为空，则结果为大小为minlength的张量填充零。 如果n是位置i的值，则如果指定了weights则为out[n] += weights[i]，否则指定out[n] += 1。 Note 使用 CUDA 后端时，此操作可能会导致不确定的行为，不容易关闭。 有关背景，请参见重现性的注释。 Parameters 输入 (tensor)– 1-d int 张量 权重 (tensor)–可选，输入张量中每个值的权重。 应具有与输入张量相同的大小。 minlength (python：int )–可选，最小存储箱数。 应该是非负的。 Returns 如果input为非空，则为Size([max(input) + 1])形状的张量，否则为Size(0) Return type 输出(张量） Example: >>> input = torch.randint(0, 8, (5,), dtype=torch.int64) >>> weights = torch.linspace(0, 1, steps=5) >>> input, weights (tensor([4, 3, 6, 3, 4]), tensor([ 0.0000, 0.2500, 0.5000, 0.7500, 1.0000]) >>> torch.bincount(input) tensor([0, 0, 0, 2, 2, 0, 1]) >>> input.bincount(weights) tensor([0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.5000]) torch.broadcast_tensors(*tensors) → List of Tensors¶ 根据广播语义广播给定张量。 Parameters *张量 –任意数量的相同类型的张量 Warning 广播张量的一个以上元素可以引用单个存储位置。 结果，就地操作(尤其是矢量化的操作）可能会导致错误的行为。 如果需要写张量，请先克隆它们。 Example: >>> x = torch.arange(3).view(1, 3) >>> y = torch.arange(2).view(2, 1) >>> a, b = torch.broadcast_tensors(x, y) >>> a.size() torch.Size([2, 3]) >>> a tensor([[0, 1, 2], [0, 1, 2]]) torch.cartesian_prod(*tensors)¶ 给定张量序列的笛卡尔积。 行为类似于 python 的 itertools.product 。 Parameters *张量 –任意数量的一维张量。 Returns A tensor equivalent to converting all the input tensors into lists, 在这些列表上执行 itertools.product ，最后将结果列表转换为张量。 Return type Tensor Example: >>> a = [1, 2, 3] >>> b = [4, 5] >>> list(itertools.product(a, b)) [(1, 4), (1, 5), (2, 4), (2, 5), (3, 4), (3, 5)] >>> tensor_a = torch.tensor(a) >>> tensor_b = torch.tensor(b) >>> torch.cartesian_prod(tensor_a, tensor_b) tensor([[1, 4], [1, 5], [2, 4], [2, 5], [3, 4], [3, 5]]) torch.cdist(x1, x2, p=2, compute_mode='use_mm_for_euclid_dist_if_necessary')¶ 计算批处理行向量的两个集合的每对之间的 p 范数距离。 Parameters x1 (tensor)–形状为的输入张量。 x2 (tensor)–形状为的输入张量。 p -p 范数距离的 p 值，以计算每个向量对之间的距离。 compute_mode –'use_mm_for_euclid_dist_if_necessary'-如果 P > 25 或 R > 25'use_mm_for_euclid_dist'-将始终使用矩阵乘法方法来计算欧几里德距离(p = 2） 欧式距离(p = 2）'donot_use_mm_for_euclid_dist'-永远不会使用矩阵乘法方法来计算欧式距离(p = 2）默认值：use_mm_for_euclid_dist_if_necessary。 如果 x1 具有形状，而 x2 具有形状，则输出将具有形状。 如果，则此函数等效于 scipy.spatial.distance.cdist(input，'minkowski'，p = p）。 当等于 scipy.spatial.distance.cdist(input，'hamming'）* M 。 当时，最接近的 scipy 函数是 scipy.spatial.distance.cdist(xn，lambda x，y：np.abs(x-y）.max(））。 Example >>> a = torch.tensor([[0.9041, 0.0196], [-0.3108, -2.4423], [-0.4821, 1.059]]) >>> a tensor([[ 0.9041, 0.0196], [-0.3108, -2.4423], [-0.4821, 1.0590]]) >>> b = torch.tensor([[-2.1763, -0.4713], [-0.6986, 1.3702]]) >>> b tensor([[-2.1763, -0.4713], [-0.6986, 1.3702]]) >>> torch.cdist(a, b, p=2) tensor([[3.1193, 2.0959], [2.7138, 3.8322], [2.2830, 0.3791]]) torch.combinations(input, r=2, with_replacement=False) → seq¶ 计算给定张量的长度的组合。 当 with_replacement 设置为 False 时，该行为类似于 python 的 itertools.combinations ；当 with_replacement 设置为时，该行为与 itertools.combinations_with_replacement 相似。 HTG10]设置为 True 。 Parameters 输入 (tensor)–一维矢量。 r (python：int ， 可选）–要组合的元素数 with_replacement (布尔值 ， 可选）–是否允许重复复制 Returns 等于将所有输入张量转换为列表的张量，对这些列表执行 itertools.combinations 或 itertools.combinations_with_replacement ，最后将结果列表转换为张量。 Return type Tensor Example: >>> a = [1, 2, 3] >>> list(itertools.combinations(a, r=2)) [(1, 2), (1, 3), (2, 3)] >>> list(itertools.combinations(a, r=3)) [(1, 2, 3)] >>> list(itertools.combinations_with_replacement(a, r=2)) [(1, 1), (1, 2), (1, 3), (2, 2), (2, 3), (3, 3)] >>> tensor_a = torch.tensor(a) >>> torch.combinations(tensor_a) tensor([[1, 2], [1, 3], [2, 3]]) >>> torch.combinations(tensor_a, r=3) tensor([[1, 2, 3]]) >>> torch.combinations(tensor_a, with_replacement=True) tensor([[1, 1], [1, 2], [1, 3], [2, 2], [2, 3], [3, 3]]) torch.cross(input, other, dim=-1, out=None) → Tensor¶ 返回向量在input和other的维度dim中的叉积。 input和other的大小必须相同，并且dim尺寸的大小应为 3。 如果未提供dim，则默认为找到的第一个尺寸为 3 的尺寸。 Parameters input (Tensor) – the input tensor. other (Tensor) – the second input tensor 暗淡的 (python：int ， 可选）–取叉积的尺寸。 out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(4, 3) >>> a tensor([[-0.3956, 1.1455, 1.6895], [-0.5849, 1.3672, 0.3599], [-1.1626, 0.7180, -0.0521], [-0.1339, 0.9902, -2.0225]]) >>> b = torch.randn(4, 3) >>> b tensor([[-0.0257, -1.4725, -1.2251], [-1.1479, -0.7005, -1.9757], [-1.3904, 0.3726, -1.1836], [-0.9688, -0.7153, 0.2159]]) >>> torch.cross(a, b, dim=1) tensor([[ 1.0844, -0.5281, 0.6120], [-2.4490, -1.5687, 1.9792], [-0.8304, -1.3037, 0.5650], [-1.2329, 1.9883, 1.0551]]) >>> torch.cross(a, b) tensor([[ 1.0844, -0.5281, 0.6120], [-2.4490, -1.5687, 1.9792], [-0.8304, -1.3037, 0.5650], [-1.2329, 1.9883, 1.0551]]) torch.cumprod(input, dim, out=None, dtype=None) → Tensor¶ 返回维度为dim的input元素的累积积。 例如，如果input是大小为 N 的向量，则结果也将是大小为 N 的向量(带有元素）。 Parameters input (Tensor) – the input tensor. 暗淡的 (python：int )–执行操作的尺寸 dtype (torch.dtype, optional) – the desired data type of returned tensor. If specified, the input tensor is casted to dtype before the operation is performed. This is useful for preventing data type overflows. Default: None. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(10) >>> a tensor([ 0.6001, 0.2069, -0.1919, 0.9792, 0.6727, 1.0062, 0.4126, -0.2129, -0.4206, 0.1968]) >>> torch.cumprod(a, dim=0) tensor([ 0.6001, 0.1241, -0.0238, -0.0233, -0.0157, -0.0158, -0.0065, 0.0014, -0.0006, -0.0001]) >>> a[5] = 0.0 >>> torch.cumprod(a, dim=0) tensor([ 0.6001, 0.1241, -0.0238, -0.0233, -0.0157, -0.0000, -0.0000, 0.0000, -0.0000, -0.0000]) torch.cumsum(input, dim, out=None, dtype=None) → Tensor¶ 返回维度为dim的input元素的累积和。 For example, if input is a vector of size N, the result will also be a vector of size N, with elements. Parameters input (Tensor) – the input tensor. dim (python:int) – the dimension to do the operation over dtype (torch.dtype, optional) – the desired data type of returned tensor. If specified, the input tensor is casted to dtype before the operation is performed. This is useful for preventing data type overflows. Default: None. out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(10) >>> a tensor([-0.8286, -0.4890, 0.5155, 0.8443, 0.1865, -0.1752, -2.0595, 0.1850, -1.1571, -0.4243]) >>> torch.cumsum(a, dim=0) tensor([-0.8286, -1.3175, -0.8020, 0.0423, 0.2289, 0.0537, -2.0058, -1.8209, -2.9780, -3.4022]) torch.diag(input, diagonal=0, out=None) → Tensor¶ 如果input是矢量(1-D 张量），则返回以input的元素为对角线的 2-D 方形张量。 如果input是矩阵(2-D 张量），则返回带有input的对角元素的 1-D 张量。 参数 diagonal 控制要考虑的对角线： 如果 diagonal = 0，则它是主对角线。 如果 diagonal > 0，则它在主对角线上方。 如果 diagonal Parameters input (Tensor) – the input tensor. 对角线 (python：int ， 可选）–对角线 out (Tensor, optional) – the output tensor. See also torch.diagonal() 始终返回其输入的对角线。 torch.diagflat() 始终使用输入指定的对角线元素构造张量。 Examples: 获取输入向量为对角线的方阵： >>> a = torch.randn(3) >>> a tensor([ 0.5950,-0.0872, 2.3298]) >>> torch.diag(a) tensor([[ 0.5950, 0.0000, 0.0000], [ 0.0000,-0.0872, 0.0000], [ 0.0000, 0.0000, 2.3298]]) >>> torch.diag(a, 1) tensor([[ 0.0000, 0.5950, 0.0000, 0.0000], [ 0.0000, 0.0000,-0.0872, 0.0000], [ 0.0000, 0.0000, 0.0000, 2.3298], [ 0.0000, 0.0000, 0.0000, 0.0000]]) 获取给定矩阵的第 k 个对角线： >>> a = torch.randn(3, 3) >>> a tensor([[-0.4264, 0.0255,-0.1064], [ 0.8795,-0.2429, 0.1374], [ 0.1029,-0.6482,-1.6300]]) >>> torch.diag(a, 0) tensor([-0.4264,-0.2429,-1.6300]) >>> torch.diag(a, 1) tensor([ 0.0255, 0.1374]) torch.diag_embed(input, offset=0, dim1=-2, dim2=-1) → Tensor¶ 创建一个张量，其某些 2D 平面(由dim1和dim2指定）的对角线由input填充。 为了便于创建批处理对角矩阵，默认情况下选择由返回张量的最后两个维构成的 2D 平面。 参数offset控制要考虑的对角线： 如果offset = 0，则它是主对角线。 如果offset >为 0，则它​​在主对角线上方。 如果offset 将计算新矩阵的大小，以使指定的对角线成为最后一个输入尺寸的大小。 注意，对于以外的offset，dim1和dim2的顺序很重要。 交换它们等效于更改offset的符号。 将 torch.diagonal() 应用于具有相同参数的该函数的输出，将产生与输入相同的矩阵。 但是， torch.diagonal() 具有不同的默认尺寸，因此需要明确指定这些尺寸。 Parameters 输入 (tensor)–输入张量。 必须至少为一维。 偏移量 (python：int ， 可选）–要考虑的对角线。 默认值：0(主对角线）。 dim1 (python：int ， 可选）–取对角线的第一维。 默认值：-2。 dim2 (python：int ， 可选）–取对角线的第二维。 默认值：-1。 Example: >>> a = torch.randn(2, 3) >>> torch.diag_embed(a) tensor([[[ 1.5410, 0.0000, 0.0000], [ 0.0000, -0.2934, 0.0000], [ 0.0000, 0.0000, -2.1788]], [[ 0.5684, 0.0000, 0.0000], [ 0.0000, -1.0845, 0.0000], [ 0.0000, 0.0000, -1.3986]]]) >>> torch.diag_embed(a, offset=1, dim1=0, dim2=2) tensor([[[ 0.0000, 1.5410, 0.0000, 0.0000], [ 0.0000, 0.5684, 0.0000, 0.0000]], [[ 0.0000, 0.0000, -0.2934, 0.0000], [ 0.0000, 0.0000, -1.0845, 0.0000]], [[ 0.0000, 0.0000, 0.0000, -2.1788], [ 0.0000, 0.0000, 0.0000, -1.3986]], [[ 0.0000, 0.0000, 0.0000, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.0000]]]) torch.diagflat(input, offset=0) → Tensor¶ If input is a vector (1-D tensor), then returns a 2-D square tensor with the elements of input as the diagonal. 如果input是一维以上的张量，则返回一个二维张量，其对角线元素等于展平的input。 The argument offset controls which diagonal to consider: If offset = 0, it is the main diagonal. If offset > 0, it is above the main diagonal. If offset Parameters input (Tensor) – the input tensor. 偏移量 (python：int ， 可选）–要考虑的对角线。 默认值：0(主对角线）。 Examples: >>> a = torch.randn(3) >>> a tensor([-0.2956, -0.9068, 0.1695]) >>> torch.diagflat(a) tensor([[-0.2956, 0.0000, 0.0000], [ 0.0000, -0.9068, 0.0000], [ 0.0000, 0.0000, 0.1695]]) >>> torch.diagflat(a, 1) tensor([[ 0.0000, -0.2956, 0.0000, 0.0000], [ 0.0000, 0.0000, -0.9068, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.1695], [ 0.0000, 0.0000, 0.0000, 0.0000]]) >>> a = torch.randn(2, 2) >>> a tensor([[ 0.2094, -0.3018], [-0.1516, 1.9342]]) >>> torch.diagflat(a) tensor([[ 0.2094, 0.0000, 0.0000, 0.0000], [ 0.0000, -0.3018, 0.0000, 0.0000], [ 0.0000, 0.0000, -0.1516, 0.0000], [ 0.0000, 0.0000, 0.0000, 1.9342]]) torch.diagonal(input, offset=0, dim1=0, dim2=1) → Tensor¶ 返回input的局部视图，其对角线元素相对于dim1和dim2附加为尺寸的末端形状。 The argument offset controls which diagonal to consider: If offset = 0, it is the main diagonal. If offset > 0, it is above the main diagonal. If offset 将 torch.diag_embed() 应用于具有相同参数的此函数的输出，将产生一个带有输入对角线项的对角矩阵。 但是， torch.diag_embed() 具有不同的默认尺寸，因此需要明确指定这些尺寸。 Parameters 输入 (tensor)–输入张量。 必须至少为二维。 offset (python:int__, optional) – which diagonal to consider. Default: 0 (main diagonal). dim1 (python：int ， 可选）–取对角线的第一维。 默认值：0 dim2 (python：int ， 可选）–取对角线的第二维。 默认值：1。 Note 要取一批对角线，请传入 dim1 = -2，dim2 = -1。 Examples: >>> a = torch.randn(3, 3) >>> a tensor([[-1.0854, 1.1431, -0.1752], [ 0.8536, -0.0905, 0.0360], [ 0.6927, -0.3735, -0.4945]]) >>> torch.diagonal(a, 0) tensor([-1.0854, -0.0905, -0.4945]) >>> torch.diagonal(a, 1) tensor([ 1.1431, 0.0360]) >>> x = torch.randn(2, 5, 4, 2) >>> torch.diagonal(x, offset=-1, dim1=1, dim2=2) tensor([[[-1.2631, 0.3755, -1.5977, -1.8172], [-1.1065, 1.0401, -0.2235, -0.7938]], [[-1.7325, -0.3081, 0.6166, 0.2335], [ 1.0500, 0.7336, -0.3836, -1.1015]]]) torch.einsum(equation, *operands) → Tensor¶ 此函数提供了一种使用爱因斯坦求和约定来计算多线性表达式(即乘积和）的方法。 Parameters 公式(字符串）–该公式以与操作数和结果的每个维相关联的小写字母(索引）形式给出。 左侧列出了操作数维，以逗号分隔。 每个张量维应该有一个索引字母。 右侧紧随-> 之后，并给出输出的索引。 如果省略-> 和右侧，则将其隐式定义为所有索引的按字母顺序排序的列表，这些列表在左侧仅出现一次。 在将操作数条目相乘后，将输出中不等于的索引相加。 如果同一操作数的索引出现多次，则采用对角线。 椭圆…代表固定数量的尺寸。 如果推断出右侧，则省略号尺寸位于输出的开头。 操作数 (tensor)–计算爱因斯坦总和的操作数。 Examples: >>> x = torch.randn(5) >>> y = torch.randn(4) >>> torch.einsum('i,j->ij', x, y) # outer product tensor([[-0.0570, -0.0286, -0.0231, 0.0197], [ 1.2616, 0.6335, 0.5113, -0.4351], [ 1.4452, 0.7257, 0.5857, -0.4984], [-0.4647, -0.2333, -0.1883, 0.1603], [-1.1130, -0.5588, -0.4510, 0.3838]]) >>> A = torch.randn(3,5,4) >>> l = torch.randn(2,5) >>> r = torch.randn(2,4) >>> torch.einsum('bn,anm,bm->ba', l, A, r) # compare torch.nn.functional.bilinear tensor([[-0.3430, -5.2405, 0.4494], [ 0.3311, 5.5201, -3.0356]]) >>> As = torch.randn(3,2,5) >>> Bs = torch.randn(3,5,4) >>> torch.einsum('bij,bjk->bik', As, Bs) # batch matrix multiplication tensor([[[-1.0564, -1.5904, 3.2023, 3.1271], [-1.6706, -0.8097, -0.8025, -2.1183]], [[ 4.2239, 0.3107, -0.5756, -0.2354], [-1.4558, -0.3460, 1.5087, -0.8530]], [[ 2.8153, 1.8787, -4.3839, -1.2112], [ 0.3728, -2.1131, 0.0921, 0.8305]]]) >>> A = torch.randn(3, 3) >>> torch.einsum('ii->i', A) # diagonal tensor([-0.7825, 0.8291, -0.1936]) >>> A = torch.randn(4, 3, 3) >>> torch.einsum('...ii->...i', A) # batch diagonal tensor([[-1.0864, 0.7292, 0.0569], [-0.9725, -1.0270, 0.6493], [ 0.5832, -1.1716, -1.5084], [ 0.4041, -1.1690, 0.8570]]) >>> A = torch.randn(2, 3, 4, 5) >>> torch.einsum('...ij->...ji', A).shape # batch permute torch.Size([2, 3, 5, 4]) torch.flatten(input, start_dim=0, end_dim=-1) → Tensor¶ 展平张量中连续的暗淡范围。 Parameters input (Tensor) – the input tensor. start_dim (python：int )–第一个变暗的像素 end_dim (python：int )–最后一个变暗的像素 Example: >>> t = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]]) >>> torch.flatten(t) tensor([1, 2, 3, 4, 5, 6, 7, 8]) >>> torch.flatten(t, start_dim=1) tensor([[1, 2, 3, 4], [5, 6, 7, 8]]) torch.flip(input, dims) → Tensor¶ 沿给定轴反转 n-D 张量的顺序，以暗淡表示。 Parameters input (Tensor) – the input tensor. 使变暗(列表 或 元组）–翻转轴 Example: >>> x = torch.arange(8).view(2, 2, 2) >>> x tensor([[[ 0, 1], [ 2, 3]], [[ 4, 5], [ 6, 7]]]) >>> torch.flip(x, [0, 1]) tensor([[[ 6, 7], [ 4, 5]], [[ 2, 3], [ 0, 1]]]) torch.rot90(input, k, dims) → Tensor¶ 在调光轴指定的平面中将 n-D 张量旋转 90 度。 如果 k > 0，则旋转方向是从第一个轴到第二个轴，对于 k Parameters input (Tensor) – the input tensor. k (python：int )–旋转次数 使变暗(列表 或 元组）–旋转轴 Example: >>> x = torch.arange(4).view(2, 2) >>> x tensor([[0, 1], [2, 3]]) >>> torch.rot90(x, 1, [0, 1]) tensor([[1, 3], [0, 2]]) >>> x = torch.arange(8).view(2, 2, 2) >>> x tensor([[[0, 1], [2, 3]], [[4, 5], [6, 7]]]) >>> torch.rot90(x, 1, [1, 2]) tensor([[[1, 3], [0, 2]], [[5, 7], [4, 6]]]) torch.histc(input, bins=100, min=0, max=0, out=None) → Tensor¶ 计算张量的直方图。 元素被分类为 min 和 max 之间的等宽单元。 如果 min 和 max 均为零，则使用数据的最小值和最大值。 Parameters input (Tensor) – the input tensor. 箱 (python：int )–直方图箱数 min (python：int )–范围的下限(包括） 最大 (python：int )–范围的上限(包括） out (Tensor, optional) – the output tensor. Returns 直方图表示为张量 Return type Tensor Example: >>> torch.histc(torch.tensor([1., 2, 1]), bins=4, min=0, max=3) tensor([ 0., 2., 1., 0.]) torch.meshgrid(*tensors, **kwargs)¶ 取张量(每个张量可以是标量或一维向量），并创建 N 维网格，其中通过扩展定义 第网格。 和输入超出其他输入定义的尺寸。 Args: 张量(张量列表）：标量或一维张量的列表。 标量将被自动视为大小为的张量 Returns: seq(张量序列）：如果输入的张量为，则输出也将具有张量，其中所有张量均为。 Example: &gt;&gt;&gt; x = torch.tensor([1, 2, 3]) &gt;&gt;&gt; y = torch.tensor([4, 5, 6]) &gt;&gt;&gt; grid_x, grid_y = torch.meshgrid(x, y) &gt;&gt;&gt; grid_x tensor([[1, 1, 1], [2, 2, 2], [3, 3, 3]]) &gt;&gt;&gt; grid_y tensor([[4, 5, 6], [4, 5, 6], [4, 5, 6]]) torch.renorm(input, p, dim, maxnorm, out=None) → Tensor¶ 返回一个张量，其中input沿维度dim的每个子张量均被规范化，以使子张量的 p -norm 小于值maxnorm Note 如果某行的范数低于 maxnorm ，则该行不变 Parameters input (Tensor) – the input tensor. p (python：float )–范数计算的能力 暗淡的 (python：int )–切片以获得子张量的维度 maxnorm (python：float )–保持每个子张量低于的最大规范 out (Tensor, optional) – the output tensor. Example: >>> x = torch.ones(3, 3) >>> x[1].fill_(2) tensor([ 2., 2., 2.]) >>> x[2].fill_(3) tensor([ 3., 3., 3.]) >>> x tensor([[ 1., 1., 1.], [ 2., 2., 2.], [ 3., 3., 3.]]) >>> torch.renorm(x, 1, 0, 5) tensor([[ 1.0000, 1.0000, 1.0000], [ 1.6667, 1.6667, 1.6667], [ 1.6667, 1.6667, 1.6667]]) torch.repeat_interleave()¶ torch.repeat_interleave(input, repeats, dim=None) → Tensor 重复张量的元素。 Warning 这与torch.repeat()不同，但与 numpy.repeat 相似。 Parameters input (Tensor) – the input tensor. 重复 (tensor 或 python：int )–每个元素的重复次数。 重复播放以适合给定轴的形状。 暗淡的 (python：int ， 可选）–沿其重复值的尺寸。 默认情况下，使用展平的输入数组，并返回展平的输出数组。 Returns Repeated tensor which has the same shape as input, except along the 给定的轴。 Return type Tensor Example: >>> x = torch.tensor([1, 2, 3]) >>> x.repeat_interleave(2) tensor([1, 1, 2, 2, 3, 3]) >>> y = torch.tensor([[1, 2], [3, 4]]) >>> torch.repeat_interleave(y, 2) tensor([1, 1, 2, 2, 3, 3, 4, 4]) >>> torch.repeat_interleave(y, 3, dim=1) tensor([[1, 1, 1, 2, 2, 2], [3, 3, 3, 4, 4, 4]]) >>> torch.repeat_interleave(y, torch.tensor([1, 2]), dim=0) tensor([[1, 2], [3, 4], [3, 4]]) torch.repeat_interleave(repeats) → Tensor 如果重复为张量([n1，n2，n3，…]），则输出将为张量([0，0，…，1，1， …，2，2，…，…]），其中 0 出现 n1 次， 1 出现 n2 次，[ 2 出现 n3 次，等等。 torch.roll(input, shifts, dims=None) → Tensor¶ 沿给定尺寸滚动张量。 移出最后位置的元素将重新引入第一个位置。 如果未指定尺寸，则张量将在滚动之前变平，然后恢复为原始形状。 Parameters input (Tensor) – the input tensor. 移位 (python：int 或 python：ints 的元组）–张量元素移位的位数 。 如果 shifts 是一个元组，则 dims 必须是相同大小的元组，并且每个维度将滚动相应的值 变暗 (python：int 或 tuple of python：ints )–滚动轴 Example: >>> x = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8]).view(4, 2) >>> x tensor([[1, 2], [3, 4], [5, 6], [7, 8]]) >>> torch.roll(x, 1, 0) tensor([[7, 8], [1, 2], [3, 4], [5, 6]]) >>> torch.roll(x, -1, 0) tensor([[3, 4], [5, 6], [7, 8], [1, 2]]) >>> torch.roll(x, shifts=(2, 1), dims=(0, 1)) tensor([[6, 5], [8, 7], [2, 1], [4, 3]]) torch.tensordot(a, b, dims=2)¶ 返回 a 和 b 在多个维度上的收缩。 tensordot 实现了广义矩阵乘积。 Parameters a (tensor)–左张量收缩 b (tensor)–右张量收缩 变暗 (python：int 或 python：integers 的两个列表的元组）–要收缩的尺寸数或尺寸的显式列表 分别用于a和b 当使用整数参数dims = 调用并且a和b的维数分别为和时，它将计算 当使用列表形式的dims调用时，给定的尺寸将代替a的最后一个和的第一个收缩。 这些尺寸的尺寸必须匹配，但是 tensordot 将处理广播的尺寸。 Examples: >>> a = torch.arange(60.).reshape(3, 4, 5) >>> b = torch.arange(24.).reshape(4, 3, 2) >>> torch.tensordot(a, b, dims=([1, 0], [0, 1])) tensor([[4400., 4730.], [4532., 4874.], [4664., 5018.], [4796., 5162.], [4928., 5306.]]) >>> a = torch.randn(3, 4, 5, device='cuda') >>> b = torch.randn(4, 5, 6, device='cuda') >>> c = torch.tensordot(a, b, dims=2).cpu() tensor([[ 8.3504, -2.5436, 6.2922, 2.7556, -1.0732, 3.2741], [ 3.3161, 0.0704, 5.0187, -0.4079, -4.3126, 4.8744], [ 0.8223, 3.9445, 3.2168, -0.2400, 3.4117, 1.7780]]) torch.trace(input) → Tensor¶ 返回输入二维矩阵对角线元素的总和。 Example: >>> x = torch.arange(1., 10.).view(3, 3) >>> x tensor([[ 1., 2., 3.], [ 4., 5., 6.], [ 7., 8., 9.]]) >>> torch.trace(x) tensor(15.) torch.tril(input, diagonal=0, out=None) → Tensor¶ 返回矩阵(2-D 张量）或矩阵批次input的下三角部分，结果张量out的其他元素设置为 0。 矩阵的下三角部分定义为对角线之上和之下的元素。 参数 diagonal 控制要考虑的对角线。 如果 diagonal = 0，则保留主对角线上和下方的所有元素。 正值包括在主对角线上方的对角线，同样，负值排除在主对角线下方的对角线。 主对角线是的索引集，其中是矩阵的维数。 Parameters input (Tensor) – the input tensor. diagonal (python:int__, optional) – the diagonal to consider out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(3, 3) >>> a tensor([[-1.0813, -0.8619, 0.7105], [ 0.0935, 0.1380, 2.2112], [-0.3409, -0.9828, 0.0289]]) >>> torch.tril(a) tensor([[-1.0813, 0.0000, 0.0000], [ 0.0935, 0.1380, 0.0000], [-0.3409, -0.9828, 0.0289]]) >>> b = torch.randn(4, 6) >>> b tensor([[ 1.2219, 0.5653, -0.2521, -0.2345, 1.2544, 0.3461], [ 0.4785, -0.4477, 0.6049, 0.6368, 0.8775, 0.7145], [ 1.1502, 3.2716, -1.1243, -0.5413, 0.3615, 0.6864], [-0.0614, -0.7344, -1.3164, -0.7648, -1.4024, 0.0978]]) >>> torch.tril(b, diagonal=1) tensor([[ 1.2219, 0.5653, 0.0000, 0.0000, 0.0000, 0.0000], [ 0.4785, -0.4477, 0.6049, 0.0000, 0.0000, 0.0000], [ 1.1502, 3.2716, -1.1243, -0.5413, 0.0000, 0.0000], [-0.0614, -0.7344, -1.3164, -0.7648, -1.4024, 0.0000]]) >>> torch.tril(b, diagonal=-1) tensor([[ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [ 0.4785, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [ 1.1502, 3.2716, 0.0000, 0.0000, 0.0000, 0.0000], [-0.0614, -0.7344, -1.3164, 0.0000, 0.0000, 0.0000]]) torch.tril_indices(row, col, offset=0, dtype=torch.long, device='cpu', layout=torch.strided) → Tensor¶ 返回 2×N 张量中row-col矩阵的下三角部分的索引，其中第一行包含所有索引的行坐标，第二行包含列坐标。 索引是根据行然后按列排序的。 The lower triangular part of the matrix is defined as the elements on and below the diagonal. 参数offset控制要考虑的对角线。 如果offset = 0，则保留主对角线上和下方的所有元素。 正值包括在主对角线上方的对角线，同样，负值排除在主对角线下方的对角线。 主要对角线是的索引集，其中是矩阵的尺寸。 注意：在“ cuda”上运行时，行* col 必须小于，以防止计算期间溢出。 Parameters 行(int）–二维矩阵中的行数。 col (int）–二维矩阵中的列数。 偏移量(int）–与主对角线的对角线偏移。 默认值：如果未提供，则为 0。 dtype (torch.dtype ，可选）–返回张量的所需数据类型。 默认值：如果None，torch.long。 device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. 布局 (torch.layout ，可选）–当前仅支持torch.strided。 Example:: >>> a = torch.tril_indices(3, 3) >>> a tensor([[0, 1, 1, 2, 2, 2], [0, 0, 1, 0, 1, 2]]) >>> a = torch.tril_indices(4, 3, -1) >>> a tensor([[1, 2, 2, 3, 3, 3], [0, 0, 1, 0, 1, 2]]) >>> a = torch.tril_indices(4, 3, 1) >>> a tensor([[0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3], [0, 1, 0, 1, 2, 0, 1, 2, 0, 1, 2]]) torch.triu(input, diagonal=0, out=None) → Tensor¶ 返回矩阵(2-D 张量）或矩阵批次input的上三角部分，结果张量out的其他元素设置为 0。 矩阵的上三角部分定义为对角线上方和上方的元素。 参数 diagonal 控制要考虑的对角线。 如果 diagonal = 0，则保留主对角线上和上方的所有元素。 正值排除主要对角线上方的对角线，同样，负值包括主要对角线下方的对角线。 主对角线是的索引集，其中是矩阵的维数。 Parameters input (Tensor) – the input tensor. diagonal (python:int__, optional) – the diagonal to consider out (Tensor, optional) – the output tensor. Example: >>> a = torch.randn(3, 3) >>> a tensor([[ 0.2309, 0.5207, 2.0049], [ 0.2072, -1.0680, 0.6602], [ 0.3480, -0.5211, -0.4573]]) >>> torch.triu(a) tensor([[ 0.2309, 0.5207, 2.0049], [ 0.0000, -1.0680, 0.6602], [ 0.0000, 0.0000, -0.4573]]) >>> torch.triu(a, diagonal=1) tensor([[ 0.0000, 0.5207, 2.0049], [ 0.0000, 0.0000, 0.6602], [ 0.0000, 0.0000, 0.0000]]) >>> torch.triu(a, diagonal=-1) tensor([[ 0.2309, 0.5207, 2.0049], [ 0.2072, -1.0680, 0.6602], [ 0.0000, -0.5211, -0.4573]]) >>> b = torch.randn(4, 6) >>> b tensor([[ 0.5876, -0.0794, -1.8373, 0.6654, 0.2604, 1.5235], [-0.2447, 0.9556, -1.2919, 1.3378, -0.1768, -1.0857], [ 0.4333, 0.3146, 0.6576, -1.0432, 0.9348, -0.4410], [-0.9888, 1.0679, -1.3337, -1.6556, 0.4798, 0.2830]]) >>> torch.triu(b, diagonal=1) tensor([[ 0.0000, -0.0794, -1.8373, 0.6654, 0.2604, 1.5235], [ 0.0000, 0.0000, -1.2919, 1.3378, -0.1768, -1.0857], [ 0.0000, 0.0000, 0.0000, -1.0432, 0.9348, -0.4410], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.4798, 0.2830]]) >>> torch.triu(b, diagonal=-1) tensor([[ 0.5876, -0.0794, -1.8373, 0.6654, 0.2604, 1.5235], [-0.2447, 0.9556, -1.2919, 1.3378, -0.1768, -1.0857], [ 0.0000, 0.3146, 0.6576, -1.0432, 0.9348, -0.4410], [ 0.0000, 0.0000, -1.3337, -1.6556, 0.4798, 0.2830]]) torch.triu_indices(row, col, offset=0, dtype=torch.long, device='cpu', layout=torch.strided) → Tensor¶ 返回 2×N 张量中row x col矩阵的上三角部分的索引，其中第一行包含所有索引的行坐标，第二行包含列坐标。 索引是根据行然后按列排序的。 The upper triangular part of the matrix is defined as the elements on and above the diagonal. 参数offset控制要考虑的对角线。 如果offset = 0，则保留主对角线上和上方的所有元素。 正值排除主要对角线上方的对角线，同样，负值包括主要对角线下方的对角线。 主要对角线是的索引集，其中是矩阵的尺寸。 NOTE: when running on ‘cuda’, row * col must be less than to prevent overflow during calculation. Parameters row (int) – number of rows in the 2-D matrix. col (int) – number of columns in the 2-D matrix. offset (int) – diagonal offset from the main diagonal. Default: if not provided, 0. dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, torch.long. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). device will be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. layout (torch.layout, optional) – currently only support torch.strided. Example:: >>> a = torch.triu_indices(3, 3) >>> a tensor([[0, 0, 0, 1, 1, 2], [0, 1, 2, 1, 2, 2]]) >>> a = torch.triu_indices(4, 3, -1) >>> a tensor([[0, 0, 0, 1, 1, 1, 2, 2, 3], [0, 1, 2, 0, 1, 2, 1, 2, 2]]) >>> a = torch.triu_indices(4, 3, 1) >>> a tensor([[0, 0, 1], [1, 2, 2]]) BLAS 和 LAPACK 操作 torch.addbmm(beta=1, input, alpha=1, batch1, batch2, out=None) → Tensor¶ 执行存储在batch1和batch2中的矩阵的批矩阵矩阵乘积，并减少加法步骤(所有矩阵乘法沿第一维累积）。 input被添加到最终结果中。 batch1和batch2必须是 3D 张量，每个张量包含相同数量的矩阵。 如果batch1是张量，batch2是张量，则input必须是可广播的，带有张量，而out将是张量。 。 对于类型为 FloatTensor 或 DoubleTensor 的输入，参数beta和alpha必须为实数，否则应为整数。 Parameters beta (数字 ， 可选）– input(）的乘数 输入 (tensor)–要添加的矩阵 alpha (编号 ， 可选）– batch1 @ batch2 (）的乘数 batch1 (tensor)–第一批要相乘的矩阵 batch2 (tensor)–要相乘的第二批矩阵 out (Tensor, optional) – the output tensor. Example: >>> M = torch.randn(3, 5) >>> batch1 = torch.randn(10, 3, 4) >>> batch2 = torch.randn(10, 4, 5) >>> torch.addbmm(M, batch1, batch2) tensor([[ 6.6311, 0.0503, 6.9768, -12.0362, -2.1653], [ -4.8185, -1.4255, -6.6760, 8.9453, 2.5743], [ -3.8202, 4.3691, 1.0943, -1.1109, 5.4730]]) torch.addmm(beta=1, input, alpha=1, mat1, mat2, out=None) → Tensor¶ 对矩阵mat1和mat2进行矩阵乘法。 矩阵input被添加到最终结果中。 如果mat1是张量，mat2是张量，那么input必须是可广播的，带有张量，而out将是 张量。 alpha和beta分别是mat1和mat2与添加的矩阵input之间的矩阵向量乘积的比例因子。 对于类型为 FloatTensor 或 DoubleTensor 的输入，参数beta和alpha必须为实数，否则应为整数。 Parameters beta (Number__, optional) – multiplier for input () input (Tensor) – matrix to be added alpha (编号 ， 可选）– (）的乘数 mat1 (tensor)–要相乘的第一个矩阵 mat2 (tensor)–要相乘的第二个矩阵 out (Tensor, optional) – the output tensor. Example: >>> M = torch.randn(2, 3) >>> mat1 = torch.randn(2, 3) >>> mat2 = torch.randn(3, 3) >>> torch.addmm(M, mat1, mat2) tensor([[-4.8716, 1.4671, -1.3746], [ 0.7573, -3.9555, -2.8681]]) torch.addmv(beta=1, input, alpha=1, mat, vec, out=None) → Tensor¶ 执行矩阵mat与向量vec的矩阵向量积。 向量input被添加到最终结果中。 如果mat是张量，vec是大小 m 的一维张量，则input必须是可广播，且一维张量为 n 和out大小将是 n 大小的一维张量。 alpha和beta分别是mat和vec与添加的张量input之间的矩阵向量乘积的比例因子。 对于类型为 FloatTensor 或 DoubleTensor 的输入，参数beta和alpha必须为实数，否则应为整数 Parameters beta (Number__, optional) – multiplier for input () 输入 (tensor)–要添加的向量 alpha (编号 ， 可选）– (）的乘数 垫 (tensor)–要相乘的矩阵 vec (tensor)–要相乘的向量 out (Tensor, optional) – the output tensor. Example: >>> M = torch.randn(2) >>> mat = torch.randn(2, 3) >>> vec = torch.randn(3) >>> torch.addmv(M, mat, vec) tensor([-0.3768, -5.5565]) torch.addr(beta=1, input, alpha=1, vec1, vec2, out=None) → Tensor¶ 执行向量vec1和vec2的外积并将其添加到矩阵input中。 可选值beta和alpha分别是vec1和vec2与添加矩阵input之间的外部乘积的比例因子。 如果vec1是 n 大小的向量，而vec2是 m 大小的向量，则input必须是可广播且矩阵为 和out大小将是大小的矩阵。 For inputs of type FloatTensor or DoubleTensor, arguments beta and alpha must be real numbers, otherwise they should be integers Parameters beta (Number__, optional) – multiplier for input () input (Tensor) – matrix to be added alpha (编号 ， 可选）– (）的乘数 vec1 (tensor)–外积的第一个向量 vec2 (tensor)–外积的第二向量 out (Tensor, optional) – the output tensor. Example: >>> vec1 = torch.arange(1., 4.) >>> vec2 = torch.arange(1., 3.) >>> M = torch.zeros(3, 2) >>> torch.addr(M, vec1, vec2) tensor([[ 1., 2.], [ 2., 4.], [ 3., 6.]]) torch.baddbmm(beta=1, input, alpha=1, batch1, batch2, out=None) → Tensor¶ 在batch1和batch2中执行矩阵的批处理矩阵矩阵乘积。 input被添加到最终结果中。 batch1和batch2必须是 3D 张量，每个张量包含相同数量的矩阵。 如果batch1是张量，batch2是张量，那么input必须是可广播的，带有张量，而out将是 张量。 alpha和beta的含义均与 torch.addbmm() 中使用的缩放因子相同。 For inputs of type FloatTensor or DoubleTensor, arguments beta and alpha must be real numbers, otherwise they should be integers. Parameters beta (Number__, optional) – multiplier for input () input (Tensor) – the tensor to be added alpha (编号 ， 可选）– (）的乘数 batch1 (Tensor) – the first batch of matrices to be multiplied batch2 (Tensor) – the second batch of matrices to be multiplied out (Tensor, optional) – the output tensor. Example: >>> M = torch.randn(10, 3, 5) >>> batch1 = torch.randn(10, 3, 4) >>> batch2 = torch.randn(10, 4, 5) >>> torch.baddbmm(M, batch1, batch2).size() torch.Size([10, 3, 5]) torch.bmm(input, mat2, out=None) → Tensor¶ 对input和mat2中存储的矩阵执行批处理矩阵矩阵乘积。 input和mat2必须是 3D 张量，每个张量包含相同数量的矩阵。 如果input是张量，mat2是张量，out将是张量。 Note 该功能不广播。 有关广播矩阵产品，请参见 torch.matmul() 。 Parameters 输入 (tensor)–要相乘的第一批矩阵 mat2 (tensor)–第二批矩阵相乘 out (Tensor, optional) – the output tensor. Example: >>> input = torch.randn(10, 3, 4) >>> mat2 = torch.randn(10, 4, 5) >>> res = torch.bmm(input, mat2) >>> res.size() torch.Size([10, 3, 5]) torch.chain_matmul(*matrices)¶ 返回 2-D 张量的矩阵乘积。 使用矩阵链顺序算法可以有效地计算该乘积，该算法选择以算术运算 ([CLRS])产生最低成本的顺序。 注意，由于这是一个计算乘积的函数，因此必须大于或等于 2；因此，必须大于或等于 2。 如果等于 2，则返回平凡的矩阵矩阵乘积。 如果为 1，则为空操作-原始矩阵按原样返回。 Parameters 矩阵(张量... )–由 2 个或多个 2D 张量确定其乘积的序列。 Returns 如果张量的尺寸为，则乘积将为尺寸。 Return type Tensor Example: >>> a = torch.randn(3, 4) >>> b = torch.randn(4, 5) >>> c = torch.randn(5, 6) >>> d = torch.randn(6, 7) >>> torch.chain_matmul(a, b, c, d) tensor([[ -2.3375, -3.9790, -4.1119, -6.6577, 9.5609, -11.5095, -3.2614], [ 21.4038, 3.3378, -8.4982, -5.2457, -10.2561, -2.4684, 2.7163], [ -0.9647, -5.8917, -2.3213, -5.2284, 12.8615, -12.2816, -2.5095]]) torch.cholesky(input, upper=False, out=None) → Tensor¶ 计算对称正定矩阵或一批对称正定矩阵的 Cholesky 分解。 如果upper为True，则返回的矩阵U为上三角，分解形式为： 如果upper为False，则返回的矩阵L为下三角，分解形式为： 如果upper为True，并且为一批对称的正定矩阵，则返回的张量将由各个矩阵的上三角 Cholesky 因子组成。 同样，当upper为False时，返回的张量将由每个单独矩阵的下三角 Cholesky 因子组成。 Parameters 输入 (tensor)–大小为的输入张量，其中 * 为零或更多个批处理尺寸，包括 对称正定矩阵。 上 (bool ， 可选）–指示是否返回上三角矩阵或下三角矩阵的标志。 默认值：False out (tensor ， 可选）–输出矩阵 Example: >>> a = torch.randn(3, 3) >>> a = torch.mm(a, a.t()) # make symmetric positive-definite >>> l = torch.cholesky(a) >>> a tensor([[ 2.4112, -0.7486, 1.4551], [-0.7486, 1.3544, 0.1294], [ 1.4551, 0.1294, 1.6724]]) >>> l tensor([[ 1.5528, 0.0000, 0.0000], [-0.4821, 1.0592, 0.0000], [ 0.9371, 0.5487, 0.7023]]) >>> torch.mm(l, l.t()) tensor([[ 2.4112, -0.7486, 1.4551], [-0.7486, 1.3544, 0.1294], [ 1.4551, 0.1294, 1.6724]]) >>> a = torch.randn(3, 2, 2) >>> a = torch.matmul(a, a.transpose(-1, -2)) + 1e-03 # make symmetric positive-definite >>> l = torch.cholesky(a) >>> z = torch.matmul(l, l.transpose(-1, -2)) >>> torch.max(torch.abs(z - a)) # Max non-zero tensor(2.3842e-07) torch.cholesky_inverse(input, upper=False, out=None) → Tensor¶ 使用其 Cholesky 因子计算对称正定矩阵的逆：返回矩阵inv。 使用 LAPACK 例程dpotri和spotri(以及相应的 MAGMA 例程）计算逆。 如果upper为False，则为下三角，这样返回的张量为 如果upper为True，或未提供，则为上三角，使得返回的张量为 Parameters 输入 (tensor)–输入二维张量，上或下三角 Cholesky 因子 上部 (bool ， 可选）–是否返回下部(默认）或上部三角矩阵 out (tensor ， 可选）– inv 的输出张量 Example: >>> a = torch.randn(3, 3) >>> a = torch.mm(a, a.t()) + 1e-05 * torch.eye(3) # make symmetric positive definite >>> u = torch.cholesky(a) >>> a tensor([[ 0.9935, -0.6353, 1.5806], [ -0.6353, 0.8769, -1.7183], [ 1.5806, -1.7183, 10.6618]]) >>> torch.cholesky_inverse(u) tensor([[ 1.9314, 1.2251, -0.0889], [ 1.2251, 2.4439, 0.2122], [-0.0889, 0.2122, 0.1412]]) >>> a.inverse() tensor([[ 1.9314, 1.2251, -0.0889], [ 1.2251, 2.4439, 0.2122], [-0.0889, 0.2122, 0.1412]]) torch.cholesky_solve(input, input2, upper=False, out=None) → Tensor¶ 给定其 Cholesky 因子矩阵，以正半定矩阵解线性方程组。 如果upper为False，则为且下部三角形，并且返回 c 使得： 如果upper为True，则不提供为上三角形，并且返回 c ，使得： torch.cholesky_solve(b，u）可以接受 2D 输入 b，u 或一批 2D 矩阵的输入。 如果输入为批次，则返回成批输出 c Parameters 输入 (tensor)–大小为的输入矩阵，其中为零或更大批处理尺寸 input2 (tensor)–大小为的输入矩阵，其中为零个或多个由上或下三角组成的批处理尺寸 胆固醇系数 上 (bool ， 可选）–是否考虑将 Cholesky 因子视为下三角矩阵还是上三角矩阵。 默认值：False。 输出 (tensor ， 可选）– c 的输出张量 Example: >>> a = torch.randn(3, 3) >>> a = torch.mm(a, a.t()) # make symmetric positive definite >>> u = torch.cholesky(a) >>> a tensor([[ 0.7747, -1.9549, 1.3086], [-1.9549, 6.7546, -5.4114], [ 1.3086, -5.4114, 4.8733]]) >>> b = torch.randn(3, 2) >>> b tensor([[-0.6355, 0.9891], [ 0.1974, 1.4706], [-0.4115, -0.6225]]) >>> torch.cholesky_solve(b, u) tensor([[ -8.1625, 19.6097], [ -5.8398, 14.2387], [ -4.3771, 10.4173]]) >>> torch.mm(a.inverse(), b) tensor([[ -8.1626, 19.6097], [ -5.8398, 14.2387], [ -4.3771, 10.4173]]) torch.dot(input, tensor) → Tensor¶ 计算两个张量的点积(内积）。 Note 该功能不广播。 Example: >>> torch.dot(torch.tensor([2, 3]), torch.tensor([2, 1])) tensor(7) torch.eig(input, eigenvectors=False, out=None) -> (Tensor, Tensor)¶ 计算实方矩阵的特征值和特征向量。 Note 由于特征值和特征向量可能很复杂，因此仅 torch.symeig() 支持反向传递 Parameters 输入 (tensor)–形状为的方阵，将为其计算特征值和特征向量 特征向量 (bool )– True以计算特征值和特征向量； 否则，将仅计算特征值 out (元组 ， 可选）–输出张量 Returns 包含的 namedtuple(特征值，特征向量） 特征值(tensor）：形状。 每行是input的特征值，其中第一个元素是实部，第二个元素是虚部。 特征值不一定是有序的。 特征向量(tensor）：如果eigenvectors=False为空，则为张量。 否则，可以使用形状的张量来计算对应特征值的归一化(单位长度）特征向量，如下所示。 如果对应的特征值[j] 是实数，则特征向量[：，j] 列是与特征值[j] 相对应的特征向量。 如果相应的特征值[j] 和特征值[j + 1] 形成复共轭对，则真实特征向量可以计算为，。 Return type (张量，张量） torch.geqrf(input, out=None) -> (Tensor, Tensor)¶ 这是直接调用 LAPACK 的底层函数。 该函数返回[eqg0f] 的 LAPACK 文档中定义的 namedtuple(a，tau）。 通常，您通常要使用 torch.qr() 。 计算input的 QR 分解，但不将和构造为明确的单独矩阵。 而是直接调用基础的 LAPACK 函数？geqrf ，该函数产生一系列“基本反射器”。 有关更多详细信息，请参见 geqrf 的 LAPACK 文档。 Parameters 输入 (tensor)–输入矩阵 out (元组 ， 可选）–(张量，张量）的输出元组 torch.ger(input, vec2, out=None) → Tensor¶ input和vec2的外部乘积。 如果input是大小为的向量，而vec2是大小为的向量，则out必须是大小为的矩阵。 Note This function does not broadcast. Parameters 输入 (tensor)–一维输入向量 vec2 (tensor)–一维输入向量 输出 (tensor ， 可选）–可选输出矩阵 Example: >>> v1 = torch.arange(1., 5.) >>> v2 = torch.arange(1., 4.) >>> torch.ger(v1, v2) tensor([[ 1., 2., 3.], [ 2., 4., 6.], [ 3., 6., 9.], [ 4., 8., 12.]]) torch.inverse(input, out=None) → Tensor¶ 取方阵input的逆。 input可以是 2D 方形张量的批处理，在这种情况下，此函数将返回由各个逆组成的张量。 Note 无论原始步幅如何，返回的张量都将被转置，即使用 input.contiguous(）。transpose(-2，-1）.stride(）之类的步幅 Parameters 输入 (tensor)–大小为的输入张量，其中 * 为零或更大批处理尺寸 out (Tensor, optional) – the output tensor. Example: >>> x = torch.rand(4, 4) >>> y = torch.inverse(x) >>> z = torch.mm(x, y) >>> z tensor([[ 1.0000, -0.0000, -0.0000, 0.0000], [ 0.0000, 1.0000, 0.0000, 0.0000], [ 0.0000, 0.0000, 1.0000, 0.0000], [ 0.0000, -0.0000, -0.0000, 1.0000]]) >>> torch.max(torch.abs(z - torch.eye(4))) # Max non-zero tensor(1.1921e-07) >>> # Batched inverse example >>> x = torch.randn(2, 3, 4, 4) >>> y = torch.inverse(x) >>> z = torch.matmul(x, y) >>> torch.max(torch.abs(z - torch.eye(4).expand_as(x))) # Max non-zero tensor(1.9073e-06) torch.det(input) → Tensor¶ 计算平方矩阵或批次平方矩阵的行列式。 Note 当input不可逆时，向后通过 det() 内部使用 SVD 结果。 在这种情况下，如果input没有不同的奇异值，则通过 det() 向后翻倍将不稳定。 有关详细信息，请参见 svd() 。 Parameters 输入 (tensor)–大小为(*, n, n)的输入张量，其中*为零或更大的批量尺寸。 Example: >>> A = torch.randn(3, 3) >>> torch.det(A) tensor(3.7641) >>> A = torch.randn(3, 2, 2) >>> A tensor([[[ 0.9254, -0.6213], [-0.5787, 1.6843]], [[ 0.3242, -0.9665], [ 0.4539, -0.0887]], [[ 1.1336, -0.4025], [-0.7089, 0.9032]]]) >>> A.det() tensor([1.1990, 0.4099, 0.7386]) torch.logdet(input) → Tensor¶ 计算平方矩阵或批次平方矩阵的对数行列式。 Note 如果input的对数行列式为 0，则结果为-inf；如果input的行列式为负数，则结果为nan。 Note 当input不可逆时，向后通过 logdet() 内部使用 SVD 结果。 在这种情况下，如果input没有不同的奇异值，则通过 logdet() 向后翻倍将不稳定。 有关详细信息，请参见 svd() 。 Parameters input (Tensor) – the input tensor of size (*, n, n) where * is zero or more batch dimensions. Example: >>> A = torch.randn(3, 3) >>> torch.det(A) tensor(0.2611) >>> torch.logdet(A) tensor(-1.3430) >>> A tensor([[[ 0.9254, -0.6213], [-0.5787, 1.6843]], [[ 0.3242, -0.9665], [ 0.4539, -0.0887]], [[ 1.1336, -0.4025], [-0.7089, 0.9032]]]) >>> A.det() tensor([1.1990, 0.4099, 0.7386]) >>> A.det().log() tensor([ 0.1815, -0.8917, -0.3031]) torch.slogdet(input) -> (Tensor, Tensor)¶ 计算平方矩阵或一批平方矩阵的行列式的正负号和对数绝对值。 Note 如果input的行列式为零，则返回(0, -inf)。 Note 当input不可逆时，向后通过 slogdet() 内部使用 SVD 结果。 在这种情况下，如果input没有不同的奇异值，则通过 slogdet() 向后翻倍将不稳定。 有关详细信息，请参见 svd() 。 Parameters input (Tensor) – the input tensor of size (*, n, n) where * is zero or more batch dimensions. Returns 包含行列式的符号和绝对行列式的对数值的 namedtuple(符号，logabsdet）。 Example: >>> A = torch.randn(3, 3) >>> A tensor([[ 0.0032, -0.2239, -1.1219], [-0.6690, 0.1161, 0.4053], [-1.6218, -0.9273, -0.0082]]) >>> torch.det(A) tensor(-0.7576) >>> torch.logdet(A) tensor(nan) >>> torch.slogdet(A) torch.return_types.slogdet(sign=tensor(-1.), logabsdet=tensor(-0.2776)) torch.lstsq(input, A, out=None) → Tensor¶ 计算大小为的满秩矩阵和大小为的矩阵的最小二乘和最小范数问题的解。 如果， lstsq() 解决了最小二乘问题： 如果， lstsq() 解决了最小范数问题： 返回的张量具有形状。 的前行包含解决方案。 如果为，则每列中解决方案的剩余平方和由该列其余行中元素的平方和得出。 Note GPU 不支持的情况。 Parameters 输入 (tensor)–矩阵 A (tensor)–由矩阵构成的 out (元组 ， 可选）–可选目标张量 Returns 一个命名元组(解决方案，QR），其中包含： 解(tensor）：最小二乘解 QR (Tensor )：QR 因式分解的详细信息 Return type (Tensor, Tensor) Note 无论输入矩阵的跨度如何，返回的矩阵将始终进行转置。 即，他们将具有(1，m）而不是(m，1）的步幅。 Example: >>> A = torch.tensor([[1., 1, 1], [2, 3, 4], [3, 5, 2], [4, 2, 5], [5, 4, 3]]) >>> B = torch.tensor([[-10., -3], [ 12, 14], [ 14, 12], [ 16, 16], [ 18, 16]]) >>> X, _ = torch.lstsq(B, A) >>> X tensor([[ 2.0000, 1.0000], [ 1.0000, 1.0000], [ 1.0000, 2.0000], [ 10.9635, 4.8501], [ 8.9332, 5.2418]]) torch.lu(A, pivot=True, get_infos=False, out=None)¶ 计算矩阵或矩阵批次的 LU 分解A。 返回一个包含 LU 分解和A的枢轴的元组。 如果pivot设置为True，则完成旋转。 Note 该函数返回的枢轴为 1 索引。 如果pivot为False，则返回的枢轴是一个张量，该张量填充有适当大小的零。 Note pivot = False的 LU 分解不适用于 CPU，尝试这样做会引发错误。 但是，CUDA 可使用pivot = False的 LU 分解。 Note 该函数不会检查分解是否成功，因为get_infos为True，因为返回元组的第三个元素中存在分解的状态。 Note 在 CUDA 设备上批量处理大小小于或等于 32 的平方矩阵的情况下，由于 MAGMA 库中的错误，对奇异矩阵重复进行 LU 因式分解(请参见岩浆问题 13）。 Parameters A (tensor)–大小的张量 枢轴 (bool ， 可选）–控制是否完成枢轴。 默认值：True get_infos (bool ， 可选）–如果设置为True，则返回信息 IntTensor。 默认值：False 输出(元组 ， 可选）–可选输出元组。 如果get_infos为True，则元组中的元素为 Tensor，IntTensor 和 IntTensor。 如果get_infos为False，则元组中的元素为 Tensor，IntTensor。 默认值：None Returns 张量的元组包含 分解(tensor）：大小的分解 枢轴 (IntTensor )：大小为的枢轴 信息 (IntTensor ，可选）：如果get_infos为True，则此张量为，其中非零值表示是否 矩阵分解或每个小批量成功或失败 Return type (张量，IntTensor，IntTensor(可选）） Example: >>> A = torch.randn(2, 3, 3) >>> A_LU, pivots = torch.lu(A) >>> A_LU tensor([[[ 1.3506, 2.5558, -0.0816], [ 0.1684, 1.1551, 0.1940], [ 0.1193, 0.6189, -0.5497]], [[ 0.4526, 1.2526, -0.3285], [-0.7988, 0.7175, -0.9701], [ 0.2634, -0.9255, -0.3459]]]) >>> pivots tensor([[ 3, 3, 3], [ 3, 3, 3]], dtype=torch.int32) >>> A_LU, pivots, info = torch.lu(A, get_infos=True) >>> if info.nonzero().size(0) == 0: ... print('LU factorization succeeded for all samples!') LU factorization succeeded for all samples! torch.lu_solve(input, LU_data, LU_pivots, out=None) → Tensor¶ 使用 torch.lu() 中 A 的部分枢轴 LU 分解，返回线性系统的 LU 解。 Parameters b (tensor)–尺寸为的 RHS 张量，其中为零或更大的批量尺寸。 LU_data (tensor)– A 从 torch.lu() 大小为的 A 的透视 LU 分解，其中为 零个或多个批次尺寸。 LU_pivots (IntTensor )– LU 分解的枢轴来自 torch.lu() ，大小为，其中为零或更大的批生产尺寸。 LU_pivots的批次尺寸必须等于LU_data的批次尺寸。 out (Tensor, optional) – the output tensor. Example: >>> A = torch.randn(2, 3, 3) >>> b = torch.randn(2, 3, 1) >>> A_LU = torch.lu(A) >>> x = torch.lu_solve(b, *A_LU) >>> torch.norm(torch.bmm(A, x) - b) tensor(1.00000e-07 * 2.8312) torch.lu_unpack(LU_data, LU_pivots, unpack_data=True, unpack_pivots=True)¶ 解压缩数据并从张量的 LU 分解中枢转。 返回张量的元组为(the pivots, the L tensor, the U tensor)。 Parameters LU_data (tensor)–打包 LU 分解数据 LU_pivots (tensor)–压缩 LU 分解枢轴 unpack_data (bool )–指示是否应拆包数据的标志 unpack_pivots (bool )–指示是否应拆开枢轴的标志 Examples: >>> A = torch.randn(2, 3, 3) >>> A_LU, pivots = A.lu() >>> P, A_L, A_U = torch.lu_unpack(A_LU, pivots) >>> >>> # can recover A from factorization >>> A_ = torch.bmm(P, torch.bmm(A_L, A_U)) >>> # LU factorization of a rectangular matrix: >>> A = torch.randn(2, 3, 2) >>> A_LU, pivots = A.lu() >>> P, A_L, A_U = torch.lu_unpack(A_LU, pivots) >>> P tensor([[[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]], [[0., 0., 1.], [0., 1., 0.], [1., 0., 0.]]]) >>> A_L tensor([[[ 1.0000, 0.0000], [ 0.4763, 1.0000], [ 0.3683, 0.1135]], [[ 1.0000, 0.0000], [ 0.2957, 1.0000], [-0.9668, -0.3335]]]) >>> A_U tensor([[[ 2.1962, 1.0881], [ 0.0000, -0.8681]], [[-1.0947, 0.3736], [ 0.0000, 0.5718]]]) >>> A_ = torch.bmm(P, torch.bmm(A_L, A_U)) >>> torch.norm(A_ - A) tensor(2.9802e-08) torch.matmul(input, other, out=None) → Tensor¶ 两个张量的矩阵乘积。 行为取决于张量的维数，如下所示： 如果两个张量都是一维的，则返回点积(标量）。 如果两个参数都是二维的，则返回矩阵矩阵乘积。 如果第一个自变量是一维的，第二个自变量是二维的，则为了矩阵乘法，会将 1 附加到其维上。 矩阵相乘后，将删除前置尺寸。 如果第一个参数为 2 维，第二个参数为 1 维，则返回矩阵向量乘积。 如果两个自变量至少为一维且至少一个自变量为 N 维(其中 N > 2），则返回批处理矩阵乘法。 如果第一个自变量是一维的，则将 1 附加到其维的前面，以实现批量矩阵乘法并在之后将其删除。 如果第二个参数是一维的，则将 1 附加到其维上，以实现成批矩阵倍数的目的，然后将其删除。 非矩阵(即批处理）尺寸是广播的(因此必须是可广播的）。 例如，如果input是张量，other是张量，则out将是张量。 Note 此功能的一维点积产品版本不支持out参数。 Parameters 输入 (tensor)–要相乘的第一个张量 其他 (tensor)–要相乘的第二张量 out (Tensor, optional) – the output tensor. Example: >>> # vector x vector >>> tensor1 = torch.randn(3) >>> tensor2 = torch.randn(3) >>> torch.matmul(tensor1, tensor2).size() torch.Size([]) >>> # matrix x vector >>> tensor1 = torch.randn(3, 4) >>> tensor2 = torch.randn(4) >>> torch.matmul(tensor1, tensor2).size() torch.Size([3]) >>> # batched matrix x broadcasted vector >>> tensor1 = torch.randn(10, 3, 4) >>> tensor2 = torch.randn(4) >>> torch.matmul(tensor1, tensor2).size() torch.Size([10, 3]) >>> # batched matrix x batched matrix >>> tensor1 = torch.randn(10, 3, 4) >>> tensor2 = torch.randn(10, 4, 5) >>> torch.matmul(tensor1, tensor2).size() torch.Size([10, 3, 5]) >>> # batched matrix x broadcasted matrix >>> tensor1 = torch.randn(10, 3, 4) >>> tensor2 = torch.randn(4, 5) >>> torch.matmul(tensor1, tensor2).size() torch.Size([10, 3, 5]) torch.matrix_power(input, n) → Tensor¶ 返回平方矩阵乘幂n的矩阵。 对于一批矩阵，将每个单独的矩阵提高到幂n。 如果n为负，则矩阵的逆(如果是可逆的）提高到幂n。 对于一批矩阵，将成批的逆(如果可逆）提高到幂n。 如果n为 0，则返回一个单位矩阵。 Parameters input (Tensor) – the input tensor. n (python：int )–将矩阵提升为 Example: >>> a = torch.randn(2, 2, 2) >>> a tensor([[[-1.9975, -1.9610], [ 0.9592, -2.3364]], [[-1.2534, -1.3429], [ 0.4153, -1.4664]]]) >>> torch.matrix_power(a, 3) tensor([[[ 3.9392, -23.9916], [ 11.7357, -0.2070]], [[ 0.2468, -6.7168], [ 2.0774, -0.8187]]]) torch.matrix_rank(input, tol=None, symmetric=False) → Tensor¶ 返回二维张量的数值等级。 默认情况下，使用 SVD 完成计算矩阵等级的方法。 如果symmetric为True，则假定input是对称的，并且通过获得特征值来完成秩的计算。 tol是阈值，低于该阈值的奇异值(或当symmetric为True时的特征值）被视为 0。如果未指定tol，则tol设置为S.max() * max(S.size()) * eps，其中 S 是奇异值(或symmetric是True时的特征值），eps是input数据类型的 epsilon 值。 Parameters 输入 (tensor)–输入二维张量 tol (python：float ， 可选）–公差值。 默认值：None 对称 (bool ， 可选）–指示input是否对称。 默认值：False Example: >>> a = torch.eye(10) >>> torch.matrix_rank(a) tensor(10) >>> b = torch.eye(10) >>> b[0, 0] = 0 >>> torch.matrix_rank(b) tensor(9) torch.mm(input, mat2, out=None) → Tensor¶ 对矩阵input和mat2进行矩阵乘法。 如果input是张量，mat2是张量，out将是张量。 Note This function does not broadcast. For broadcasting matrix products, see torch.matmul(). Parameters 输入 (tensor)–要相乘的第一个矩阵 mat2 (Tensor) – the second matrix to be multiplied out (Tensor, optional) – the output tensor. Example: >>> mat1 = torch.randn(2, 3) >>> mat2 = torch.randn(3, 3) >>> torch.mm(mat1, mat2) tensor([[ 0.4851, 0.5037, -0.3633], [-0.0760, -3.6705, 2.4784]]) torch.mv(input, vec, out=None) → Tensor¶ 执行矩阵input与向量vec的矩阵向量积。 如果input是张量，vec是大小的一维张量，则out将是大小的一维。 Note This function does not broadcast. Parameters 输入 (tensor)–要相乘的矩阵 vec (Tensor) – vector to be multiplied out (Tensor, optional) – the output tensor. Example: >>> mat = torch.randn(2, 3) >>> vec = torch.randn(3) >>> torch.mv(mat, vec) tensor([ 1.0404, -0.6361]) torch.orgqr(input, input2) → Tensor¶ 根据 torch.geqrf() 返回的(输入，input2）元组，计算 QR 分解的正交矩阵 Q 。 这将直接调用基础的 LAPACK 函数？orgqr 。 有关更多详细信息，请参见 orgqr 的 LAPACK 文档。 Parameters 输入 (tensor)–来自 torch.geqrf() 的 a 。 input2 (tensor)–来自 torch.geqrf() 的 tau 。 torch.ormqr(input, input2, input3, left=True, transpose=False) → Tensor¶ 将垫(由input3赋予）乘以 torch.geqrf() 表示的 QR 因式分解的正交 Q 矩阵，该矩阵由(a (tau）(由[input，input2给予））。 这将直接调用基础的 LAPACK 函数？ormqr 。 有关更多详细信息，请参见 ormqr 的 LAPACK 文档。 Parameters input (Tensor) – the a from torch.geqrf(). input2 (Tensor) – the tau from torch.geqrf(). input3 (tensor)–要相乘的矩阵。 torch.pinverse(input, rcond=1e-15) → Tensor¶ 计算 2D 张量的伪逆(也称为 Moore-Penrose 逆）。 请查看 Moore-Penrose 逆了解更多详细信息 Note 使用奇异值分解实现此方法。 Note 在矩阵 [1] 的元素中，伪逆不一定是连续函数。 因此，导数并不总是存在，并且仅以恒定等级存在 [2] 。 但是，由于使用 SVD 结果实现，因此该方法可向后传播，并且可能不稳定。 由于内部使用 SVD，因此双向后退也会变得不稳定。 有关更多详细信息，请参见 svd() 。 Parameters 输入 (tensor)–大小为的输入张量，其中为零或更大批处理尺寸 rcond (python：float )–一个浮点值，用于确定小的奇异值的截止值。 默认值：1e-15 Returns 尺寸为的input的伪逆。 Example: >>> input = torch.randn(3, 5) >>> input tensor([[ 0.5495, 0.0979, -1.4092, -0.1128, 0.4132], [-1.1143, -0.3662, 0.3042, 1.6374, -0.9294], [-0.3269, -0.5745, -0.0382, -0.5922, -0.6759]]) >>> torch.pinverse(input) tensor([[ 0.0600, -0.1933, -0.2090], [-0.0903, -0.0817, -0.4752], [-0.7124, -0.1631, -0.2272], [ 0.1356, 0.3933, -0.5023], [-0.0308, -0.1725, -0.5216]]) >>> # Batched pinverse example >>> a = torch.randn(2,6,3) >>> b = torch.pinverse(a) >>> torch.matmul(b, a) tensor([[[ 1.0000e+00, 1.6391e-07, -1.1548e-07], [ 8.3121e-08, 1.0000e+00, -2.7567e-07], [ 3.5390e-08, 1.4901e-08, 1.0000e+00]], [[ 1.0000e+00, -8.9407e-08, 2.9802e-08], [-2.2352e-07, 1.0000e+00, 1.1921e-07], [ 0.0000e+00, 8.9407e-08, 1.0000e+00]]]) torch.qr(input, some=True, out=None) -> (Tensor, Tensor)¶ 计算矩阵或一批矩阵input的 QR 分解，并返回张量的命名元组(Q，R），使得其中是正交矩阵或一批正交矩阵，而是 上三角矩阵或一批上三角矩阵。 如果some为True，则此函数返回瘦(​​精简）QR 因式分解。 否则，如果some为False，则此函数返回完整的 QR 因式分解。 Note 如果input的元素的幅度较大，则可能会失去精度 Note 尽管它始终可以为您提供有效的分解，但在各个平台上可能不会给您相同的分解-这取决于您的 LAPACK 实现。 Parameters 输入 (tensor)–大小为的输入张量，其中 * 为零个或多个批处理尺寸，包括尺寸矩阵 。 一些 (bool ， 可选）–设置为True可减少 QR 分解，将False进行完全 QR 分解。 out (元组 ， 可选）– Q 和 R 张量的元组 input = torch.matmul(Q, R)。 Q 和 R 的尺寸分别为和，如果some:为True则为，否则为。 Example: >>> a = torch.tensor([[12., -51, 4], [6, 167, -68], [-4, 24, -41]]) >>> q, r = torch.qr(a) >>> q tensor([[-0.8571, 0.3943, 0.3314], [-0.4286, -0.9029, -0.0343], [ 0.2857, -0.1714, 0.9429]]) >>> r tensor([[ -14.0000, -21.0000, 14.0000], [ 0.0000, -175.0000, 70.0000], [ 0.0000, 0.0000, -35.0000]]) >>> torch.mm(q, r).round() tensor([[ 12., -51., 4.], [ 6., 167., -68.], [ -4., 24., -41.]]) >>> torch.mm(q.t(), q).round() tensor([[ 1., 0., 0.], [ 0., 1., -0.], [ 0., -0., 1.]]) >>> a = torch.randn(3, 4, 5) >>> q, r = torch.qr(a, some=False) >>> torch.allclose(torch.matmul(q, r), a) True >>> torch.allclose(torch.matmul(q.transpose(-2, -1), q), torch.eye(5)) True torch.solve(input, A, out=None) -> (Tensor, Tensor)¶ 此函数将求解返回到由表示的线性方程组和 A 的 LU 分解，以便将其作为命名元解决方案 LU 。 LU 包含 L 和 U 因素，用于 A 的 LU 分解。 torch.solve(B，A）可以接受 2D 输入 B，A 或一批 2D 矩阵的输入。 如果输入是批次，则返回批次输出解决方案 LU 。 Note 不管原始步幅如何，返回的矩阵解决方案和 LU 都将转置，即，步幅类似 B.contiguous(）。transpose(-1，-2）。 stride(）和 A.contiguous(）。transpose(-1，-2）.stride(）。 Parameters 输入 (tensor)–大小为的输入矩阵，其中为零或更大的批次尺寸。 A (tensor)–大小为的输入方阵，其中为零或更大的批处理尺寸。 输出(( tensor ， tensor ） ， 可选）–可选输出元组。 Example: >>> A = torch.tensor([[6.80, -2.11, 5.66, 5.97, 8.23], [-6.05, -3.30, 5.36, -4.44, 1.08], [-0.45, 2.58, -2.70, 0.27, 9.04], [8.32, 2.71, 4.35, -7.17, 2.14], [-9.67, -5.14, -7.26, 6.08, -6.87]]).t() >>> B = torch.tensor([[4.02, 6.19, -8.22, -7.57, -3.03], [-1.56, 4.00, -8.67, 1.75, 2.86], [9.81, -4.09, -4.57, -8.61, 8.99]]).t() >>> X, LU = torch.solve(B, A) >>> torch.dist(B, torch.mm(A, X)) tensor(1.00000e-06 * 7.0977) >>> # Batched solver example >>> A = torch.randn(2, 3, 1, 4, 4) >>> B = torch.randn(2, 3, 1, 4, 6) >>> X, LU = torch.solve(B, A) >>> torch.dist(B, A.matmul(X)) tensor(1.00000e-06 * 3.6386) torch.svd(input, some=True, compute_uv=True, out=None) -> (Tensor, Tensor, Tensor)¶ 该函数返回一个命名元组(U, S, V)，它是输入实数矩阵或一批实数矩阵input这样的奇异值分解。 如果some为True(默认值），则该方法返回简化后的奇异值分解，即，如果input的最后两个维为m和n，则返回 U 和 V 矩阵将仅包含正交列。 如果compute_uv为False，则返回的 U 和 V 矩阵将分别为形状为和的零矩阵。 some在这里将被忽略。 Note 奇异值以降序返回。 如果input是一批矩阵，则该批中每个矩阵的奇异值将按降序返回。 Note SVD 在 CPU 上的实现使用 LAPACK 例程？gesdd (分治算法）代替？gesvd 来提高速度。 类似地，GPU 上的 SVD 也使用 MAGMA 例程 gesdd 。 Note 无论原始步幅如何，返回的矩阵 U 都将转置，即步幅为U.contiguous().transpose(-2, -1).stride() Note 向后通过 U 和 V 输出时，需要格外小心。 仅当input具有所有不同的奇异值的完整等级时，此类操作才真正稳定。 否则，由于未正确定义渐变，可能会出现NaN。 另外，请注意，即使原始后退仅出现在 S 上，两次后退通常也会通过 U 和 V 进行额外的后退。 Note 当some = False时，U[..., :, min(m, n):]和V[..., :, min(m, n):]上的梯度将向后忽略，因为这些向量可以是子空间的任意基。 Note 当compute_uv = False时，由于向后操作需要来自正向的 U 和 V ，因此无法执行反向。 Parameters 输入 (tensor)–大小为的输入张量，其中 * 是零个或多个由组成的批量 矩阵。 一些 (bool ， 可选）–控制返回的 U 和 V compute_uv (bool ， 可选）–选择是否计算 U 和 V 或不 out (元组 ， 可选）–张量的输出元组 Example: >>> a = torch.randn(5, 3) >>> a tensor([[ 0.2364, -0.7752, 0.6372], [ 1.7201, 0.7394, -0.0504], [-0.3371, -1.0584, 0.5296], [ 0.3550, -0.4022, 1.5569], [ 0.2445, -0.0158, 1.1414]]) >>> u, s, v = torch.svd(a) >>> u tensor([[ 0.4027, 0.0287, 0.5434], [-0.1946, 0.8833, 0.3679], [ 0.4296, -0.2890, 0.5261], [ 0.6604, 0.2717, -0.2618], [ 0.4234, 0.2481, -0.4733]]) >>> s tensor([2.3289, 2.0315, 0.7806]) >>> v tensor([[-0.0199, 0.8766, 0.4809], [-0.5080, 0.4054, -0.7600], [ 0.8611, 0.2594, -0.4373]]) >>> torch.dist(a, torch.mm(torch.mm(u, torch.diag(s)), v.t())) tensor(8.6531e-07) >>> a_big = torch.randn(7, 5, 3) >>> u, s, v = torch.svd(a_big) >>> torch.dist(a_big, torch.matmul(torch.matmul(u, torch.diag_embed(s)), v.transpose(-2, -1))) tensor(2.6503e-06) torch.symeig(input, eigenvectors=False, upper=True, out=None) -> (Tensor, Tensor)¶ 此函数返回实数对称矩阵input或一批实数对称矩阵的特征值和特征向量，由一个命名元组(特征值，特征向量）表示。 此函数计算input的所有特征值(和向量），使得。 布尔参数eigenvectors定义特征向量和特征值或仅特征值的计算。 如果为False，则仅计算特征值。 如果为True，则同时计算特征值和特征向量。 由于假定输入矩阵input是对称的，因此默认情况下仅使用上三角部分。 如果upper为False，则使用下部三角形部分。 Note 特征值以升序返回。 如果input是一批矩阵，则该批中每个矩阵的特征值将以升序返回。 Note 无论原始步幅如何，返回的矩阵 V 都将转置，即使用步幅 V.contiguous(）。transpose(-1，-2）.stride(）。 Note 向后通过输出时，需要格外小心。 只有当所有特征值都不同时，这种操作才真正稳定。 否则，可能会出现NaN，因为未正确定义渐变。 Parameters 输入 (tensor)–大小为的输入张量，其中 * 为零或更多由对称矩阵组成的批处理尺寸。 特征向量(布尔 ， 可选）–控制是否必须计算特征向量 上部(布尔 ， 可选）–控制是考虑上三角区域还是下三角区域 out (tuple__, optional) – the output tuple of (Tensor, Tensor) Returns A namedtuple (eigenvalues, eigenvectors) containing 特征值(tensor）：形状。 特征值按升序排列。 特征向量(tensor）：形状。 如果eigenvectors=False，则为张量为空。 否则，该张量包含input的正交特征向量。 Return type (Tensor, Tensor) Examples: >>> a = torch.randn(5, 5) >>> a = a + a.t() # To make a symmetric >>> a tensor([[-5.7827, 4.4559, -0.2344, -1.7123, -1.8330], [ 4.4559, 1.4250, -2.8636, -3.2100, -0.1798], [-0.2344, -2.8636, 1.7112, -5.5785, 7.1988], [-1.7123, -3.2100, -5.5785, -2.6227, 3.1036], [-1.8330, -0.1798, 7.1988, 3.1036, -5.1453]]) >>> e, v = torch.symeig(a, eigenvectors=True) >>> e tensor([-13.7012, -7.7497, -2.3163, 5.2477, 8.1050]) >>> v tensor([[ 0.1643, 0.9034, -0.0291, 0.3508, 0.1817], [-0.2417, -0.3071, -0.5081, 0.6534, 0.4026], [-0.5176, 0.1223, -0.0220, 0.3295, -0.7798], [-0.4850, 0.2695, -0.5773, -0.5840, 0.1337], [ 0.6415, -0.0447, -0.6381, -0.0193, -0.4230]]) >>> a_big = torch.randn(5, 2, 2) >>> a_big = a_big + a_big.transpose(-2, -1) # To make a_big symmetric >>> e, v = a_big.symeig(eigenvectors=True) >>> torch.allclose(torch.matmul(v, torch.matmul(e.diag_embed(), v.transpose(-2, -1))), a_big) True torch.trapz()¶ torch.trapz(y, x, *, dim=-1) → Tensor 使用梯形法则估计暗的。 Parameters y (tensor)–积分函数的值 x (tensor)–函数 y 的采样点。 如果 x 不按升序排列，则其减小的时间间隔将对估计的积分产生负面影响(即遵循惯例）。 暗淡的 (python：int )–集成所沿的维度。 默认情况下，使用最后一个尺寸。 Returns 一个与输入形状相同的张量，除了删除了暗淡的。 返回的张量的每个元素代表沿着暗淡的估计积分。 Example: >>> y = torch.randn((2, 3)) >>> y tensor([[-2.1156, 0.6857, -0.2700], [-1.2145, 0.5540, 2.0431]]) >>> x = torch.tensor([[1, 3, 4], [1, 2, 3]]) >>> torch.trapz(y, x) tensor([-1.2220, 0.9683]) torch.trapz(y, *, dx=1, dim=-1) → Tensor 如上所述，但是采样点以 dx 的距离均匀间隔。 Parameters y (Tensor) – The values of the function to integrate dx (python：float )–采样 y 的点之间的距离。 dim (python:int) – The dimension along which to integrate. By default, use the last dimension. Returns A Tensor with the same shape as the input, except with dim removed. Each element of the returned tensor represents the estimated integral along dim. torch.triangular_solve(input, A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)¶ 用三角系数矩阵和多个右侧求解方程组。 特别是，求解并假定为带有默认关键字参数的上三角。 torch.triangular_solve(b，A）可以接受 2D 输入 b，A 或一批 2D 矩阵的输入。 如果输入为批次，则返回成批输出 X Parameters 输入 (tensor)–尺寸为的多个右侧，其中是零个以上的批次尺寸(） A (tensor)–大小为的输入三角系数矩阵，其中为零或更大的批处理尺寸 上 (bool ， 可选）–是求解方程的上三角系统(默认）还是下三角系统 方程组。 默认值：True。 换位(布尔 ， 可选）–在将发送到求解器之前是否应该对其进行换位。 默认值：False。 单边形(布尔 ， 可选）– 是否为单位三角形。 如果为 True，则假定的对角元素为 1，并且未从引用。 默认值：False。 Returns 一个命名元组(解决方案，cloned_coefficient）其中 cloned_coefficient 是的克隆，而解决方案是到的解决方案(或其他变体） 的方程组，具体取决于关键字参数。） Examples: >>> A = torch.randn(2, 2).triu() >>> A tensor([[ 1.1527, -1.0753], [ 0.0000, 0.7986]]) >>> b = torch.randn(2, 3) >>> b tensor([[-0.0210, 2.3513, -1.5492], [ 1.5429, 0.7403, -1.0243]]) >>> torch.triangular_solve(b, A) torch.return_types.triangular_solve( solution=tensor([[ 1.7841, 2.9046, -2.5405], [ 1.9320, 0.9270, -1.2826]]), cloned_coefficient=tensor([[ 1.1527, -1.0753], [ 0.0000, 0.7986]])) 实用工具 torch.compiled_with_cxx11_abi()¶ 返回 PyTorch 是否使用 _GLIBCXX_USE_CXX11_ABI = 1 构建 torch.result_type(tensor1, tensor2) → dtype¶ 返回 torch.dtype ，这是对提供的输入张量执行算术运算得出的。 有关类型升级逻辑的更多信息，请参见类型升级文档。 Parameters 张量 1 (tensor 或 数字）–输入张量或数字 张量 2 (tensor 或 数字）–输入张量或数字 Example: >>> torch.result_type(torch.tensor([1, 2], dtype=torch.int), 1.0) torch.float32 >>> torch.result_type(torch.tensor([1, 2], dtype=torch.uint8), torch.tensor(1)) torch.uint8 torch.can_cast(from, to) → bool¶ 确定在类型提升文档中描述的 PyTorch 转换规则下是否允许类型转换。 Parameters 中的 (dpython：type )–原始的 torch.dtype 。 到 (dpython：type )–目标 torch.dtype 。 Example: >>> torch.can_cast(torch.double, torch.float) True >>> torch.can_cast(torch.float, torch.int) False torch.promote_types(type1, type2) → dtype¶ 返回尺寸和标量种类最小的 torch.dtype ，其大小不小于 type1 或 type2 。 有关类型升级逻辑的更多信息，请参见类型升级文档。 Parameters type1 (torch.dtype)– type2 (torch.dtype)– Example: >>> torch.promote_types(torch.int32, torch.float32)) torch.float32 >>> torch.promote_types(torch.uint8, torch.long) torch.long 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:35:32 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"75.html":{"url":"75.html","title":"torch.nn","keywords":"","body":"torch.nn 原文： https://pytorch.org/docs/stable/nn.html 参数 class torch.nn.Parameter¶ 一种被视为模块参数的 Tensor。 参数是 Tensor 子类，当与 Module 一起使用时，具有非常特殊的属性-将它们分配为模块属性时，它们会自动添加到其列表中 参数，并会出现，例如 在 parameters() 迭代器中。 分配张量不会产生这种效果。 这是因为可能要在模型中缓存一些临时状态，例如 RNN 的最后一个隐藏状态。 如果不存在 Parameter 这样的类，这些临时人员也将被注册。 参数 数据 (tensor)–参数张量。 require_grad (布尔 ， 可选）–如果参数需要渐变。 有关更多详细信息，请参见从后向中排除子图。 默认值： True 货柜 模组 class torch.nn.Module¶ 所有神经网络模块的基类。 您的模型也应该继承此类。 模块也可以包含其他模块，从而可以将它们嵌套在树形结构中。 您可以将子模块分配为常规属性： import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x)) return F.relu(self.conv2(x)) 以这种方式分配的子模块将被注册，并且当您调用 to() 等时，也会转换其参数。 add_module(name, module)¶ 将子模块添加到当前模块。 可以使用给定名称将模块作为属性访问。 Parameters 名称(字符串）–子模块的名称。 可以使用给定名称从该模块访问子模块 模块 (模块)–要添加到该模块的子模块。 apply(fn)¶ 将fn递归应用于每个子模块(由.children()返回）以及自身。 典型的用法包括初始化模型的参数(另请参见 torch.nn.init)。 Parameters fn (Module ->无）–应用于每个子模块的功能 退货 自 返回类型 模块 例： >>> def init_weights(m): >>> print(m) >>> if type(m) == nn.Linear: >>> m.weight.data.fill_(1.0) >>> print(m.weight) >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2)) >>> net.apply(init_weights) Linear(in_features=2, out_features=2, bias=True) Parameter containing: tensor([[ 1., 1.], [ 1., 1.]]) Linear(in_features=2, out_features=2, bias=True) Parameter containing: tensor([[ 1., 1.], [ 1., 1.]]) Sequential( (0): Linear(in_features=2, out_features=2, bias=True) (1): Linear(in_features=2, out_features=2, bias=True) ) Sequential( (0): Linear(in_features=2, out_features=2, bias=True) (1): Linear(in_features=2, out_features=2, bias=True) ) buffers(recurse=True)¶ 返回模块缓冲区上的迭代器。 Parameters 递归 (bool )–如果为 True，则产生此模块和所有子模块的缓冲区。 否则，仅产生作为该模块直接成员的缓冲区。 Yields torch张紧器 –模块缓冲区 Example: >>> for buf in model.buffers(): >>> print(type(buf.data), buf.size()) (20L,) (20L, 1L, 5L, 5L) children()¶ 返回直接子代模块上的迭代器。 Yields 模块 –子模块 cpu()¶ 将所有模型参数和缓冲区移至 CPU。 Returns self Return type Module cuda(device=None)¶ 将所有模型参数和缓冲区移至 GPU。 这也使相关的参数并缓冲不同的对象。 因此，在构建优化程序之前，如果模块在优化过程中可以在 GPU 上运行，则应调用它。 Parameters 设备 (python：int ， 可选）–如果指定，则所有参数都将复制到该设备 Returns self Return type Module double()¶ 将所有浮点参数和缓冲区强制转换为double数据类型。 Returns self Return type Module dump_patches = False¶ 这为 load_state_dict() 提供了更好的 BC 支持。 在 state_dict() 中，版本号将保存为返回状态 dict 的属性 _metadata 中，因此会被腌制。 _metadata 是字典，其键遵循状态 dict 的命名约定。 有关如何在加载中使用此信息的信息，请参见_load_from_state_dict。 如果从模块添加/删除了新的参数/缓冲区，则该数字将增加，并且模块的 _load_from_state_dict 方法可以比较版本号，并且如果状态 dict 来自更改之前，则可以进行适当的更改。 eval()¶ 将模块设置为评估模式。 这仅对某些模块有影响。 请参阅特定模块的文档，以了解其在训练/评估模式下的行为的详细信息(如果受到影响），例如 Dropout ，BatchNorm等 这等效于 self.train(False) 。 Returns self Return type Module extra_repr()¶ 设置模块的额外表示形式 要打印自定义的额外信息，您应该在自己的模块中重新实现此方法。 单行和多行字符串都是可以接受的。 float()¶ 将所有浮点参数和缓冲区强制转换为 float 数据类型。 Returns self Return type Module forward(*input)¶ 定义每次调用时执行的计算。 应该被所有子类覆盖。 注意 尽管需要在此函数中定义向前传递的配方，但此后应调用 Module 实例，而不是此实例，因为前者负责运行已注册的钩子，而后者则静默地忽略它们。 half()¶ 将所有浮点参数和缓冲区强制转换为half数据类型。 Returns self Return type Module load_state_dict(state_dict, strict=True)¶ 将参数和缓冲区从 state_dict 复制到此模块及其子代中。 如果strict为True，则 state_dict 的键必须与该模块的 state_dict() 功能返回的键完全匹配。 Parameters state_dict (dict )–包含参数和持久缓冲区的 dict。 严格 (bool ， 可选）–是否严格要求 state_dict 中的键与 此模块的 state_dict() 功能返回的键。 默认值：True Returns missing_keys 是包含缺失键的 str 列表 意外的密钥是包含意外密钥的 str 列表 Return type 具有missing_keys和unexpected_keys字段的NamedTuple modules()¶ 返回网络中所有模块的迭代器。 Yields 模块 –网络中的模块 Note 重复的模块仅返回一次。 在以下示例中，l将仅返回一次。 Example: >>> l = nn.Linear(2, 2) >>> net = nn.Sequential(l, l) >>> for idx, m in enumerate(net.modules()): print(idx, '->', m) 0 -> Sequential( (0): Linear(in_features=2, out_features=2, bias=True) (1): Linear(in_features=2, out_features=2, bias=True) ) 1 -> Linear(in_features=2, out_features=2, bias=True) named_buffers(prefix='', recurse=True)¶ 返回模块缓冲区上的迭代器，同时产生缓冲区的名称和缓冲区本身。 Parameters 前缀 (str )–前缀为所有缓冲区名称的前缀。 recurse (bool) – if True, then yields buffers of this module and all submodules. Otherwise, yields only buffers that are direct members of this module. Yields (字符串，torch张量） –包含名称和缓冲区的元组 Example: >>> for name, buf in self.named_buffers(): >>> if name in ['running_var']: >>> print(buf.size()) named_children()¶ 返回直接子模块的迭代器，同时产生模块名称和模块本身。 Yields (字符串，模块） –包含名称和子模块的元组 Example: >>> for name, module in model.named_children(): >>> if name in ['conv4', 'conv5']: >>> print(module) named_modules(memo=None, prefix='')¶ 在网络中的所有模块上返回一个迭代器，同时产生模块的名称和模块本身。 Yields (字符串，模块） –名称和模块的元组 Note Duplicate modules are returned only once. In the following example, l will be returned only once. Example: >>> l = nn.Linear(2, 2) >>> net = nn.Sequential(l, l) >>> for idx, m in enumerate(net.named_modules()): print(idx, '->', m) 0 -> ('', Sequential( (0): Linear(in_features=2, out_features=2, bias=True) (1): Linear(in_features=2, out_features=2, bias=True) )) 1 -> ('0', Linear(in_features=2, out_features=2, bias=True)) named_parameters(prefix='', recurse=True)¶ 返回模块参数上的迭代器，同时产生参数名称和参数本身。 Parameters 前缀 (str )–前缀所有参数名称。 递归 (bool )–如果为 True，则产生该模块和所有子模块的参数。 否则，仅产生作为该模块直接成员的参数。 Yields (字符串，参数） –包含名称和参数的元组 Example: >>> for name, param in self.named_parameters(): >>> if name in ['bias']: >>> print(param.size()) parameters(recurse=True)¶ 返回模块参数上的迭代器。 通常将其传递给优化器。 Parameters recurse (bool) – if True, then yields parameters of this module and all submodules. Otherwise, yields only parameters that are direct members of this module. Yields 参数 –模块参数 Example: >>> for param in model.parameters(): >>> print(type(param.data), param.size()) (20L,) (20L, 1L, 5L, 5L) register_backward_hook(hook)¶ 在模块上注册向后挂钩。 每当计算相对于模块输入的梯度时，都会调用该挂钩。 挂钩应具有以下签名： hook(module, grad_input, grad_output) -> Tensor or None 如果模块具有多个输入或输出，则grad_input和grad_output可能是元组。 挂钩不应该修改其参数，但可以选择相对于输入返回新的梯度，该梯度将在后续计算中代替grad_input使用。 Returns 可以通过调用handle.remove()来删除添加的钩子的句柄 Return type torch.utils.hooks.RemovableHandle 警告 对于执行许多操作的复杂 Module ，当前实现不具有所呈现的行为。 在某些故障情况下，grad_input和grad_output将仅包含输入和输出的子集的梯度​​。 对于此类 Module ，应在特定的输入或输出上直接使用 torch.Tensor.register_hook() 以获取所需的梯度。 register_buffer(name, tensor)¶ 将持久性缓冲区添加到模块。 这通常用于注册不应被视为模型参数的缓冲区。 例如，BatchNorm 的running_mean不是参数，而是持久状态的一部分。 可以使用给定名称将缓冲区作为属性进行访问。 Parameters 名称(字符串）–缓冲区的名称。 可以使用给定名称从此模块访问缓冲区 张量 (tensor)–要注册的缓冲区。 Example: >>> self.register_buffer('running_mean', torch.zeros(num_features)) register_forward_hook(hook)¶ 在模块上注册一个前向挂钩。 每当 forward() 计算输出后，该挂钩都会被调用。 它应具有以下签名： hook(module, input, output) -> None or modified output 挂钩可以修改输出。 它可以就地修改输入，但是不会对正向产生影响，因为在调用 forward() 之后会调用它。 Returns a handle that can be used to remove the added hook by calling handle.remove() Return type torch.utils.hooks.RemovableHandle register_forward_pre_hook(hook)¶ 在模块上注册前向预钩。 每次调用 forward() 之前，都会调用该挂钩。 它应具有以下签名： hook(module, input) -> None or modified input 挂钩可以修改输入。 用户可以在挂钩中返回一个元组或一个修改后的值。 如果返回单个值，则将值包装到一个元组中(除非该值已经是一个元组）。 Returns a handle that can be used to remove the added hook by calling handle.remove() Return type torch.utils.hooks.RemovableHandle register_parameter(name, param)¶ 向模块添加参数。 可以使用给定名称将参数作为属性访问。 Parameters 名称(字符串）–参数的名称。 可以使用给定名称从此模块访问参数 参数 (参数)–要添加到模块的参数。 requires_grad_(requires_grad=True)¶ 更改 autograd 是否应记录此模块中参数的操作。 此方法就地设置参数的requires_grad属性。 此方法有助于冻结模块的一部分以分别微调或训练模型的各个部分(例如 GAN 训练）。 Parameters require_grad (bool )– autograd 是否应记录此模块中参数的操作。 默认值：True。 Returns self Return type Module state_dict(destination=None, prefix='', keep_vars=False)¶ 返回包含模块整个状态的字典。 包括参数和持久缓冲区(例如运行平均值）。 键是相应的参数和缓冲区名称。 Returns 包含模块整体状态的字典 Return type 字典 Example: >>> module.state_dict().keys() ['bias', 'weight'] to(*args, **kwargs)¶ 移动和/或强制转换参数和缓冲区。 这可以称为 to(device=None, dtype=None, non_blocking=False) to(dtype, non_blocking=False) to(tensor, non_blocking=False) 它的签名类似于 torch.Tensor.to() ，但仅接受所需的浮点dtype。 此外，此方法只会将浮点参数和缓冲区强制转换为dtype(如果给定）。 如果已给定，则积分参数和缓冲区将被移动device，但 dtypes 不变。 设置non_blocking时，如果可能，它将尝试相对于主机进行异步转换/移动，例如，将具有固定内存的 CPU 张量移动到 CUDA 设备。 请参见下面的示例。 Note 此方法就地修改模块。 Parameters 设备(torch.device）–该模块中参数和缓冲区的所需设备 dtype (torch.dtype）–此模块中浮点参数和缓冲区的所需浮点类型 张量 (torch张量)–张量，其 dtype 和 device 是此模块中所有参数和缓冲区的所需 dtype 和 device Returns self Return type Module Example: >>> linear = nn.Linear(2, 2) >>> linear.weight Parameter containing: tensor([[ 0.1913, -0.3420], [-0.5113, -0.2325]]) >>> linear.to(torch.double) Linear(in_features=2, out_features=2, bias=True) >>> linear.weight Parameter containing: tensor([[ 0.1913, -0.3420], [-0.5113, -0.2325]], dtype=torch.float64) >>> gpu1 = torch.device(\"cuda:1\") >>> linear.to(gpu1, dtype=torch.half, non_blocking=True) Linear(in_features=2, out_features=2, bias=True) >>> linear.weight Parameter containing: tensor([[ 0.1914, -0.3420], [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1') >>> cpu = torch.device(\"cpu\") >>> linear.to(cpu) Linear(in_features=2, out_features=2, bias=True) >>> linear.weight Parameter containing: tensor([[ 0.1914, -0.3420], [-0.5112, -0.2324]], dtype=torch.float16) train(mode=True)¶ 将模块设置为训练模式。 This has any effect only on certain modules. See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g. Dropout, BatchNorm, etc. Parameters 模式 (bool )–是设置训练模式(True）还是评估模式(False）。 默认值：True。 Returns self Return type Module type(dst_type)¶ 将所有参数和缓冲区强制转换为dst_type。 Parameters dst_type (python：type 或 字符串）–所需类型 Returns self Return type Module zero_grad()¶ 将所有模型参数的梯度设置为零。 顺序的 class torch.nn.Sequential(*args)¶ 顺序容器。 模块将按照在构造函数中传递的顺序添加到模块中。 或者，也可以传递模块的有序字典。 为了更容易理解，这是一个小示例： # Example of using Sequential model = nn.Sequential( nn.Conv2d(1,20,5), nn.ReLU(), nn.Conv2d(20,64,5), nn.ReLU() ) # Example of using Sequential with OrderedDict model = nn.Sequential(OrderedDict([ ('conv1', nn.Conv2d(1,20,5)), ('relu1', nn.ReLU()), ('conv2', nn.Conv2d(20,64,5)), ('relu2', nn.ReLU()) ])) 模块列表 class torch.nn.ModuleList(modules=None)¶ 将子模块保存在列表中。 ModuleList 可以像常规 Python 列表一样被索引，但是其中包含的模块已正确注册，并且对所有 Module 方法都是可见的。 Parameters 模块(可迭代 ， 可选）–可迭代的模块 Example: class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)]) def forward(self, x): # ModuleList can act as an iterable, or be indexed using ints for i, l in enumerate(self.linears): x = self.linears[i // 2](x) + l(x) return x append(module)¶ 将给定模块附加到列表的末尾。 Parameters 模块 (nn.Module)–要附加的模块 extend(modules)¶ 将可迭代的 Python 模块附加到列表的末尾。 Parameters 模块(可迭代）–可迭代的模块 insert(index, module)¶ 在列表中给定索引之前插入给定模块。 Parameters 索引 (python：int )–要插入的索引。 模块 (nn.Module)–要插入的模块 ModuleDict class torch.nn.ModuleDict(modules=None)¶ 将子模块保存在字典中。 ModuleDict 可以像常规的 Python 字典一样被索引，但是其中包含的模块已正确注册，并且对所有 Module 方法都是可见的。 ModuleDict 是有序字典， 插入顺序，以及 在 update() 中，OrderedDict或另一个 ModuleDict 的合并顺序 (update() 的顺序）。 请注意， update() 和其他无序映射类型(例如 Python 的普通dict）不会保留合并映射的顺序。 Parameters 模块(可迭代 ， 可选）–(字符串：模块）的映射(字典）或键值对的可迭代 类型(字符串，模块） Example: class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() self.choices = nn.ModuleDict({ 'conv': nn.Conv2d(10, 10, 3), 'pool': nn.MaxPool2d(3) }) self.activations = nn.ModuleDict([ ['lrelu', nn.LeakyReLU()], ['prelu', nn.PReLU()] ]) def forward(self, x, choice, act): x = self.choices[choice](x) x = self.activations[act](x) return x clear()¶ 从 ModuleDict 中删除所有项目。 items()¶ 返回一个可迭代的 ModuleDict 键/值对。 keys()¶ 返回一个可迭代的 ModuleDict 键。 pop(key)¶ 从 ModuleDict 中删除密钥并返回其模块。 Parameters 键(字符串）–从 ModuleDict 弹出的键 update(modules)¶ 使用来自映射或可迭代，覆盖现有键的键值对更新 ModuleDict 。 Note 如果modules是OrderedDict， ModuleDict 或键值对的可迭代项，则将保留其中的新元素顺序。 Parameters 模块(可迭代）–从字符串到 Module 的映射(字典），或键值对类型的可迭代(字符串， ] Module) values()¶ 返回一个 ModuleDict 值的可迭代值。 参数表 class torch.nn.ParameterList(parameters=None)¶ 将参数保存在列表中。 ParameterList 可以像常规 Python 列表一样被索引，但是其中包含的参数已正确注册，并且将由所有 Module 方法可见。 Parameters 参数(可迭代的 ， 可选）–可迭代的 Parameter Example: class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() self.params = nn.ParameterList([nn.Parameter(torch.randn(10, 10)) for i in range(10)]) def forward(self, x): # ParameterList can act as an iterable, or be indexed using ints for i, p in enumerate(self.params): x = self.params[i // 2].mm(x) + p.mm(x) return x append(parameter)¶ 在列表的末尾附加一个给定的参数。 Parameters 参数 (nn.Parameter)–要附加的参数 extend(parameters)¶ 将可迭代的 Python 参数附加到列表的末尾。 Parameters 参数(可迭代）–可迭代的参数 ParameterDict class torch.nn.ParameterDict(parameters=None)¶ 将参数保存在字典中。 可以像常规 Python 词典一样对 ParameterDict 进行索引，但是它包含的参数已正确注册，并且对所有 Module 方法都可见。 ParameterDict 是有序字典， the order of insertion, and 在 update() 中，OrderedDict或另一个 ParameterDict 的合并顺序 (update() 的顺序）。 请注意， update() 和其他无序映射类型(例如 Python 的普通dict）不会保留合并映射的顺序。 Parameters 参数(可迭代的 ， 可选）–(字符串： Parameter)的映射(字典） 或类型(字符串 Parameter)的键值对的可迭代 Example: class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() self.params = nn.ParameterDict({ 'left': nn.Parameter(torch.randn(5, 10)), 'right': nn.Parameter(torch.randn(5, 10)) }) def forward(self, x, choice): x = self.params[choice].mm(x) return x clear()¶ 从 ParameterDict 中删除所有项目。 items()¶ 返回一个 ParameterDict 键/值对的可迭代对象。 keys()¶ 返回一个可迭代的 ParameterDict 键。 pop(key)¶ 从 ParameterDict 中删除键并返回其参数。 Parameters 键(字符串）–从 ParameterDict 弹出的键 update(parameters)¶ 使用来自映射或可迭代，覆盖现有键的键值对更新 ParameterDict 。 Note 如果parameters是OrderedDict， ParameterDict 或键值对的可迭代项，则将保留其中的新元素顺序。 Parameters 参数(可迭代的）–从字符串到 Parameter 的映射(字典），或键值对类型的可迭代(字符串， ] Parameter) values()¶ 返回 ParameterDict 值的可迭代值。 卷积层 转换 1d class torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')¶ 在由多个输入平面组成的输入信号上应用一维卷积。 在最简单的情况下，具有输入大小和输出的图层的输出值可以精确地描述为： 其中是有效的互相关运算符，是批处理大小，表示通道数，是信号序列的长度。 stride控制互相关的步幅，单个数字或一个元素的元组。 对于padding点数，padding控制两侧的隐式零填充量。 dilation控制内核点之间的间距； 也称为àtrous 算法。 很难描述，但是此链接很好地展示了dilation的功能。 groups控制输入和输出之间的连接。 in_channels和out_channels必须都可以被groups整除。 例如， > 在组= 1 时，所有输入都卷积为所有输出。 >>> 在 groups = 2 时，该操作等效于并排设置两个 conv 层，每个 conv 层看到一半的输入通道，并产生一半的输出通道，并且随后都将它们级联。 >>> * 在 groups = in_channels时，每个输入通道都与自己的大小为的一组滤波器卷积。 Note 根据内核的大小，输入的(最后）几列可能会丢失，因为它是有效的互相关，而不是完整的互相关 。 由用户决定是否添加适当的填充。 Note 当组== in_channels 和 out_channels == K * in_channels 时，其中 K 是一个正整数，此操作在文献中也被称为深度卷积。 换句话说，对于大小为的输入，可以通过参数构造具有深度乘数 K 的深度卷积。 Note 在某些情况下，将 CUDA 后端与 CuDNN 一起使用时，该运算符可能会选择不确定的算法来提高性能。 如果不希望这样做，则可以通过设置torch.backends.cudnn.deterministic = True来使操作具有确定性(可能会降低性能）。 请参阅关于可再现性的注意事项作为背景。 Parameters in_channels (python：int )–输入图像中的通道数 out_channels (python：int )–卷积产生的通道数 kernel_size (python：int 或 元组）–卷积内核的大小 步幅 (python：int 或 元组 ， 可选）–步幅 卷积。 默认值：1 填充 (python：int 或 元组 ， 可选）–零填充 添加到输入的两侧。 默认值：0 padding_mode (字符串 ， 可选）– 零 扩展 (python：int 或 元组 ， 可选）–内核之间的间隔 元素。 默认值：1 组 (python：int ， 可选）–从输入通道到输出通道的阻塞连接数。 默认值：1 偏置 (bool ， 可选）–如果True，则向输出添加可学习的偏置。 默认值：True Shape: 输入： 输出：其中 Variables 〜Conv1d.weight (tensor)–形状为的模块的可学习重量。 这些权重的值来自，其中 〜Conv1d.bias (tensor)–形状模块的可学习偏差(out_channels）。 如果bias为True，则这些权重的值将从采样，其中 例子： >>> m = nn.Conv1d(16, 33, 3, stride=2) >>> input = torch.randn(20, 16, 50) >>> output = m(input) 转换 2d class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')¶ 对由多个输入平面组成的输入信号应用 2D 卷积。 在最简单的情况下，具有输入大小和输出的图层的输出值可以精确地描述为： 其中是有效的 2D 互相关运算符，是批处理大小，表示通道数，是输入平面的高度(以像素为单位），并且[ 是以像素为单位的宽度。 stride控制互相关的步幅，单个数字或元组。 对于每个维度的padding点数，padding控制两侧的隐式零填充量。 dilation controls the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this link has a nice visualization of what dilation does. groups controls the connections between inputs and outputs. in_channels and out_channels must both be divisible by groups. For example, > At groups=1, all inputs are convolved to all outputs. >>> At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels, and producing half the output channels, and both subsequently concatenated. >>> * 在 groups = in_channels时，每个输入通道都与自己的一组过滤器卷积，大小为。 参数kernel_size，stride，padding和dilation可以是： 单个int –在这种情况下，高度和宽度尺寸将使用相同的值 两个整数的tuple –在这种情况下，第一个 int 用于高度尺寸，第二个 int 用于宽度尺寸 Note 根据内核的大小，输入的(最后）几列可能会丢失，因为它是有效的互相关，而不是完整的互相关 。 由用户决定是否添加适当的填充。 Note When groups == in_channels and out_channels == K * in_channels, where K is a positive integer, this operation is also termed in literature as depthwise convolution. 换句话说，对于大小为的输入，可以通过参数构造具有深度乘数 K 的深度卷积。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters in_channels (python:int) – Number of channels in the input image out_channels (python:int) – Number of channels produced by the convolution kernel_size (python:int or tuple) – Size of the convolving kernel stride (python:int or tuple__, optional) – Stride of the convolution. Default: 1 填充 (python：int 或 元组 ， 可选）–零填充 添加到输入的两侧。 默认值：0 padding_mode (string__, optional) – zeros 扩展 (python：int 或 元组 ， 可选）–内核之间的间隔 元素。 默认值：1 组 (python：int ， 可选）–从输入通道到输出通道的阻塞连接数。 默认值：1 bias (bool__, optional) – If True, adds a learnable bias to the output. Default: True Shape: 输入： 输出：其中 Variables 〜Conv2d.weight (tensor)–形状为 的模块的可学习重量。 这些权重的值取自，其中 〜Conv2d.bias (tensor)–形状模块的可学习偏差(out_channels）。 如果bias为True，则这些权重的值将从采样，其中 Examples: >>> # With square kernels and equal stride >>> m = nn.Conv2d(16, 33, 3, stride=2) >>> # non-square kernels and unequal stride and with padding >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2)) >>> # non-square kernels and unequal stride and with padding and dilation >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1)) >>> input = torch.randn(20, 16, 50, 100) >>> output = m(input) 转换 3d class torch.nn.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')¶ 在由多个输入平面组成的输入信号上应用 3D 卷积。 在最简单的情况下，具有输入大小和输出的图层的输出值可以精确地描述为： 其中是有效的 3D 互相关运算符 stride控制互相关的步幅。 padding controls the amount of implicit zero-paddings on both sides for padding number of points for each dimension. dilation控制内核点之间的间距； 也称为àtrous 算法。 很难描述，但是此链接很好地展示了dilation的功能。 groups controls the connections between inputs and outputs. in_channels and out_channels must both be divisible by groups. For example, > At groups=1, all inputs are convolved to all outputs. >>> At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels, and producing half the output channels, and both subsequently concatenated. >>> * 在 groups = in_channels时，每个输入通道都与自己的大小为的一组滤波器卷积。 The parameters kernel_size, stride, padding, dilation can either be: 单个int –在这种情况下，深度，高度和宽度尺寸使用相同的值 三个整数的tuple –在这种情况下，第一个 int 用于深度尺寸，第二个 int 用于高度尺寸，第三个 int 为宽度尺寸 Note Depending of the size of your kernel, several (of the last) columns of the input might be lost, because it is a valid cross-correlation, and not a full cross-correlation. It is up to the user to add proper padding. Note When groups == in_channels and out_channels == K * in_channels, where K is a positive integer, this operation is also termed in literature as depthwise convolution. 换句话说，对于大小为的输入，可以通过参数构造具有深度乘数 K 的深度卷积。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters in_channels (python:int) – Number of channels in the input image out_channels (python:int) – Number of channels produced by the convolution kernel_size (python:int or tuple) – Size of the convolving kernel stride (python:int or tuple__, optional) – Stride of the convolution. Default: 1 填充 (python：int 或 元组 ， 可选）–零填充 添加到输入的所有三个方面。 默认值：0 padding_mode (string__, optional) – zeros dilation (python:int or tuple__, optional) – Spacing between kernel elements. Default: 1 groups (python:int__, optional) – Number of blocked connections from input channels to output channels. Default: 1 bias (bool__, optional) – If True, adds a learnable bias to the output. Default: True Shape: 输入： 输出：其中 Variables 〜Conv3d.weight (tensor)–形状为 的模块的可学习重量。 这些权重的值取自，其中 〜Conv3d.bias (tensor)–形状模块的可学习偏差(out_channels）。 如果bias为True，则这些权重的值将从采样，其中 Examples: >>> # With square kernels and equal stride >>> m = nn.Conv3d(16, 33, 3, stride=2) >>> # non-square kernels and unequal stride and with padding >>> m = nn.Conv3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(4, 2, 0)) >>> input = torch.randn(20, 16, 10, 50, 100) >>> output = m(input) ConvTranspose1d class torch.nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros')¶ 在由多个输入平面组成的输入图像上应用一维转置的卷积运算符。 该模块可以看作是 Conv1d 相对于其输入的梯度。 它也被称为分数步法卷积或反卷积(尽管它不是实际的反卷积运算）。 stride controls the stride for the cross-correlation. 对于dilation * (kernel_size - 1) - padding点数，padding控制两侧的隐式零填充量。 有关详细信息，请参见下面的注释。 output_padding控制添加到输出形状一侧的附加尺寸。 有关详细信息，请参见下面的注释。 dilation controls the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this link has a nice visualization of what dilation does. groups controls the connections between inputs and outputs. in_channels and out_channels must both be divisible by groups. For example, > At groups=1, all inputs are convolved to all outputs. >>> At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels, and producing half the output channels, and both subsequently concatenated. >>> * 在 groups = in_channels时，每个输入通道都与自己的一组过滤器(大小为）卷积。 Note Depending of the size of your kernel, several (of the last) columns of the input might be lost, because it is a valid cross-correlation, and not a full cross-correlation. It is up to the user to add proper padding. Note padding参数有效地将dilation * (kernel_size - 1) - padding的零填充量添加到两种输入大小。 进行设置时，以相同的参数初始化 Conv1d 和 ConvTranspose1d 时，它们在输入和输出形状方面彼此相反。 但是，当stride &gt; 1， Conv1d 将多个输入形状映射到相同的输出形状时。 提供output_padding可通过有效地增加一侧的计算输出形状来解决这种歧义。 请注意，output_padding仅用于查找输出形状，而实际上并未向输出添加零填充。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters in_channels (python:int) – Number of channels in the input image out_channels (python:int) – Number of channels produced by the convolution kernel_size (python:int or tuple) – Size of the convolving kernel stride (python:int or tuple__, optional) – Stride of the convolution. Default: 1 填充 (python：int 或 元组 ， 可选）– dilation * (kernel_size - 1) - padding 零填充将添加到输入的两侧。 默认值：0 output_padding (python：int 或 元组 ， 可选）–已添加其他大小 到输出形状的一侧。 默认值：0 groups (python:int__, optional) – Number of blocked connections from input channels to output channels. Default: 1 bias (bool__, optional) – If True, adds a learnable bias to the output. Default: True dilation (python:int or tuple__, optional) – Spacing between kernel elements. Default: 1 Shape: Input: Output: where Variables 〜ConvTranspose1d.weight (tensor)–形状为 的模块的可学习重量。 这些权重的值取自，其中 〜ConvTranspose1d.bias (tensor)–形状模块的可学习偏差(out_channels）。 如果bias为True，则这些权重的值将从采样，其中 ConvTranspose2d class torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros')¶ 在由多个输入平面组成的输入图像上应用二维转置卷积运算符。 该模块可以看作是 Conv2d 相对于其输入的梯度。 它也被称为分数步法卷积或反卷积(尽管它不是实际的反卷积运算）。 stride controls the stride for the cross-correlation. padding controls the amount of implicit zero-paddings on both sides for dilation * (kernel_size - 1) - padding number of points. See note below for details. output_padding controls the additional size added to one side of the output shape. See note below for details. dilation controls the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this link has a nice visualization of what dilation does. groups controls the connections between inputs and outputs. in_channels and out_channels must both be divisible by groups. For example, > At groups=1, all inputs are convolved to all outputs. >>> At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels, and producing half the output channels, and both subsequently concatenated. >>> * At groups= in_channels, each input channel is convolved with its own set of filters (of size ). 参数kernel_size，stride，padding和output_padding可以是： 单个int –在这种情况下，高度和宽度尺寸将使用相同的值 a tuple of two ints – in which case, the first int is used for the height dimension, and the second int for the width dimension Note Depending of the size of your kernel, several (of the last) columns of the input might be lost, because it is a valid cross-correlation, and not a full cross-correlation. It is up to the user to add proper padding. Note padding参数有效地将dilation * (kernel_size - 1) - padding的零填充量添加到两种输入大小。 进行设置时，以相同的参数初始化 Conv2d 和 ConvTranspose2d 时，它们在输入和输出形状方面彼此相反。 但是，当stride &gt; 1， Conv2d 将多个输入形状映射到相同的输出形状时。 提供output_padding可通过有效地增加一侧的计算输出形状来解决这种歧义。 请注意，output_padding仅用于查找输出形状，而实际上并未向输出添加零填充。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters in_channels (python:int) – Number of channels in the input image out_channels (python:int) – Number of channels produced by the convolution kernel_size (python:int or tuple) – Size of the convolving kernel stride (python:int or tuple__, optional) – Stride of the convolution. Default: 1 填充 (python：int 或 元组 ， 可选）– dilation * (kernel_size - 1) - padding 零填充将添加到输入中每个维度的两侧。 默认值：0 output_padding (python：int 或 元组 ， 可选）–已添加其他大小 输出形状中每个尺寸的一侧。 默认值：0 groups (python:int__, optional) – Number of blocked connections from input channels to output channels. Default: 1 bias (bool__, optional) – If True, adds a learnable bias to the output. Default: True dilation (python:int or tuple__, optional) – Spacing between kernel elements. Default: 1 Shape: Input: Output: where Variables 〜ConvTranspose2d.weight (tensor)–形状为 的模块的可学习重量。 这些权重的值取自，其中 〜ConvTranspose2d.bias (tensor)–形状模块的可学习偏差(out_channels）如果bias为True，则值 这些权重来自，其中 Examples: >>> # With square kernels and equal stride >>> m = nn.ConvTranspose2d(16, 33, 3, stride=2) >>> # non-square kernels and unequal stride and with padding >>> m = nn.ConvTranspose2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2)) >>> input = torch.randn(20, 16, 50, 100) >>> output = m(input) >>> # exact output size can be also specified as an argument >>> input = torch.randn(1, 16, 12, 12) >>> downsample = nn.Conv2d(16, 16, 3, stride=2, padding=1) >>> upsample = nn.ConvTranspose2d(16, 16, 3, stride=2, padding=1) >>> h = downsample(input) >>> h.size() torch.Size([1, 16, 6, 6]) >>> output = upsample(h, output_size=input.size()) >>> output.size() torch.Size([1, 16, 12, 12]) ConvTranspose3d class torch.nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros')¶ 在由多个输入平面组成的输入图像上应用 3D 转置卷积运算符。 转置的卷积运算符将每个输入值逐个元素地乘以一个可学习的内核，并对所有输入特征平面的输出求和。 该模块可以看作是 Conv3d 相对于其输入的梯度。 它也被称为分数步法卷积或反卷积(尽管它不是实际的反卷积运算）。 stride controls the stride for the cross-correlation. padding controls the amount of implicit zero-paddings on both sides for dilation * (kernel_size - 1) - padding number of points. See note below for details. output_padding controls the additional size added to one side of the output shape. See note below for details. dilation controls the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this link has a nice visualization of what dilation does. groups controls the connections between inputs and outputs. in_channels and out_channels must both be divisible by groups. For example, > At groups=1, all inputs are convolved to all outputs. >>> At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels, and producing half the output channels, and both subsequently concatenated. >>> * At groups= in_channels, each input channel is convolved with its own set of filters (of size ). The parameters kernel_size, stride, padding, output_padding can either be: 单个int –在这种情况下，深度，高度和宽度尺寸使用相同的值 a tuple of three ints – in which case, the first int is used for the depth dimension, the second int for the height dimension and the third int for the width dimension Note Depending of the size of your kernel, several (of the last) columns of the input might be lost, because it is a valid cross-correlation, and not a full cross-correlation. It is up to the user to add proper padding. Note padding参数有效地将dilation * (kernel_size - 1) - padding的零填充量添加到两种输入大小。 进行设置时，以相同的参数初始化 Conv3d 和 ConvTranspose3d 时，它们在输入和输出形状方面彼此相反。 但是，当stride &gt; 1， Conv3d 将多个输入形状映射到相同的输出形状时。 提供output_padding可通过有效地增加一侧的计算输出形状来解决这种歧义。 请注意，output_padding仅用于查找输出形状，而实际上并未向输出添加零填充。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters in_channels (python:int) – Number of channels in the input image out_channels (python:int) – Number of channels produced by the convolution kernel_size (python:int or tuple) – Size of the convolving kernel stride (python:int or tuple__, optional) – Stride of the convolution. Default: 1 padding (python:int or tuple__, optional) – dilation * (kernel_size - 1) - padding zero-padding will be added to both sides of each dimension in the input. Default: 0 output_padding (python:int or tuple__, optional) – Additional size added to one side of each dimension in the output shape. Default: 0 groups (python:int__, optional) – Number of blocked connections from input channels to output channels. Default: 1 bias (bool__, optional) – If True, adds a learnable bias to the output. Default: True dilation (python:int or tuple__, optional) – Spacing between kernel elements. Default: 1 Shape: Input: Output: where Variables 〜ConvTranspose3d.weight (tensor)–形状为 的模块的可学习重量。 这些权重的值取自，其中 〜ConvTranspose3d.bias (tensor)–形状模块的可学习偏差(out_channels）如果bias为True，则值 这些权重来自，其中 Examples: >>> # With square kernels and equal stride >>> m = nn.ConvTranspose3d(16, 33, 3, stride=2) >>> # non-square kernels and unequal stride and with padding >>> m = nn.ConvTranspose3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(0, 4, 2)) >>> input = torch.randn(20, 16, 10, 50, 100) >>> output = m(input) 展开 class torch.nn.Unfold(kernel_size, dilation=1, padding=0, stride=1)¶ 从批处理输入张量中提取滑动局部块。 考虑形状为的成批input张量，其中为批尺寸，为通道尺寸，代表任意空间尺寸。 此操作将input的空间尺寸内每个kernel_size大小的滑动块压平为形状为的 3-D output张量的列(即最后一个尺寸），其中为总数 每个块内的值数量(一个块具有个空间位置，每个位置包含通道矢量），是此类块的总数： 其中由input(以上）的空间尺寸形成，而在所有空间尺寸上。 因此，在最后一个维度(列维度）上索引output将给出特定块内的所有值。 padding，stride和dilation自变量指定如何检索滑块。 stride控制滑块的步幅。 在重塑之前，padding控制每个维的padding个点的两侧的隐式零填充量。 dilation controls the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this link has a nice visualization of what dilation does. Parameters kernel_size (python：int 或 元组）–滑块的大小 跨度 (python：int 或 元组 ， 可选）–跨度 输入空间维度中的滑块。 默认值：1 填充 (python：int 或 元组 ， 可选）–隐式零填充 将被添加到输入的两侧。 默认值：0 扩张 (python：int 或 元组 ， 可选）–一个参数 控制邻域内元素的步幅。 默认值：1 如果kernel_size，dilation，padding或stride是长度为 1 的 int 或元组，则它们的值将在所有空间维度上复制。 对于两个输入空间维度，此操作有时称为im2col。 Note Fold 通过对来自所有包含块的所有值求和来计算所得大张量中的每个组合值。 Unfold 通过复制大张量来提取局部块中的值。 因此，如果这些块重叠，则它们不是彼此相反。 通常，折叠和展开操作如下相关。 考虑使用相同参数创建的 Fold 和 Unfold 实例： >>> fold_params = dict(kernel_size=..., dilation=..., padding=..., stride=...) >>> fold = nn.Fold(output_size=..., **fold_params) >>> unfold = nn.Unfold(**fold_params) 然后，对于任何(受支持的）input张量，以下等式成立： fold(unfold(input)) == divisor * input 其中divisor是仅取决于input的形状和 dtype 的张量： >>> input_ones = torch.ones(input.shape, dtype=input.dtype) >>> divisor = fold(unfold(input_ones)) 当divisor张量不包含零元素时，则fold和unfold运算互为逆(最大除数）。 Warning 当前，仅支持 4D 输入张量(像图像一样的批状张量）。 Shape: 输入： 输出：如上所述 Examples: >>> unfold = nn.Unfold(kernel_size=(2, 3)) >>> input = torch.randn(2, 5, 3, 4) >>> output = unfold(input) >>> # each patch contains 30 values (2x3=6 vectors, each of 5 channels) >>> # 4 blocks (2x3 kernels) in total in the 3x4 input >>> output.size() torch.Size([2, 30, 4]) >>> # Convolution is equivalent with Unfold + Matrix Multiplication + Fold (or view to output shape) >>> inp = torch.randn(1, 3, 10, 12) >>> w = torch.randn(2, 3, 4, 5) >>> inp_unf = torch.nn.functional.unfold(inp, (4, 5)) >>> out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2) >>> out = torch.nn.functional.fold(out_unf, (7, 8), (1, 1)) >>> # or equivalently (and avoiding a copy), >>> # out = out_unf.view(1, 2, 7, 8) >>> (torch.nn.functional.conv2d(inp, w) - out).abs().max() tensor(1.9073e-06) 折 class torch.nn.Fold(output_size, kernel_size, dilation=1, padding=0, stride=1)¶ 将一系列滑动局部块组合成一个大型的张量。 考虑一个包含形状的滑动局部块(例如图像块）的批处理input张量，其中是批处理尺寸，是一个块内的值数(一个块具有 每个包含通道向量的空间位置），是块的总数。 (这与 Unfold 的输出形状完全相同。）此操作通过求和重叠值，将这些局部块组合为形状为的大output张量。 与 Unfold 类似，参数必须满足 其中覆盖所有空间尺寸。 output_size描述了滑动局部块的大包含张量的空间形状。 当多个输入形状例如使用stride &gt; 0映射到相同数量的滑块时，解决歧义很有用。 The padding, stride and dilation arguments specify how the sliding blocks are retrieved. stride controls the stride for the sliding blocks. padding controls the amount of implicit zero-paddings on both sides for padding number of points for each dimension before reshaping. dilation controls the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this link has a nice visualization of what dilation does. Parameters output_size (python：int 或 元组）–输出的空间尺寸形状(即output.sizes()[2:]） kernel_size (python:int or tuple) – the size of the sliding blocks 跨度 (python：int 或 元组）–滑动块在输入空间维度上的跨度。 默认值：1 padding (python:int or tuple__, optional) – implicit zero padding to be added on both sides of input. Default: 0 dilation (python:int or tuple__, optional) – a parameter that controls the stride of elements within the neighborhood. Default: 1 如果output_size，kernel_size，dilation，padding或stride是长度为 1 的整数或元组，则它们的值将在所有空间维度上复制。 对于两个输出空间维度，此操作有时称为col2im。 Note Fold calculates each combined value in the resulting large tensor by summing all values from all containing blocks. Unfold extracts the values in the local blocks by copying from the large tensor. So, if the blocks overlap, they are not inverses of each other. In general, folding and unfolding operations are related as follows. Consider Fold and Unfold instances created with the same parameters: >>> fold_params = dict(kernel_size=..., dilation=..., padding=..., stride=...) >>> fold = nn.Fold(output_size=..., **fold_params) >>> unfold = nn.Unfold(**fold_params) Then for any (supported) input tensor the following equality holds: fold(unfold(input)) == divisor * input where divisor is a tensor that depends only on the shape and dtype of the input: >>> input_ones = torch.ones(input.shape, dtype=input.dtype) >>> divisor = fold(unfold(input_ones)) When the divisor tensor contains no zero elements, then fold and unfold operations are inverses of each other (upto constant divisor). Warning 当前，仅支持 4D 输出张量(像图像一样的批状张量）。 Shape: 输入： 输出：如上所述 Examples: >>> fold = nn.Fold(output_size=(4, 5), kernel_size=(2, 2)) >>> input = torch.randn(1, 3 * 2 * 2, 12) >>> output = fold(input) >>> output.size() torch.Size([1, 3, 4, 5]) 汇聚层 MaxPool1d class torch.nn.MaxPool1d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)¶ 在由多个输入平面组成的输入信号上应用一维最大池化。 在最简单的情况下，具有输入大小和输出的图层的输出值可以精确地描述为： 如果padding不为零，则对于padding点的数量，输入将在两侧隐式填充零。 dilation控制内核点之间的间距。 很难描述，但是此链接很好地展示了dilation的功能。 Parameters kernel_size –取最大值的窗口大小 步幅 –窗口的步幅。 默认值为kernel_size 填充 –在两侧都添加隐式零填充 膨胀 –控制窗口中元素步幅的参数 return_indices –如果True，将返回最大索引以及输出。 以后对 torch.nn.MaxUnpool1d 有用 ceil_mode –为 True 时，将使用 ceil 而不是 floor 计算输出形状 Shape: 输入： 输出：，其中 Examples: >>> # pool of size=3, stride=2 >>> m = nn.MaxPool1d(3, stride=2) >>> input = torch.randn(20, 16, 50) >>> output = m(input) MaxPool2d class torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)¶ 在由多个输入平面组成的输入信号上应用 2D 最大合并。 在最简单的情况下，具有输入大小，输出和kernel_size 的图层的输出值可以精确地描述为： If padding is non-zero, then the input is implicitly zero-padded on both sides for padding number of points. dilation controls the spacing between the kernel points. It is harder to describe, but this link has a nice visualization of what dilation does. The parameters kernel_size, stride, padding, dilation can either be: a single int – in which case the same value is used for the height and width dimension a tuple of two ints – in which case, the first int is used for the height dimension, and the second int for the width dimension Parameters kernel_size – the size of the window to take a max over stride – the stride of the window. Default value is kernel_size padding – implicit zero padding to be added on both sides dilation – a parameter that controls the stride of elements in the window return_indices –如果True，将返回最大索引以及输出。 以后对 torch.nn.MaxUnpool2d 有用 ceil_mode – when True, will use ceil instead of floor to compute the output shape Shape: 输入： 输出：，其中 Examples: >>> # pool of square window of size=3, stride=2 >>> m = nn.MaxPool2d(3, stride=2) >>> # pool of non-square window >>> m = nn.MaxPool2d((3, 2), stride=(2, 1)) >>> input = torch.randn(20, 16, 50, 32) >>> output = m(input) MaxPool3d class torch.nn.MaxPool3d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)¶ 在由多个输入平面组成的输入信号上应用 3D 最大池化。 在最简单的情况下，具有输入大小，输出和kernel_size 的图层的输出值可以精确地描述为： If padding is non-zero, then the input is implicitly zero-padded on both sides for padding number of points. dilation controls the spacing between the kernel points. It is harder to describe, but this link has a nice visualization of what dilation does. The parameters kernel_size, stride, padding, dilation can either be: a single int – in which case the same value is used for the depth, height and width dimension a tuple of three ints – in which case, the first int is used for the depth dimension, the second int for the height dimension and the third int for the width dimension Parameters kernel_size – the size of the window to take a max over stride – the stride of the window. Default value is kernel_size 填充 –在所有三个面上都添加隐式零填充 dilation – a parameter that controls the stride of elements in the window return_indices –如果True，将返回最大索引以及输出。 以后对 torch.nn.MaxUnpool3d 有用 ceil_mode – when True, will use ceil instead of floor to compute the output shape Shape: 输入： 输出：，其中 Examples: >>> # pool of square window of size=3, stride=2 >>> m = nn.MaxPool3d(3, stride=2) >>> # pool of non-square window >>> m = nn.MaxPool3d((3, 2, 2), stride=(2, 1, 2)) >>> input = torch.randn(20, 16, 50,44, 31) >>> output = m(input) MaxUnpool1d class torch.nn.MaxUnpool1d(kernel_size, stride=None, padding=0)¶ 计算 MaxPool1d 的局部逆。 MaxPool1d 不能完全反转，因为会丢失非最大值。 MaxUnpool1d 接收包括最大值索引在内的 MaxPool1d 的输出作为输入，并计算一个部分逆，其中所有非最大值都设置为零。 Note MaxPool1d 可以将多个输入大小映射到相同的输出大小。 因此，反转过程可能会变得模棱两可。 为了解决这个问题，您可以在前进调用中提供所需的输出大小作为附加参数output_size。 请参阅下面的输入和示例。 Parameters kernel_size (python：int 或 元组）–最大池窗口的大小。 跨度 (python：int 或 元组）–最大合并窗口的跨度。 默认设置为kernel_size。 填充 (python：int 或 元组）–已添加到输入中的填充 Inputs: 输入：输入张量反转 指标： MaxPool1d 给出的指标 output_size (可选）：目标输出大小 Shape: 输入： 输出：，其中 或由呼叫运营商中的output_size给定 Example: >>> pool = nn.MaxPool1d(2, stride=2, return_indices=True) >>> unpool = nn.MaxUnpool1d(2, stride=2) >>> input = torch.tensor([[[1., 2, 3, 4, 5, 6, 7, 8]]]) >>> output, indices = pool(input) >>> unpool(output, indices) tensor([[[ 0., 2., 0., 4., 0., 6., 0., 8.]]]) >>> # Example showcasing the use of output_size >>> input = torch.tensor([[[1., 2, 3, 4, 5, 6, 7, 8, 9]]]) >>> output, indices = pool(input) >>> unpool(output, indices, output_size=input.size()) tensor([[[ 0., 2., 0., 4., 0., 6., 0., 8., 0.]]]) >>> unpool(output, indices) tensor([[[ 0., 2., 0., 4., 0., 6., 0., 8.]]]) MaxUnpool2d class torch.nn.MaxUnpool2d(kernel_size, stride=None, padding=0)¶ 计算 MaxPool2d 的局部逆。 MaxPool2d 不能完全反转，因为会丢失非最大值。 MaxUnpool2d 接收包括最大值索引在内的 MaxPool2d 的输出作为输入，并计算一个部分逆，其中所有非最大值都设置为零。 Note MaxPool2d 可以将多个输入大小映射到相同的输出大小。 因此，反转过程可能会变得模棱两可。 为了解决这个问题，您可以在前进调用中提供所需的输出大小作为附加参数output_size。 请参阅下面的输入和示例。 Parameters kernel_size (python:int or tuple) – Size of the max pooling window. stride (python:int or tuple) – Stride of the max pooling window. It is set to kernel_size by default. padding (python:int or tuple) – Padding that was added to the input Inputs: input: the input Tensor to invert 指标： MaxPool2d 给出的指标 output_size (optional): the targeted output size Shape: Input: Output: , where or as given by output_size in the call operator Example: >>> pool = nn.MaxPool2d(2, stride=2, return_indices=True) >>> unpool = nn.MaxUnpool2d(2, stride=2) >>> input = torch.tensor([[[[ 1., 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12], [13, 14, 15, 16]]]]) >>> output, indices = pool(input) >>> unpool(output, indices) tensor([[[[ 0., 0., 0., 0.], [ 0., 6., 0., 8.], [ 0., 0., 0., 0.], [ 0., 14., 0., 16.]]]]) >>> # specify a different output size than input size >>> unpool(output, indices, output_size=torch.Size([1, 1, 5, 5])) tensor([[[[ 0., 0., 0., 0., 0.], [ 6., 0., 8., 0., 0.], [ 0., 0., 0., 14., 0.], [ 16., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0.]]]]) MaxUnpool3d class torch.nn.MaxUnpool3d(kernel_size, stride=None, padding=0)¶ 计算 MaxPool3d 的局部逆。 MaxPool3d 不能完全反转，因为会丢失非最大值。 MaxUnpool3d 将包含最大值索引的 MaxPool3d 的输出作为输入，并计算将所有非最大值均设置为零的部分逆。 Note MaxPool3d 可以将多个输入大小映射到相同的输出大小。 因此，反转过程可能会变得模棱两可。 为了解决这个问题，您可以在前进调用中提供所需的输出大小作为附加参数output_size。 请参阅下面的输入部分。 Parameters kernel_size (python:int or tuple) – Size of the max pooling window. stride (python:int or tuple) – Stride of the max pooling window. It is set to kernel_size by default. padding (python:int or tuple) – Padding that was added to the input Inputs: input: the input Tensor to invert 指标： MaxPool3d 给出的指标 output_size (optional): the targeted output size Shape: Input: Output: , where or as given by output_size in the call operator Example: >>> # pool of square window of size=3, stride=2 >>> pool = nn.MaxPool3d(3, stride=2, return_indices=True) >>> unpool = nn.MaxUnpool3d(3, stride=2) >>> output, indices = pool(torch.randn(20, 16, 51, 33, 15)) >>> unpooled_output = unpool(output, indices) >>> unpooled_output.size() torch.Size([20, 16, 51, 33, 15]) 平均池 1d class torch.nn.AvgPool1d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True)¶ 在由多个输入平面组成的输入信号上应用一维平均池。 在最简单的情况下，具有输入大小，输出和kernel_size 的图层的输出值可以精确地描述为： 如果padding不为零，则对于padding点的数量，输入将在两侧隐式填充零。 参数kernel_size，stride和padding可以分别是int或一个元素元组。 Parameters kernel_size –窗口的大小 stride – the stride of the window. Default value is kernel_size padding – implicit zero padding to be added on both sides ceil_mode – when True, will use ceil instead of floor to compute the output shape count_include_pad –为 True 时，将在平均计算中包括零填充 Shape: Input: Output: , where Examples: >>> # pool with window of size=3, stride=2 >>> m = nn.AvgPool1d(3, stride=2) >>> m(torch.tensor([[[1.,2,3,4,5,6,7]]])) tensor([[[ 2., 4., 6.]]]) 平均池 2d class torch.nn.AvgPool2d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)¶ 在由多个输入平面组成的输入信号上应用 2D 平均池。 In the simplest case, the output value of the layer with input size , output and kernel_size can be precisely described as: If padding is non-zero, then the input is implicitly zero-padded on both sides for padding number of points. 参数kernel_size，stride和padding可以是： a single int – in which case the same value is used for the height and width dimension a tuple of two ints – in which case, the first int is used for the height dimension, and the second int for the width dimension Parameters kernel_size – the size of the window stride – the stride of the window. Default value is kernel_size padding – implicit zero padding to be added on both sides ceil_mode – when True, will use ceil instead of floor to compute the output shape count_include_pad – when True, will include the zero-padding in the averaging calculation divisor_override -如果指定，它将用作除数，否则 attr： kernel_size Shape: Input: Output: , where Examples: >>> # pool of square window of size=3, stride=2 >>> m = nn.AvgPool2d(3, stride=2) >>> # pool of non-square window >>> m = nn.AvgPool2d((3, 2), stride=(2, 1)) >>> input = torch.randn(20, 16, 50, 32) >>> output = m(input) 平均池 3d class torch.nn.AvgPool3d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)¶ 在由多个输入平面组成的输入信号上应用 3D 平均池。 In the simplest case, the output value of the layer with input size , output and kernel_size can be precisely described as: 如果padding不为零，则对于padding点的数量，输入将在所有三个侧面隐式填充零。 参数kernel_size和stride可以是： a single int – in which case the same value is used for the depth, height and width dimension a tuple of three ints – in which case, the first int is used for the depth dimension, the second int for the height dimension and the third int for the width dimension Parameters kernel_size – the size of the window stride – the stride of the window. Default value is kernel_size padding – implicit zero padding to be added on all three sides ceil_mode – when True, will use ceil instead of floor to compute the output shape count_include_pad – when True, will include the zero-padding in the averaging calculation divisor_override – if specified, it will be used as divisor, otherwise attr:kernel_size will be used Shape: Input: Output: , where Examples: >>> # pool of square window of size=3, stride=2 >>> m = nn.AvgPool3d(3, stride=2) >>> # pool of non-square window >>> m = nn.AvgPool3d((3, 2, 2), stride=(2, 1, 2)) >>> input = torch.randn(20, 16, 50,44, 31) >>> output = m(input) 分数最大池 2d class torch.nn.FractionalMaxPool2d(kernel_size, output_size=None, output_ratio=None, return_indices=False, _random_samples=None)¶ 在由多个输入平面组成的输入信号上应用 2D 分数最大池化。 Ben Graham 的论文 Fractional MaxPooling 中详细描述了分数最大池化 在区域中通过由目标输出大小确定的随机步长应用最大合并操作。 输出要素的数量等于输入平面的数量。 Parameters kernel_size –接管最大值的窗口大小。 可以是单个数字 k(对于 k x k 的平方核）或元组(kh，kw） output_size – oH x oW 形式的图像的目标输出尺寸。 可以是一个元组(oH，oW），也可以是一个正方形图像 oH x oH 的一个数字 oH output_ratio –如果希望输出大小与输入大小的比率，可以指定此选项。 这必须是范围为(0，1）的数字或元组 return_indices -如果True，则将返回索引以及输出。 有助于传递给nn.MaxUnpool2d()。 默认值：False 例子 >>> # pool of square window of size=3, and target output size 13x12 >>> m = nn.FractionalMaxPool2d(3, output_size=(13, 12)) >>> # pool of square window and target output size being half of input image size >>> m = nn.FractionalMaxPool2d(3, output_ratio=(0.5, 0.5)) >>> input = torch.randn(20, 16, 50, 32) >>> output = m(input) LPPool1d class torch.nn.LPPool1d(norm_type, kernel_size, stride=None, ceil_mode=False)¶ 在由多个输入平面组成的输入信号上应用一维功率平均池。 在每个窗口上，计算的函数为： 在 p = 时，获得最大池化 在 p = 1 时，总和池(与平均池成正比） Note 如果 p 的幂的和为零，则此函数的梯度不确定。 在这种情况下，此实现会将梯度设置为零。 Parameters kernel_size –单个整数，窗口的大小 跨度 –一个 int，即窗口的跨度。 默认值为kernel_size ceil_mode – when True, will use ceil instead of floor to compute the output shape Shape: Input: Output: , where Examples:: >>> # power-2 pool of window of length 3, with stride 2. >>> m = nn.LPPool1d(2, 3, stride=2) >>> input = torch.randn(20, 16, 50) >>> output = m(input) LPPool2d class torch.nn.LPPool2d(norm_type, kernel_size, stride=None, ceil_mode=False)¶ 在由多个输入平面组成的输入信号上应用 2D 功率平均池。 On each window, the function computed is: At p = , one gets Max Pooling 在 p = 1 时，将获得“汇总池”(与平均池成比例） The parameters kernel_size, stride can either be: a single int – in which case the same value is used for the height and width dimension a tuple of two ints – in which case, the first int is used for the height dimension, and the second int for the width dimension Note If the sum to the power of p is zero, the gradient of this function is not defined. This implementation will set the gradient to zero in this case. Parameters kernel_size – the size of the window stride – the stride of the window. Default value is kernel_size ceil_mode – when True, will use ceil instead of floor to compute the output shape Shape: Input: Output: , where Examples: >>> # power-2 pool of square window of size=3, stride=2 >>> m = nn.LPPool2d(2, 3, stride=2) >>> # pool of non-square window of power 1.2 >>> m = nn.LPPool2d(1.2, (3, 2), stride=(2, 1)) >>> input = torch.randn(20, 16, 50, 32) >>> output = m(input) AdaptiveMaxPool1d class torch.nn.AdaptiveMaxPool1d(output_size, return_indices=False)¶ 在由多个输入平面组成的输入信号上应用一维自适应最大池化。 对于任何输入大小，输出大小均为 H。 输出要素的数量等于输入平面的数量。 Parameters output_size –目标输出大小 H return_indices -如果True，则将返回索引以及输出。 传递给 nn.MaxUnpool1d 很有用。 默认值：False Examples >>> # target output size of 5 >>> m = nn.AdaptiveMaxPool1d(5) >>> input = torch.randn(1, 64, 8) >>> output = m(input) AdaptiveMaxPool2d class torch.nn.AdaptiveMaxPool2d(output_size, return_indices=False)¶ 在由多个输入平面组成的输入信号上应用 2D 自适应最大池化。 对于任何输入大小，输出大小均为 H xW。 输出要素的数量等于输入平面的数量。 Parameters output_size – H x W 形式的图像的目标输出大小。可以是元组(H，W），也可以是正方形图像 H x H 的单个 H。H 和 W 可以是 int或None表示大小与输入的大小相同。 return_indices -如果True，则将返回索引以及输出。 传递给 nn.MaxUnpool2d 很有用。 默认值：False Examples >>> # target output size of 5x7 >>> m = nn.AdaptiveMaxPool2d((5,7)) >>> input = torch.randn(1, 64, 8, 9) >>> output = m(input) >>> # target output size of 7x7 (square) >>> m = nn.AdaptiveMaxPool2d(7) >>> input = torch.randn(1, 64, 10, 9) >>> output = m(input) >>> # target output size of 10x7 >>> m = nn.AdaptiveMaxPool2d((None, 7)) >>> input = torch.randn(1, 64, 10, 9) >>> output = m(input) AdaptiveMaxPool3d class torch.nn.AdaptiveMaxPool3d(output_size, return_indices=False)¶ 在由多个输入平面组成的输入信号上应用 3D 自适应最大池化。 对于任何输入大小，输出大小均为 D xH xW。 输出要素的数量等于输入平面的数量。 Parameters output_size – D x H x W 形式的图像的目标输出尺寸。可以是一个元组(D，H，W），也可以是一个多维数据集 D x D x D 的单个 D。D， H 和 W 可以是int或None，这意味着大小将与输入的大小相同。 return_indices -如果True，则将返回索引以及输出。 传递给 nn.MaxUnpool3d 很有用。 默认值：False Examples >>> # target output size of 5x7x9 >>> m = nn.AdaptiveMaxPool3d((5,7,9)) >>> input = torch.randn(1, 64, 8, 9, 10) >>> output = m(input) >>> # target output size of 7x7x7 (cube) >>> m = nn.AdaptiveMaxPool3d(7) >>> input = torch.randn(1, 64, 10, 9, 8) >>> output = m(input) >>> # target output size of 7x9x8 >>> m = nn.AdaptiveMaxPool3d((7, None, None)) >>> input = torch.randn(1, 64, 10, 9, 8) >>> output = m(input) AdaptiveAvgPool1d class torch.nn.AdaptiveAvgPool1d(output_size)¶ 在由多个输入平面组成的输入信号上应用一维自适应平均池。 The output size is H, for any input size. The number of output features is equal to the number of input planes. Parameters output_size – the target output size H Examples >>> # target output size of 5 >>> m = nn.AdaptiveAvgPool1d(5) >>> input = torch.randn(1, 64, 8) >>> output = m(input) AdaptiveAvgPool2d class torch.nn.AdaptiveAvgPool2d(output_size)¶ 在由多个输入平面组成的输入信号上应用 2D 自适应平均池。 The output is of size H x W, for any input size. The number of output features is equal to the number of input planes. Parameters output_size – the target output size of the image of the form H x W. Can be a tuple (H, W) or a single H for a square image H x H. H and W can be either a int, or None which means the size will be the same as that of the input. Examples >>> # target output size of 5x7 >>> m = nn.AdaptiveAvgPool2d((5,7)) >>> input = torch.randn(1, 64, 8, 9) >>> output = m(input) >>> # target output size of 7x7 (square) >>> m = nn.AdaptiveAvgPool2d(7) >>> input = torch.randn(1, 64, 10, 9) >>> output = m(input) >>> # target output size of 10x7 >>> m = nn.AdaptiveMaxPool2d((None, 7)) >>> input = torch.randn(1, 64, 10, 9) >>> output = m(input) AdaptiveAvgPool3d class torch.nn.AdaptiveAvgPool3d(output_size)¶ 在由多个输入平面组成的输入信号上应用 3D 自适应平均池。 The output is of size D x H x W, for any input size. The number of output features is equal to the number of input planes. Parameters output_size – D x H x W 形式的目标输出大小。可以是元组(D，H，W），也可以是多维数据集 D xD x D 的单个数字 D。D，H 和 W 可以是int或None，这意味着大小将与输入的大小相同。 Examples >>> # target output size of 5x7x9 >>> m = nn.AdaptiveAvgPool3d((5,7,9)) >>> input = torch.randn(1, 64, 8, 9, 10) >>> output = m(input) >>> # target output size of 7x7x7 (cube) >>> m = nn.AdaptiveAvgPool3d(7) >>> input = torch.randn(1, 64, 10, 9, 8) >>> output = m(input) >>> # target output size of 7x9x8 >>> m = nn.AdaptiveMaxPool3d((7, None, None)) >>> input = torch.randn(1, 64, 10, 9, 8) >>> output = m(input) 填充层 ReflectionPad1d class torch.nn.ReflectionPad1d(padding)¶ 使用输入边界的反射来填充输入张量。 对于 N 维填充，请使用 torch.nn.functional.pad() 。 Parameters 填充 (python：int ， 元组）–填充的大小。 如果为 int ，则在所有边界中使用相同的填充。 如果 2- 元组，则使用(，） Shape: 输入： 输出：其中 Examples: >>> m = nn.ReflectionPad1d(2) >>> input = torch.arange(8, dtype=torch.float).reshape(1, 2, 4) >>> input tensor([[[0., 1., 2., 3.], [4., 5., 6., 7.]]]) >>> m(input) tensor([[[2., 1., 0., 1., 2., 3., 2., 1.], [6., 5., 4., 5., 6., 7., 6., 5.]]]) >>> # using different paddings for different sides >>> m = nn.ReflectionPad1d((3, 1)) >>> m(input) tensor([[[3., 2., 1., 0., 1., 2., 3., 2.], [7., 6., 5., 4., 5., 6., 7., 6.]]]) ReflectionPad2d class torch.nn.ReflectionPad2d(padding)¶ Pads the input tensor using the reflection of the input boundary. For N-dimensional padding, use torch.nn.functional.pad(). Parameters 填充 (python：int ， 元组）–填充的大小。 如果为 int ，则在所有边界中使用相同的填充。 如果是 4- 元组，则使用(，，和） Shape: Input: 输出：其中 Examples: >>> m = nn.ReflectionPad2d(2) >>> input = torch.arange(9, dtype=torch.float).reshape(1, 1, 3, 3) >>> input tensor([[[[0., 1., 2.], [3., 4., 5.], [6., 7., 8.]]]]) >>> m(input) tensor([[[[8., 7., 6., 7., 8., 7., 6.], [5., 4., 3., 4., 5., 4., 3.], [2., 1., 0., 1., 2., 1., 0.], [5., 4., 3., 4., 5., 4., 3.], [8., 7., 6., 7., 8., 7., 6.], [5., 4., 3., 4., 5., 4., 3.], [2., 1., 0., 1., 2., 1., 0.]]]]) >>> # using different paddings for different sides >>> m = nn.ReflectionPad2d((1, 1, 2, 0)) >>> m(input) tensor([[[[7., 6., 7., 8., 7.], [4., 3., 4., 5., 4.], [1., 0., 1., 2., 1.], [4., 3., 4., 5., 4.], [7., 6., 7., 8., 7.]]]]) 复制板 1d class torch.nn.ReplicationPad1d(padding)¶ 使用输入边界的复制来填充输入张量。 For N-dimensional padding, use torch.nn.functional.pad(). Parameters padding (python:int__, tuple) – the size of the padding. If is int, uses the same padding in all boundaries. If a 2-tuple, uses (, ) Shape: Input: Output: where Examples: >>> m = nn.ReplicationPad1d(2) >>> input = torch.arange(8, dtype=torch.float).reshape(1, 2, 4) >>> input tensor([[[0., 1., 2., 3.], [4., 5., 6., 7.]]]) >>> m(input) tensor([[[0., 0., 0., 1., 2., 3., 3., 3.], [4., 4., 4., 5., 6., 7., 7., 7.]]]) >>> # using different paddings for different sides >>> m = nn.ReplicationPad1d((3, 1)) >>> m(input) tensor([[[0., 0., 0., 0., 1., 2., 3., 3.], [4., 4., 4., 4., 5., 6., 7., 7.]]]) 复制板 2d class torch.nn.ReplicationPad2d(padding)¶ Pads the input tensor using replication of the input boundary. For N-dimensional padding, use torch.nn.functional.pad(). Parameters padding (python:int__, tuple) – the size of the padding. If is int, uses the same padding in all boundaries. If a 4-tuple, uses (, , , ) Shape: Input: Output: where Examples: >>> m = nn.ReplicationPad2d(2) >>> input = torch.arange(9, dtype=torch.float).reshape(1, 1, 3, 3) >>> input tensor([[[[0., 1., 2.], [3., 4., 5.], [6., 7., 8.]]]]) >>> m(input) tensor([[[[0., 0., 0., 1., 2., 2., 2.], [0., 0., 0., 1., 2., 2., 2.], [0., 0., 0., 1., 2., 2., 2.], [3., 3., 3., 4., 5., 5., 5.], [6., 6., 6., 7., 8., 8., 8.], [6., 6., 6., 7., 8., 8., 8.], [6., 6., 6., 7., 8., 8., 8.]]]]) >>> # using different paddings for different sides >>> m = nn.ReplicationPad2d((1, 1, 2, 0)) >>> m(input) tensor([[[[0., 0., 1., 2., 2.], [0., 0., 1., 2., 2.], [0., 0., 1., 2., 2.], [3., 3., 4., 5., 5.], [6., 6., 7., 8., 8.]]]]) 复制板 3d class torch.nn.ReplicationPad3d(padding)¶ Pads the input tensor using replication of the input boundary. For N-dimensional padding, use torch.nn.functional.pad(). Parameters 填充 (python：int ， 元组）–填充的大小。 如果为 int ，则在所有边界中使用相同的填充。 如果是 6-元组，则使用(，，，，，） Shape: Input: 输出：其中 Examples: >>> m = nn.ReplicationPad3d(3) >>> input = torch.randn(16, 3, 8, 320, 480) >>> output = m(input) >>> # using different paddings for different sides >>> m = nn.ReplicationPad3d((3, 3, 6, 6, 1, 1)) >>> output = m(input) ZeroPad2d class torch.nn.ZeroPad2d(padding)¶ 用零填充输入张量边界。 For N-dimensional padding, use torch.nn.functional.pad(). Parameters padding (python:int__, tuple) – the size of the padding. If is int, uses the same padding in all boundaries. If a 4-tuple, uses (, , , ) Shape: Input: Output: where Examples: >>> m = nn.ZeroPad2d(2) >>> input = torch.randn(1, 1, 3, 3) >>> input tensor([[[[-0.1678, -0.4418, 1.9466], [ 0.9604, -0.4219, -0.5241], [-0.9162, -0.5436, -0.6446]]]]) >>> m(input) tensor([[[[ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [ 0.0000, 0.0000, -0.1678, -0.4418, 1.9466, 0.0000, 0.0000], [ 0.0000, 0.0000, 0.9604, -0.4219, -0.5241, 0.0000, 0.0000], [ 0.0000, 0.0000, -0.9162, -0.5436, -0.6446, 0.0000, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]]) >>> # using different paddings for different sides >>> m = nn.ZeroPad2d((1, 1, 2, 0)) >>> m(input) tensor([[[[ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [ 0.0000, -0.1678, -0.4418, 1.9466, 0.0000], [ 0.0000, 0.9604, -0.4219, -0.5241, 0.0000], [ 0.0000, -0.9162, -0.5436, -0.6446, 0.0000]]]]) ConstantPad1d class torch.nn.ConstantPad1d(padding, value)¶ 用恒定值填充输入张量边界。 For N-dimensional padding, use torch.nn.functional.pad(). Parameters 填充 (python：int ， 元组）–填充的大小。 如果为 int ，则在两个边界中使用相同的填充。 如果 2- 元组，则使用(，） Shape: Input: Output: where Examples: >>> m = nn.ConstantPad1d(2, 3.5) >>> input = torch.randn(1, 2, 4) >>> input tensor([[[-1.0491, -0.7152, -0.0749, 0.8530], [-1.3287, 1.8966, 0.1466, -0.2771]]]) >>> m(input) tensor([[[ 3.5000, 3.5000, -1.0491, -0.7152, -0.0749, 0.8530, 3.5000, 3.5000], [ 3.5000, 3.5000, -1.3287, 1.8966, 0.1466, -0.2771, 3.5000, 3.5000]]]) >>> m = nn.ConstantPad1d(2, 3.5) >>> input = torch.randn(1, 2, 3) >>> input tensor([[[ 1.6616, 1.4523, -1.1255], [-3.6372, 0.1182, -1.8652]]]) >>> m(input) tensor([[[ 3.5000, 3.5000, 1.6616, 1.4523, -1.1255, 3.5000, 3.5000], [ 3.5000, 3.5000, -3.6372, 0.1182, -1.8652, 3.5000, 3.5000]]]) >>> # using different paddings for different sides >>> m = nn.ConstantPad1d((3, 1), 3.5) >>> m(input) tensor([[[ 3.5000, 3.5000, 3.5000, 1.6616, 1.4523, -1.1255, 3.5000], [ 3.5000, 3.5000, 3.5000, -3.6372, 0.1182, -1.8652, 3.5000]]]) ConstantPad2d class torch.nn.ConstantPad2d(padding, value)¶ Pads the input tensor boundaries with a constant value. For N-dimensional padding, use torch.nn.functional.pad(). Parameters padding (python:int__, tuple) – the size of the padding. If is int, uses the same padding in all boundaries. If a 4-tuple, uses (, , , ) Shape: Input: Output: where Examples: >>> m = nn.ConstantPad2d(2, 3.5) >>> input = torch.randn(1, 2, 2) >>> input tensor([[[ 1.6585, 0.4320], [-0.8701, -0.4649]]]) >>> m(input) tensor([[[ 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000], [ 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000], [ 3.5000, 3.5000, 1.6585, 0.4320, 3.5000, 3.5000], [ 3.5000, 3.5000, -0.8701, -0.4649, 3.5000, 3.5000], [ 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000], [ 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000]]]) >>> # using different paddings for different sides >>> m = nn.ConstantPad2d((3, 0, 2, 1), 3.5) >>> m(input) tensor([[[ 3.5000, 3.5000, 3.5000, 3.5000, 3.5000], [ 3.5000, 3.5000, 3.5000, 3.5000, 3.5000], [ 3.5000, 3.5000, 3.5000, 1.6585, 0.4320], [ 3.5000, 3.5000, 3.5000, -0.8701, -0.4649], [ 3.5000, 3.5000, 3.5000, 3.5000, 3.5000]]]) ConstantPad3d class torch.nn.ConstantPad3d(padding, value)¶ Pads the input tensor boundaries with a constant value. For N-dimensional padding, use torch.nn.functional.pad(). Parameters padding (python:int__, tuple) – the size of the padding. If is int, uses the same padding in all boundaries. If a 6-tuple, uses (, , , , , ) Shape: Input: Output: where Examples: >>> m = nn.ConstantPad3d(3, 3.5) >>> input = torch.randn(16, 3, 10, 20, 30) >>> output = m(input) >>> # using different paddings for different sides >>> m = nn.ConstantPad3d((3, 3, 6, 6, 0, 1), 3.5) >>> output = m(input) 非线性激活(加权和，非线性） ELU class torch.nn.ELU(alpha=1.0, inplace=False)¶ 应用逐元素函数： Parameters alpha – ELU 公式的值。 默认值：1.0 就地 –可以选择就地进行操作。 默认值：False Shape: 输入：其中 * 表示任意数量的附加尺寸 输出：，形状与输入相同 Examples: >>> m = nn.ELU() >>> input = torch.randn(2) >>> output = m(input) 硬收缩 class torch.nn.Hardshrink(lambd=0.5)¶ 逐个应用硬收缩功能： Parameters lambd – Hardshrink 配方的值。 默认值：0.5 Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Examples: >>> m = nn.Hardshrink() >>> input = torch.randn(2) >>> output = m(input) 哈丹 class torch.nn.Hardtanh(min_val=-1.0, max_val=1.0, inplace=False, min_value=None, max_value=None)¶ 逐个应用 HardTanh 函数 HardTanh 定义为： 线性区域的范围可以使用min_val和max_val进行调整。 Parameters min_val –线性区域范围的最小值。 默认值：-1 max_val –线性区域范围的最大值。 默认值：1 inplace – can optionally do the operation in-place. Default: False 不推荐使用关键字参数min_value和max_value，而推荐使用min_val和max_val。 Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Examples: >>> m = nn.Hardtanh(-2, 2) >>> input = torch.randn(2) >>> output = m(input) 漏尿 class torch.nn.LeakyReLU(negative_slope=0.01, inplace=False)¶ Applies the element-wise function: 要么 Parameters negative_slope –控制负斜率的角度。 默认值：1e-2 inplace – can optionally do the operation in-place. Default: False Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Examples: >>> m = nn.LeakyReLU(0.1) >>> input = torch.randn(2) >>> output = m(input) LogSigmoid class torch.nn.LogSigmoid¶ Applies the element-wise function: Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Examples: >>> m = nn.LogSigmoid() >>> input = torch.randn(2) >>> output = m(input) 多头注意力 class torch.nn.MultiheadAttention(embed_dim, num_heads, dropout=0.0, bias=True, add_bias_kv=False, add_zero_attn=False, kdim=None, vdim=None)¶ 允许模型共同关注来自不同表示子空间的信息。 请参阅参考：注意就是您所需要的 Parameters embed_dim -模型的总尺寸。 num_heads –平行注意头。 dropout – attn_output_weights 上的 Dropout 层。 默认值：0.0 偏置 –将偏置添加为模块参数。 默认值：True。 add_bias_kv –将偏差添加到键和值序列的 dim = 0。 add_zero_attn –将新一批零添加到调暗值为 1 的键和值序列。 kdim -密钥中的功能总数。 默认值：无。 vdim -密钥中的功能总数。 默认值：无。 注意 –如果 kdim 和 vdim 为 None，则将它们设置为 embed_dim，以便 键和值具有相同数量的功能。 (查询 ，）– Examples: >>> multihead_attn = nn.MultiheadAttention(embed_dim, num_heads) >>> attn_output, attn_output_weights = multihead_attn(query, key, value) forward(query, key, value, key_padding_mask=None, need_weights=True, attn_mask=None)¶ Parameters 键，值(查询 ，）–将查询和一组键值对映射到输出。 有关更多详细信息，请参见“注意就是全部”。 key_padding_mask –如果提供，则将忽略按键中指定的填充元素。 这是一个二进制掩码。 当值为 True 时，注意层上的相应值将用-inf 填充。 need_weights -输出 attn_output_weights。 attn_mask –防止注意某些位置的遮罩。 这是一个附加蒙版(即这些值将添加到关注层）。 Shape: 输入： 查询：其中 L 是目标序列长度，N 是批处理大小，E 是嵌入维数。 密钥：，其中 S 是源序列长度，N 是批处理大小，E 是嵌入维数。 值：其中 S 是源序列长度，N 是批处理大小，E 是嵌入维数。 key_padding_mask：，ByteTensor，其中 N 是批处理大小，S 是源序列长度。 attn_mask：其中 L 是目标序列长度，S 是源序列长度。 输出： attn_output：其中 L 是目标序列长度，N 是批处理大小，E 是嵌入维数。 attn_output_weights：其中 N 是批处理大小，L 是目标序列长度，S 是源序列长度。 预备 class torch.nn.PReLU(num_parameters=1, init=0.25)¶ Applies the element-wise function: or 此处是可学习的参数。 当不带参数调用时， nn.PReLU(）在所有输入通道上使用单个参数。 如果使用 nn.PReLU(nChannels）进行调用，则每个输入通道将使用单独的。 Note 学习以获得良好性能时，不应使用重量衰减。 Note 通道暗淡是输入的第二暗淡。 当输入的亮度为 Parameters num_parameters (python：int )–要学习的的数量。 尽管将 int 作为输入，但是只有两个值是合法的：1，即输入的通道数。 默认值：1 初始 (python：float )– 的初始值。 默认值：0.25 Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Variables 〜PReLU.weight (tensor)–可学习的形状权重(num_parameters）。 Examples: >>> m = nn.PReLU() >>> input = torch.randn(2) >>> output = m(input) ReLU class torch.nn.ReLU(inplace=False)¶ 将整流的线性单位函数按元素应用： Parameters inplace – can optionally do the operation in-place. Default: False Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Examples: >>> m = nn.ReLU() >>> input = torch.randn(2) >>> output = m(input) An implementation of CReLU - https://arxiv.org/abs/1603.05201 >>> m = nn.ReLU() >>> input = torch.randn(2).unsqueeze(0) >>> output = torch.cat((m(input),m(-input))) ReLU6 class torch.nn.ReLU6(inplace=False)¶ Applies the element-wise function: Parameters inplace – can optionally do the operation in-place. Default: False Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Examples: >>> m = nn.ReLU6() >>> input = torch.randn(2) >>> output = m(input) RReLU class torch.nn.RReLU(lower=0.125, upper=0.3333333333333333, inplace=False)¶ 如本文所述，按元素应用随机泄漏的整流衬套单元功能： 卷积网络中修正激活的经验评估。 该函数定义为： 其中是从均匀分布中随机抽样的。 参见： https://arxiv.org/pdf/1505.00853.pdf Parameters 下-均匀分布的下限。 默认值： 上限 –均匀分布的上限。 默认值： inplace – can optionally do the operation in-place. Default: False Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Examples: >>> m = nn.RReLU(0.1, 0.3) >>> input = torch.randn(2) >>> output = m(input) SELU class torch.nn.SELU(inplace=False)¶ 按元素应用，例如： 和。 更多细节可以在论文自归一化神经网络中找到。 Parameters 原位 (bool ， 可选）–可以选择就地进行操作。 默认值：False Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Examples: >>> m = nn.SELU() >>> input = torch.randn(2) >>> output = m(input) 中央图书馆 class torch.nn.CELU(alpha=1.0, inplace=False)¶ Applies the element-wise function: 可以在论文连续微分指数线性单位中找到更多详细信息。 Parameters alpha – CELU 配方的值。 默认值：1.0 inplace – can optionally do the operation in-place. Default: False Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Examples: >>> m = nn.CELU() >>> input = torch.randn(2) >>> output = m(input) 格鲁 class torch.nn.GELU¶ 应用高斯误差线性单位函数： 其中是高斯分布的累积分布函数。 Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Examples: >>> m = nn.GELU() >>> input = torch.randn(2) >>> output = m(input) 乙状结肠 class torch.nn.Sigmoid¶ Applies the element-wise function: Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Examples: >>> m = nn.Sigmoid() >>> input = torch.randn(2) >>> output = m(input) 软加 class torch.nn.Softplus(beta=1, threshold=20)¶ Applies the element-wise function: SoftPlus 是 ReLU 函数的平滑近似，可用于将机器的输出约束为始终为正。 为了获得数值稳定性，对于超过一定值的输入，实现将恢复为线性函数。 Parameters beta – Softplus 制剂的值。 默认值：1 阈值 –高于此阈值的值恢复为线性函数。 默认值：20 Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Examples: >>> m = nn.Softplus() >>> input = torch.randn(2) >>> output = m(input) 软缩 class torch.nn.Softshrink(lambd=0.5)¶ 逐个应用软收缩功能： Parameters lambd –软收缩配方的值。 默认值：0.5 Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Examples: >>> m = nn.Softshrink() >>> input = torch.randn(2) >>> output = m(input) 软签 class torch.nn.Softsign¶ Applies the element-wise function: Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Examples: >>> m = nn.Softsign() >>> input = torch.randn(2) >>> output = m(input) h class torch.nn.Tanh¶ Applies the element-wise function: Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Examples: >>> m = nn.Tanh() >>> input = torch.randn(2) >>> output = m(input) Tanhshrink class torch.nn.Tanhshrink¶ Applies the element-wise function: Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Examples: >>> m = nn.Tanhshrink() >>> input = torch.randn(2) >>> output = m(input) 阈 class torch.nn.Threshold(threshold, value, inplace=False)¶ 设置输入张量的每个元素的阈值。 阈值定义为： Parameters 阈值 –达到阈值的值 值 –要替换为的值 inplace – can optionally do the operation in-place. Default: False Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Examples: >>> m = nn.Threshold(0.1, 20) >>> input = torch.randn(2) >>> output = m(input) 非线性激活(其他） 软敏 class torch.nn.Softmin(dim=None)¶ 将 Softmin 函数应用于缩放后的 n 维输入张量，以便 n 维输出张量的元素在 [0，1] 范围内，总和为 1。 Softmin 定义为： Shape: 输入：其中 * 表示任意数量的附加尺寸 输出：，形状与输入相同 Parameters dim (python：int )–将计算 Softmin 的维度(因此，沿着 dim 的每个切片的总和为 1）。 Returns 与输入具有相同尺寸和形状的张量，其值在[0，1]范围内 Examples: >>> m = nn.Softmin() >>> input = torch.randn(2, 3) >>> output = m(input) 软最大 class torch.nn.Softmax(dim=None)¶ 将 Softmax 函数应用于缩放后的 n 维输入 Tensor，以使 n 维输出 Tensor 的元素在[0,1]范围内，总和为 1。 Softmax 定义为： Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Returns 与输入具有相同尺寸和形状的张量，其值在[0，1]范围内 Parameters dim (python：int )–将计算 Softmax 的维度(因此，沿着 dim 的每个切片的总和为 1）。 Note 该模块无法直接与 NLLLoss 配合使用，后者希望 Log 是在 Softmax 及其自身之间进行计算的。 请改用 LogSoftmax (速度更快，并且具有更好的数值属性）。 Examples: >>> m = nn.Softmax(dim=1) >>> input = torch.randn(2, 3) >>> output = m(input) Softmax2d class torch.nn.Softmax2d¶ 将 SoftMax 应用于要素上的每个空间位置。 当给定Channels x Height x Width的图像时，它将 Softmax 应用于每个位置 Shape: 输入： 输出：(形状与输入相同） Returns a Tensor of the same dimension and shape as the input with values in the range [0, 1] Examples: >>> m = nn.Softmax2d() >>> # you softmax over the 2nd dimension >>> input = torch.randn(2, 3, 12, 13) >>> output = m(input) LogSoftmax class torch.nn.LogSoftmax(dim=None)¶ 将功能应用于 n 维输入张量。 LogSoftmax 公式可以简化为： Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Parameters 暗淡的 (python：int )–用来计算 LogSoftmax 的尺寸。 Returns 与输入具有相同尺寸和形状的张量，其值在[-inf，0）范围内 Examples: >>> m = nn.LogSoftmax() >>> input = torch.randn(2, 3) >>> output = m(input) AdaptiveLogSoftmaxWithLoss class torch.nn.AdaptiveLogSoftmaxWithLoss(in_features, n_classes, cutoffs, div_value=4.0, head_bias=False)¶ 如 Edouard Grave，Armand Joulin，MoustaphaCissé，David Grangier 和 HervéJégou 在中针对 GPU 所述的高效 softmax 逼近。 自适应 softmax 是用于训练具有大输出空间的模型的近似策略。 当标签分布高度不平衡时，例如在自然语言建模中，单词频率分布大致遵循 Zipf 定律时，此方法最为有效。 自适应 softmax 根据标签的频率将标签划分为几个簇。 这些集群每个可能包含不同数量的目标。 此外，包含较少标签的群集将较低维的嵌入分配给这些标签，从而加快了计算速度。 对于每个小批量，仅评估至少存在一个目标的集群。 这个想法是，频繁访问的集群(如第一个集群，包含最频繁的标签），也应该便宜计算-也就是说，包含少量分配的标签。 我们强烈建议您查看原始文件以了解更多详细信息。 cutoffs应该是按升序排序的有序整数序列。 它控制集群的数量以及将目标划分为集群。 例如，设置cutoffs = [10, 100, 1000]意味着第一个 10 个目标将分配给自适应 softmax 的“头部”，目标 11、12，…，100 个将分配给第一个目标 集群，目标 101、102，…，1000 将分配给第二个集群，而目标 1001、1002，…，n_classes-1 将分配给最后一个，第三个 簇。 div_value用于计算每个附加聚类的大小，以的形式给出，其中是聚类索引(具有较少索引的聚类具有较大索引，而聚类从开始）。 head_bias如果设置为 True，则会向自适应 softmax 的“头部”添加一个偏差项。 有关详细信息，请参见纸张。 在官方实现中设置为 False。 Warning 传递给该模块的标签应根据其频率进行分类。 这意味着最频繁的标签应由索引 0 表示，最不频繁的标签应由索引 n_classes-1 表示。 Note 该模块返回带有output和loss字段的NamedTuple。 有关详细信息，请参见其他文档。 Note 要计算所有类别的对数概率，可以使用log_prob方法。 Parameters in_features (python：int )–输入张量中的特征数 n_classes (python：int )–数据集中的类数 临界值(序列）–用于将目标分配给其存储桶的临界值 div_value (python：float ， 可选）–用作计算集群大小的指数的值。 默认值：4.0 head_bias (bool ， 可选）–如果True，则向自适应 softmax 的“ head”添加一个偏差项。 默认值：False Returns 输出是大小为N的张量，其中包含每个示例的计算目标对数概率 损失是表示计算出的负对数似然损失的标量 Return type 具有output和loss字段的NamedTuple Shape: 输入： 目标：其中每个值都满足 输出 1： 输出 2：Scalar log_prob(input)¶ 计算所有的日志概率 Parameters 输入 (tensor)–小批量示例 Returns 范围内每个类别的对数概率，其中是传递给AdaptiveLogSoftmaxWithLoss构造函数的参数。 Shape: 输入： 输出： predict(input)¶ 这等效于 self.log_pob(input）.argmax(dim = 1），但在某些情况下效率更高。 Parameters input (Tensor) – a minibatch of examples Returns 每个示例中概率最高的类别 Return type 输出(张量） Shape: Input: 输出： 归一化层 BatchNorm1d class torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)¶ 如论文中所述，对 2D 或 3D 输入(具有可选附加通道尺寸的 1D 输入的微型批处理）应用批归一化：通过减少内部协变量偏移加速深度网络训练。 均值和标准偏差是在微型批次上按维度计算的，并且和是大小为 C 的可学习参数矢量(其中 C 是输入大小 )。 默认情况下，的元素设置为 1，的元素设置为 0。 同样默认情况下，在训练过程中，该层会继续对其计算的均值和方差进行估算，然后将其用于评估期间的标准化。 运行估计保持默认值momentum 0.1。 如果track_running_stats设置为False，则此层将不保持运行估计，而是在评估期间也使用批处理统计信息。 Note momentum参数不同于优化程序类中使用的参数以及传统的动量概念。 在数学上，此处用于运行统计信息的更新规则为，其中是估计的统计信息，是新的观测值。 由于批量归一化是在 C 维度上完成的，因此要计算(N，L）切片的统计信息，因此通常将其称为“时间批量归一化”。 Parameters num_features – 来自大小为的预期输入，或来自大小为的输入 eps –分母增加的值，以保证数值稳定性。 默认值：1e-5 动量 –用于 running_mean 和 running_var 计算的值。 可以设置为None以获得累积移动平均线(即简单平均线）。 默认值：0.1 仿射 –一个布尔值，当设置为True时，此模块具有可学习的仿射参数。 默认值：True track_running_stats –一个布尔值，设置为True时，此模块跟踪运行平均值和方差；设置为False时，此模块不跟踪此类统计信息，并且始终使用批处理统计信息 训练和评估模式。 默认值：True Shape: 输入：或 输出：或(形状与输入相同） Examples: >>> # With Learnable Parameters >>> m = nn.BatchNorm1d(100) >>> # Without Learnable Parameters >>> m = nn.BatchNorm1d(100, affine=False) >>> input = torch.randn(20, 100) >>> output = m(input) BatchNorm2d class torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)¶ 如论文中所述，对 4D 输入(具有附加通道尺寸的 2D 输入的微型批处理）应用批归一化：通过减少内部协变量偏移来加速深度网络训练。 The mean and standard-deviation are calculated per-dimension over the mini-batches and and are learnable parameter vectors of size C (where C is the input size). By default, the elements of are set to 1 and the elements of are set to 0. Also by default, during training this layer keeps running estimates of its computed mean and variance, which are then used for normalization during evaluation. The running estimates are kept with a default momentum of 0.1. If track_running_stats is set to False, this layer then does not keep running estimates, and batch statistics are instead used during evaluation time as well. Note This momentum argument is different from one used in optimizer classes and the conventional notion of momentum. Mathematically, the update rule for running statistics here is , where is the estimated statistic and is the new observed value. 由于批量归一化是在 C 维度上完成的，因此要计算(N，H，W）切片的统计信息，因此通常将其称为“空间批量归一化”。 Parameters num_features – 来自大小为的预期输入 eps – a value added to the denominator for numerical stability. Default: 1e-5 momentum – the value used for the running_mean and running_var computation. Can be set to None for cumulative moving average (i.e. simple average). Default: 0.1 affine – a boolean value that when set to True, this module has learnable affine parameters. Default: True track_running_stats – a boolean value that when set to True, this module tracks the running mean and variance, and when set to False, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: True Shape: Input: Output: (same shape as input) Examples: >>> # With Learnable Parameters >>> m = nn.BatchNorm2d(100) >>> # Without Learnable Parameters >>> m = nn.BatchNorm2d(100, affine=False) >>> input = torch.randn(20, 100, 35, 45) >>> output = m(input) BatchNorm3d class torch.nn.BatchNorm3d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)¶ 如论文中所述，对 5D 输入(具有附加通道尺寸的 3D 输入的微型批处理）应用批归一化：通过减少内部协变量偏移加速深度网络训练。 The mean and standard-deviation are calculated per-dimension over the mini-batches and and are learnable parameter vectors of size C (where C is the input size). By default, the elements of are set to 1 and the elements of are set to 0. Also by default, during training this layer keeps running estimates of its computed mean and variance, which are then used for normalization during evaluation. The running estimates are kept with a default momentum of 0.1. If track_running_stats is set to False, this layer then does not keep running estimates, and batch statistics are instead used during evaluation time as well. Note This momentum argument is different from one used in optimizer classes and the conventional notion of momentum. Mathematically, the update rule for running statistics here is , where is the estimated statistic and is the new observed value. 由于批量归一化是在 C 维度上完成的，因此要计算(N，D，H，W）切片的统计信息，因此通常将这种体积批量归一化或时空称为术语 批处理规范化。 Parameters num_features – 来自大小为的预期输入 eps – a value added to the denominator for numerical stability. Default: 1e-5 momentum – the value used for the running_mean and running_var computation. Can be set to None for cumulative moving average (i.e. simple average). Default: 0.1 affine – a boolean value that when set to True, this module has learnable affine parameters. Default: True track_running_stats – a boolean value that when set to True, this module tracks the running mean and variance, and when set to False, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: True Shape: 输入： 输出：(形状与输入相同） Examples: >>> # With Learnable Parameters >>> m = nn.BatchNorm3d(100) >>> # Without Learnable Parameters >>> m = nn.BatchNorm3d(100, affine=False) >>> input = torch.randn(20, 100, 35, 45, 10) >>> output = m(input) 集团规范 class torch.nn.GroupNorm(num_groups, num_channels, eps=1e-05, affine=True)¶ 如论文组归一化中所述，将组归一化应用于微型输入。 输入通道分为num_groups组，每个组包含num_channels / num_groups通道。 均值和标准差在每个组中分别计算。 如果affine为True，则和是大小为num_channels的可学习的每通道仿射变换参数矢量。 该层使用在训练和评估模式下从输入数据中计算出的统计信息。 Parameters num_groups (python：int )–将通道分隔为的组数 num_channels (python：int )–输入中预期的通道数 eps –分母增加的值，以保证数值稳定性。 默认值：1e-5 仿射 –一个布尔值，当设置为True时，此模块具有可学习的每通道仿射参数，分别初始化为 1(用于权重）和零(用于偏差）。 默认值：True。 Shape: 输入：，其中 输出：(形状与输入相同） Examples: >>> input = torch.randn(20, 6, 10, 10) >>> # Separate 6 channels into 3 groups >>> m = nn.GroupNorm(3, 6) >>> # Separate 6 channels into 6 groups (equivalent with InstanceNorm) >>> m = nn.GroupNorm(6, 6) >>> # Put all 6 channels into a single group (equivalent with LayerNorm) >>> m = nn.GroupNorm(1, 6) >>> # Activating the module >>> output = m(input) SyncBatchNorm class torch.nn.SyncBatchNorm(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, process_group=None)¶ 如论文中所述，对 N 维输入(具有附加通道维的[N-2] D 输入的小批量）进行批量归一化批量归一化：通过减少内部协变量偏移加速深度网络训练 。 均值和标准偏差是在同一过程组的所有微型批次中按维度计算的。 和是大小为 C (其中 C 是输入大小）的可学习参数向量。 默认情况下，从采样的元素，并将的元素设置为 0。 Also by default, during training this layer keeps running estimates of its computed mean and variance, which are then used for normalization during evaluation. The running estimates are kept with a default momentum of 0.1. If track_running_stats is set to False, this layer then does not keep running estimates, and batch statistics are instead used during evaluation time as well. Note momentum参数不同于优化程序类中使用的参数以及传统的动量概念。 在数学上，此处用于运行统计信息的更新规则为，其中是估计的统计信息，是新的观测值。 由于批量归一化是在 C 维度上完成的，因此要计算(N，+）切片的统计信息，因此通常将其称为体积批量归一化或时空批量归一化。 当前，SyncBatchNorm 仅支持每个进程具有单个 GPU 的 DistributedDataParallel。 在使用 DDP 包装网络之前，使用 torch.nn.SyncBatchNorm.convert_sync_batchnorm(）将 BatchNorm 层转换为 SyncBatchNorm。 Parameters num_features – 来自大小为的预期输入 eps – a value added to the denominator for numerical stability. Default: 1e-5 momentum – the value used for the running_mean and running_var computation. Can be set to None for cumulative moving average (i.e. simple average). Default: 0.1 affine – a boolean value that when set to True, this module has learnable affine parameters. Default: True track_running_stats – a boolean value that when set to True, this module tracks the running mean and variance, and when set to False, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: True process_group –统计信息的同步分别在每个进程组内发生。 默认行为是在整个世界范围内同步 Shape: 输入： 输出：(形状与输入相同） Examples: >>> # With Learnable Parameters >>> m = nn.SyncBatchNorm(100) >>> # creating process group (optional) >>> # process_ids is a list of int identifying rank ids. >>> process_group = torch.distributed.new_group(process_ids) >>> # Without Learnable Parameters >>> m = nn.BatchNorm3d(100, affine=False, process_group=process_group) >>> input = torch.randn(20, 100, 35, 45, 10) >>> output = m(input) >>> # network is nn.BatchNorm layer >>> sync_bn_network = nn.SyncBatchNorm.convert_sync_batchnorm(network, process_group) >>> # only single gpu per process is currently supported >>> ddp_sync_bn_network = torch.nn.parallel.DistributedDataParallel( >>> sync_bn_network, >>> device_ids=[args.local_rank], >>> output_device=args.local_rank) classmethod convert_sync_batchnorm(module, process_group=None)¶ 辅助函数将模型中的 torch.nn.BatchNormND 层转换为 torch.nn.SyncBatchNorm 层。 Parameters 模块 (nn.Module)–包含模块 process_group (可选）–进程组到范围的同步， 默认是整个世界 Returns 具有转换后的 torch.nn.SyncBatchNorm 层的原始模块 Example: >>> # Network with nn.BatchNorm layer >>> module = torch.nn.Sequential( >>> torch.nn.Linear(20, 100), >>> torch.nn.BatchNorm1d(100) >>> ).cuda() >>> # creating process group (optional) >>> # process_ids is a list of int identifying rank ids. >>> process_group = torch.distributed.new_group(process_ids) >>> sync_bn_module = convert_sync_batchnorm(module, process_group) InstanceNorm1d class torch.nn.InstanceNorm1d(num_features, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)¶ 如论文中所述，将实例标准化应用于 3D 输入(具有可选附加通道尺寸的 1D 输入的微型批处理）实例标准化：快速样式化的缺失成分。 微型批处理中每个对象的维数均值和标准差分别计算。 如果affine为True，则和是大小为 C (其中 C 为输入大小）的可学习参数矢量。 默认情况下，该层使用在训练和评估模式下从输入数据计算出的实例统计信息。 如果track_running_stats设置为True，则在训练过程中，此层将继续对其计算的均值和方差进行估算，然后将其用于评估期间的标准化。 运行估计保持默认值momentum 0.1。 Note This momentum argument is different from one used in optimizer classes and the conventional notion of momentum. Mathematically, the update rule for running statistics here is , where is the estimated statistic and is the new observed value. Note InstanceNorm1d 和 LayerNorm 非常相似，但有一些细微的差异。 InstanceNorm1d 应用于多维数据序列之类的通道数据的每个通道，但是 LayerNorm 通常应用于整个样本，并且通常用于 NLP 任务。 另外， LayerNorm 应用逐元素仿射变换，而 InstanceNorm1d 通常不应用仿射变换。 Parameters num_features – from an expected input of size or from input of size eps – a value added to the denominator for numerical stability. Default: 1e-5 动量 –用于 running_mean 和 running_var 计算的值。 默认值：0.1 仿射 –一个布尔值，当设置为True时，此模块具有可学习的仿射参数，其初始化方式与批量标准化相同。 默认值：False。 track_running_stats –一个布尔值，设置为True时，此模块跟踪运行平均值和方差；设置为False时，此模块不跟踪此类统计信息，并且始终使用批处理统计信息 训练和评估模式。 默认值：False Shape: 输入： 输出：(形状与输入相同） Examples: >>> # Without Learnable Parameters >>> m = nn.InstanceNorm1d(100) >>> # With Learnable Parameters >>> m = nn.InstanceNorm1d(100, affine=True) >>> input = torch.randn(20, 100, 40) >>> output = m(input) InstanceNorm2d class torch.nn.InstanceNorm2d(num_features, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)¶ 如论文中所述，将实例标准化应用于 4D 输入(具有附加通道尺寸的 2D 输入的小批量）实例标准化：快速样式化的缺失成分。 The mean and standard-deviation are calculated per-dimension separately for each object in a mini-batch. and are learnable parameter vectors of size C (where C is the input size) if affine is True. By default, this layer uses instance statistics computed from input data in both training and evaluation modes. If track_running_stats is set to True, during training this layer keeps running estimates of its computed mean and variance, which are then used for normalization during evaluation. The running estimates are kept with a default momentum of 0.1. Note This momentum argument is different from one used in optimizer classes and the conventional notion of momentum. Mathematically, the update rule for running statistics here is , where is the estimated statistic and is the new observed value. Note InstanceNorm2d 和 LayerNorm 非常相似，但有一些细微的差异。 InstanceNorm2d 适用于 RGB 图像之类的通道数据的每个通道，但是 LayerNorm 通常适用于整个样本，并且通常用于 NLP 任务。 另外， LayerNorm 应用逐元素仿射变换，而 InstanceNorm2d 通常不应用仿射变换。 Parameters num_features – from an expected input of size eps – a value added to the denominator for numerical stability. Default: 1e-5 momentum – the value used for the running_mean and running_var computation. Default: 0.1 affine – a boolean value that when set to True, this module has learnable affine parameters, initialized the same way as done for batch normalization. Default: False. track_running_stats – a boolean value that when set to True, this module tracks the running mean and variance, and when set to False, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: False Shape: Input: Output: (same shape as input) Examples: >>> # Without Learnable Parameters >>> m = nn.InstanceNorm2d(100) >>> # With Learnable Parameters >>> m = nn.InstanceNorm2d(100, affine=True) >>> input = torch.randn(20, 100, 35, 45) >>> output = m(input) InstanceNorm3d class torch.nn.InstanceNorm3d(num_features, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)¶ 如论文中所述，将实例标准化应用于 5D 输入(具有附加通道尺寸的 3D 输入的微型批处理）实例标准化：快速样式化缺少的成分。 微型批处理中每个对象的维数均值和标准差分别计算。 如果affine为True，则和是大小为 C 的可学习参数矢量(其中 C 为输入大小）。 By default, this layer uses instance statistics computed from input data in both training and evaluation modes. If track_running_stats is set to True, during training this layer keeps running estimates of its computed mean and variance, which are then used for normalization during evaluation. The running estimates are kept with a default momentum of 0.1. Note This momentum argument is different from one used in optimizer classes and the conventional notion of momentum. Mathematically, the update rule for running statistics here is , where is the estimated statistic and is the new observed value. Note InstanceNorm3d 和 LayerNorm 非常相似，但有一些细微的差异。 InstanceNorm3d 适用于通道数据的每个通道，例如具有 RGB 颜色的 3D 模型，但 LayerNorm 通常适用于整个样本，并且经常用于 NLP 任务。 另外， LayerNorm 应用逐元素仿射变换，而 InstanceNorm3d 通常不应用仿射变换。 Parameters num_features – from an expected input of size eps – a value added to the denominator for numerical stability. Default: 1e-5 momentum – the value used for the running_mean and running_var computation. Default: 0.1 affine – a boolean value that when set to True, this module has learnable affine parameters, initialized the same way as done for batch normalization. Default: False. track_running_stats – a boolean value that when set to True, this module tracks the running mean and variance, and when set to False, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: False Shape: Input: Output: (same shape as input) Examples: >>> # Without Learnable Parameters >>> m = nn.InstanceNorm3d(100) >>> # With Learnable Parameters >>> m = nn.InstanceNorm3d(100, affine=True) >>> input = torch.randn(20, 100, 35, 45, 10) >>> output = m(input) 层范数 class torch.nn.LayerNorm(normalized_shape, eps=1e-05, elementwise_affine=True)¶ 如论文层规范化中所述，在小批量输入上应用层规范化。 平均值和标准偏差是在最后一定数量的尺寸上分别计算的，这些尺寸必须具有normalized_shape指定的形状。 如果elementwise_affine为True，则和是normalized_shape的可学习仿射变换参数。 Note 与批量归一化和实例归一化不同，后者使用affine选项对每个通道/平面应用标量缩放和偏置，而层归一化则使用elementwise_affine对每个元素缩放和偏置。 This layer uses statistics computed from input data in both training and evaluation modes. Parameters normalized_shape (python：int 或 列表 或 torch尺寸）– 输入尺寸的预期输入 如果使用单个整数，则将其视为一个单例列表，并且此模块将在最后一个预期为该特定大小的维度上进行规范化。 eps – a value added to the denominator for numerical stability. Default: 1e-5 elementwise_affine –一个布尔值，当设置为True时，此模块具有可学习的按元素仿射参数，分别初始化为 1(用于权重）和零(用于偏差）。 默认值：True。 Shape: 输入： 输出：(形状与输入相同） Examples: >>> input = torch.randn(20, 5, 10, 10) >>> # With Learnable Parameters >>> m = nn.LayerNorm(input.size()[1:]) >>> # Without Learnable Parameters >>> m = nn.LayerNorm(input.size()[1:], elementwise_affine=False) >>> # Normalize over last two dimensions >>> m = nn.LayerNorm([10, 10]) >>> # Normalize over last dimension of size 10 >>> m = nn.LayerNorm(10) >>> # Activating the module >>> output = m(input) LocalResponseNorm class torch.nn.LocalResponseNorm(size, alpha=0.0001, beta=0.75, k=1.0)¶ 在由多个输入平面组成的输入信号上应用本地响应归一化，其中通道占据第二维。 跨通道应用标准化。 Parameters 大小 –用于标准化的相邻信道的数量 alpha –乘法因子。 默认值：0.0001 beta -指数。 默认值：0.75 k –加法因子。 默认值：1 Shape: Input: Output: (same shape as input) Examples: >>> lrn = nn.LocalResponseNorm(2) >>> signal_2d = torch.randn(32, 5, 24, 24) >>> signal_4d = torch.randn(16, 5, 7, 7, 7, 7) >>> output_2d = lrn(signal_2d) >>> output_4d = lrn(signal_4d) 循环层 RNN 库 class torch.nn.RNNBase(mode, input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False)¶ flatten_parameters()¶ 重置参数数据指针，以便它们可以使用更快的代码路径。 现在，仅当模块在 GPU 上并且启用 cuDNN 时，此方法才有效。 否则，这是无人操作。 RNN class torch.nn.RNN(*args, **kwargs)¶ 将具有或非线性的多层 Elman RNN 应用于输入序列。 对于输入序列中的每个元素，每一层都会计算以下功能： 其中是时间 t 的隐藏状态，是时间 t 的输入，而是时间的上一层的隐藏状态 ] t-1 或时间 0 时的初始隐藏状态。 如果nonlinearity为'relu'，则使用 ReLU 代替 tanh 。 Parameters input_size -输入 x 中预期功能的数量 hidden_​​size –处于隐藏状态的特征数 h num_layers –循环层数。 例如，设置num_layers=2意味着将两个 RNN 堆叠在一起以形成堆叠的 RNN ，而第二个 RNN 则接收第一个 RNN 的输出并计算最终结果。 默认值：1 非线性 –使用的非线性。 可以是'tanh'或'relu'。 默认值：'tanh' 偏置-如果False，则该层不使用偏置权重 b_ih 和 b_hh 。 默认值：True batch_first –如果为True，则输入和输出张量以(批，序列，特征）的形式提供。 默认值：False dropout –如果不为零，则在除最后一层之外的每个 RNN 层的输出上引入 Dropout 层，其丢弃概率等于dropout。 默认值：0 双向 –如果True成为双向 RNN。 默认值：False Inputs: input, h_0 形状为(seq_len，批处理，input_size）的输入：：包含输入序列特征的张量。 输入也可以是打包的可变长度序列。 有关详细信息，请参见 torch.nn.utils.rnn.pack_padded_sequence() 或 torch.nn.utils.rnn.pack_sequence() 。 h0 的形状为(num_layers * num_directions，批处理，hidden​​size）：张量，包含批处理中每个元素的初始隐藏状态。 如果未提供，则默认为零。 如果 RNN 是双向的，则 num_directions 应该为 2，否则应为 1。 Outputs: output, h_n 输出形状为(seqlen，批处理，num_directions * hidden​​size）的 ：张量包含来自 RNN 的最后一层的输出特征 (h_t )，对于每个[ t 。 如果已将 torch.nn.utils.rnn.PackedSequence 作为输入，则输出也将是打包序列。 对于未包装的情况，可以使用output.view(seq_len, batch, num_directions, hidden_size)分隔方向，向前和向后分别是方向 0 和 1 。 同样，在包装好的情况下，方向也可以分开。 hn 的形状为(num_layers * num_directions，批处理，hidden​​size）：包含 t = seq_len 的隐藏状态的张量。 像输出一样，可以使用h_n.view(num_layers, num_directions, batch, hidden_size)分离各层。 Shape: Input1：包含输入特征的张量，其中和 L 表示序列长度。 Input2：张量，包含批次中每个元素的初始隐藏状态。 如果未提供，则默认为零。 其中如果 RNN 是双向的，则 num_directions 应该为 2，否则应为 1。 输出 1：，其中 输出 2：张量，包含批次中每个元素的下一个隐藏状态 Variables 〜RNN.weight_ih_l [k] –第 k 层的可学习的输入隐藏权重，形状为(hidden​​size，input_size），其中 k = 0 。 否则，形状为(hidden​​size，numdirections * hidden​​size） 〜RNN.weight_hh_l [k] –第 k 层可学习的隐藏权重，形状为(hidden​​size，hidden​​size） 〜RNN.bias_ih_l [k] –第 k 层的可学习的输入隐藏偏差，形状为(hidden_​​size） 〜RNN.bias_hh_l [k] –第 k 层的可学习的隐藏偏差，形状为(hidden_​​size） Note 所有权重和偏差均从初始化，其中 Note 如果满足以下条件：1）启用 cudnn，2）输入数据在 GPU 上 3）输入数据具有 dtype torch.float16 4）使用 V100 GPU，5）输入数据不是PackedSequence格式的持久算法 可以选择以提高性能。 Examples: >>> rnn = nn.RNN(10, 20, 2) >>> input = torch.randn(5, 3, 10) >>> h0 = torch.randn(2, 3, 20) >>> output, hn = rnn(input, h0) LSTM class torch.nn.LSTM(*args, **kwargs)¶ 将多层长短期记忆(LSTM）RNN 应用于输入序列。 For each element in the input sequence, each layer computes the following function: 其中是时间 t 的隐藏状态，是时间 t 的单元状态，是时间 t 的输入 ，是时间 t-1 时层的隐藏状态，或者是时间 0 时的初始隐藏状态，以及，，， 分别是输入，忘记，单元和输出门。 是 S 型函数，是 Hadamard 乘积。 在多层 LSTM 中，第层(）的输入是前一层的隐藏状态乘以压降，其中每个是伯努利随机变量 概率为dropout的是。 Parameters input_size – The number of expected features in the input x hidden_size – The number of features in the hidden state h num_layers –循环层数。 例如，设置num_layers=2意味着将两个 LSTM 堆叠在一起以形成堆叠的 LSTM ，而第二个 LSTM 则接收第一个 LSTM 的输出并计算最终结果。 默认值：1 bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True batch_first –如果为True，则输入和输出张量按(batch，seq，feature）提供。 默认值：False dropout –如果不为零，则在除最后一层以外的每个 LSTM 层的输出上引入 Dropout 层，其丢弃概率等于dropout。 默认值：0 双向 –如果True变为双向 LSTM。 默认值：False Inputs: input, (h_0, c_0) 形状为(seq_len，批处理，input_size）的输入：：包含输入序列特征的张量。 输入也可以是打包的可变长度序列。 有关详细信息，请参见 torch.nn.utils.rnn.pack_padded_sequence() 或 torch.nn.utils.rnn.pack_sequence() 。 h0 的形状为(num_layers * num_directions，批处理，hidden​​size）：张量，包含批处理中每个元素的初始隐藏状态。 如果 LSTM 是双向的，则 num_directions 应该为 2，否则应为 1。 c_0 的形状为(numlayers * num_directions，批处理，hidden​​size）：张量，包含批处理中每个元素的初始单元状态。 如果未提供(h_0，c_0），则 h_0 和 c_0 均默认为零。 Outputs: output, (h_n, c_n) 每个[[G] t 。 如果已将 torch.nn.utils.rnn.PackedSequence 作为输入，则输出也将是打包序列。 For the unpacked case, the directions can be separated using output.view(seq_len, batch, num_directions, hidden_size), with forward and backward being direction 0 and 1 respectively. Similarly, the directions can be separated in the packed case. h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len. 像输出一样，可以使用h_n.view(num_layers, num_directions, batch, hidden_size)分隔各层，并且对于 c_n 同样。 cn 的形状为(num_layers * num_directions，batch，hidden​​size）：张量，其中包含 t = seq_len 的像元状态。 Variables 〜LSTM.weight_ih_l [k] – 形状为(4 k = 0 的[hidden_​​size，input_size）。 否则，形状为(4 hidden​​size，num_directions * hidden​​size） 〜LSTM.weight_hh_l [k] – 层(Whi | W_hf | W_hg | W_ho）的可学习的隐藏权重，形状为(4 * hidden​​size，hidden_​​size） 〜LSTM.bias_ih_l [k] – 层(bii | b_if | b_ig | b_io）的可学习输入隐藏偏置，形状为(4 * hidden​​size） 〜LSTM.bias_hh_l [k] – 层(bhi | b_hf | b_hg | b_ho）的可学习的隐藏偏置，形状为(4 * hidden​​size） Note All the weights and biases are initialized from where Note If the following conditions are satisfied: 1) cudnn is enabled, 2) input data is on the GPU 3) input data has dtype torch.float16 4) V100 GPU is used, 5) input data is not in PackedSequence format persistent algorithm can be selected to improve performance. Examples: >>> rnn = nn.LSTM(10, 20, 2) >>> input = torch.randn(5, 3, 10) >>> h0 = torch.randn(2, 3, 20) >>> c0 = torch.randn(2, 3, 20) >>> output, (hn, cn) = rnn(input, (h0, c0)) 格鲁 class torch.nn.GRU(*args, **kwargs)¶ 将多层门控循环单元(GRU）RNN 应用于输入序列。 For each element in the input sequence, each layer computes the following function: 其中是时间 t 的隐藏状态，是时间 t 的输入，是时间 t 时层的隐藏状态 -1 或时间 0 时的初始隐藏状态，以及，和分别是复位门，更新门和新门。 是 S 型函数，是 Hadamard 乘积。 在多层 GRU 中，第层(）的输入是前一层的隐藏状态乘以压降，其中每个是伯努利随机变量 概率为dropout的是。 Parameters input_size – The number of expected features in the input x hidden_size – The number of features in the hidden state h num_layers –循环层数。 例如，设置num_layers=2意味着将两个 GRU 堆叠在一起以形成堆叠的 GRU ，而第二个 GRU 则接收第一个 GRU 的输出并计算最终结果。 默认值：1 bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True batch_first – If True, then the input and output tensors are provided as (batch, seq, feature). Default: False 丢失 –如果不为零，则在除最后一层之外的每个 GRU 层的输出上引入丢失层，丢失概率等于dropout。 默认值：0 双向 –如果True成为双向 GRU。 默认值：False Inputs: input, h_0 形状为(seq_len，批处理，input_size）的输入：：包含输入序列特征的张量。 输入也可以是打包的可变长度序列。 有关详细信息，请参见 torch.nn.utils.rnn.pack_padded_sequence() 。 h_0 of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial hidden state for each element in the batch. Defaults to zero if not provided. If the RNN is bidirectional, num_directions should be 2, else it should be 1. Outputs: output, h_n 输出形状为(seqlen，batch，num_directions * hidden​​size）的：：对于每个 t ，张量包含来自 GRU 最后一层的输出特征 h_t。 如果已给定 torch.nn.utils.rnn.PackedSequence ，则输出也将是打包序列。 对于未包装的情况，可以使用output.view(seq_len, batch, num_directions, hidden_size)分离方向，向前和向后分别是方向 0 和 1 。 同样，在包装好的情况下，方向也可以分开。 h_n 的形状为(numlayers * num_directions，批处理，hidden​​size）：张量，其中包含的隐藏状态 t = seq_len Like output, the layers can be separated using h_n.view(num_layers, num_directions, batch, hidden_size). Shape: Input1: tensor containing input features where and L represents a sequence length. Input2: tensor containing the initial hidden state for each element in the batch. Defaults to zero if not provided. where If the RNN is bidirectional, num_directions should be 2, else it should be 1. Output1: where Output2: tensor containing the next hidden state for each element in the batch Variables 〜GRU.weight_ih_l [k] – 层(Wir | W_iz | W_in）的可学习的输入隐藏权重，形状为(3 * hidden​​size，inputsize） k = 0 。 否则，形状为(3 * hidden​​size，numdirections * hidden​​size） 〜GRU.weight_hh_l [k] – 层(Whr | W_hz | W_hn）的可学习隐藏权重，形状为(3 * hidden​​size，hidden_​​size） 〜GRU.bias_ih_l [k] – 层(bir | b_iz | b_in）的可学习输入隐藏偏置，形状为(3 * hidden​​size） 〜GRU.bias_hh_l [k] – 层(bhr | b_hz | b_hn）的可学习的隐藏偏置，形状为(3 * hidden​​size） Note All the weights and biases are initialized from where Note If the following conditions are satisfied: 1) cudnn is enabled, 2) input data is on the GPU 3) input data has dtype torch.float16 4) V100 GPU is used, 5) input data is not in PackedSequence format persistent algorithm can be selected to improve performance. Examples: >>> rnn = nn.GRU(10, 20, 2) >>> input = torch.randn(5, 3, 10) >>> h0 = torch.randn(2, 3, 20) >>> output, hn = rnn(input, h0) 核细胞 class torch.nn.RNNCell(input_size, hidden_size, bias=True, nonlinearity='tanh')¶ 具有 tanh 或 ReLU 非线性的 Elman RNN 单元。 如果nonlinearity为'relu'，则使用 ReLU 代替 tanh。 Parameters input_size – The number of expected features in the input x hidden_size – The number of features in the hidden state h bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True nonlinearity – The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh' Inputs: input, hidden 形状为的输入(批处理，input_size）：包含输入特征的张量 形状为(批次，hidden_​​size）的隐藏：张量，其中包含批次中每个元素的初始隐藏状态。 如果未提供，则默认为零。 Outputs: h’ h’的形状为(批处理，hidden_​​size）：张量，其中包含批次中每个元素的下一个隐藏状态 Shape: Input1：包含输入特征的张量，其中 = input_size Input2：张量，包含批处理中每个元素的初始隐藏状态，其中 = hidden_​​size 如果未提供，则默认为零。 输出：张量包含批处理中每个元素的下一个隐藏状态 Variables 〜RNNCell.weight_ih –可学习的输入隐藏权重，形状为(hidden_​​size，input_size） 〜RNNCell.weight_hh –可学习的隐藏权重，形状为(hidden​​size，hidden​​size） 〜RNNCell.bias_ih –形状为(hidden_​​size）的可学习的隐藏输入偏差 〜RNNCell.bias_hh –形状为(hidden_​​size）的可学习的隐藏偏差。 Note All the weights and biases are initialized from where Examples: >>> rnn = nn.RNNCell(10, 20) >>> input = torch.randn(6, 3, 10) >>> hx = torch.randn(3, 20) >>> output = [] >>> for i in range(6): hx = rnn(input[i], hx) output.append(hx) LSTM 单元 class torch.nn.LSTMCell(input_size, hidden_size, bias=True)¶ 长短期记忆(LSTM）单元。 其中是 S 型函数，是 Hadamard 乘积。 Parameters input_size – The number of expected features in the input x hidden_size – The number of features in the hidden state h 偏置-如果False，则该层不使用偏置权重 b_ih 和 b_hh 。 默认值：True Inputs: input, (h_0, c_0) input of shape (batch, input_size): tensor containing input features h_0 的形状为(批处理，hidden_​​size）：张量，其中包含批次中每个元素的初始隐藏状态。 c_0 的形状为(批处理，hidden_​​size）：张量，其中包含批次中每个元素的初始单元状态。 If (h_0, c_0) is not provided, both h_0 and c_0 default to zero. Outputs: (h_1, c_1) h1 的形状为(批处理，hidden​​size）：张量，其中包含批次中每个元素的下一个隐藏状态 c1 的形状为(批处理，hidden​​size）：张量，其中包含批次中每个元素的下一个单元格状态 Variables 〜LSTMCell.weight_ih –可学习的输入隐藏权重，形状为(4 * hidden_​​size，input_size） 〜LSTMCell.weight_hh –可学习的隐藏权重，形状为(4 * hidden​​size，hidden​​size） 〜LSTMCell.bias_ih –形状为(4 * hidden_​​size）的可学习的隐藏输入偏差 〜LSTMCell.bias_hh –形状为(4 * hidden_​​size）的可学习的隐藏偏差。 Note All the weights and biases are initialized from where Examples: >>> rnn = nn.LSTMCell(10, 20) >>> input = torch.randn(6, 3, 10) >>> hx = torch.randn(3, 20) >>> cx = torch.randn(3, 20) >>> output = [] >>> for i in range(6): hx, cx = rnn(input[i], (hx, cx)) output.append(hx) 格鲁塞尔 class torch.nn.GRUCell(input_size, hidden_size, bias=True)¶ 门控循环单元(GRU）单元 where is the sigmoid function, and is the Hadamard product. Parameters input_size – The number of expected features in the input x hidden_size – The number of features in the hidden state h bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True Inputs: input, hidden input of shape (batch, input_size): tensor containing input features hidden of shape (batch, hidden_size): tensor containing the initial hidden state for each element in the batch. Defaults to zero if not provided. Outputs: h’ h’ of shape (batch, hidden_size): tensor containing the next hidden state for each element in the batch Shape: Input1: tensor containing input features where = input_size Input2: tensor containing the initial hidden state for each element in the batch where = hidden_size Defaults to zero if not provided. Output: tensor containing the next hidden state for each element in the batch Variables 〜GRUCell.weight_ih –可学习的输入隐藏权重，形状为(3 * hidden_​​size，input_size） 〜GRUCell.weight_hh –可学习的隐藏权重，形状为(3 * hidden​​size，hidden​​size） 〜GRUCell.bias_ih –可学习的输入隐藏偏差，形状为(3 * hidden_​​size） 〜GRUCell.bias_hh –可学习的隐藏偏差，形状为(3 * hidden_​​size） Note All the weights and biases are initialized from where Examples: >>> rnn = nn.GRUCell(10, 20) >>> input = torch.randn(6, 3, 10) >>> hx = torch.randn(3, 20) >>> output = [] >>> for i in range(6): hx = rnn(input[i], hx) output.append(hx) 变压器层 变压器 class torch.nn.Transformer(d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, dropout=0.1, activation='relu', custom_encoder=None, custom_decoder=None)¶ 变压器模型。 用户可以根据需要修改属性。 该体系结构基于论文“注意就是您所需要的”。 Ashish Vaswani，Noam Shazeer，Niki Parmar，Jakob Uszkoreit，Llion Jones，Aidan N Gomez，Lukasz Kaiser 和 Illia Polosukhin。 2017 年。您只需要关注即可。 《神经信息处理系统的发展》，第 6000-6010 页。 用户可以使用相应的参数构建 BERT (https://arxiv.org/abs/1810.04805)模型。 Parameters d_model –编码器/解码器输入中的预期功能数量(默认= 512）。 nhead –多头注意力模型中的头数(默认为 8）。 num_encoder_layers –编码器中的子编码器层数(默认为 6）。 num_decoder_layers –解码器中子解码器层的数量(默认为 6）。 dim_feedforward -前馈网络模型的尺寸(默认= 2048）。 dropout -退出值(默认值= 0.1）。 激活 –编码器/解码器中间层 relu 或 gelu 的激活功能(默认= relu）。 custom_encoder –自定义编码器(默认=无）。 custom_decoder -自定义解码器(默认=无）。 Examples:: >>> transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12) >>> src = torch.rand((10, 32, 512)) >>> tgt = torch.rand((20, 32, 512)) >>> out = transformer_model(src, tgt) 注意：中提供了将 nn.Transformer 模块应用于单词语言模型的完整示例，网址为 https://github.com/pytorch/examples/tree/master/word_language_model forward(src, tgt, src_mask=None, tgt_mask=None, memory_mask=None, src_key_padding_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None)¶ 接收并处理屏蔽的源/目标序列。 Parameters src –编码器的序列(必需）。 tgt –解码器的序列(必需）。 src_mask – src 序列的附加掩码(可选）。 tgt_mask – tgt 序列的附加掩码(可选）。 memory_mask –编码器输出的附加掩码(可选）。 src_key_padding_mask –每批 src 密钥的 ByteTensor 掩码(可选）。 tgt_key_padding_mask –每批 tgt 密钥的 ByteTensor 掩码(可选）。 memory_key_padding_mask –每批存储密钥的 ByteTensor 掩码(可选）。 Shape: src：。 tgt：。 src_mask：。 tgt_mask：。 memory_mask：。 src_key_padding_mask：。 tgt_key_padding_mask：。 memory_key_padding_mask：。 注意：[src / tgt / memory] ​​_mask 应该用 float('-inf'）表示被遮盖的位置，而 float(0.0）表示其他。 这些掩码可确保对位置 i 的预测仅取决于未掩码的位置 j，并且对批次中的每个序列均应用相同的预测。 [src / tgt / memory] ​​_key_padding_mask 应该是 ByteTensor，其中 True 值是应该用 float('-inf'）掩盖的位置，而 False 值将保持不变。 此掩码可确保在屏蔽后不会从位置 i 获取任何信息，并且对于批次中的每个序列都有单独的掩码。 输出：。 注意：由于转换器模型中的多头注意架构，转换器的输出序列长度与解码的输入序列(即目标）长度相同。 其中 S 是源序列长度，T 是目标序列长度，N 是批处理大小，E 是特征编号 Examples >>> output = transformer_model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask) generate_square_subsequent_mask(sz)¶ 为该序列生成一个正方形蒙版。 屏蔽的位置填充有 float('-inf'）。 未屏蔽的位置填充有 float(0.0）。 变压器编码器 class torch.nn.TransformerEncoder(encoder_layer, num_layers, norm=None)¶ TransformerEncoder 是 N 个编码器层的堆栈 Parameters coder_layer – TransformerEncoderLayer(）类的实例(必需）。 num_layers –编码器中子编码器层的数量(必填）。 规范 –图层归一化组件(可选）。 Examples:: >>> encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8) >>> transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6) >>> src = torch.rand(10, 32, 512) >>> out = transformer_encoder(src) forward(src, mask=None, src_key_padding_mask=None)¶ 将输入依次通过编码器层。 Parameters src –编码器的序列(必需）。 掩码 – src 序列的掩码(可选）。 src_key_padding_mask –每批 src 密钥的掩码(可选）。 Shape: 请参阅 Transformer 类中的文档。 变压器解码器 class torch.nn.TransformerDecoder(decoder_layer, num_layers, norm=None)¶ TransformerDecoder 是 N 个解码器层的堆栈 Parameters coder_layer – TransformerDecoderLayer(）类的实例(必需）。 num_layers –解码器中子解码器层的数量(必填）。 norm – the layer normalization component (optional). Examples:: >>> decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8) >>> transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=6) >>> memory = torch.rand(10, 32, 512) >>> tgt = torch.rand(20, 32, 512) >>> out = transformer_decoder(tgt, memory) forward(tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None)¶ 输入(和掩码）依次通过解码器层。 Parameters tgt – the sequence to the decoder (required). 存储器 –从编码器最后一层开始的顺序(必需）。 tgt_mask – tgt 序列的掩码(可选）。 memory_mask –内存序列的掩码(可选）。 tgt_key_padding_mask –每批 tgt 密钥的掩码(可选）。 memory_key_padding_mask –每批存储密钥的掩码(可选）。 Shape: see the docs in Transformer class. TransformerEncoderLayer class torch.nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=2048, dropout=0.1, activation='relu')¶ TransformerEncoderLayer 由自检和前馈网络组成。 此标准编码器层基于“注意就是您所需要的”一文。 Ashish Vaswani，Noam Shazeer，Niki Parmar，Jakob Uszkoreit，Llion Jones，Aidan N Gomez，Lukasz Kaiser 和 Illia Polosukhin。 2017 年。您只需要关注即可。 《神经信息处理系统的发展》，第 6000-6010 页。 用户可以在应用过程中以不同的方式修改或实现。 Parameters d_model –输入中预期特征的数量(必填）。 nhead –多头注意力模型中的头数(必填）。 dim_feedforward – the dimension of the feedforward network model (default=2048). dropout – the dropout value (default=0.1). 激活 –中间层，relu 或 gelu(默认值= relu）的激活功能。 Examples:: >>> encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8) >>> src = torch.rand(10, 32, 512) >>> out = encoder_layer(src) forward(src, src_mask=None, src_key_padding_mask=None)¶ 使输入通过编码器层。 Parameters src –编码器层的序列(必需）。 src_mask – src 序列的掩码(可选）。 src_key_padding_mask – the mask for the src keys per batch (optional). Shape: see the docs in Transformer class. 变压器解码器层 class torch.nn.TransformerDecoderLayer(d_model, nhead, dim_feedforward=2048, dropout=0.1, activation='relu')¶ TransformerDecoderLayer 由自组织，多头组织和前馈网络组成。 这个标准的解码器层基于论文“注意就是全部”。 Ashish Vaswani，Noam Shazeer，Niki Parmar，Jakob Uszkoreit，Llion Jones，Aidan N Gomez，Lukasz Kaiser 和 Illia Polosukhin。 2017 年。您只需要关注即可。 《神经信息处理系统的发展》，第 6000-6010 页。 用户可以在应用过程中以不同的方式修改或实现。 Parameters d_model – the number of expected features in the input (required). nhead – the number of heads in the multiheadattention models (required). dim_feedforward – the dimension of the feedforward network model (default=2048). dropout – the dropout value (default=0.1). activation – the activation function of intermediate layer, relu or gelu (default=relu). Examples:: >>> decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8) >>> memory = torch.rand(10, 32, 512) >>> tgt = torch.rand(20, 32, 512) >>> out = decoder_layer(tgt, memory) forward(tgt, memory, tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None)¶ 将输入(和掩码）通过解码器层。 Parameters tgt –解码器层的序列(必需）。 memory – the sequnce from the last layer of the encoder (required). tgt_mask – the mask for the tgt sequence (optional). memory_mask – the mask for the memory sequence (optional). tgt_key_padding_mask – the mask for the tgt keys per batch (optional). memory_key_padding_mask – the mask for the memory keys per batch (optional). Shape: see the docs in Transformer class. 线性层 身分识别 class torch.nn.Identity(*args, **kwargs)¶ 对参数不敏感的占位符身份运算符。 Parameters args –任何参数(未使用） kwargs –任何关键字参数(未使用） Examples: >>> m = nn.Identity(54, unused_argument1=0.1, unused_argument2=False) >>> input = torch.randn(128, 20) >>> output = m(input) >>> print(output.size()) torch.Size([128, 20]) 线性的 class torch.nn.Linear(in_features, out_features, bias=True)¶ 对输入数据应用线性变换： Parameters in_features –每个输入样本的大小 out_features –每个输出样本的大小 偏差-如果设置为False，则该图层将不会学习加法偏差。 默认值：True Shape: 输入：，其中表示任意数量的附加尺寸， 输出：，除最后一个尺寸外，所有尺寸均与输入和相同。 Variables 〜Linear.weight -形状为的模块的可学习重量。 值从初始化，其中 〜Linear.bias -形状的模块的可学习偏差。 如果bias为True，则从初始化值，其中 Examples: >>> m = nn.Linear(20, 30) >>> input = torch.randn(128, 20) >>> output = m(input) >>> print(output.size()) torch.Size([128, 30]) 双线性 class torch.nn.Bilinear(in1_features, in2_features, out_features, bias=True)¶ 对输入数据应用双线性变换： Parameters in1_features –每个第一个输入样本的大小 in2_features –每秒钟输入样本的大小 out_features – size of each output sample 偏差-如果设置为 False，则该图层将不会学习加法偏差。 默认值：True Shape: 输入 1：，其中和表示任意数量的附加尺寸。 除了最后输入的维度外，其他所有维度均应相同。 输入 2：其中。 输出：，其中和除最后一个尺寸外的所有尺寸均与输入相同。 Variables 〜Bilinear.weight -形状为的模块的可学习权重。 值从初始化，其中 〜Bilinear.bias -形状的模块的可学习偏差。 如果bias为True，则从初始化值，其中 Examples: >>> m = nn.Bilinear(20, 30, 40) >>> input1 = torch.randn(128, 20) >>> input2 = torch.randn(128, 30) >>> output = m(input1, input2) >>> print(output.size()) torch.Size([128, 40]) 辍学层 退出 class torch.nn.Dropout(p=0.5, inplace=False)¶ 在训练期间，使用伯努利分布的样本以概率p将输入张量的某些元素随机归零。 在每个前向呼叫中，每个通道将独立清零。 如论文中所述，通过防止特征检测器的共同适应来改善神经网络，这已被证明是一种有效的技术，可用于规范化和防止神经元的共同适应。 此外，在训练期间，将输出缩放为。 这意味着在评估期间，模块仅计算身份函数。 Parameters p –元素归零的概率。 默认值：0.5 就地 –如果设置为True，将就地执行此操作。 默认值：False Shape: 输入：。 输入可以是任何形状 输出：。 输出与输入的形状相同 Examples: >>> m = nn.Dropout(p=0.2) >>> input = torch.randn(20, 16) >>> output = m(input) Dropout2d class torch.nn.Dropout2d(p=0.5, inplace=False)¶ 随机将整个通道调零(通道是 2D 特征图，例如，批输入中第个样本的第个通道是 2D 张量）。 使用伯努利分布中的样本，每个信道将在每次前向呼叫中以概率p独立清零。 通常，输入来自nn.Conv2d模块。 如论文中所述，使用卷积网络进行有效的对象定位，如果特征图中的相邻像素高度相关(通常是早期卷积层的情况），则 i.i.d。 辍学不会使激活规律化，否则只会导致有效学习率下降。 在这种情况下，nn.Dropout2d()将有助于促进要素地图之间的独立性，应改用nn.Dropout2d()。 Parameters p (python：float ， 可选）–元素归零的概率。 原位 (bool ， 可选）–如果设置为True，则将原位执行此操作 Shape: Input: Output: (same shape as input) Examples: >>> m = nn.Dropout2d(p=0.2) >>> input = torch.randn(20, 16, 32, 32) >>> output = m(input) 辍学 3d class torch.nn.Dropout3d(p=0.5, inplace=False)¶ 随机将整个通道调零(通道是 3D 特征图，例如，批输入中第个样本的第个通道是 3D 张量）。 使用伯努利分布中的样本，每个信道将在每次前向呼叫中以概率p独立清零。 通常，输入来自nn.Conv3d模块。 As described in the paper Efficient Object Localization Using Convolutional Networks , if adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then i.i.d. dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. 在这种情况下，nn.Dropout3d()将有助于促进要素地图之间的独立性，应改用nn.Dropout3d()。 Parameters p (python：float ， 可选）–元素归零的概率。 inplace (bool__, optional) – If set to True, will do this operation in-place Shape: Input: Output: (same shape as input) Examples: >>> m = nn.Dropout3d(p=0.2) >>> input = torch.randn(20, 16, 4, 32, 32) >>> output = m(input) AlphaDropout class torch.nn.AlphaDropout(p=0.5, inplace=False)¶ 将 Alpha Dropout 应用于输入。 Alpha Dropout 是一种 Dropout，可以维持自我规范化属性。 对于均值为零且单位标准差为零的输入，Alpha Dropout 的输出将保持输入的原始均值和标准差。 Alpha Dropout 与 SELU 激活功能紧密结合，可确保输出具有零均值和单位标准偏差。 在训练期间，它使用来自伯努利分布的样本以概率 p 随机掩盖输入张量的某些元素。 在每个前向调用中，要屏蔽的元素都会随机化，并进行缩放和移位以保持零均值和单位标准差。 在评估过程中，模块仅计算身份函数。 More details can be found in the paper Self-Normalizing Neural Networks . Parameters p (python：float )–元素被删除的概率。 默认值：0.5 inplace (bool__, optional) – If set to True, will do this operation in-place Shape: Input: . Input can be of any shape Output: . Output is of the same shape as input Examples: >>> m = nn.AlphaDropout(p=0.2) >>> input = torch.randn(20, 16) >>> output = m(input) 稀疏层 嵌入 class torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None)¶ 一个简单的查找表，用于存储固定字典和大小的嵌入。 该模块通常用于存储单词嵌入并使用索引检索它们。 模块的输入是索引列表，输出是相应的词嵌入。 Parameters num_embeddings (python：int )–嵌入字典的大小 embedding_dim (python：int )–每个嵌入向量的大小 padding_idx (python：int ， 可选）–如果给定，则在padding_idx处嵌入输出以填充输出(初始化为 零）。 max_norm (python：float ， 可选）–如果给定，则范数大于max_norm的每个嵌入矢量将重新规范化为具有 规范max_norm。 norm_type (python：float ， 可选）–为max_norm选项计算的 p 范数的 p。 默认值2。 scale_grad_by_freq (布尔值 ， 可选））–如果给定，则将按照最小 批量。 默认值False。 稀疏 (bool ， 可选）–如果True，则梯度 w.r.t. weight矩阵将是稀疏张量。 有关稀疏渐变的更多详细信息，请参见注释。 Variables 〜Embedding.weight (tensor)–形状模块的可学习权重(num_embeddings，embedding_dim）从初始化 Shape: 输入：，任意形状的 LongTensor，包含要提取的索引 输出：，其中 * 是输入形状， Note 请记住，只有有限数量的优化程序支持稀疏渐变：当前为optim.SGD (CUDA 和 CPU )，optim.SparseAdam (CUDA 和[ CPU )和optim.Adagrad (CPU ) Note 设置padding_idx时，padding_idx的嵌入矢量初始化为全零。 但是，请注意，此向量可以在以后进行修改，例如，使用定制的初始化方法，从而更改用于填充输出的向量。 来自 Embedding 的矢量的梯度始终为零。 Examples: >>> # an Embedding module containing 10 tensors of size 3 >>> embedding = nn.Embedding(10, 3) >>> # a batch of 2 samples of 4 indices each >>> input = torch.LongTensor([[1,2,4,5],[4,3,2,9]]) >>> embedding(input) tensor([[[-0.0251, -1.6902, 0.7172], [-0.6431, 0.0748, 0.6969], [ 1.4970, 1.3448, -0.9685], [-0.3677, -2.7265, -0.1685]], [[ 1.4970, 1.3448, -0.9685], [ 0.4362, -0.4004, 0.9400], [-0.6431, 0.0748, 0.6969], [ 0.9124, -2.3616, 1.1151]]]) >>> # example with padding_idx >>> embedding = nn.Embedding(10, 3, padding_idx=0) >>> input = torch.LongTensor([[0,2,0,5]]) >>> embedding(input) tensor([[[ 0.0000, 0.0000, 0.0000], [ 0.1535, -2.0309, 0.9315], [ 0.0000, 0.0000, 0.0000], [-0.1655, 0.9897, 0.0635]]]) classmethod from_pretrained(embeddings, freeze=True, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)¶ 从给定的二维 FloatTensor 创建嵌入实例。 Parameters 嵌入 (tensor)–包含嵌入权重的 FloatTensor。 第一维作为num_embeddings传递给嵌入，第二维作为embedding_dim传递给 Embedding。 冻结(布尔 ， 可选）–如果True，则张量不会在学习过程中更新。 等效于embedding.weight.requires_grad = False。 默认值：True padding_idx (python：int ， 可选）–请参阅模块初始化文档。 max_norm (python：float ， 可选）–请参阅模块初始化文档。 norm_type (python：float ， 可选）–请参阅模块初始化文档。 默认值2。 scale_grad_by_freq (布尔值 ， 可选）–请参见模块初始化文档。 默认值False。 稀疏 (bool ， 可选）–请参阅模块初始化文档。 Examples: >>> # FloatTensor containing pretrained weights >>> weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]]) >>> embedding = nn.Embedding.from_pretrained(weight) >>> # Get embeddings for index 1 >>> input = torch.LongTensor([1]) >>> embedding(input) tensor([[ 4.0000, 5.1000, 6.3000]]) 嵌入袋 class torch.nn.EmbeddingBag(num_embeddings, embedding_dim, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, mode='mean', sparse=False, _weight=None)¶ 计算嵌入“袋”的总和或方法，而无需实例化中间嵌入。 对于恒定长度且没有per_sample_weights的袋子，此类 mode=\"sum\"等于 Embedding ，然后是torch.sum(dim=0)， mode=\"mean\"等于 Embedding ，然后是torch.mean(dim=0)， mode=\"max\"的等效于 Embedding ，然后是torch.max(dim=0)。 但是， EmbeddingBag 比使用这些操作链要花费更多的时间和内存。 EmbeddingBag 还支持按样本权重作为正向传递的参数。 在执行mode指定的加权缩减之前，这会缩放嵌入的输出。 如果通过per_sample_weights``，则唯一支持的mode是\"sum\"，它根据per_sample_weights`计算加权和。 Parameters num_embeddings (python:int) – size of the dictionary of embeddings embedding_dim (python:int) – the size of each embedding vector max_norm (python:float__, optional) – If given, each embedding vector with norm larger than max_norm is renormalized to have norm max_norm. norm_type (python:float__, optional) – The p of the p-norm to compute for the max_norm option. Default 2. scale_grad_by_freq (布尔 ， 可选）–如果指定，则将按比例缩小坡度中单词的频率 批量。 默认值False。 注意：mode=\"max\"时不支持此选项。 模式(字符串 ， 可选）– \"sum\"，\"mean\"或\"max\"。 指定减少袋子的方式。 \"sum\"会考虑per_sample_weights来计算加权总和。 \"mean\"计算袋子中值的平均值，\"max\"计算每个袋子中的最大值。 默认值：\"mean\" 稀疏 (bool ， 可选）–如果True，则梯度 w.r.t. weight矩阵将是稀疏张量。 有关稀疏渐变的更多详细信息，请参见注释。 注意：mode=\"max\"时不支持此选项。 Variables 〜EmbeddingBag.weight (tensor)–形状为的模块的可学习权重(从初始化的 num_embeddings，embedding_dim） 。 Inputs: input (LongTensor), offsets (LongTensor, optional), and per_index_weights(张量，可选） 如果input是形状为(B，N）的二维， 它将被视为B袋(序列），每个袋子的长度都是固定长度N，这将返回B值的汇总值取决于mode。 在这种情况下，offsets被忽略，必须为None。 如果input是形状为(N）的 1D， 它将被视为多个包(序列）的串联。 offsets必须是一维张量，其中包含input中每个包的起始索引位置。 因此，对于形状为(B）的offsets，input将被视为具有B袋。 空袋子(即长度为 0 的袋子）将返回由零填充的向量。 per_sample_weights (Tensor, optional): a tensor of float / double weights, or None 表示所有权重应为1。 如果指定，per_sample_weights必须具有与输入完全相同的形状，并且如果不是None，则将其视为具有相同的offsets。 仅支持mode='sum'。 输出形状：(B，embedding_dim） Examples: >>> # an Embedding module containing 10 tensors of size 3 >>> embedding_sum = nn.EmbeddingBag(10, 3, mode='sum') >>> # a batch of 2 samples of 4 indices each >>> input = torch.LongTensor([1,2,4,5,4,3,2,9]) >>> offsets = torch.LongTensor([0,4]) >>> embedding_sum(input, offsets) tensor([[-0.8861, -5.4350, -0.0523], [ 1.1306, -2.5798, -1.0044]]) classmethod from_pretrained(embeddings, freeze=True, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, mode='mean', sparse=False)¶ 从给定的二维 FloatTensor 创建 EmbeddingBag 实例。 Parameters 嵌入 (tensor)–包含 EmbeddingBag 权重的 FloatTensor。 第一维正以“ num_embeddings”传递给 EmbeddingBag，第二维以“ embedding_dim”传递。 冻结(布尔 ， 可选）–如果True，则张量不会在学习过程中更新。 等效于embeddingbag.weight.requires_grad = False。 默认值：True max_norm (python：float ， 可选）–请参阅模块初始化文档。 默认值：None norm_type (python:float__, optional) – See module initialization documentation. Default 2. scale_grad_by_freq (boolean__, optional) – See module initialization documentation. Default False. 模式(字符串 ， 可选）–请参见模块初始化文档。 默认值：\"mean\" 稀疏 (bool ， 可选）–请参阅模块初始化文档。 默认值：False。 Examples: >>> # FloatTensor containing pretrained weights >>> weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]]) >>> embeddingbag = nn.EmbeddingBag.from_pretrained(weight) >>> # Get embeddings for index 1 >>> input = torch.LongTensor([[1, 0]]) >>> embeddingbag(input) tensor([[ 2.5000, 3.7000, 4.6500]]) 距离功能 余弦相似度 class torch.nn.CosineSimilarity(dim=1, eps=1e-08)¶ 传回与之间的余弦相似度(沿 dim 计算）。 Parameters 昏暗的 (python：int ， 可选）–计算余弦相似度的维度。 默认值：1 eps (python：float ， 可选）–避免被零除的小值。 默认值：1e-8 Shape: 输入 1：，其中 D 在位置变暗 Input2：，形状与 Input1 相同 输出： Examples:: >>> input1 = torch.randn(100, 128) >>> input2 = torch.randn(100, 128) >>> cos = nn.CosineSimilarity(dim=1, eps=1e-6) >>> output = cos(input1, input2) 成对距离 class torch.nn.PairwiseDistance(p=2.0, eps=1e-06, keepdim=False)¶ 使用 p 范数计算向量和之间的成对成对距离： Parameters p (实数）–规范度。 默认值：2 eps (python：float ， 可选）–避免被零除的小值。 默认值：1e-6 keepdim (bool ， 可选）–确定是否保留矢量尺寸。 默认值：False Shape: 输入 1：，其中 D =矢量尺寸 Input2：，形状与 Input1 相同 输出：。 如果keepdim为True，则。 Examples:: >>> pdist = nn.PairwiseDistance(p=2) >>> input1 = torch.randn(100, 128) >>> input2 = torch.randn(100, 128) >>> output = pdist(input1, input2) 损失函数 L1 损失 class torch.nn.L1Loss(size_average=None, reduce=None, reduction='mean')¶ 创建一个标准，该标准测量输入中的每个元素与目标中的平均绝对误差(MAE）。 未减少的损失(即reduction设置为'none'）的损失可描述为： 其中是批次大小。 如果reduction不是'none'(默认为'mean'），则： 和是任意形状的张量，每个张量共有个元素。 求和运算仍对所有元素进行运算，并除以。 如果一组reduction = 'sum'可以避免被划分。 Parameters size_average (布尔 ， 可选）–已弃用(请参见reduction）。 默认情况下，损失是批次中每个损失元素的平均数。 请注意，对于某些损失，每个样本有多个元素。 如果将字段size_average设置为False，则每个小批量的损失总和。 当 reduce 为False时将被忽略。 默认值：True 还原(布尔 ， 可选）–已弃用(请参阅reduction）。 默认情况下，取决于size_average，对每个小批量的观测值求平均或求和。 当reduce为False时，返回每批元素损失，并忽略size_average。 默认值：True 缩减(字符串 ， 可选）–指定要应用于输出的缩减：'none' | 'mean' | 'sum'。 'none'：不应用任何减少量； 'mean'：输出的总和除以输出中元素的数量； 'sum'：将对输出求和。 注意：size_average和reduce正在淘汰中，与此同时，指定这两个 args 中的任何一个将覆盖reduction。 默认值：'mean' Shape: 输入：其中表示任意数量的附加尺寸 目标：，形状与输入相同 输出：标量。 如果reduction为'none'，则的形状与输入相同 Examples: >>> loss = nn.L1Loss() >>> input = torch.randn(3, 5, requires_grad=True) >>> target = torch.randn(3, 5) >>> output = loss(input, target) >>> output.backward() 选配 class torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')¶ 创建一个标准，该标准测量输入和目标中每个元素之间的均方误差(L2 平方平方）。 The unreduced (i.e. with reduction set to 'none') loss can be described as: where is the batch size. If reduction is not 'none' (default 'mean'), then: and are tensors of arbitrary shapes with a total of elements each. The sum operation still operates over all the elements, and divides by . The division by can be avoided if one sets reduction = 'sum'. Parameters size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: Input: where means, any number of additional dimensions Target: , same shape as the input Examples: >>> loss = nn.MSELoss() >>> input = torch.randn(3, 5, requires_grad=True) >>> target = torch.randn(3, 5) >>> output = loss(input, target) >>> output.backward() 交叉熵损失 class torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')¶ 此标准将nn.LogSoftmax()和nn.NLLLoss()合并为一个类别。 在训练带有 C 类的分类问题时很有用。 如果提供的话，可选参数weight应该是一维张量，为每个类分配权重。 当您的训练集不平衡时，此功能特别有用。 输入预计将包含每个类别的原始，未标准化的分数。 对于 K -维情况(稍后描述），输入必须为或和大小的张量。 对于一个大小为 minibatch 的 1D 张量张量的每个值，此标准都希望在范围内的类别索引作为目标； 如果指定了 ignore_index ，则此条件也接受该类索引(该索引可能不一定在类范围内）。 损失可描述为： 或在指定weight参数的情况下： 对于每个小批量，损失是通过观察得出的平均值。 通过提供大小为的输入(其中是尺寸的数量）和适当形状的目标，也可以用于更高尺寸的输入(例如 2D 图像）(请参见下文）。 Parameters 重量 (tensor ， 可选）–为每个类别提供手动缩放比例的重量。 如果给定，则其张量必须为 C size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True ignore_index (python：int ， 可选）–指定目标值，该目标值将被忽略并且不会对输入梯度产生影响。 当size_average为True时，损耗是在不可忽略的目标上平均的。 reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: 输入：，其中 C =类的数量，或在 K -尺寸损失的情况下，和一起使用。 目标：，其中每个值为，或者在 K 维丢失的情况下为和。 输出：标量。 如果reduction为'none'，则与 K 尺寸相同：或，带有的对象在 K 维丢失的情况下。 Examples: >>> loss = nn.CrossEntropyLoss() >>> input = torch.randn(3, 5, requires_grad=True) >>> target = torch.empty(3, dtype=torch.long).random_(5) >>> output = loss(input, target) >>> output.backward() CTCLoss class torch.nn.CTCLoss(blank=0, reduction='mean', zero_infinity=False)¶ 连接主义者的时间分类损失。 计算连续(非分段）时间序列与目标序列之间的损失。 CTCLoss 将输入与目标进行可能的对齐之和加起来，从而产生相对于每个输入节点可微分的损耗值。 假设输入与目标的比对是“多对一”，这限制了目标序列的长度，因此它必须是输入长度的。 Parameters 空白 (python：int ， 可选）–空白标签。 默认值。 缩减(字符串 ， 可选）–指定要应用于输出的缩减：'none' | 'mean' | 'sum'。 'none'：不应用减少量，'mean'：将输出损失除以目标长度，然后取批次的平均值。 默认值：'mean' zero_infinity (bool ， 可选）–是否将无限大损失和相关的梯度归零。 默认值：False无限损失主要发生在输入太短而无法与目标对齐时。 Shape: Log_probs：大小为的张量，其中，和。 输出的对数概率(例如，使用 torch.nn.functional.log_softmax() 获得的概率）。 目标：大小为或的张量，其中和。 它代表靶序列。 目标序列中的每个元素都是一个类索引。 并且目标索引不能为空(默认= 0）。 在形式中，将目标填充到最长序列的长度，然后堆叠。 在格式中，假定目标未填充且在 1 维内连接。 Input_lengths：大小为的元组或张量，其中。 它代表输入的长度(每个必须为）。 并且在序列被填充为相等长度的假设下，为每个序列指定长度以实现屏蔽。 Target_lengths：大小为的元组或张量，其中。 它代表目标的长度。 在将序列填充为相等长度的假设下，为每个序列指定长度以实现屏蔽。 如果目标形状为，则 target_lengths 实际上是每个目标序列的终止索引，从而使批次中每个目标的target_n = targets[n,0:s_n]。 每个长度都必须为如果目标是作为单个目标的并置的 1d 张量给出的，则 target_lengths 必须加起来为张量的总长度。 输出：标量。 如果reduction为'none'，则为，其中。 Example: >>> T = 50 # Input sequence length >>> C = 20 # Number of classes (including blank) >>> N = 16 # Batch size >>> S = 30 # Target sequence length of longest target in batch >>> S_min = 10 # Minimum target length, for demonstration purposes >>> >>> # Initialize random batch of input vectors, for *size = (T,N,C) >>> input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_() >>> >>> # Initialize random batch of targets (0 = blank, 1:C = classes) >>> target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long) >>> >>> input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long) >>> target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long) >>> ctc_loss = nn.CTCLoss() >>> loss = ctc_loss(input, target, input_lengths, target_lengths) >>> loss.backward() Reference: A. Graves 等人：连接主义者的时间分类：使用循环神经网络标记未分段的序列数据： https://www.cs.toronto.edu/~graves/icml_2006.pdf Note 为了使用 CuDNN，必须满足以下条件：targets必须为级联格式，所有input_lengths都必须为 T 。 ，target_lengths ，整数参数必须为 dtype torch.int32。 常规实现使用(在 PyTorch 中更常见） torch.long dtype。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. 亏损 class torch.nn.NLLLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')¶ 负对数似然损失。 训练带有 C 类的分类问题很有用。 如果提供，则可选参数weight应该是一维 Tensor，为每个类分配权重。 当您的训练集不平衡时，此功能特别有用。 通过前向调用给出的输入预计将包含每个类的对数概率。 对于 K -维情况(稍后描述），输入的张量必须为或和的大小。 通过在网络的最后一层添加 LogSoftmax 层，可以轻松获得神经网络中的对数概率。 如果您不想添加额外的图层，则可以改用 CrossEntropyLoss 。 该损失预期的目标应该是范围内的类别索引，其中 C =类别数； 如果指定了 ignore_index ，则此丢失也将接受该类索引(该索引可能不一定在类范围内）。 The unreduced (i.e. with reduction set to 'none') loss can be described as: 其中是批次大小。 如果reduction不是'none'(默认为'mean'），则 通过提供大小为的输入(其中是尺寸的数量）和适当形状的目标，也可以用于更高尺寸的输入(例如 2D 图像）(请参见下文）。 对于图像，它计算每像素 NLL 损耗。 Parameters 重量 (tensor ， 可选）–为每个类别提供手动缩放比例的重量。 如果给定，则它必须是 C 大小的张量。 否则，将其视为拥有全部。 size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True ignore_index (python：int ， 可选）–指定目标值，该目标值将被忽略并且不会对输入梯度产生影响。 当size_average为True时，损耗是在不可忽略的目标上平均的。 reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: Input: where C = number of classes, or with in the case of K-dimensional loss. Target: where each value is , or with in the case of K-dimensional loss. 输出：标量。 如果reduction为'none'，则与 K 尺寸相同：或，带有的对象在 K 维丢失的情况下。 Examples: >>> m = nn.LogSoftmax(dim=1) >>> loss = nn.NLLLoss() >>> # input is of size N x C = 3 x 5 >>> input = torch.randn(3, 5, requires_grad=True) >>> # each element in target has to have 0 >> target = torch.tensor([1, 0, 4]) >>> output = loss(m(input), target) >>> output.backward() >>> >>> >>> # 2D loss example (used, for example, with image inputs) >>> N, C = 5, 4 >>> loss = nn.NLLLoss() >>> # input is of size N x C x height x width >>> data = torch.randn(N, 16, 10, 10) >>> conv = nn.Conv2d(16, C, (3, 3)) >>> m = nn.LogSoftmax(dim=1) >>> # each element in target has to have 0 >> target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C) >>> output = loss(m(conv(data)), target) >>> output.backward() 泊松 class torch.nn.PoissonNLLLoss(log_input=True, full=False, size_average=None, eps=1e-08, reduce=None, reduction='mean')¶ 带有目标泊松分布的负对数似然损失。 The loss can be described as: 最后一项可以省略，也可以用斯特林公式近似。 逼近值用于大于 1 的目标值。对于小于或等于 1 的目标值，零添加到损耗中。 Parameters log_input (bool ， 可选）–如果True的损失计算为，如果False的损失计算 是。 完整的 (bool ， 可选）– 是否计算全部损失； i。 e。 添加斯特林近似项 size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True eps (python：float ， 可选）–较小的值，以避免在log_input = False时评估。 默认值：1e-8 reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Examples: >>> loss = nn.PoissonNLLLoss() >>> log_input = torch.randn(5, 2, requires_grad=True) >>> target = torch.randn(5, 2) >>> output = loss(log_input, target) >>> output.backward() Shape: Input: where means, any number of additional dimensions Target: , same shape as the input 输出：默认情况下为标量。 如果reduction为'none'，则的形状与输入相同 损失 class torch.nn.KLDivLoss(size_average=None, reduce=None, reduction='mean')¶ Kullback-Leibler 散度损失 KL 散度是用于连续分布的有用距离度量，并且在对(离散采样）连续输出分布的空间进行直接回归时通常很有用。 与 NLLLoss 一样，给定的输入预期包含对数概率，并且不限于 2D 张量。 目标以概率给出(即，不取对数）。 该标准要求目标 张量与输入 张量大小相同。 The unreduced (i.e. with reduction set to 'none') loss can be described as: 其中索引跨越input的所有维度，并且具有与input相同的形状。 如果reduction不是'none'(默认为'mean'），则： 在默认的reduction模式'mean'中，损耗是对观察值和尺寸上的的每个小批量进行平均的。 'batchmean'模式给出正确的 KL 散度，其中损失仅在批次范围内平均。 在下一个主要版本中，'mean'模式的行为将更改为与'batchmean'相同。 Parameters size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True 缩减(字符串 ， 可选）–指定要应用于输出的缩减：'none' | 'batchmean' | 'sum' | 'mean'。 'none'：不应用减少。 'batchmean'：输出的总和将除以 batchsize。 'sum'：将对输出求和。 'mean'：输出将除以输出中的元素数。 默认值：'mean' Note size_average和reduce正在弃用的过程中，与此同时，指定这两个 args 中的任何一个将覆盖reduction。 Note reduction = 'mean'未返回真实的 kl 散度值，请使用与 KL 数学定义一致的reduction = 'batchmean'。 在下一个主要版本中，'mean'将更改为与'batchmean'相同。 Shape: Input: where means, any number of additional dimensions Target: , same shape as the input 输出：默认情况下为标量。 如果：attr：reduction为'none'，则的形状与输入的形状相同 BCELoss class torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')¶ 创建一个衡量目标和输出之间的二进制交叉熵的标准： The unreduced (i.e. with reduction set to 'none') loss can be described as: where is the batch size. If reduction is not 'none' (default 'mean'), then 这用于测量例如自动编码器中的重建误差。 请注意，目标应为 0 到 1 之间的数字。 Parameters 重量 (tensor ， 可选）–手工重新定标重量，以补偿每个批次元素的损失。 如果给定，则必须是大小为 nbatch 的张量。 size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: Input: where means, any number of additional dimensions Target: , same shape as the input 输出：标量。 如果reduction为'none'，则与输入形状相同。 Examples: >>> m = nn.Sigmoid() >>> loss = nn.BCELoss() >>> input = torch.randn(3, requires_grad=True) >>> target = torch.empty(3).random_(2) >>> output = loss(m(input), target) >>> output.backward() BCEWithLogitsLoss class torch.nn.BCEWithLogitsLoss(weight=None, size_average=None, reduce=None, reduction='mean', pos_weight=None)¶ 这种损失将乙状结肠层和 BCELoss 合并为一个类别。 该版本比使用普通的 Sigmoid 和随后的 BCELoss 在数值上更稳定，因为通过将操作合并为一层，我们利用了 log-sum-exp 技巧进行数值计算 稳定性。 The unreduced (i.e. with reduction set to 'none') loss can be described as: where is the batch size. If reduction is not 'none' (default 'mean'), then 这用于测量例如自动编码器中的重建误差。 请注意，目标 t [i] 应为 0 到 1 之间的数字。 通过在积极的例子中增加权重，可以权衡召回率和准确性。 在多标签分类的情况下，损失可描述为： 其中，是类别编号(对于多标签二进制分类，；对于单标签二进制分类，），是批次中样品的数量，是样品的重量 课程的肯定答案。 增加查全率，增加精度。 例如，如果数据集包含一个类的 100 个正例和 300 个负例，则该类的 pos_weight 应等于。 损失将好像数据集包含阳性示例。 Examples: >>> target = torch.ones([10, 64], dtype=torch.float32) # 64 classes, batch size = 10 >>> output = torch.full([10, 64], 0.999) # A prediction (logit) >>> pos_weight = torch.ones([64]) # All weights are equal to 1 >>> criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight) >>> criterion(output, target) # -log(sigmoid(0.999)) tensor(0.3135) Parameters weight (Tensor, optional) – a manual rescaling weight given to the loss of each batch element. If given, has to be a Tensor of size nbatch. size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' pos_weight (tensor ， 可选）–正例的权重。 必须是长度等于类数的向量。 Shape: 输入：其中表示任意数量的附加尺寸 Target: , same shape as the input Output: scalar. If reduction is 'none', then , same shape as input. Examples: >>> loss = nn.BCEWithLogitsLoss() >>> input = torch.randn(3, requires_grad=True) >>> target = torch.empty(3).random_(2) >>> output = loss(input, target) >>> output.backward() 保证金排名损失 class torch.nn.MarginRankingLoss(margin=0.0, size_average=None, reduce=None, reduction='mean')¶ 创建一个标准来测量给定输入，，两个 1D 迷你批量张量和标签 1D 迷你批量张量(包含 1 或-1）的损耗。 如果，则假定第一个输入的排名应高于第二个输入(具有更大的值），反之亦然。 迷你批次中每个样本的损失函数为： Parameters 边距 (python：float ， 可选）–默认值为。 size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: 输入：，其中 N 是批次大小， D 是样本大小。 目标： 输出：标量。 如果reduction是'none'，则。 嵌入损耗 class torch.nn.HingeEmbeddingLoss(margin=1.0, size_average=None, reduce=None, reduction='mean')¶ 在输入张量和标签张量(包含 1 或-1）的情况下测量损耗。 通常用于测量两个输入是否相似或不相似，例如 使用 L1 成对距离作为，通常用于学习非线性嵌入或半监督学习。 微型批次中第个样本的损失函数为 总损失函数为 其中。 Parameters 边距 (python：float ， 可选）–默认值为 1 。 size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: 输入：其中表示任意数量的尺寸。 求和运算对所有元素进行运算。 目标：，形状与输入相同 输出：标量。 如果reduction为'none'，则形状与输入相同 多标签保证金损失 class torch.nn.MultiLabelMarginLoss(size_average=None, reduce=None, reduction='mean')¶ 创建一个标准，以优化输入(2D 微型批量张量）和输出(2D 目标类别索引的张量。 对于小批量中的每个样品： 其中，，，和都适用于和。 和的大小必须相同。 该标准仅考虑从正面开始的非负目标的连续块。 这允许不同的样本具有可变数量的目标类别。 Parameters size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: 输入：或，其中 N 是批处理大小， C 是类别数。 目标：或，标有-1 的标签目标确保与输入形状相同。 Output: scalar. If reduction is 'none', then . Examples: >>> loss = nn.MultiLabelMarginLoss() >>> x = torch.FloatTensor([[0.1, 0.2, 0.4, 0.8]]) >>> # for target y, only consider labels 3 and 0, not after label -1 >>> y = torch.LongTensor([[3, 0, -1, 1]]) >>> loss(x, y) >>> # 0.25 * ((1-(0.1-0.2)) + (1-(0.1-0.4)) + (1-(0.8-0.2)) + (1-(0.8-0.4))) tensor(0.8500) 平滑 L1 损失 class torch.nn.SmoothL1Loss(size_average=None, reduce=None, reduction='mean')¶ 如果每个元素的绝对误差小于 1，则创建一个使用平方项的条件，否则，则使用 L1 项。 它对异常值的敏感性不及 MSELoss ，并且在某些情况下可以防止爆炸梯度(例如，参见 Ross Girshick 的 Fast R-CNN 论文）。 也称为胡贝尔损耗： 其中的计算公式为： 具有总共个元素的和任意形状，求和运算仍对所有元素进行运算，并除以。 如果设置reduction = 'sum'，则可以避免被划分。 Parameters size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: Input: where means, any number of additional dimensions Target: , same shape as the input Output: scalar. If reduction is 'none', then , same shape as the input 软保证金损失 class torch.nn.SoftMarginLoss(size_average=None, reduce=None, reduction='mean')¶ 创建一个标准，以优化输入张量与目标张量(包含 1 或-1）之间的两类分类逻辑损失。 Parameters size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: 输入：其中表示任意数量的附加尺寸 Target: , same shape as the input Output: scalar. If reduction is 'none', then same shape as the input MultiLabelSoftMarginLoss class torch.nn.MultiLabelSoftMarginLoss(weight=None, size_average=None, reduce=None, reduction='mean')¶ 创建一个标准，该标准基于大小的输入和目标之间的最大熵，优化多标签“一对全”损失。 对于小批量中的每个样品： 其中和。 Parameters weight (Tensor, optional) – a manual rescaling weight given to each class. If given, it has to be a Tensor of size C. Otherwise, it is treated as if having all ones. size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: 输入：，其中 N 是批次大小， C 是类别数量。 目标：，用-1 填充的标签目标确保与输入形状相同。 Output: scalar. If reduction is 'none', then . 余弦嵌入损失 class torch.nn.CosineEmbeddingLoss(margin=0.0, size_average=None, reduce=None, reduction='mean')¶ 创建一个标准来测量给定输入张量，和张量标签的损耗，其值为 1 或-1。 这用于使用余弦距离来测量两个输入是否相似或不相似，并且通常用于学习非线性嵌入或半监督学习。 每个样本的损失函数为： Parameters 保证金 (python：float ， 可选）–应该是从到， 建议使用。 如果缺少margin，则默认值为。 size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' 多保证金亏损 class torch.nn.MultiMarginLoss(p=1, margin=1.0, weight=None, size_average=None, reduce=None, reduction='mean')¶ 创建一个标准，以优化输入(2D 微型批处理张量）和输出(目标的 1D 张量）之间的多类分类铰链损耗(基于边距的损耗） 类别索引）： 对于每个小批量样品，一维输入和标量输出的损耗为： 其中和。 (可选）您可以通过将 1D weight张量传递到构造函数中来对类进行非相等加权。 损失函数将变为： Parameters p (python：int ， 可选）–默认值为。 仅支持和值。 边距 (python：float ， 可选）–默认值为。 weight (Tensor, optional) – a manual rescaling weight given to each class. If given, it has to be a Tensor of size C. Otherwise, it is treated as if having all ones. size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' 三重保证金亏损 class torch.nn.TripletMarginLoss(margin=1.0, p=2.0, eps=1e-06, swap=False, size_average=None, reduce=None, reduction='mean')¶ 创建一个标准，该标准在输入张量，，和值大于的边距下测量三重态损失。 这用于测量样本之间的相对相似性。 一个三元组由 a ， p 和 n 组成(即锚定，阳性示例和[HTG14 负面示例）。 所有输入张量的形状应为。 V. Balntas，E. Riba 等人的论文学习具有三重态损失的浅卷积特征描述符中详细描述了距离交换。 The loss function for each sample in the mini-batch is: 哪里 Parameters 边距 (python：float ， 可选）–默认值：。 p (python：int ， 可选）–成对距离的标准度。 默认值：。 交换 (bool ， 可选）–距离交换在论文中详细描述。通过以下方法学习浅卷积特征描述符 V. Balntas，E。Riba 等人的三重损失。 默认值：False。 size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: 输入：其中是矢量尺寸。 Output: scalar. If reduction is 'none', then . >>> triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2) >>> anchor = torch.randn(100, 128, requires_grad=True) >>> positive = torch.randn(100, 128, requires_grad=True) >>> negative = torch.randn(100, 128, requires_grad=True) >>> output = triplet_loss(anchor, positive, negative) >>> output.backward() 视觉层 像素随机播放 class torch.nn.PixelShuffle(upscale_factor)¶ 将形状为的张量中的元素重新排列为形状为的张量中的元素。 这对于实现跨度为的有效子像素卷积很有用。 看论文：Shi 等人的使用高效的亚像素卷积神经网络进行实时单图像和视频超分辨率。 al(2016）了解更多详情。 Parameters upscale_factor (python：int )–通过提高空间分辨率的因子 Shape: 输入：，其中 输出：，其中和 Examples: >>> pixel_shuffle = nn.PixelShuffle(3) >>> input = torch.randn(1, 9, 4, 4) >>> output = pixel_shuffle(input) >>> print(output.size()) torch.Size([1, 1, 12, 12]) 上采样 class torch.nn.Upsample(size=None, scale_factor=None, mode='nearest', align_corners=None)¶ 上采样给定的多通道 1D(时间），2D(空间）或 3D(体积）数据。 假定输入数据的形式为微型批处理 x 通道 x [可选深度] x [可选高度] x 宽度。 因此，对于空间输入，我们期望使用 4D 张量；对于体积输入，我们期望使用 5D 张量。 可用于上采样的算法分别是 3D，4D 和 5D 输入张量的最近邻和线性，双线性，双三次和三线性。 可以给出scale_factor或目标输出size来计算输出大小。 (因为模棱两可，您不能同时给出两者） Parameters 大小 (python：int 或 元组 [ python：int ]或 元组 [ python：int ， python：int ]或 元组 [ python：int ， python：int ， python：int ] ， 可选）–输出空间大小 scale_factor (python：float 或 元组 [ python：float ]或 元组 [ python：float ， python：float ]或 元组 [ python：float ， python：float ， python：float ] ， 可选）–空间大小的乘数。 如果是元组，则必须匹配输入大小。 模式 (str ， 可选）–上采样算法：'nearest'，'linear'，'bilinear'，[ 'bicubic'和'trilinear'。 默认值：'nearest' align_corners (bool ， 可选）–如果True，则输入和输出张量的角像素对齐，因此 保留这些像素的值。 仅在mode为'linear'，'bilinear'或'trilinear'时才有效。 默认值：False Shape: 输入：，或 输出：，或，其中 Warning 使用align_corners = True时，线性插值模式(线性，双线性，双三次和三线性）不会按比例对齐输出 和输入像素，因此输出值可能取决于输入大小。 这是这些模式(0.3.1 版之前）的默认行为。 从那时起，默认行为是align_corners = False。 有关如何影响输出的具体示例，请参见下文。 Note 如果要缩减采样/调整大小，应使用interpolate()。 Examples: >>> input = torch.arange(1, 5, dtype=torch.float32).view(1, 1, 2, 2) >>> input tensor([[[[ 1., 2.], [ 3., 4.]]]]) >>> m = nn.Upsample(scale_factor=2, mode='nearest') >>> m(input) tensor([[[[ 1., 1., 2., 2.], [ 1., 1., 2., 2.], [ 3., 3., 4., 4.], [ 3., 3., 4., 4.]]]]) >>> m = nn.Upsample(scale_factor=2, mode='bilinear') # align_corners=False >>> m(input) tensor([[[[ 1.0000, 1.2500, 1.7500, 2.0000], [ 1.5000, 1.7500, 2.2500, 2.5000], [ 2.5000, 2.7500, 3.2500, 3.5000], [ 3.0000, 3.2500, 3.7500, 4.0000]]]]) >>> m = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True) >>> m(input) tensor([[[[ 1.0000, 1.3333, 1.6667, 2.0000], [ 1.6667, 2.0000, 2.3333, 2.6667], [ 2.3333, 2.6667, 3.0000, 3.3333], [ 3.0000, 3.3333, 3.6667, 4.0000]]]]) >>> # Try scaling the same data in a larger tensor >>> >>> input_3x3 = torch.zeros(3, 3).view(1, 1, 3, 3) >>> input_3x3[:, :, :2, :2].copy_(input) tensor([[[[ 1., 2.], [ 3., 4.]]]]) >>> input_3x3 tensor([[[[ 1., 2., 0.], [ 3., 4., 0.], [ 0., 0., 0.]]]]) >>> m = nn.Upsample(scale_factor=2, mode='bilinear') # align_corners=False >>> # Notice that values in top left corner are the same with the small input (except at boundary) >>> m(input_3x3) tensor([[[[ 1.0000, 1.2500, 1.7500, 1.5000, 0.5000, 0.0000], [ 1.5000, 1.7500, 2.2500, 1.8750, 0.6250, 0.0000], [ 2.5000, 2.7500, 3.2500, 2.6250, 0.8750, 0.0000], [ 2.2500, 2.4375, 2.8125, 2.2500, 0.7500, 0.0000], [ 0.7500, 0.8125, 0.9375, 0.7500, 0.2500, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]]) >>> m = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True) >>> # Notice that values in top left corner are now changed >>> m(input_3x3) tensor([[[[ 1.0000, 1.4000, 1.8000, 1.6000, 0.8000, 0.0000], [ 1.8000, 2.2000, 2.6000, 2.2400, 1.1200, 0.0000], [ 2.6000, 3.0000, 3.4000, 2.8800, 1.4400, 0.0000], [ 2.4000, 2.7200, 3.0400, 2.5600, 1.2800, 0.0000], [ 1.2000, 1.3600, 1.5200, 1.2800, 0.6400, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]]) UpsamplingNearest2d class torch.nn.UpsamplingNearest2d(size=None, scale_factor=None)¶ 将二维最近邻居上采样应用于由多个输入通道组成的输入信号。 要指定比例，请使用size或scale_factor作为构造函数参数。 给定size时，它是图像(h，w）的输出大小。 Parameters 大小 (python：int 或 元组 [ python：int ， python：int ] ， 可选）–输出空间大小 scale_factor (python：float 或 元组 [ python：float ， python：float ] ， 可选）–空间大小的乘数。 Warning 不推荐使用此类，而推荐使用interpolate()。 Shape: Input: Output: where Examples: >>> input = torch.arange(1, 5, dtype=torch.float32).view(1, 1, 2, 2) >>> input tensor([[[[ 1., 2.], [ 3., 4.]]]]) >>> m = nn.UpsamplingNearest2d(scale_factor=2) >>> m(input) tensor([[[[ 1., 1., 2., 2.], [ 1., 1., 2., 2.], [ 3., 3., 4., 4.], [ 3., 3., 4., 4.]]]]) 上采样双线性 2d class torch.nn.UpsamplingBilinear2d(size=None, scale_factor=None)¶ 将二维双线性上采样应用于由多个输入通道组成的输入信号。 To specify the scale, it takes either the size or the scale_factor as it’s constructor argument. When size is given, it is the output size of the image (h, w). Parameters size (python:int or Tuple[python:int__, python:int], optional) – output spatial sizes scale_factor (python:float or Tuple[python:float__, python:float], optional) – multiplier for spatial size. Warning 不推荐使用此类，而推荐使用interpolate()。 等效于nn.functional.interpolate(..., mode='bilinear', align_corners=True)。 Shape: Input: Output: where Examples: >>> input = torch.arange(1, 5, dtype=torch.float32).view(1, 1, 2, 2) >>> input tensor([[[[ 1., 2.], [ 3., 4.]]]]) >>> m = nn.UpsamplingBilinear2d(scale_factor=2) >>> m(input) tensor([[[[ 1.0000, 1.3333, 1.6667, 2.0000], [ 1.6667, 2.0000, 2.3333, 2.6667], [ 2.3333, 2.6667, 3.0000, 3.3333], [ 3.0000, 3.3333, 3.6667, 4.0000]]]]) DataParallel 层(多 GPU，分布式） 数据并行 class torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0)¶ 在模块级别实现数据并行性。 该容器通过按批处理维度中的组块在指定设备之间划分输入来并行化给定module的应用程序(其他对象将每个设备复制一次）。 在前向传递中，模块在每个设备上复制，每个副本处理输入的一部分。 在向后传递过程中，每个副本的梯度被累加到原始模块中。 批处理大小应大于使用的 GPU 数量。 另请参见：使用 nn.DataParallel 而不是并行处理 允许将任意位置和关键字输入传递到 DataParallel 中，但是某些类型经过特殊处理。 张量将在指定的昏暗状态(默认值为 0）下分散为。 元组，列表和字典类型将被浅表复制。 其他类型将在不同线程之间共享，并且如果写入模型的前向传递中，则可能会损坏。 运行此 DataParallel 模块之前，并行化的module必须在device_ids[0]上具有其参数和缓冲区。 Warning 在每个转发中，module是在每个设备上复制的，因此对forward中正在运行的模块的任何更新都将丢失。 例如，如果module具有在每个forward中递增的计数器属性，则它将始终保持在初始值，因为更新是在forward之后销毁的副本上进行的。 但是， DataParallel 保证device[0]上的副本具有与基本并行化module共享存储的参数和缓冲区。 因此，将记录对device[0]上参数或缓冲区的就地更新。 例如， BatchNorm2d 和 spectral_norm() 依赖此行为来更新缓冲区。 Warning module及其子模块上定义的前向和后向挂钩将被调用len(device_ids)次，每次输入都位于特定设备上。 特别地，仅保证挂钩在相对应的设备上的操作中以正确的顺序执行。 例如，不能保证在所有 len(device_ids) forward() 调用之前执行通过 register_forward_pre_hook() 设置的挂钩。 在该设备的相应 forward() 调用之前执行。 Warning 当module在forward()中返回标量(即 0 维张量）时，此包装器将返回一个长度等于向量的设备，该矢量等于数据并行性中使用的设备数，其中包含每个设备的结果。 Note 在包裹在 DataParallel 中的 Module 中使用pack sequence -&gt; recurrent network -&gt; unpack sequence模式有个微妙之处。 有关详细信息，请参见我的循环网络不适用于数据并行性。部分。 Parameters 模块 (模块)–要并行化的模块 device_ids (python：int 的列表： 或 Torch.device)– CUDA 设备(默认：所有设备 ) output_device (python：int 或 Torch.device)–输出的设备位置(默认值：device_ids [ 0]） Variables 〜DataParallel.module (模块)–要并行化的模块 Example: >>> net = torch.nn.DataParallel(model, device_ids=[0, 1, 2]) >>> output = net(input_var) # input_var can be on any device, including CPU 分布式数据并行 class torch.nn.parallel.DistributedDataParallel(module, device_ids=None, output_device=None, dim=0, broadcast_buffers=True, process_group=None, bucket_cap_mb=25, find_unused_parameters=False, check_reduction=False)¶ 在模块级别实现基于torch.distributed包的分布式数据并行性。 该容器通过按批处理维度分块指定设备之间的输入来并行化给定模块的应用程序。 该模块在每台机器和每台设备上复制，并且每个这样的副本处理一部分输入。 在向后传递过程中，将平均每个节点的梯度。 批处理大小应大于本地使用的 GPU 数量。 另请参见：基础知识和使用 nn.DataParallel 而不是并行处理。 对输入的限制与 torch.nn.DataParallel 相同。 此类的创建要求通过调用 torch.distributed.init_process_group() 已初始化torch.distributed。 DistributedDataParallel可以通过以下两种方式使用： 单进程多 GPU 在这种情况下，将在每个主机/节点上生成一个进程，并且每个进程将在运行该节点的节点的所有 GPU 上运行。 要以这种方式使用DistributedDataParallel，您可以简单地按以下方式构建模型： >>> torch.distributed.init_process_group(backend=\"nccl\") >>> model = DistributedDataParallel(model) # device_ids will include all GPU devices by default 多进程单 GPU 强烈建议将DistributedDataParallel与多个进程配合使用，每个进程都在单个 GPU 上运行。 这是目前使用 PyTorch 进行数据并行训练的最快方法，适用于单节点(multi-GPU）和多节点数据并行训练。 对于单节点多 GPU 数据并行训练，它被证明比 torch.nn.DataParallel 快得多。 使用方法如下：在具有 N 个 GPU 的每台主机上，应生成 N 个进程，同时确保每个进程在 0 至 N-1 的单个 GPU 上可单独运行。 因此，您的工作是通过调用以下命令来确保您的训练脚本在单个给定的 GPU 上运行： >>> torch.cuda.set_device(i) 我从 0 到 N-1。 在每个过程中，应参考以下内容来构造此模块： >>> torch.distributed.init_process_group(backend='nccl', world_size=4, init_method='...') >>> model = DistributedDataParallel(model, device_ids=[i], output_device=i) 为了在每个节点上产生多个进程，可以使用torch.distributed.launch或torch.multiprocessing.spawn Note nccl后端目前是与多进程单 GPU 分布式训练一起使用的最快和强烈推荐的后端，这适用于单节点和多节点分布式训练 Note 该模块还支持混合精度分布式训练。 这意味着您的模型可以具有不同类型的参数，例如 fp16 和 fp32 的混合类型，对这些混合类型的参数进行梯度降低将可以正常工作。 另请注意，nccl后端是目前 fp16 / fp32 混合精度训练中最快，最受推荐的后端。 Note 如果在一个进程上使用torch.save检查模块，在其他进程上使用torch.load对其进行恢复，请确保为每个进程都正确配置了map_location。 没有map_location，torch.load会将模块恢复到保存模块的设备。 Warning 该模块仅适用于gloo和nccl后端。 Warning 构造函数，正向方法和输出的微分(或此模块输出的函数）是分布式同步点。 如果不同的进程可能执行不同的代码，请考虑到这一点。 Warning 该模块假定所有参数在创建时已在模型中注册。 不应添加或删除参数。 同样适用于缓冲区。 Warning 该模块假定所有参数在模型中注册的每个分布式过程都以相同的顺序进行。 模块本身将按照模型注册参数的相反顺序进行梯度全约。 换句话说，确保每个分布式过程具有完全相同的模型并因此具有完全相同的参数注册顺序是用户的责任。 Warning 该模块假定所有缓冲区和渐变都是密集的。 Warning 此模块不适用于 torch.autograd.grad() (即，仅当要在.grad参数的属性中累积梯度时才适用）。 Warning 如果您打算将此模块与nccl后端或gloo后端(使用 Infiniband）一起使用，以及使用多个工作程序的 DataLoader，请将并行处理启动方法更改为forkserver(仅适用于 Python 3），或者 spawn。 不幸的是，Gloo(使用 Infiniband）和 NCCL2 都不是安全的，如果不更改此设置，您可能会遇到死锁。 Warning 除非在forward()方法中初始化了挂钩，否则将不再调用module及其子模块上定义的向前和向后挂钩。 Warning 在用 DistributedDataParallel 包装模型之后，您永远不要尝试更改模型的参数。 换句话说，当用 DistributedDataParallel 包装模型时，DistributedDataParallel 的构造函数将在构造时在模型本身的所有参数上注册其他梯度减少函数。 如果在构造 DistributedDataParallel 之后更改模型的参数，则不支持此操作，并且可能会发生意外行为，因为可能不会调用某些参数的梯度减小函数。 Note 参数从不在进程之间广播。 该模块对梯度执行全缩减步骤，并假设优化器将在所有过程中以相同方式修改它们。 缓冲区(例如 BatchNorm 统计信息）在每次迭代中从模块广播到第 0 级进程，并广播到系统中的所有其他副本。 Parameters module (Module) – module to be parallelized device_ids (python：int 或 Torch.device 的列表）– CUDA 设备。 仅当输入模块位于单个 CUDA 设备上时才应提供此选项。 对于单设备模块，i``th :attr:modulereplica is placed on ``device_ids[i]。 对于多设备模块和 CPU 模块，device_ids 必须为 None 或为空列表，并且用于正向传递的输入数据必须放置在正确的设备上。 (默认：单设备模块的所有设备） output_device (python：int 或 Torch.device)–单设备 CUDA 输出的设备位置 模块。 对于多设备模块和 CPU 模块，它必须为 None(无），并且模块本身指定输出位置。 (对于单设备模块，默认值：device_ids [0]） broadcast_buffers (bool )–该标志在转发功能开始时启用模块的同步(广播）缓冲区。 (默认：True） process_group –用于减少所有分布式数据的进程组。 如果None，将使用由torch.distributed.init_process_group创建的默认进程组。 (默认：None） bucket_cap_mb – DistributedDataParallel 会将参数存储到多个存储桶中，以便每个存储桶的梯度缩减可能与反向计算重叠。 bucket_cap_mb控制存储桶的大小(以兆字节(MB）为单位）(默认值：25） find_unused_pa​​rameters (bool )–遍历包装模块的forward函数的返回值中包含的所有张量的自动梯度图。 在此图表中未接收到渐变的参数会被抢先标记为可以还原。 请注意，从模块参数派生的所有forward输出必须参与计算损耗，然后再参与梯度计算。 如果没有，该包装器将挂起，等待 autograd 为这些参数生成梯度。 可以使用torch.Tensor.detach将来自模块参数的其他未使用的输出从 autograd 图中分离出来。 (默认：False） check_reduction –设置为True时，它使 DistributedDataParallel 自动检查在每次迭代的正向功能开始时是否成功发布了先前迭代的向后缩减。 通常您不需要启用此选项，除非您观察到奇怪的现象，例如不同的等级得到不同的梯度，如果正确使用 DistributedDataParallel，则不会发生这种情况。 (默认：False） Variables 〜DistributedDataParallel.module (Module)–要并行化的模块 Example: >>> torch.distributed.init_process_group(backend='nccl', world_size=4, init_method='...') >>> net = torch.nn.DistributedDataParallel(model, pg) no_sync()¶ 上下文管理器，用于禁用 DDP 进程之间的梯度同步。 在此上下文中，梯度将累积在模块变量上，稍后将在退出上下文的第一个向前-向后传递中进行同步。 Example: >>> ddp = torch.nn.DistributedDataParallel(model, pg) >>> with ddp.no_sync(): ... for input in inputs: ... ddp(input).backward() # no synchronization, accumulate grads ... ddp(another_input).backward() # synchronize grads 实用工具 clipgrad_norm torch.nn.utils.clip_grad_norm_(parameters, max_norm, norm_type=2)¶ 裁剪参数可迭代的梯度范数。 范数是在所有梯度上一起计算的，就好像它们被串联到单个矢量中一样。 渐变就地修改。 Parameters 参数(可迭代的 [ tensor ]或 tensor)–张量的迭代或将张量归一化的单个张量 max_norm (python：float 或 python：int )–梯度的最大范数 norm_type (python：float 或 python：int )–使用的 p 范数的类型。 对于无穷大范数可以为'inf'。 Returns 参数的总范数(视为单个向量）。 clipgrad_value torch.nn.utils.clip_grad_value_(parameters, clip_value)¶ 将可迭代参数的梯度剪切为指定值。 渐变就地修改。 Parameters parameters (Iterable__[Tensor] or Tensor) – an iterable of Tensors or a single Tensor that will have gradients normalized clip_value (python：float 或 python：int )–渐变的最大允许值。 渐变被限制在范围内 parameters_to_vector torch.nn.utils.parameters_to_vector(parameters)¶ 将参数转换为一个向量 Parameters 参数(可迭代 [ tensor ] )–张量的迭代器 模型的参数。 Returns 单个向量表示的参数 vector_to_parameters torch.nn.utils.vector_to_parameters(vec, parameters)¶ 将一个向量转换为参数 Parameters vec (tensor)–单个矢量表示模型的参数。 parameters (Iterable__[Tensor]) – an iterator of Tensors that are the parameters of a model. BasePruningMethod class torch.nn.utils.prune.BasePruningMethod¶ 用于创建新修剪技术的抽象基类。 为需要重写诸如 compute_mask() 和 apply() 等方法的定制提供框架。 classmethod apply(module, name, *args, **kwargs)¶ 添加了前向预挂接，可进行即时修剪，并根据原始张量和修剪蒙版对张量进行重新参数化。 Parameters 模块 (nn.Module)–包含要修剪的张量的模块 名称 (str )– module中将对其进行修剪的参数名称。 args –传递给 BasePruningMethod 子类的参数 kwargs –传递给 BasePruningMethod 子类的关键字参数 apply_mask(module)¶ 只需处理要修剪的参数和生成的掩码之间的乘法。 从模块中获取遮罩和原始张量，然后返回该张量的修剪版本。 Parameters module (nn.Module) – module containing the tensor to prune Returns 输入张量的修剪版本 Return type pruned_tensor (Torch.Tensor) abstract compute_mask(t, default_mask)¶ 计算并返回输入张量t的掩码。 从基础default_mask(如果尚未修剪张量，应为 1 的掩码）开始，根据特定的修剪方法配方，生成一个随机掩码以应用于default_mask的顶部。 Parameters t (torch张量)–代表修剪参数的张量 default_mask (torch张量)–先前修剪迭代中的基础掩码，在应用新掩码后需要加以注意。 与t相同。 Returns 应用于t的遮罩，其亮度与t相同 Return type 面罩(torch。张量） prune(t, default_mask=None)¶ 根据 compute_mask() 中指定的修剪规则，计算并返回输入张量t的修剪版本。 Parameters t (torch张量)–张量到修剪(与default_mask相同的尺寸）。 default_mask (炬管张量 ， 可选）–先前修剪迭代的掩码(如果有）。 在确定应对张量的哪一部分进行修剪时考虑。 如果为 None，则默认为 1 的掩码。 Returns 张量的修剪版本t。 remove(module)¶ 从模块中删除修剪重新参数化。 被修剪的名为name的参数将被永久修剪，并且将从参数列表中删除名为name+'_orig'的参数。 同样，从缓冲区中删除名为name+'_mask'的缓冲区。 Note 修剪本身不会撤消或撤消！ 修剪容器 class torch.nn.utils.prune.PruningContainer(*args)¶ 容器，其中包含一系列用于迭代修剪的修剪方法。 跟踪修剪方法的应用顺序，并处理合并的连续修剪调用。 接受 BasePruningMethod 的实例或它们的可迭代实例作为参数。 add_pruning_method(method)¶ 将子修剪method添加到容器中。 Parameters 方法(BasePruningMethod 的子类）–要添加到容器的子修剪方法。 classmethod apply(module, name, *args, **kwargs)¶ Adds the forward pre-hook that enables pruning on the fly and the reparametrization of a tensor in terms of the original tensor and the pruning mask. Parameters module (nn.Module) – module containing the tensor to prune name (str) – parameter name within module on which pruning will act. args – arguments passed on to a subclass of BasePruningMethod kwargs – keyword arguments passed on to a subclass of a BasePruningMethod apply_mask(module)¶ Simply handles the multiplication between the parameter being pruned and the generated mask. Fetches the mask and the original tensor from the module and returns the pruned version of the tensor. Parameters module (nn.Module) – module containing the tensor to prune Returns pruned version of the input tensor Return type pruned_tensor (torch.Tensor) compute_mask(t, default_mask)¶ 通过计算新的局部掩码并返回其与default_mask的组合来应用最新的method。 新的部分掩码应在default_mask未归零的条目或通道上计算。 将根据PRUNING_TYPE(由类型处理程序处理）来计算新掩码的张量t的哪一部分： 对于“非结构化”，蒙版将根据乱码计算 非屏蔽条目列表； 对于“结构化”，遮罩将根据非遮罩计算 张量中的通道； 对于“全局”，将在所有条目中计算掩码。 Parameters t (torch张量)–代表要修剪的参数的张量(与default_mask尺寸相同）。 default_mask (torch张量)–先前修剪迭代的掩码。 Returns 合并了default_mask和来自当前修剪method的新蒙版(与default_mask和t尺寸相同）的新蒙版的新蒙版。 Return type mask (torch.Tensor) prune(t, default_mask=None)¶ 根据 compute_mask() 中指定的修剪规则，计算并返回输入张量t的修剪版本。 Parameters t (torch.Tensor) – tensor to prune (of same dimensions as default_mask). default_mask (torch.Tensor, optional) – mask from previous pruning iteration, if any. To be considered when determining what portion of the tensor that pruning should act on. If None, default to a mask of ones. Returns pruned version of tensor t. remove(module)¶ Removes the pruning reparameterization from a module. The pruned parameter named name remains permanently pruned, and the parameter named name+'_orig' is removed from the parameter list. Similarly, the buffer named name+'_mask' is removed from the buffers. Note Pruning itself is NOT undone or reversed! Identity class torch.nn.utils.prune.Identity¶ 实用修剪方法，不修剪任何单位，而是用一个“ 1”的掩码生成修剪参数。 classmethod apply(module, name)¶ Adds the forward pre-hook that enables pruning on the fly and the reparametrization of a tensor in terms of the original tensor and the pruning mask. Parameters module (nn.Module) – module containing the tensor to prune name (str) – parameter name within module on which pruning will act. apply_mask(module)¶ Simply handles the multiplication between the parameter being pruned and the generated mask. Fetches the mask and the original tensor from the module and returns the pruned version of the tensor. Parameters module (nn.Module) – module containing the tensor to prune Returns pruned version of the input tensor Return type pruned_tensor (torch.Tensor) prune(t, default_mask=None)¶ 根据compute_mask()中指定的修剪规则，计算并返回输入张量t的修剪版本。 Parameters t (torch.Tensor) – tensor to prune (of same dimensions as default_mask). default_mask (torch.Tensor, optional) – mask from previous pruning iteration, if any. To be considered when determining what portion of the tensor that pruning should act on. If None, default to a mask of ones. Returns pruned version of tensor t. remove(module)¶ Removes the pruning reparameterization from a module. The pruned parameter named name remains permanently pruned, and the parameter named name+'_orig' is removed from the parameter list. Similarly, the buffer named name+'_mask' is removed from the buffers. Note Pruning itself is NOT undone or reversed! 随机非结构化 class torch.nn.utils.prune.RandomUnstructured(amount)¶ 在张量中随机修剪(当前未修剪）单位。 Parameters name (str) – parameter name within module on which pruning will act. 数量 (python：int 或 python：float )–修剪参数的数量。 如果float，则应在 0.0 到 1.0 之间，并且代表要修剪的参数的分数。 如果int，则表示要修剪的参数的绝对数量。 classmethod apply(module, name, amount)¶ Adds the forward pre-hook that enables pruning on the fly and the reparametrization of a tensor in terms of the original tensor and the pruning mask. Parameters module (nn.Module) – module containing the tensor to prune name (str) – parameter name within module on which pruning will act. amount (python:int or python:float) – quantity of parameters to prune. If float, should be between 0.0 and 1.0 and represent the fraction of parameters to prune. If int, it represents the absolute number of parameters to prune. apply_mask(module)¶ Simply handles the multiplication between the parameter being pruned and the generated mask. Fetches the mask and the original tensor from the module and returns the pruned version of the tensor. Parameters module (nn.Module) – module containing the tensor to prune Returns pruned version of the input tensor Return type pruned_tensor (torch.Tensor) prune(t, default_mask=None)¶ Computes and returns a pruned version of input tensor t according to the pruning rule specified in compute_mask(). Parameters t (torch.Tensor) – tensor to prune (of same dimensions as default_mask). default_mask (torch.Tensor, optional) – mask from previous pruning iteration, if any. To be considered when determining what portion of the tensor that pruning should act on. If None, default to a mask of ones. Returns pruned version of tensor t. remove(module)¶ Removes the pruning reparameterization from a module. The pruned parameter named name remains permanently pruned, and the parameter named name+'_orig' is removed from the parameter list. Similarly, the buffer named name+'_mask' is removed from the buffers. Note Pruning itself is NOT undone or reversed! L1 非结构化 class torch.nn.utils.prune.L1Unstructured(amount)¶ 通过将具有最低 L1 范数的单元归零，在张量中修剪(当前未修剪的）单元。 Parameters amount (python:int or python:float) – quantity of parameters to prune. If float, should be between 0.0 and 1.0 and represent the fraction of parameters to prune. If int, it represents the absolute number of parameters to prune. classmethod apply(module, name, amount)¶ Adds the forward pre-hook that enables pruning on the fly and the reparametrization of a tensor in terms of the original tensor and the pruning mask. Parameters module (nn.Module) – module containing the tensor to prune name (str) – parameter name within module on which pruning will act. amount (python:int or python:float) – quantity of parameters to prune. If float, should be between 0.0 and 1.0 and represent the fraction of parameters to prune. If int, it represents the absolute number of parameters to prune. apply_mask(module)¶ Simply handles the multiplication between the parameter being pruned and the generated mask. Fetches the mask and the original tensor from the module and returns the pruned version of the tensor. Parameters module (nn.Module) – module containing the tensor to prune Returns pruned version of the input tensor Return type pruned_tensor (torch.Tensor) prune(t, default_mask=None)¶ Computes and returns a pruned version of input tensor t according to the pruning rule specified in compute_mask(). Parameters t (torch.Tensor) – tensor to prune (of same dimensions as default_mask). default_mask (torch.Tensor, optional) – mask from previous pruning iteration, if any. To be considered when determining what portion of the tensor that pruning should act on. If None, default to a mask of ones. Returns pruned version of tensor t. remove(module)¶ Removes the pruning reparameterization from a module. The pruned parameter named name remains permanently pruned, and the parameter named name+'_orig' is removed from the parameter list. Similarly, the buffer named name+'_mask' is removed from the buffers. Note Pruning itself is NOT undone or reversed! 随机结构 class torch.nn.utils.prune.RandomStructured(amount, dim=-1)¶ 在张量中随机修剪整个(当前未修剪的）通道。 Parameters amount (python:int or python:float) – quantity of parameters to prune. If float, should be between 0.0 and 1.0 and represent the fraction of parameters to prune. If int, it represents the absolute number of parameters to prune. 暗淡 (python：int ， 可选）–暗淡的索引，我们沿着该暗淡定义了修剪通道。 默认值：-1。 classmethod apply(module, name, amount, dim=-1)¶ Adds the forward pre-hook that enables pruning on the fly and the reparametrization of a tensor in terms of the original tensor and the pruning mask. Parameters module (nn.Module) – module containing the tensor to prune name (str) – parameter name within module on which pruning will act. amount (python:int or python:float) – quantity of parameters to prune. If float, should be between 0.0 and 1.0 and represent the fraction of parameters to prune. If int, it represents the absolute number of parameters to prune. dim (python:int__, optional) – index of the dim along which we define channels to prune. Default: -1. apply_mask(module)¶ Simply handles the multiplication between the parameter being pruned and the generated mask. Fetches the mask and the original tensor from the module and returns the pruned version of the tensor. Parameters module (nn.Module) – module containing the tensor to prune Returns pruned version of the input tensor Return type pruned_tensor (torch.Tensor) compute_mask(t, default_mask)¶ 计算并返回输入张量t的掩码。 从基础default_mask(如果尚未修剪张量，应为 1 的掩码）开始，通过沿张量的指定暗部随机清零通道，生成随机掩码以应用于default_mask顶部 。 Parameters t (torch.Tensor) – tensor representing the parameter to prune default_mask (torch.Tensor) – Base mask from previous pruning iterations, that need to be respected after the new mask is applied. Same dims as t. Returns mask to apply to t, of same dims as t Return type mask (torch.Tensor) Raises IndexError –如果self.dim &gt;= len(t.shape) prune(t, default_mask=None)¶ 根据 compute_mask() 中指定的修剪规则，计算并返回输入张量t的修剪版本。 Parameters t (torch.Tensor) – tensor to prune (of same dimensions as default_mask). default_mask (torch.Tensor, optional) – mask from previous pruning iteration, if any. To be considered when determining what portion of the tensor that pruning should act on. If None, default to a mask of ones. Returns pruned version of tensor t. remove(module)¶ Removes the pruning reparameterization from a module. The pruned parameter named name remains permanently pruned, and the parameter named name+'_orig' is removed from the parameter list. Similarly, the buffer named name+'_mask' is removed from the buffers. Note Pruning itself is NOT undone or reversed! Ln 结构化 class torch.nn.utils.prune.LnStructured(amount, n, dim=-1)¶ 根据张量的 Ln 范数在张量中修剪整个(当前未修剪的）通道。 Parameters 数量 (python：int 或 python：float )–修剪通道的数量。 如果float，则应在 0.0 到 1.0 之间，并且代表要修剪的参数的分数。 如果int，则表示要修剪的参数的绝对数量。 n (python：int ， python：float ， inf ， -inf ， '来回 ， 'nuc'）–请参阅有效的文档 torch.norm() 中参数p的条目。 dim (python:int__, optional) – index of the dim along which we define channels to prune. Default: -1. classmethod apply(module, name, amount, n, dim)¶ Adds the forward pre-hook that enables pruning on the fly and the reparametrization of a tensor in terms of the original tensor and the pruning mask. Parameters module (nn.Module) – module containing the tensor to prune name (str) – parameter name within module on which pruning will act. amount (python:int or python:float) – quantity of parameters to prune. If float, should be between 0.0 and 1.0 and represent the fraction of parameters to prune. If int, it represents the absolute number of parameters to prune. n (python:int__, python:float__, inf__, -inf__, 'fro'__, 'nuc') – See documentation of valid entries for argument p in torch.norm(). 暗淡 (python：int )–暗淡的索引，我们沿其定义修剪的通道。 apply_mask(module)¶ Simply handles the multiplication between the parameter being pruned and the generated mask. Fetches the mask and the original tensor from the module and returns the pruned version of the tensor. Parameters module (nn.Module) – module containing the tensor to prune Returns pruned version of the input tensor Return type pruned_tensor (torch.Tensor) compute_mask(t, default_mask)¶ 计算并返回输入张量t的掩码。 从基本default_mask(如果尚未修剪张量，应为 1 的掩码）开始，通过将沿指定的暗角(具有最低 Ln 的通道）归零，生成一个掩码以应用于default_mask顶部 -规范。 Parameters t (torch.Tensor) – tensor representing the parameter to prune default_mask (torch张量)–先前修剪迭代中的基础掩码，在应用新掩码后需要加以注意。 与t相同。 Returns mask to apply to t, of same dims as t Return type mask (torch.Tensor) Raises IndexError – if self.dim &gt;= len(t.shape) prune(t, default_mask=None)¶ 根据 compute_mask() 中指定的修剪规则，计算并返回输入张量t的修剪版本。 Parameters t (torch.Tensor) – tensor to prune (of same dimensions as default_mask). default_mask (torch.Tensor, optional) – mask from previous pruning iteration, if any. To be considered when determining what portion of the tensor that pruning should act on. If None, default to a mask of ones. Returns pruned version of tensor t. remove(module)¶ Removes the pruning reparameterization from a module. The pruned parameter named name remains permanently pruned, and the parameter named name+'_orig' is removed from the parameter list. Similarly, the buffer named name+'_mask' is removed from the buffers. Note Pruning itself is NOT undone or reversed! CustomFromMask class torch.nn.utils.prune.CustomFromMask(mask)¶ classmethod apply(module, name, mask)¶ Adds the forward pre-hook that enables pruning on the fly and the reparametrization of a tensor in terms of the original tensor and the pruning mask. Parameters module (nn.Module) – module containing the tensor to prune name (str) – parameter name within module on which pruning will act. apply_mask(module)¶ Simply handles the multiplication between the parameter being pruned and the generated mask. Fetches the mask and the original tensor from the module and returns the pruned version of the tensor. Parameters module (nn.Module) – module containing the tensor to prune Returns pruned version of the input tensor Return type pruned_tensor (torch.Tensor) prune(t, default_mask=None)¶ Computes and returns a pruned version of input tensor t according to the pruning rule specified in compute_mask(). Parameters t (torch.Tensor) – tensor to prune (of same dimensions as default_mask). default_mask (torch.Tensor, optional) – mask from previous pruning iteration, if any. To be considered when determining what portion of the tensor that pruning should act on. If None, default to a mask of ones. Returns pruned version of tensor t. remove(module)¶ Removes the pruning reparameterization from a module. The pruned parameter named name remains permanently pruned, and the parameter named name+'_orig' is removed from the parameter list. Similarly, the buffer named name+'_mask' is removed from the buffers. Note Pruning itself is NOT undone or reversed! 身份 torch.nn.utils.prune.identity(module, name)¶ 将修剪重新参数化应用于与module中称为name的参数相对应的张量，而无需实际修剪任何单位。 通过以下方式就地修改模块(并返回修改后的模块）：1）添加一个名为name+'_mask'的命名缓冲区，该缓冲区与通过修剪方法应用于参数name的二进制掩码相对应。 2）用已修剪版本替换参数name，而原始(未修剪）参数存储在名为name+'_orig'的新参数中。 Note 掩码是一个张量。 Parameters 模块 (nn.Module)–包含要修剪的张量的模块。 name (str) – parameter name within module on which pruning will act. Returns 输入模块的修改(即修剪）版本 Return type 模块 (nn.Module) Examples >>> m = prune.identity(nn.Linear(2, 3), 'bias') >>> print(m.bias_mask) tensor([1., 1., 1.]) random_unstructured torch.nn.utils.prune.random_unstructured(module, name, amount)¶ 通过删除随机选择的(当前未修剪的）单位的指定amount来修剪与module中称为name的参数相对应的张量。 通过以下方式就地修改模块(并返回修改后的模块）：1）添加一个名为name+'_mask'的命名缓冲区，该缓冲区与通过修剪方法应用于参数名称的二进制掩码相对应。 2）用已修剪版本替换参数name，而原始(未修剪）参数存储在名为name+'_orig'的新参数中。 Parameters module (nn.Module) – module containing the tensor to prune name (str) – parameter name within module on which pruning will act. amount (python:int or python:float) – quantity of parameters to prune. If float, should be between 0.0 and 1.0 and represent the fraction of parameters to prune. If int, it represents the absolute number of parameters to prune. Returns modified (i.e. pruned) version of the input module Return type module (nn.Module) Examples >>> m = prune.random_unstructured(nn.Linear(2, 3), 'weight', amount=1) >>> torch.sum(m.weight_mask == 0) tensor(1) l1_unstructured torch.nn.utils.prune.l1_unstructured(module, name, amount)¶ 通过删除 L1 范数最低的(当前未修剪）单位的指定量，修剪与module中称为name的参数相对应的张量。 通过以下方式就地修改模块(并返回修改后的模块）：1）添加一个名为name+'_mask'的命名缓冲区，该缓冲区与通过修剪方法应用于参数name的二进制掩码相对应。 2）用已修剪版本替换参数name，而原始(未修剪）参数存储在名为name+'_orig'的新参数中。 Parameters module (nn.Module) – module containing the tensor to prune name (str) – parameter name within module on which pruning will act. amount (python:int or python:float) – quantity of parameters to prune. If float, should be between 0.0 and 1.0 and represent the fraction of parameters to prune. If int, it represents the absolute number of parameters to prune. Returns modified (i.e. pruned) version of the input module Return type module (nn.Module) Examples >>> m = prune.l1_unstructured(nn.Linear(2, 3), 'weight', amount=0.2) >>> m.state_dict().keys() odict_keys(['bias', 'weight_orig', 'weight_mask']) 随机结构 torch.nn.utils.prune.random_structured(module, name, amount, dim)¶ 通过沿着随机选择的指定dim移除(当前未修剪的）通道的指定amount来修剪与module中称为name的参数相对应的张量。 通过以下方式就地修改模块(并返回修改后的模块）：1）添加一个名为name+'_mask'的命名缓冲区，该缓冲区与通过修剪方法应用于参数name的二进制掩码相对应。 2）用已修剪版本替换参数name，而原始(未修剪）参数存储在名为name+'_orig'的新参数中。 Parameters module (nn.Module) – module containing the tensor to prune name (str) – parameter name within module on which pruning will act. amount (python:int or python:float) – quantity of parameters to prune. If float, should be between 0.0 and 1.0 and represent the fraction of parameters to prune. If int, it represents the absolute number of parameters to prune. 暗淡 (python：int )–暗淡的索引，我们沿其定义修剪的通道。 Returns modified (i.e. pruned) version of the input module Return type module (nn.Module) Examples >>> m = prune.random_structured( nn.Linear(5, 3), 'weight', amount=3, dim=1 ) >>> columns_pruned = int(sum(torch.sum(m.weight, dim=0) == 0)) >>> print(columns_pruned) 3 ln_ 结构化 torch.nn.utils.prune.ln_structured(module, name, amount, n, dim)¶ 通过沿着具有最低 L''n`范数的指定dim移除(当前未修剪的）通道的指定amount来修剪与module中称为name的参数相对应的张量。 通过以下方式就地修改模块(并返回修改后的模块）：1）添加一个名为name+'_mask'的命名缓冲区，该缓冲区与通过修剪方法应用于参数name的二进制掩码相对应。 2）用已修剪版本替换参数name，而原始(未修剪）参数存储在名为name+'_orig'`的新参数中。 Parameters module (nn.Module) – module containing the tensor to prune name (str) – parameter name within module on which pruning will act. amount (python:int or python:float) – quantity of parameters to prune. If float, should be between 0.0 and 1.0 and represent the fraction of parameters to prune. If int, it represents the absolute number of parameters to prune. n (python:int__, python:float__, inf__, -inf__, 'fro'__, 'nuc') – See documentation of valid entries for argument p in torch.norm(). dim (python:int) – index of the dim along which we define channels to prune. Returns modified (i.e. pruned) version of the input module Return type module (nn.Module) Examples >>> m = prune.ln_structured( nn.Conv2d(5, 3, 2), 'weight', amount=0.3, dim=1, n=float('-inf') ) global_unstructured torch.nn.utils.prune.global_unstructured(parameters, pruning_method, **kwargs)¶ 通过应用指定的pruning_method全局修剪与parameters中所有参数相对应的张量。 通过以下方式修改模块：1）添加一个名为name+'_mask'的命名缓冲区，该缓冲区与通过修剪方法应用于参数name的二进制掩码相对应。 2）用已修剪版本替换参数name，而原始(未修剪）参数存储在名为name+'_orig'的新参数中。 Parameters 参数 (( 模块 ， 名称 ）的迭代 ] 元组）–以全局方式修剪的模型参数，即在决定要修剪的权重之前，先汇总所有权重。 模块必须为nn.Module类型，名称必须为字符串。 pruning_method (函数）–该模块中的有效修剪函数，或者是由用户实现的，满足实施准则并具有PRUNING_TYPE='unstructured'的自定义函数。 kwargs –其他关键字参数，例如：amount(整数或浮点数）：跨指定参数修剪的参数数量。 如果float，则应在 0.0 到 1.0 之间，并且代表要修剪的参数的分数。 如果int，则表示要修剪的参数的绝对数量。 Raises TypeError –如果PRUNING_TYPE != 'unstructured' Note 由于除非通过参数的大小对规范进行规范化，否则全局结构化修剪没有多大意义，因此我们现在将全局修剪的范围限制为非结构化方法。 Examples >>> net = nn.Sequential(OrderedDict([ ('first', nn.Linear(10, 4)), ('second', nn.Linear(4, 1)), ])) >>> parameters_to_prune = ( (net.first, 'weight'), (net.second, 'weight'), ) >>> prune.global_unstructured( parameters_to_prune, pruning_method=prune.L1Unstructured, amount=10, ) >>> print(sum(torch.nn.utils.parameters_to_vector(net.buffers()) == 0)) tensor(10, dtype=torch.uint8) custom_from_mask torch.nn.utils.prune.custom_from_mask(module, name, mask)¶ 通过在mask中应用预先计算的掩码，修剪与module中称为name的参数相对应的张量。 通过以下方式就地修改模块(并返回修改后的模块）：1）添加一个名为name+'_mask'的命名缓冲区，该缓冲区与通过修剪方法应用于参数name的二进制掩码相对应。 2）用已修剪版本替换参数name，而原始(未修剪）参数存储在名为name+'_orig'的新参数中。 Parameters module (nn.Module) – module containing the tensor to prune name (str) – parameter name within module on which pruning will act. 掩码 (tensor)–应用于参数的二进制掩码。 Returns modified (i.e. pruned) version of the input module Return type module (nn.Module) Examples >>> m = prune.custom_from_mask( nn.Linear(5, 3), name='bias', mask=torch.Tensor([0, 1, 0]) ) >>> print(m.bias_mask) tensor([0., 1., 0.]) 去掉 torch.nn.utils.prune.remove(module, name)¶ 从模块中删除修剪重新参数化，并从前向挂钩中删除修剪方法。 被修剪的名为name的参数将被永久修剪，并且将从参数列表中删除名为name+'_orig'的参数。 同样，从缓冲区中删除名为name+'_mask'的缓冲区。 Note Pruning itself is NOT undone or reversed! Parameters module (nn.Module) – module containing the tensor to prune name (str) – parameter name within module on which pruning will act. Examples >>> m = random_pruning(nn.Linear(5, 7), name='weight', amount=0.2) >>> m = remove_pruning(m, name='weight') is_pruned torch.nn.utils.prune.is_pruned(module)¶ 通过在从 BasePruningMethod 继承的模块中查找forward_pre_hooks，检查是否修剪了module。 Parameters 模块 (nn.Module)–已修剪或未修剪的对象 Returns 是否修剪module的二进制答案。 Examples >>> m = nn.Linear(5, 7) >>> print(prune.is_pruned(m)) False >>> prune.random_pruning(m, name='weight', amount=0.2) >>> print(prune.is_pruned(m)) True weight_norm torch.nn.utils.weight_norm(module, name='weight', dim=0)¶ 将权重归一化应用于给定模块中的参数。 权重归一化是将权重张量的大小与其方向解耦的重新参数化。 这用两个参数替换了name指定的参数(例如'weight'）：一个指定幅度(例如'weight_g'）和一个指定方向(例如'weight_v'）。 权重归一化是通过一个挂钩实现的，该挂钩在每次forward()调用之前从幅度和方向重新计算权重张量。 默认情况下，使用dim=0，将针对每个输出通道/平面独立计算范数。 要计算整个重量张量的范数，请使用dim=None。 参见 https://arxiv.org/abs/1602.07868 Parameters 模块 (模块)–包含模块 名称 (str ， 可选）–重量参数的名称 昏暗的 (python：int ， 可选）–计算范数的维度 Returns 带有重量标准钩的原始模块 Example: >>> m = weight_norm(nn.Linear(20, 40), name='weight') >>> m Linear(in_features=20, out_features=40, bias=True) >>> m.weight_g.size() torch.Size([40, 1]) >>> m.weight_v.size() torch.Size([40, 20]) remove_weight_norm torch.nn.utils.remove_weight_norm(module, name='weight')¶ 从模块中删除权重归一化重新参数化。 Parameters module (Module) – containing module name (str__, optional) – name of weight parameter 例 >>> m = weight_norm(nn.Linear(20, 40)) >>> remove_weight_norm(m) Spectrum_norm torch.nn.utils.spectral_norm(module, name='weight', n_power_iterations=1, eps=1e-12, dim=None)¶ 将频谱归一化应用于给定模块中的参数。 频谱归一化通过使用权重矩阵计算的权重矩阵的频谱范数重新调整权重张量，从而稳定了生成对抗网络(GAN）中鉴别器(批评家）的训练。 如果权重张量的尺寸大于 2，则在幂迭代方法中将其重塑为 2D 以获得频谱范数。 这是通过一个挂钩实现的，该挂钩在每次forward()调用之前计算频谱范数并重新调整权重。 请参阅生成对抗网络的频谱归一化。 Parameters module (nn.Module) – containing module name (str__, optional) – name of weight parameter n_power_iterations (python：int ， 可选）–计算频谱范数的功率迭代次数 eps (python：float ， 可选）– epsilon 在计算范数时具有数值稳定性 暗淡的 (python：int ， 可选）–尺寸对应于输出数量，默认为0，除了模块 是 ConvTranspose {1,2,3} d 的实例，当它是1时 Returns 带有频谱范数挂钩的原始模块 Example: >>> m = spectral_norm(nn.Linear(20, 40)) >>> m Linear(in_features=20, out_features=40, bias=True) >>> m.weight_u.size() torch.Size([40]) remove_spectral_norm torch.nn.utils.remove_spectral_norm(module, name='weight')¶ 从模块中删除频谱归一化重新参数化。 Parameters module (Module) – containing module name (str__, optional) – name of weight parameter Example >>> m = spectral_norm(nn.Linear(40, 10)) >>> remove_spectral_norm(m) 打包序列 torch.nn.utils.rnn.PackedSequence(data, batch_sizes=None, sorted_indices=None, unsorted_indices=None)¶ 保存打包序列的batch_sizes的数据和列表。 所有 RNN 模块都将打包序列作为输入。 Note 此类的实例永远不要手动创建。 它们应通过 pack_padded_sequence() 之类的函数实例化。 批次大小代表批次中每个序列步骤的数量元素，而不是传递给 pack_padded_sequence() 的变化序列长度。 例如，给定数据abc和x， PackedSequence 将包含数据axbc和batch_sizes=[2,1,1]。 Variables 〜PackedSequence.data (tensor)–包含压缩序列的张量 〜PackedSequence.batch_sizes (tensor)–整数张量，用于保存有关每个序列步骤的批次大小信息 〜PackedSequence.sorted_indices (tensor ， 可选）–保持此 [ PackedSequence 由序列构建。 〜PackedSequence.unsorted_indices (tensor ， 可选）–整数的张量，表示如何恢复原始值 顺序正确的序列。 Note data可以在任意设备上和任意 dtype 上。 sorted_indices和unsorted_indices必须是与data在同一设备上的torch.int64张量。 但是，batch_sizes应该始终是 CPU torch.int64张量。 这个不变量在整个 PackedSequence 类中保持不变，并且所有在 PyTorch 中构造：class：PackedSequence 的函数都保持不变(即，它们仅传递符合此约束的张量）。 pack_padded_sequence torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=False, enforce_sorted=True)¶ 打包一个 Tensor，其中包含可变长度的填充序列。 input的大小可以为T x B x *，其中 T 是最长序列的长度(等于lengths[0]），B是批处理大小，*是任意数量的尺寸 (包括 0）。 如果batch_first为True，则预期为B x T x * input。 对于未排序的序列，请使用 force_sorted = False 。 如果enforce_sorted为True，则序列应按长度降序排列，即input[:,0]应为最长序列，而input[:,B-1]为最短序列。 forcen_sorted = True 仅对于 ONNX 导出是必需的。 Note 此函数接受至少具有二维的任何输入。 您可以将其应用于包装标签，并与它们一起使用 RNN 的输出直接计算损失。 可以通过访问 .data属性来从 PackedSequence 对象中检索张量。 Parameters 输入 (tensor)–填充了可变长度序列的批处理。 长度 (tensor)–每个批处理元素的序列长度列表。 batch_first (bool ， 可选）–如果为True，则输入应为B x T x *格式。 强制排序的 (bool ， 可选）–如果True，则输入应包含按长度降序排列的序列 。 如果为False，则不检查此条件。 默认值：True。 Returns PackedSequence 对象 pad_packed_sequence torch.nn.utils.rnn.pad_packed_sequence(sequence, batch_first=False, padding_value=0.0, total_length=None)¶ 填充打包的可变长度序列批次。 这是 pack_padded_sequence() 的逆运算。 返回的 Tensor 数据大小为T x B x *，其中 T 是最长序列的长度， B 是批处理大小。 如果batch_first为 True，则数据将转置为B x T x *格式。 批处理元素将按其长度顺序减小。 Note total_length可用于在包裹在 DataParallel 中的 Module 中实现pack sequence -&gt; recurrent network -&gt; unpack sequence模式。 有关详细信息，请参见此常见问题解答部分。 Parameters 序列 (PackedSequence )–批量填充 batch_first (布尔 ， 可选）–如果为True，则输出为B x T x *格式。 padding_value (python：float ， 可选）–填充元素的值。 total_length (python：int ， 可选）–如果不是None，则输出将被填充为长度total_length 。 如果total_length小于sequence中的最大序列长度，则此方法将抛出ValueError。 Returns 张量元组包含填充的序列，张量包含批处理中每个序列的长度列表。 pad_sequence torch.nn.utils.rnn.pad_sequence(sequences, batch_first=False, padding_value=0)¶ 用padding_value填充可变长度张量的列表 pad_sequence沿新维度堆叠张量列表，并将它们填充为相等的长度。 例如，如果输入是大小为L x *的序列列表，并且 batch_first 为 False，否则为T x B x *。 B 是批处理大小。 它等于sequences中的元素数。 T 是最长序列的长度。 L 是序列的长度。 * 是任意数量的尾随尺寸，包括无。 Example >>> from torch.nn.utils.rnn import pad_sequence >>> a = torch.ones(25, 300) >>> b = torch.ones(22, 300) >>> c = torch.ones(15, 300) >>> pad_sequence([a, b, c]).size() torch.Size([25, 3, 300]) Note 此函数返回张量为T x B x *或B x T x *的张量，其中 T 是最长序列的长度。 此函数假定序列中所有张量的尾随尺寸和类型相同。 Parameters 序列(列表 [ tensor ] )–可变长度序列的列表。 batch_first (布尔 ， 可选）–如果为 True，则输出为B x T x *，否则为T x B x * padding_value (python：float ， 可选）–填充元素的值。 默认值：0 Returns 如果batch_first为False，则大小为T x B x *的张量。 否则大小为B x T x *的张量 pack_sequence torch.nn.utils.rnn.pack_sequence(sequences, enforce_sorted=True)¶ 打包可变长度张量的列表 sequences应该是大小为L x *的张量的列表，其中 L 是序列的长度， * 是任意数量的尾随尺寸，包括零。 对于未排序的序列，请使用 force_sorted = False 。 如果enforce_sorted为True，则序列应按长度减小的顺序排序。 enforce_sorted = True仅对于 ONNX 导出是必需的。 Example >>> from torch.nn.utils.rnn import pack_sequence >>> a = torch.tensor([1,2,3]) >>> b = torch.tensor([4,5]) >>> c = torch.tensor([6]) >>> pack_sequence([a, b, c]) PackedSequence(data=tensor([ 1, 4, 6, 2, 5, 3]), batch_sizes=tensor([ 3, 2, 1])) Parameters 序列(列表 [ tensor ] )–递减序列的列表 长度。 强制排序的 (bool ， 可选）–如果True，则检查输入是否包含按长度排序的降序序列。 如果为False，则不检查此条件。 默认值：True。 Returns a PackedSequence object 展平 class torch.nn.Flatten(start_dim=1, end_dim=-1)¶ 将连续范围的暗角展平为张量。 用于Sequential。 ：param start_dim：首先变暗到变平(默认= 1）。 ：param end_dim：最后变暗到变平(默认= -1）。 Shape: 输入： 输出：(默认情况下）。 Examples:: >>> m = nn.Sequential( >>> nn.Conv2d(1, 32, 5, 1, 1), >>> nn.Flatten() >>> ) 量化功能 量化是指用于执行计算并以低于浮点精度的位宽存储张量的技术。 PyTorch 支持每个张量和每个通道非对称线性量化。 要了解更多如何在 PyTorch 中使用量化函数的信息，请参阅量化文档。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"76.html":{"url":"76.html","title":"torch功能","keywords":"","body":"torch功能 原文： https://pytorch.org/docs/stable/nn.functional.html 卷积函数 转换 torch.nn.functional.conv1d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) → Tensor¶ 在由多个输入平面组成的输入信号上应用一维卷积。 有关详细信息和输出形状，请参见 Conv1d 。 注意 在某些情况下，将 CUDA 后端与 CuDNN 一起使用时，该运算符可能会选择不确定的算法来提高性能。 如果不希望这样做，则可以通过设置torch.backends.cudnn.deterministic = True来使操作具有确定性(可能会降低性能）。 请参阅关于可再现性的注意事项作为背景。 参数 输入 –形状为的输入张量 重量 –形状为的过滤器 偏差-形状的可选偏差。 默认值：None 步幅 –卷积内核的步幅。 可以是一个整数或一个元素的元组(sW，）。 默认值：1 填充 –输入两侧的隐式填充。 可以是一个整数或一个元素的元组(padW，）。 默认值：0 膨胀 –内核元素之间的间距。 可以是一个整数或一个元素的元组(dW，）。 默认值：1 组 –将输入分成组，应该可被组数整除。 默认值：1 例子： >>> filters = torch.randn(33, 16, 3) >>> inputs = torch.randn(20, 16, 50) >>> F.conv1d(inputs, filters) 转换 2d torch.nn.functional.conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) → Tensor¶ 在由多个输入平面组成的输入图像上应用 2D 卷积。 有关详细信息和输出形状，请参见 Conv2d 。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters 输入 –形状为的输入张量 重量 –形状为的过滤器 偏差-形状的可选偏差张量。 默认值：None 步幅 –卷积内核的步幅。 可以是单个数字或元组(sH，sW）。 默认值：1 填充 –输入两侧的隐式填充。 可以是单个数字或元组(padH，padW）。 默认值：0 膨胀 –内核元素之间的间距。 可以是单个数字或元组(dH，dW）。 默认值：1 组 –将输入分成组，应该可被组数整除。 默认值：1 Examples: >>> # With square kernels and equal stride >>> filters = torch.randn(8,4,3,3) >>> inputs = torch.randn(1,4,5,5) >>> F.conv2d(inputs, filters, padding=1) conv3d torch.nn.functional.conv3d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) → Tensor¶ 在由多个输入平面组成的输入图像上应用 3D 卷积。 有关详细信息和输出形状，请参见 Conv3d 。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters 输入 –形状为的输入张量 重量 –形状为的过滤器 偏置-形状为的可选偏置张量。 默认值：无 步幅 –卷积内核的步幅。 可以是单个数字或元组(sT，sH，sW）。 默认值：1 填充 –输入两侧的隐式填充。 可以是单个数字或元组(padT，padH，padW）。 默认值：0 膨胀 –内核元素之间的间距。 可以是单个数字或元组(dT，dH，dW）。 默认值：1 groups – split input into groups, should be divisible by the number of groups. Default: 1 Examples: >>> filters = torch.randn(33, 16, 3, 3, 3) >>> inputs = torch.randn(20, 16, 50, 10, 20) >>> F.conv3d(inputs, filters) conv_transpose1d torch.nn.functional.conv_transpose1d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1) → Tensor¶ 在由几个输入平面组成的输入信号上应用一维转置卷积运算符，有时也称为“反卷积”。 有关详细信息和输出形状，请参见 ConvTranspose1d 。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters input – input tensor of shape 重量 –形状为的过滤器 偏差-形状的可选偏差。 默认值：无 步幅 –旋转内核的步幅。 可以是单个数字或元组(sW,)。 默认值：1 填充 – dilation * (kernel_size - 1) - padding零填充将添加到输入中每个尺寸的两侧。 可以是单个数字或元组(padW,)。 默认值：0 output_padding –在输出形状的每个尺寸的一侧添加了附加尺寸。 可以是单个数字或元组(out_padW)。 默认值：0 groups – split input into groups, should be divisible by the number of groups. Default: 1 膨胀 –内核元素之间的间距。 可以是单个数字或元组(dW,)。 默认值：1 Examples: >>> inputs = torch.randn(20, 16, 50) >>> weights = torch.randn(16, 33, 5) >>> F.conv_transpose1d(inputs, weights) conv_transpose2d torch.nn.functional.conv_transpose2d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1) → Tensor¶ 在由多个输入平面组成的输入图像上应用二维转置卷积运算符，有时也称为“反卷积”。 有关详细信息和输出形状，请参见 ConvTranspose2d 。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters input – input tensor of shape 重量 –形状为的过滤器 bias – optional bias of shape . Default: None 步幅 –旋转内核的步幅。 可以是单个数字或元组(sH, sW)。 默认值：1 填充 – dilation * (kernel_size - 1) - padding零填充将添加到输入中每个尺寸的两侧。 可以是单个数字或元组(padH, padW)。 默认值：0 output_padding –在输出形状的每个尺寸的一侧添加了附加尺寸。 可以是单个数字或元组(out_padH, out_padW)。 默认值：0 groups – split input into groups, should be divisible by the number of groups. Default: 1 膨胀 –内核元素之间的间距。 可以是单个数字或元组(dH, dW)。 默认值：1 Examples: >>> # With square kernels and equal stride >>> inputs = torch.randn(1, 4, 5, 5) >>> weights = torch.randn(4, 8, 3, 3) >>> F.conv_transpose2d(inputs, weights, padding=1) conv_transpose3d torch.nn.functional.conv_transpose3d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1) → Tensor¶ 在由多个输入平面组成的输入图像上应用 3D 转置卷积运算符，有时也称为“反卷积” 有关详细信息和输出形状，请参见 ConvTranspose3d 。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters input – input tensor of shape 重量 –形状为的过滤器 bias – optional bias of shape . Default: None 步幅 –旋转内核的步幅。 可以是单个数字或元组(sT, sH, sW)。 默认值：1 填充 – dilation * (kernel_size - 1) - padding零填充将添加到输入中每个尺寸的两侧。 可以是单个数字或元组(padT, padH, padW)。 默认值：0 output_padding –在输出形状的每个尺寸的一侧添加了附加尺寸。 可以是单个数字或元组(out_padT, out_padH, out_padW)。 默认值：0 groups – split input into groups, should be divisible by the number of groups. Default: 1 dilation – the spacing between kernel elements. Can be a single number or a tuple (dT, dH, dW). Default: 1 Examples: >>> inputs = torch.randn(20, 16, 50, 10, 20) >>> weights = torch.randn(16, 33, 3, 3, 3) >>> F.conv_transpose3d(inputs, weights) 展开 torch.nn.functional.unfold(input, kernel_size, dilation=1, padding=0, stride=1)¶ 从批处理输入张量中提取滑动局部块。 警告 当前，仅支持 4D 输入张量(像图像一样的批状张量）。 Warning 展开张量中的一个以上元素可以引用单个存储位置。 结果，就地操作(尤其是矢量化的操作）可能会导致错误的行为。 如果您需要写张量，请先克隆它。 有关详细信息，请参见 torch.nn.Unfold 折 torch.nn.functional.fold(input, output_size, kernel_size, dilation=1, padding=0, stride=1)¶ 将一系列滑动局部块组合成一个大型的张量。 Warning 当前，仅支持 4D 输出张量(像图像一样的批状张量）。 有关详细信息，请参见 torch.nn.Fold 池化功能 avg_pool1d torch.nn.functional.avg_pool1d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True) → Tensor¶ 在由多个输入平面组成的输入信号上应用一维平均池。 有关详细信息和输出形状，请参见 AvgPool1d 。 Parameters input – input tensor of shape kernel_size –窗口的大小。 可以是单个数字或元组(kW，） 步幅 –窗口的步幅。 可以是单个数字或元组(sW，）。 默认值：kernel_size 填充 –输入两侧的隐式零填充。 可以是单个数字或元组(padW，）。 默认值：0 ceil_mode –为 True 时，将使用 ceil 代替 floor 计算输出形状。 默认值：False count_include_pad –为 True 时，将在平均计算中包括零填充。 默认值：True Examples: >>> # pool of square window of size=3, stride=2 >>> input = torch.tensor([[[1, 2, 3, 4, 5, 6, 7]]], dtype=torch.float32) >>> F.avg_pool1d(input, kernel_size=3, stride=2) tensor([[[ 2., 4., 6.]]]) avg_pool2d torch.nn.functional.avg_pool2d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None) → Tensor¶ 以步长步长在区域中应用 2D 平均合并操作。 输出要素的数量等于输入平面的数量。 有关详细信息和输出形状，请参见 AvgPool2d 。 Parameters 输入 –输入张量 kernel_size –池区域的大小。 可以是单个数字或元组(kH，kW） 跨度 –合并操作的跨度。 可以是单个数字或元组(sH，sW）。 默认值：kernel_size 填充 –输入两侧的隐式零填充。 可以是单个数字或元组(padH，padW）。 默认值：0 ceil_mode –为 True 时，将在公式中使用 ceil 而不是 floor 计算输出形状。 默认值：False count_include_pad – when True, will include the zero-padding in the averaging calculation. Default: True divisor_override –如果指定，它将用作除数，否则将使用池化区域的大小。 默认值：无 avg_pool3d torch.nn.functional.avg_pool3d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None) → Tensor¶ 以步长步长在区域中应用 3D 平均合并操作。 输出特征的数量等于。 有关详细信息和输出形状，请参见 AvgPool3d 。 Parameters 输入 –输入张量 kernel_size –池区域的大小。 可以是单个数字或元组(kT，kH，kW） 跨度 –合并操作的跨度。 可以是单个数字或元组(sT，sH，sW）。 默认值：kernel_size 填充 –输入两侧的隐式零填充。 可以是单个数字或元组(padT，padH，padW），默认值：0 ceil_mode –为 True 时，将在公式中使用 ceil 代替 floor 来计算输出形状 count_include_pad –为 True 时，将在平均计算中包括零填充 divisor_override – if specified, it will be used as divisor, otherwise size of the pooling region will be used. Default: None max_pool1d torch.nn.functional.max_pool1d(*args, **kwargs)¶ 在由多个输入平面组成的输入信号上应用一维最大池化。 有关详细信息，请参见 MaxPool1d 。 max_pool2d torch.nn.functional.max_pool2d(*args, **kwargs)¶ 在由多个输入平面组成的输入信号上应用 2D 最大合并。 有关详细信息，请参见 MaxPool2d 。 max_pool3d torch.nn.functional.max_pool3d(*args, **kwargs)¶ 在由多个输入平面组成的输入信号上应用 3D 最大池化。 有关详细信息，请参见 MaxPool3d 。 max_unpool1d torch.nn.functional.max_unpool1d(input, indices, kernel_size, stride=None, padding=0, output_size=None)¶ 计算MaxPool1d的部分逆。 有关详细信息，请参见 MaxUnpool1d 。 max_unpool2d torch.nn.functional.max_unpool2d(input, indices, kernel_size, stride=None, padding=0, output_size=None)¶ 计算MaxPool2d的部分逆。 有关详细信息，请参见 MaxUnpool2d 。 max_unpool3d torch.nn.functional.max_unpool3d(input, indices, kernel_size, stride=None, padding=0, output_size=None)¶ 计算MaxPool3d的部分逆。 有关详细信息，请参见 MaxUnpool3d 。 lp_pool1d torch.nn.functional.lp_pool1d(input, norm_type, kernel_size, stride=None, ceil_mode=False)¶ 在由多个输入平面组成的输入信号上应用一维功率平均池。 如果 p 的所有输入的总和为零，则梯度也设置为零。 有关详细信息，请参见 LPPool1d 。 lp_pool2d torch.nn.functional.lp_pool2d(input, norm_type, kernel_size, stride=None, ceil_mode=False)¶ 在由多个输入平面组成的输入信号上应用 2D 功率平均池。 如果 p 的所有输入的总和为零，则梯度也设置为零。 有关详细信息，请参见 LPPool2d 。 adaptive_max_pool1d torch.nn.functional.adaptive_max_pool1d(*args, **kwargs)¶ 在由多个输入平面组成的输入信号上应用一维自适应最大池化。 有关详细信息和输出形状，请参见 AdaptiveMaxPool1d 。 Parameters output_size –目标输出大小(单个整数） return_indices –是否返回池索引。 默认值：False adaptive_max_pool2d torch.nn.functional.adaptive_max_pool2d(*args, **kwargs)¶ 在由多个输入平面组成的输入信号上应用 2D 自适应最大池化。 有关详细信息和输出形状，请参见 AdaptiveMaxPool2d 。 Parameters output_size –目标输出大小(单整数或双整数元组） return_indices – whether to return pooling indices. Default: False adaptive_max_pool3d torch.nn.functional.adaptive_max_pool3d(*args, **kwargs)¶ 在由多个输入平面组成的输入信号上应用 3D 自适应最大池化。 有关详细信息和输出形状，请参见 AdaptiveMaxPool3d 。 Parameters output_size –目标输出大小(单整数或三整数元组） return_indices – whether to return pooling indices. Default: False adaptive_avg_pool1d torch.nn.functional.adaptive_avg_pool1d(input, output_size) → Tensor¶ 在由多个输入平面组成的输入信号上应用一维自适应平均池。 有关详细信息和输出形状，请参见 AdaptiveAvgPool1d 。 Parameters output_size – the target output size (single integer) adaptive_avg_pool2d torch.nn.functional.adaptive_avg_pool2d(input, output_size)¶ 在由多个输入平面组成的输入信号上应用 2D 自适应平均池。 有关详细信息和输出形状，请参见 AdaptiveAvgPool2d 。 Parameters output_size – the target output size (single integer or double-integer tuple) adaptive_avg_pool3d torch.nn.functional.adaptive_avg_pool3d(input, output_size)¶ 在由多个输入平面组成的输入信号上应用 3D 自适应平均池。 有关详细信息和输出形状，请参见 AdaptiveAvgPool3d 。 Parameters output_size – the target output size (single integer or triple-integer tuple) 非线性激活功能 阈 torch.nn.functional.threshold(input, threshold, value, inplace=False)¶ 设置输入张量的每个元素的阈值。 有关更多详细信息，请参见 Threshold 。 torch.nn.functional.threshold_(input, threshold, value) → Tensor¶ threshold() 的就地版本。 露露 torch.nn.functional.relu(input, inplace=False) → Tensor¶ 按元素应用整流线性单位函数。 有关更多详细信息，请参见 ReLU 。 torch.nn.functional.relu_(input) → Tensor¶ relu() 的就地版本。 Hardtanh torch.nn.functional.hardtanh(input, min_val=-1., max_val=1., inplace=False) → Tensor¶ 逐个应用 HardTanh 函数。 有关更多详细信息，请参见 Hardtanh 。 torch.nn.functional.hardtanh_(input, min_val=-1., max_val=1.) → Tensor¶ hardtanh() 的就地版本。 relu6 torch.nn.functional.relu6(input, inplace=False) → Tensor¶ 应用逐元素函数。 有关更多详细信息，请参见 ReLU6 。 lu torch.nn.functional.elu(input, alpha=1.0, inplace=False)¶ 按元素应用。 有关更多详细信息，请参见 ELU 。 torch.nn.functional.elu_(input, alpha=1.) → Tensor¶ elu() 的就地版本。 塞卢 torch.nn.functional.selu(input, inplace=False) → Tensor¶ 将与和逐元素应用。 有关更多详细信息，请参见 SELU 。 塞卢 torch.nn.functional.celu(input, alpha=1., inplace=False) → Tensor¶ 按元素应用。 有关更多详细信息，请参见 CELU 。 leaky_relu torch.nn.functional.leaky_relu(input, negative_slope=0.01, inplace=False) → Tensor¶ 按元素应用 有关更多详细信息，请参见 LeakyReLU 。 torch.nn.functional.leaky_relu_(input, negative_slope=0.01) → Tensor¶ leaky_relu() 的就地版本。 前路 torch.nn.functional.prelu(input, weight) → Tensor¶ 逐个应用功能，其中权重是可学习的参数。 有关更多详细信息，请参见 PReLU 。 雷雷鲁 torch.nn.functional.rrelu(input, lower=1./8, upper=1./3, training=False, inplace=False) → Tensor¶ 随机泄漏的 ReLU。 有关更多详细信息，请参见 RReLU 。 torch.nn.functional.rrelu_(input, lower=1./8, upper=1./3, training=False) → Tensor¶ rrelu() 的就地版本。 谷氨酸 torch.nn.functional.glu(input, dim=-1) → Tensor¶ 门控线性单元。 计算： 其中输入沿暗淡分成两半，形成 a 和 b ，是 S 型函数，是 矩阵之间的按元素乘积。 请参阅带门控卷积网络的语言建模。 Parameters 输入 (tensor)–输入张量 暗淡的 (python：int )–分割输入的维度。 默认值：-1 格鲁 torch.nn.functional.gelu(input) → Tensor¶ 逐元素应用功能 其中是高斯分布的累积分布函数。 请参见高斯误差线性单位(GELU）。 对数乙状结肠 torch.nn.functional.logsigmoid(input) → Tensor¶ 按元素应用 有关更多详细信息，请参见 LogSigmoid 。 硬缩 torch.nn.functional.hardshrink(input, lambd=0.5) → Tensor¶ 逐个应用硬收缩功能 有关更多详细信息，请参见 Hardshrink 。 tanhshrink torch.nn.functional.tanhshrink(input) → Tensor¶ 按元素应用 有关更多详细信息，请参见 Tanhshrink 。 软签 torch.nn.functional.softsign(input) → Tensor¶ 按元素应用功能 有关更多详细信息，请参见 Softsign 。 软加 torch.nn.functional.softplus(input, beta=1, threshold=20) → Tensor¶ 软敏 torch.nn.functional.softmin(input, dim=None, _stacklevel=3, dtype=None)¶ 应用 softmin 函数。 注意。 有关数学公式，请参见 softmax 定义。 有关更多详细信息，请参见 Softmin 。 Parameters 输入 (tensor)–输入 dim (python：int )–将计算 softmin 的维度(因此，沿着 dim 的每个切片的总和为 1）。 dtype (torch.dtype，可选）–返回张量的所需数据类型。 如果指定，则在执行操作之前将输入张量转换为dtype。 这对于防止数据类型溢出很有用。 默认值：无。 软最大 torch.nn.functional.softmax(input, dim=None, _stacklevel=3, dtype=None)¶ 应用 softmax 函数。 Softmax 定义为： 它将沿着暗淡应用于所有切片，并将对其进行重新缩放，以使元素位于 [0，1] 范围内，总和为 1。 有关更多详细信息，请参见 Softmax 。 Parameters input (Tensor) – input 暗淡的 (python：int )–将沿着其计算 softmax 的尺寸。 dtype (torch.dtype, optional) – the desired data type of returned tensor. If specified, the input tensor is casted to dtype before the operation is performed. This is useful for preventing data type overflows. Default: None. Note 此函数不能直接与 NLLLoss 一起使用，后者希望 Log 是在 Softmax 及其自身之间计算的。 请改用 log_softmax(速度更快，并且具有更好的数值属性）。 软缩 torch.nn.functional.softshrink(input, lambd=0.5) → Tensor¶ 逐个应用软收缩功能 有关更多详细信息，请参见 Softshrink 。 gumbel_softmax torch.nn.functional.gumbel_softmax(logits, tau=1, hard=False, eps=1e-10, dim=-1)¶ 来自 Gumbel-Softmax 分布的样本(链接 1 链接 2)，并且可以离散化。 Parameters logits – […，num_features] 未标准化的日志概率 tau –非负标量温度 硬性 –如果True，返回的样本将被离散为一热向量，但将被区分为好像是 autograd 中的软样本 暗淡的 (python：int )–将沿着其计算 softmax 的尺寸。 默认值：-1。 退货 Gumbel-Softmax 分布中与形状相同的采样张量对数为。 如果hard=True，则返回的样本将是一个热点，否则它们将是在 dim 上总计为 1 的概率分布。 Note 此函数是出于遗留原因而存在，将来可能会从 nn.Functional 中删除。 Note 硬性的主要技巧是执行 y_hard-y_soft.detach(）+ y_soft 它实现了两件事：-使输出值恰好为一热(因为我们先加然后减去 y_soft 值）-使梯度等于 y_soft 梯度(因为我们剥离所有其他梯度） Examples:: >>> logits = torch.randn(20, 32) >>> # Sample soft categorical using reparametrization trick: >>> F.gumbel_softmax(logits, tau=1, hard=False) >>> # Sample hard categorical using \"Straight-through\" trick: >>> F.gumbel_softmax(logits, tau=1, hard=True) log_softmax torch.nn.functional.log_softmax(input, dim=None, _stacklevel=3, dtype=None)¶ 应用 softmax，后跟对数。 虽然在数学上等效于 log(softmax(x）），但是分别执行这两个操作比较慢，并且在数值上不稳定。 此函数使用替代公式来正确计算输出和渐变。 有关更多详细信息，请参见 LogSoftmax 。 Parameters input (Tensor) – input 暗淡的 (python：int )–将沿 log_softmax 计算的维。 dtype (torch.dtype, optional) – the desired data type of returned tensor. If specified, the input tensor is casted to dtype before the operation is performed. This is useful for preventing data type overflows. Default: None. 谭 torch.nn.functional.tanh(input) → Tensor¶ 按元素应用 有关更多详细信息，请参见 Tanh 。 乙状结肠 torch.nn.functional.sigmoid(input) → Tensor¶ 应用逐元素函数 有关更多详细信息，请参见 Sigmoid 。 归一化功能 batch_norm torch.nn.functional.batch_norm(input, running_mean, running_var, weight=None, bias=None, training=False, momentum=0.1, eps=1e-05)¶ 对一批数据中的每个通道应用批标准化。 有关详细信息，请参见 BatchNorm1d ， BatchNorm2d ， BatchNorm3d 。 instance_norm torch.nn.functional.instance_norm(input, running_mean=None, running_var=None, weight=None, bias=None, use_input_stats=True, momentum=0.1, eps=1e-05)¶ 批量对每个数据样本中的每个通道应用实例归一化。 有关详细信息，请参见 InstanceNorm1d ， InstanceNorm2d ， InstanceNorm3d 。 layer_norm torch.nn.functional.layer_norm(input, normalized_shape, weight=None, bias=None, eps=1e-05)¶ 将图层归一化应用于最后一定数量的尺寸。 有关详细信息，请参见 LayerNorm 。 local_response_norm torch.nn.functional.local_response_norm(input, size, alpha=0.0001, beta=0.75, k=1.0)¶ 在由多个输入平面组成的输入信号上应用本地响应归一化，其中通道占据第二维。 跨通道应用标准化。 有关详细信息，请参见 LocalResponseNorm 。 归一化 torch.nn.functional.normalize(input, p=2, dim=1, eps=1e-12, out=None)¶ 对指定尺寸的输入执行归一化。 对于大小为的张量input，沿维度dim的每个-元素矢量都将转换为 使用默认参数时，它将沿向量的矢量使用欧几里得范数进行归一化。 Parameters 输入 –任何形状的输入张量 p (python：float )–规范制定中的指数值。 默认值：2 暗淡的 (python：int )–缩小的尺寸。 默认值：1 eps (python：float )–避免被零除的较小值。 默认值：1e-12 输出 (tensor ， 可选）–输出张量。 如果使用out，则此操作将不可区分。 线性功能 线性的 torch.nn.functional.linear(input, weight, bias=None)¶ 对输入数据应用线性变换：。 形状： 输入：其中 * 表示任意数量的附加尺寸 重量： 偏差： 输出： 双线性 torch.nn.functional.bilinear(input1, input2, weight, bias=None)¶ 对输入数据应用双线性变换： Shape: 输入 1：，其中和表示任意数量的附加尺寸。 除了最后输入的维度外，其他所有维度均应相同。 输入 2：，其中 重量： 偏倚： 输出：，其中和除最后一个尺寸外的所有尺寸都与输入相同。 辍学功能 退出 torch.nn.functional.dropout(input, p=0.5, training=True, inplace=False)¶ 在训练期间，使用伯努利分布的样本以概率p将输入张量的某些元素随机归零。 有关详细信息，请参见 Dropout 。 Parameters p –元素归零的概率。 默认值：0.5 训练 –如果为True，则申请辍学。 默认值：True 就地 –如果设置为True，将就地执行此操作。 默认值：False alpha_dropout torch.nn.functional.alpha_dropout(input, p=0.5, training=False, inplace=False)¶ 将 Alpha 滤除应用于输入。 有关详细信息，请参见 AlphaDropout 。 dropout2d torch.nn.functional.dropout2d(input, p=0.5, training=True, inplace=False)¶ 将所有通道随机调零(通道是 2D 特征图，例如，批处理输入中第个样本的第个通道是 2D 张量）。 使用伯努利分布中的样本，每个信道将在每次前向呼叫中以概率p独立清零。 有关详细信息，请参见 Dropout2d 。 Parameters p –信道归零的概率。 默认值：0.5 training – apply dropout if is True. Default: True inplace – If set to True, will do this operation in-place. Default: False dropout3d torch.nn.functional.dropout3d(input, p=0.5, training=True, inplace=False)¶ 将所有通道随机调零(通道是 3D 特征图，例如，批处理输入中第个样本的第个通道是 3D 张量）。 使用伯努利分布中的样本，每个信道将在每次前向呼叫中以概率p独立清零。 有关详细信息，请参见 Dropout3d 。 Parameters p – probability of a channel to be zeroed. Default: 0.5 training – apply dropout if is True. Default: True inplace – If set to True, will do this operation in-place. Default: False 稀疏功能 嵌入 torch.nn.functional.embedding(input, weight, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)¶ 一个简单的查找表，用于以固定的字典和大小查找嵌入。 该模块通常用于使用索引检索单词嵌入。 模块的输入是索引列表和嵌入矩阵，而输出是相应的词嵌入。 有关更多详细信息，请参见 torch.nn.Embedding 。 Parameters 输入 (LongTensor )–包含嵌入矩阵的索引的张量 权重 (tensor)–行数等于最大可能索引+ 1，并且行数等于嵌入大小的嵌入矩阵 padding_idx (python：int ， 可选）–如果给定，则在padding_idx处嵌入输出以填充输出(初始化为 零）。 max_norm (python：float ， 可选）–如果给定，则范数大于max_norm的每个嵌入向量都将重新规范化为具有 规范max_norm。 注意：这将就地修改weight。 norm_type (python：float ， 可选）–为max_norm选项计算的 p 范数的 p。 默认值2。 scale_grad_by_freq (布尔值 ， 可选））–如果给定，则将按照最小 批量。 默认值False。 稀疏 (bool ， 可选）–如果True，则梯度 w.r.t. weight将是一个稀疏张量。 有关稀疏梯度的更多详细信息，请参见 torch.nn.Embedding 下的注释。 Shape: 输入：包含要提取的索引的任意形状的 LongTensor Weight: Embedding matrix of floating point type with shape (V, embedding_dim), 其中 V =最大索引+ 1，embedding_dim =嵌入大小 输出：(，embedding_dim），其中 是输入形状 Examples: >>> # a batch of 2 samples of 4 indices each >>> input = torch.tensor([[1,2,4,5],[4,3,2,9]]) >>> # an embedding matrix containing 10 tensors of size 3 >>> embedding_matrix = torch.rand(10, 3) >>> F.embedding(input, embedding_matrix) tensor([[[ 0.8490, 0.9625, 0.6753], [ 0.9666, 0.7761, 0.6108], [ 0.6246, 0.9751, 0.3618], [ 0.4161, 0.2419, 0.7383]], [[ 0.6246, 0.9751, 0.3618], [ 0.0237, 0.7794, 0.0528], [ 0.9666, 0.7761, 0.6108], [ 0.3385, 0.8612, 0.1867]]]) >>> # example with padding_idx >>> weights = torch.rand(10, 3) >>> weights[0, :].zero_() >>> embedding_matrix = weights >>> input = torch.tensor([[0,2,0,5]]) >>> F.embedding(input, embedding_matrix, padding_idx=0) tensor([[[ 0.0000, 0.0000, 0.0000], [ 0.5609, 0.5384, 0.8720], [ 0.0000, 0.0000, 0.0000], [ 0.6262, 0.2438, 0.7471]]]) embedding_bag torch.nn.functional.embedding_bag(input, weight, offsets=None, max_norm=None, norm_type=2, scale_grad_by_freq=False, mode='mean', sparse=False, per_sample_weights=None)¶ 在不实例化中间嵌入的情况下，计算嵌入的袋的总和，平均值或最大值。 有关更多详细信息，请参见 torch.nn.EmbeddingBag 。 Note 当使用 CUDA 后端时，此操作可能会在其向后传递中引起不确定的行为，这种行为很难关闭。 有关背景，请参见重现性的注释。 Parameters 输入 (LongTensor )–将包含索引袋的张量放入嵌入矩阵 weight (Tensor) – The embedding matrix with number of rows equal to the maximum possible index + 1, and number of columns equal to the embedding size 偏移量 (LongTensor ， 可选）–仅在input为 1D 时使用。 offsets确定input中每个袋子(序列）的起始索引位置。 max_norm (python:float__, optional) – If given, each embedding vector with norm larger than max_norm is renormalized to have norm max_norm. Note: this will modify weight in-place. norm_type (python：float ， 可选）– p -norm 中的p用于计算max_norm ] 选项。 默认2。 scale_grad_by_freq (布尔 ， 可选）–如果指定，则将按比例缩小坡度中单词的频率 批量。 默认值False。 注意：mode=\"max\"时不支持此选项。 模式(字符串 ， 可选）– \"sum\"，\"mean\"或\"max\"。 指定减少袋子的方式。 默认值：\"mean\" 稀疏 (bool ， 可选）–如果True，则梯度为 w.r.t.。 weight将是一个稀疏张量。 有关稀疏渐变的更多详细信息，请参见 torch.nn.Embedding 下的注释。 注意：mode=\"max\"时不支持此选项。 per_sample_weights (tensor ， 可选）–浮点/双权重的张量，或无表示所有值 权重应取为 1。如果指定，则per_sample_weights的形状必须与输入的形状完全相同，并且如果不是[None]，则将其视为具有相同的offsets。 Shape: input(LongTensor）和offsets(LongTensor，可选） * 如果`input`是形状为&lt;cite&gt;(B，N）&lt;/cite&gt;的二维， 它将被视为`B`袋(序列），每个袋子的长度都是固定长度`N`，这将返回`B`值的汇总值取决于`mode`。 在这种情况下，`offsets`被忽略，必须为`None`。 * 如果`input`是形状为&lt;cite&gt;(N）&lt;/cite&gt;的 1D， 它将被视为多个包(序列）的串联。 `offsets`必须是一维张量，其中包含`input`中每个包的起始索引位置。 因此，对于形状为&lt;cite&gt;(B）&lt;/cite&gt;的`offsets`，`input`将被视为具有`B`袋。 空袋子(即长度为 0 的袋子）将返回由零填充的向量。 weight(张量）：形状为的模块的可学习权重(num_embeddings，embedding_dim） per_sample_weights(张量，可选）。 具有与input相同的形状。 output：形状为的汇总嵌入值(B，embedding_dim） Examples: >>> # an Embedding module containing 10 tensors of size 3 >>> embedding_matrix = torch.rand(10, 3) >>> # a batch of 2 samples of 4 indices each >>> input = torch.tensor([1,2,4,5,4,3,2,9]) >>> offsets = torch.tensor([0,4]) >>> F.embedding_bag(embedding_matrix, input, offsets) tensor([[ 0.3397, 0.3552, 0.5545], [ 0.5893, 0.4386, 0.5882]]) one_hot torch.nn.functional.one_hot(tensor, num_classes=-1) → LongTensor¶ 接受具有形状为(*)的索引值的 LongTensor，并返回形状为(*, num_classes)的张量，该张量在所有地方都为零，除非最后一个维度的索引与输入张量的对应值匹配，在这种情况下它将为 1。 另请参阅维基百科上的热门。 Parameters 张量 (LongTensor )–任何形状的类值。 num_classes (python：int )–类的总数。 如果设置为-1，则将类数推断为比输入张量中的最大类值大一。 Returns LongTensor 具有一个维度，在输入指示的最后维度的索引处具有 1 个值，在其他地方均为 0。 例子 >>> F.one_hot(torch.arange(0, 5) % 3) tensor([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0]]) >>> F.one_hot(torch.arange(0, 5) % 3, num_classes=5) tensor([[1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 1, 0, 0], [1, 0, 0, 0, 0], [0, 1, 0, 0, 0]]) >>> F.one_hot(torch.arange(0, 6).view(3,2) % 3) tensor([[[1, 0, 0], [0, 1, 0]], [[0, 0, 1], [1, 0, 0]], [[0, 1, 0], [0, 0, 1]]]) 距离功能 pairwise_distance torch.nn.functional.pairwise_distance(x1, x2, p=2.0, eps=1e-06, keepdim=False)¶ 有关详细信息，请参见 torch.nn.PairwiseDistance 余弦相似度 torch.nn.functional.cosine_similarity(x1, x2, dim=1, eps=1e-8) → Tensor¶ 返回沿 dim 计算的 x1 和 x2 之间的余弦相似度。 Parameters x1 (tensor)–第一个输入。 x2 (tensor)–第二个输入(大小匹配 x1）。 昏暗的 (python：int ， 可选）–向量的尺寸。 默认值：1 eps (python：float ， 可选）–避免被零除的小值。 默认值：1e-8 Shape: 输入：其中 D 在位置变暗处。 输出：其中 1 处于位置暗淡。 例： >>> input1 = torch.randn(100, 128) >>> input2 = torch.randn(100, 128) >>> output = F.cosine_similarity(input1, input2) >>> print(output) pdist torch.nn.functional.pdist(input, p=2) → Tensor¶ 计算输入中每​​对行向量之间的 p 范数距离。 这与 torch.norm(input [:, None]-input，dim = 2，p = p）的对角线之外的上三角部分相同。 如果行是连续的，此功能将更快。 如果输入的形状为，则输出的形状为。 如果，则此函数等效于 scipy.spatial.distance.pdist(input，'minkowski'，p = p）。 当等于 scipy.spatial.distance.pdist(input，'hamming'）* M 。 当时，最接近的 scipy 函数是 scipy.spatial.distance.pdist(xn，lambda x，y：np.abs(x-y）.max(））。 Parameters 输入-形状为的输入张量。 p -p 范数距离的 p 值，以计算每个向量对之间的距离。 损失函数 binary_cross_entropy torch.nn.functional.binary_cross_entropy(input, target, weight=None, size_average=None, reduce=None, reduction='mean')¶ 测量目标和输出之间的二进制交叉熵的函数。 有关详细信息，请参见 BCELoss 。 Parameters 输入 –任意形状的张量 目标 –与输入形状相同的张量 重量 (tensor ， 可选）–手动调整重量(如果重复以匹配输入张量形状） size_average (布尔 ， 可选）–已弃用(请参见reduction）。 默认情况下，损失是批次中每个损失元素的平均数。 请注意，对于某些损失，每个样本有多个元素。 如果将字段size_average设置为False，则每个小批量的损失总和。 当 reduce 为False时将被忽略。 默认值：True 还原(布尔 ， 可选）–已弃用(请参阅reduction）。 默认情况下，取决于size_average，对每个小批量的观测值求平均或求和。 当reduce为False时，返回每批元素损失，并忽略size_average。 默认值：True 缩减(字符串 ， 可选）–指定要应用于输出的缩减：'none' | 'mean' | 'sum'。 'none'：不应用任何减少量； 'mean'：输出的总和除以输出中元素的数量； 'sum'：将对输出求和。 注意：size_average和reduce正在淘汰中，与此同时，指定这两个 args 中的任何一个将覆盖reduction。 默认值：'mean' Examples: >>> input = torch.randn((3, 2), requires_grad=True) >>> target = torch.rand((3, 2), requires_grad=False) >>> loss = F.binary_cross_entropy(F.sigmoid(input), target) >>> loss.backward() binary_cross_entropy_with_logits torch.nn.functional.binary_cross_entropy_with_logits(input, target, weight=None, size_average=None, reduce=None, reduction='mean', pos_weight=None)¶ 测量目标和输出对数之间的二进制交叉熵的函数。 有关详细信息，请参见 BCEWithLogitsLoss 。 Parameters input – Tensor of arbitrary shape target – Tensor of the same shape as input weight (Tensor, optional) – a manual rescaling weight if provided it’s repeated to match input tensor shape size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' pos_weight (tensor ， 可选）–正例的权重。 必须是长度等于类数的向量。 Examples: >>> input = torch.randn(3, requires_grad=True) >>> target = torch.empty(3).random_(2) >>> loss = F.binary_cross_entropy_with_logits(input, target) >>> loss.backward() poisson_nll_loss torch.nn.functional.poisson_nll_loss(input, target, log_input=True, full=False, size_average=None, eps=1e-08, reduce=None, reduction='mean')¶ 泊松负对数似然损失。 有关详细信息，请参见 PoissonNLLLoss 。 Parameters 输入 –基本泊松分布的期望。 目标-随机样本。 log_input –如果将True的损失计算为，如果将False的损失计算为。 默认值：True full –是否计算全部损耗，即。 e。 添加斯特林近似项。 默认值：False 。 size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True eps (python：float ， 可选）–较小的值，以避免在log_input=False时评估。 默认值：1e-8 reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' cosine_embedding_loss torch.nn.functional.cosine_embedding_loss(input1, input2, target, margin=0, size_average=None, reduce=None, reduction='mean') → Tensor¶ 有关详细信息，请参见 CosineEmbeddingLoss 。 交叉熵 torch.nn.functional.cross_entropy(input, target, weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')¶ 该标准将 log_softmax 和 nll_loss 合并在一个函数中。 有关详细信息，请参见 CrossEntropyLoss 。 Parameters 输入 (tensor)– 其中 C =类别损失或，如果出现 2D 损失，或[ 在 K 维丢失的情况下。 目标 (tensor)– ，其中每个值是，或，其中对于 K 维损耗。 重量 (tensor ， 可选）–为每个类别提供手动缩放比例的重量。 如果给定，则其张量必须为 C size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True ignore_index (python：int ， 可选）–指定目标值，该目标值将被忽略并且不会对输入梯度产生影响。 当size_average为True时，损耗是在不可忽略的目标上平均的。 默认值：-100 reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Examples: >>> input = torch.randn(3, 5, requires_grad=True) >>> target = torch.randint(5, (3,), dtype=torch.int64) >>> loss = F.cross_entropy(input, target) >>> loss.backward() ctc_loss torch.nn.functional.ctc_loss(log_probs, targets, input_lengths, target_lengths, blank=0, reduction='mean', zero_infinity=False)¶ 连接主义者的时间分类损失。 有关详细信息，请参见 CTCLoss 。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Note When using the CUDA backend, this operation may induce nondeterministic behaviour in its backward pass that is not easily switched off. Please see the notes on Reproducibility for background. Parameters log_probs – ，其中 C =字母字符数，包括空白， T =输入长度，和 N =批处理大小 。 输出的对数概率(例如，使用 torch.nn.functional.log_softmax() 获得的概率）。 目标为 – 或(sum(target_lengths））。 目标不能为空。 在第二种形式中，假定目标是串联的。 input_lengths – 。 输入的长度(每个必须为） target_lengths – 。 目标长度 空白 (python：int ， 可选）–空白标签。 默认值。 缩减(字符串 ， 可选）–指定要应用于输出的缩减：'none' | 'mean' | 'sum'。 'none'：不应用减少量，'mean'：将输出损失除以目标长度，然后取批次的平均值，'sum'：将输出相加。 默认值：'mean' zero_infinity (bool ， 可选）–是否将无限大损失和相关的梯度归零。 默认值：False无限损失主要发生在输入太短而无法与目标对齐时。 Example: >>> log_probs = torch.randn(50, 16, 20).log_softmax(2).detach().requires_grad_() >>> targets = torch.randint(1, 20, (16, 30), dtype=torch.long) >>> input_lengths = torch.full((16,), 50, dtype=torch.long) >>> target_lengths = torch.randint(10,30,(16,), dtype=torch.long) >>> loss = F.ctc_loss(log_probs, targets, input_lengths, target_lengths) >>> loss.backward() 铰链嵌入损耗 torch.nn.functional.hinge_embedding_loss(input, target, margin=1.0, size_average=None, reduce=None, reduction='mean') → Tensor¶ 有关详细信息，请参见 HingeEmbeddingLoss 。 kl_div torch.nn.functional.kl_div(input, target, size_average=None, reduce=None, reduction='mean')¶ Kullback-Leibler 散度损失。 有关详细信息，请参见 KLDivLoss 。 Parameters input – Tensor of arbitrary shape target – Tensor of the same shape as input size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True 缩减(字符串 ， 可选）–指定要应用于输出的缩减：'none' | 'batchmean' | 'sum' | 'mean'。 'none'：不应用缩减项'batchmean'：输出的总和除以批处理大小'sum'：输出的总和'mean'：输出除以输出中的元素数 默认值：'mean' Note size_average和reduce正在弃用的过程中，与此同时，指定这两个 args 中的任何一个将覆盖reduction。 Note ：attr：reduction = 'mean'不返回真实的 kl 散度值，请使用：attr：reduction = 'batchmean'，该值与 KL 数学定义一致。 在下一个主要版本中，'mean'将更改为与“ batchmean”相同的名称。 l1_ 损失 torch.nn.functional.l1_loss(input, target, size_average=None, reduce=None, reduction='mean') → Tensor¶ 取平均逐元素绝对值差的函数。 有关详细信息，请参见 L1Loss 。 mse_loss torch.nn.functional.mse_loss(input, target, size_average=None, reduce=None, reduction='mean') → Tensor¶ 测量按元素的均方误差。 有关详细信息，请参见 MSELoss 。 margin_ranking_loss torch.nn.functional.margin_ranking_loss(input1, input2, target, margin=0, size_average=None, reduce=None, reduction='mean') → Tensor¶ 有关详细信息，请参见 MarginRankingLoss 。 multilabel_margin_loss torch.nn.functional.multilabel_margin_loss(input, target, size_average=None, reduce=None, reduction='mean') → Tensor¶ 有关详细信息，请参见 MultiLabelMarginLoss 。 multilabel_soft_margin_loss torch.nn.functional.multilabel_soft_margin_loss(input, target, weight=None, size_average=None) → Tensor¶ 有关详细信息，请参见 MultiLabelSoftMarginLoss 。 multi_margin_loss torch.nn.functional.multi_margin_loss(input, target, p=1, margin=1.0, weight=None, size_average=None, reduce=None, reduction='mean')¶ multi_margin_loss(input, target, p=1, margin=1, weight=None, size_average=None, reduce = None，reduction ='mean'）->张量 有关详细信息，请参见 MultiMarginLoss 。 nll_loss torch.nn.functional.nll_loss(input, target, weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')¶ 负对数似然损失。 有关详细信息，请参见 NLLLoss 。 Parameters 输入 – ，其中 C =二维损失时的类数或，或，如果发生 K 维损失则为。 目标 – ，其中每个值为，或，其中用于 K 维损耗。 weight (Tensor, optional) – a manual rescaling weight given to each class. If given, has to be a Tensor of size C size_average (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True ignore_index (python:int__, optional) – Specifies a target value that is ignored and does not contribute to the input gradient. When size_average is True, the loss is averaged over non-ignored targets. Default: -100 reduce (bool__, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True reduction (string__, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Example: >>> # input is of size N x C = 3 x 5 >>> input = torch.randn(3, 5, requires_grad=True) >>> # each element in target has to have 0 >> target = torch.tensor([1, 0, 4]) >>> output = F.nll_loss(F.log_softmax(input), target) >>> output.backward() smooth_l1_loss torch.nn.functional.smooth_l1_loss(input, target, size_average=None, reduce=None, reduction='mean')¶ 如果逐个元素的绝对误差低于 1，则使用平方项的函数，否则使用 L1 项。 有关详细信息，请参见 SmoothL1Loss 。 soft_margin_loss torch.nn.functional.soft_margin_loss(input, target, size_average=None, reduce=None, reduction='mean') → Tensor¶ 有关详细信息，请参见 SoftMarginLoss 。 Triplet_margin_loss torch.nn.functional.triplet_margin_loss(anchor, positive, negative, margin=1.0, p=2, eps=1e-06, swap=False, size_average=None, reduce=None, reduction='mean')¶ 有关详细信息，请参见 TripletMarginLoss 视觉功能 pixel_shuffle torch.nn.functional.pixel_shuffle()¶ 将形状为的张量中的元素重新排列为形状为的张量中的元素。 有关详细信息，请参见 PixelShuffle 。 Parameters 输入 (tensor)–输入张量 upscale_factor (python：int )–通过提高空间分辨率的因子 Examples: >>> input = torch.randn(1, 9, 4, 4) >>> output = torch.nn.functional.pixel_shuffle(input, 3) >>> print(output.size()) torch.Size([1, 1, 12, 12]) 垫 torch.nn.functional.pad(input, pad, mode='constant', value=0)¶ 填充张量。 Padding size: 从最后一个尺寸开始，往前介绍填充input某些尺寸的填充尺寸。 将填充input的尺寸。 例如，要仅填充输入张量的最后一个维度，则 pad 的形式为； 填充输入张量的最后两个维度，然后使用 ； 要填充最后 3 个尺寸，请使用 。 Padding mode: 有关每种填充模式如何工作的具体示例，请参见 torch.nn.ConstantPad2d ， torch.nn.ReflectionPad2d 和 torch.nn.ReplicationPad2d 。 恒定填充用于任意尺寸。 复制填充用于填充 5D 输入张量的最后 3 个维度，4D 输入张量的最后 2 个维度或 3D 输入张量的最后一个维度。 反射填充仅用于填充 4D 输入张量的最后 2 个维度或 3D 输入张量的最后一个维度。 Note When using the CUDA backend, this operation may induce nondeterministic behaviour in its backward pass that is not easily switched off. Please see the notes on Reproducibility for background. Parameters 输入 (tensor)– N 维张量 填充(元组）– m 元素元组，其中输入尺寸和是偶数。 模式 – 'constant'，'reflect'，'replicate'或'circular'。 默认值：'constant' 值 – 'constant'填充的填充值。 默认值：0 Examples: >>> t4d = torch.empty(3, 3, 4, 2) >>> p1d = (1, 1) # pad last dim by 1 on each side >>> out = F.pad(t4d, p1d, \"constant\", 0) # effectively zero padding >>> print(out.data.size()) torch.Size([3, 3, 4, 4]) >>> p2d = (1, 1, 2, 2) # pad last dim by (1, 1) and 2nd to last by (2, 2) >>> out = F.pad(t4d, p2d, \"constant\", 0) >>> print(out.data.size()) torch.Size([3, 3, 8, 4]) >>> t4d = torch.empty(3, 3, 4, 2) >>> p3d = (0, 1, 2, 1, 3, 3) # pad by (0, 1), (2, 1), and (3, 3) >>> out = F.pad(t4d, p3d, \"constant\", 0) >>> print(out.data.size()) torch.Size([3, 9, 7, 3]) 插 torch.nn.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None)¶ 向下/向上采样输入给定size或给定scale_factor的输入 用于插值的算法由mode确定。 当前支持时间，空间和体积采样，即，预期输入的形状为 3-D，4-D 或 5-D。 输入尺寸以以下形式解释：微型批处理 x 通道 x [可选深度] x [可选高度] x 宽度。 可用于调整大小的模式为：最接近，线性(仅 3D），双线性，双三次(仅 4D），[ 三线性(仅限 5D），区域 Parameters input (Tensor) – the input tensor 大小 (python：int 或 元组 [ python：int ]或 元组 [ python：int ， python：int ]或 元组 [ python：int ， python：int ， python：int ] )–输出空间大小。 scale_factor (python：float 或 元组 [ python：float ] )–空间大小的乘数。 如果是元组，则必须匹配输入大小。 模式 (str )–用于上采样的算法：'nearest' | 'linear' | 'bilinear' | 'bicubic' | 'trilinear' | 'area'。 默认值：'nearest' align_corners (布尔 ， 可选）–在几何上，我们将输入和输出的像素视为正方形而不是点。 如果设置为True，则输入和输出张量将按其角点像素的中心对齐，并保留角点像素处的值。 如果设置为False，则输入和输出张量按其角点像素的角点对齐，并且插值对边界值使用边缘值填充，从而使此操作独立于输入 scale_factor保持相同时的尺寸。 仅当mode为'linear'，'bilinear'，'bicubic'或'trilinear'时才有效。 默认值：False Note 使用mode='bicubic'可能会导致过冲，换句话说，它可能会产生负值或大于 255 的图像值。 如果要减少显示图像时的过冲，请明确调用result.clamp(min=0, max=255)。 Warning 使用align_corners = True时，线性插值模式(线性，双线性和三线性）不会按比例对齐输出像素和输入像素，因此输出 值可以取决于输入大小。 这是这些模式(0.3.1 版之前）的默认行为。 从那时起，默认行为是align_corners = False。 有关如何影响输出的具体示例，请参见 Upsample 。 Note When using the CUDA backend, this operation may induce nondeterministic behaviour in its backward pass that is not easily switched off. Please see the notes on Reproducibility for background. 上采样 torch.nn.functional.upsample(input, size=None, scale_factor=None, mode='nearest', align_corners=None)¶ 将输入上采样到给定的size或给定的scale_factor Warning 不推荐使用此功能，而推荐使用 torch.nn.functional.interpolate() 。 与nn.functional.interpolate(...)等效。 Note When using the CUDA backend, this operation may induce nondeterministic behaviour in its backward pass that is not easily switched off. Please see the notes on Reproducibility for background. 用于上采样的算法由mode确定。 当前支持时间，空间和体积上采样，即，预期输入的形状为 3D，4D 或 5D。 The input dimensions are interpreted in the form: mini-batch x channels x [optional depth] x [optional height] x width. 可用于上采样的模式为：最接近，线性(仅 3D），双线性，双三次(仅 4D），三线性(仅限 5D） Parameters input (Tensor) – the input tensor size (python:int or Tuple[python:int__] or Tuple[python:int__, python:int__] or Tuple[python:int__, python:int__, python:int__]) – output spatial size. scale_factor (python：float 或 元组 [ python：float ] )–空间大小的乘数。 必须是整数。 模式(字符串）–用于上采样的算法：'nearest' | 'linear' | 'bilinear' | 'bicubic' | 'trilinear'。 默认值：'nearest' align_corners (bool__, optional) – Geometrically, we consider the pixels of the input and output as squares rather than points. If set to True, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels. If set to False, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when scale_factor is kept the same. This only has an effect when mode is 'linear', 'bilinear', 'bicubic' or 'trilinear'. Default: False Note With mode='bicubic', it’s possible to cause overshoot, in other words it can produce negative values or values greater than 255 for images. Explicitly call result.clamp(min=0, max=255) if you want to reduce the overshoot when displaying the image. Warning With align_corners = True, the linearly interpolating modes (linear, bilinear, and trilinear) don’t proportionally align the output and input pixels, and thus the output values can depend on the input size. This was the default behavior for these modes up to version 0.3.1. Since then, the default behavior is align_corners = False. See Upsample for concrete examples on how this affects the outputs. upsample_nearest torch.nn.functional.upsample_nearest(input, size=None, scale_factor=None)¶ 使用最近邻的像素值对输入进行上采样。 Warning 不推荐使用此功能，而推荐使用 torch.nn.functional.interpolate() 。 与nn.functional.interpolate(..., mode='nearest')等效。 当前支持空间和体积上采样(即，预期输入为 4 维或 5 维）。 Parameters input (Tensor) – input 大小 (python：int 或 元组 [ python：int ， python：int ]或 元组 [ python：int ， python：int ， python：int ] )–输出空间大小。 scale_factor (python：int )–空间大小的乘数。 必须是整数。 Note When using the CUDA backend, this operation may induce nondeterministic behaviour in its backward pass that is not easily switched off. Please see the notes on Reproducibility for background. upsample_bilinear torch.nn.functional.upsample_bilinear(input, size=None, scale_factor=None)¶ 使用双线性上采样对输入进行上采样。 Warning 不推荐使用此功能，而推荐使用 torch.nn.functional.interpolate() 。 与nn.functional.interpolate(..., mode='bilinear', align_corners=True)等效。 预期的输入是空间(4 维）。 对于体积(5 维）输入使用 upsample_trilinear 。 Parameters input (Tensor) – input 大小 (python：int 或 元组 [ python：int ， python：int ] )–输出空间大小。 scale_factor (python：int 或 元组 [ python：int ， python：int ] )–空间大小的乘数 Note When using the CUDA backend, this operation may induce nondeterministic behaviour in its backward pass that is not easily switched off. Please see the notes on Reproducibility for background. grid_sample torch.nn.functional.grid_sample(input, grid, mode='bilinear', padding_mode='zeros', align_corners=None)¶ 给定input和流场grid，则使用input值和来自grid的像素位置来计算output。 当前，仅支持空间(4-D）和体积(5-D）input。 在空间(4-D）情况下，对于形状为的input和形状为的grid，输出将具有形状。 对于每个输出位置output[n, :, h, w]，大小为 2 的向量grid[n, h, w]指定input像素位置x和y，用于对输出值output[n, :, h, w]进行插值。 在 5D 输入的情况下，grid[n, d, h, w]指定用于内插output[n, :, d, h, w]的x，y，z像素位置。 mode自变量指定nearest或bilinear内插方法以对输入像素进行采样。 grid指定通过input空间尺寸归一化的采样像素位置。 因此，它应具有[-1, 1]范围内的大多数值。 例如，值x = -1, y = -1是input的左上像素，值x = 1, y = 1是input的右下像素。 如果grid的值超出[-1, 1]范围，则​​按padding_mode定义处理相应的输出。 选项是 padding_mode=\"zeros\"：将0用于出站网格位置， padding_mode=\"border\"：将边界值用于出站网格位置， padding_mode=\"reflection\"：将边界所反映的位置的值用于边界外的网格位置。 对于远离边界的位置，它将一直被反射直到成为边界，例如，(标准化）像素位置x = -3.5被边界-1反射并变为x' = 1.5，然后被边界1反射并变为[ x'' = -0.5。 Note 此功能通常与 affine_grid() 结合使用，以构建空间变压器网络。 Note When using the CUDA backend, this operation may induce nondeterministic behaviour in its backward pass that is not easily switched off. Please see the notes on Reproducibility for background. Parameters 输入 (tensor)–输入形状(4-D 情况）或(5-D 情况） 网格 (tensor)–形状为(4-D 情况）或(5-D 情况）的流场 模式 (str )–插值模式以计算输出值'bilinear' | 'nearest'。 默认值：'bilinear' padding_mode (str )–外部网格值的填充模式'zeros' | 'border' | 'reflection'。 默认值：'zeros' align_corners (布尔 ， 可选）–在几何上，我们将输入像素视为正方形而不是点。 如果设置为True，则极值(-1和1）被视为参考输入角像素的中心点。 如果设置为False，则它们将被视为参考输入的角像素的角点，从而使采样更加不可知。 此选项与 interpolate() 中的align_corners选项相似，因此在网格采样之前，此处使用的任何选项也应用于调整输入图像的大小。 默认值：False Returns 输出张量 返回类型 输出(张量） Warning 当align_corners = True时，网格位置取决于相对于输入图像大小的像素大小，因此对于以不同分辨率给出的同一输入， grid_sample() 采样的位置将有所不同(也就是说， 上采样或下采样）。 直到版本 1.2.0，默认行为是align_corners = True。 从那时起，默认行为已更改为align_corners = False，以使其与 interpolate() 的默认行为保持一致。 仿射网格 torch.nn.functional.affine_grid(theta, size, align_corners=None)¶ 给定一批仿射矩阵theta，生成 2D 或 3D 流场(采样网格）。 Note 此功能通常与 grid_sample() 结合使用，以构建空间变压器网络。 Parameters theta (tensor)–输入仿射矩阵，其形状为(D）(2D）或(）3D 大小(torch大小）–目标输出图像大小。 (用于 2D 的或用于 3D 的）示例：torch.Size((32，3，24，24）） align_corners (bool ， 可选）–如果True，请考虑-1和1指的是 角像素而不是图像角。 有关更完整的说明，请参见 grid_sample() 。 由 affine_grid() 生成的网格应传递至 grid_sample() ，并为此选项设置相同。 默认值：False Returns 输出张量大小(） Return type output (Tensor) Warning When align_corners = True, the grid positions depend on the pixel size relative to the input image size, and so the locations sampled by grid_sample() will differ for the same input given at different resolutions (that is, after being upsampled or downsampled). The default behavior up to version 1.2.0 was align_corners = True. Since then, the default behavior has been changed to align_corners = False, in order to bring it in line with the default for interpolate(). Warning 当align_corners = True时，对 1D 数据的 2D 仿射变换和对 2D 数据的 3D 仿射变换(即，当空间维度之一具有单位大小时）定义不明确，而不是预期的用例。 当align_corners = False时这不是问题。 在版本 1.2.0 之前的版本中，沿单位维度的所有网格点都被视为任意-1。 从版本 1.3.0 开始，在align_corners = True下，单位尺寸上的所有网格点都被认为位于`0(输入图像的中心）处。 DataParallel 功能(多 GPU，分布式） data_parallel torch.nn.parallel.data_parallel(module, inputs, device_ids=None, output_device=None, dim=0, module_kwargs=None)¶ 跨 device_ids 中提供的 GPU 并行评估模块(输入）。 这是 DataParallel 模块的功能版本。 Parameters 模块 (模块)–并行评估的模块 输入 (tensor)–模块的输入 device_ids (python：int 的列表： 或 Torch.device)–在其上复制模块的 GPU ID output_device (python：int 的列表： 或 Torch.device)–输出的 GPU 位置使用- 1 表示 CPU。 (默认值：device_ids [0]） Returns 一个 Tensor，包含位于 output_device 上的 module(input）的结果 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"77.html":{"url":"77.html","title":"torch张量","keywords":"","body":"torch张量 原文： https://pytorch.org/docs/stable/tensors.html torch.Tensor 是包含单个数据类型元素的多维矩阵。 torch定义了 9 种 CPU 张量类型和 9 种 GPU 张量类型： | 数据类型 | dtype | CPU 张量 | GPU 张量 | | --- | --- | --- | --- | | 32 位浮点 | torch.float32或torch.float | torch.FloatTensor | torch.cuda.FloatTensor | | 64 位浮点 | torch.float64或torch.double | torch.DoubleTensor | torch.cuda.DoubleTensor | | 16 位浮点 | torch.float16或torch.half | torch.HalfTensor | torch.cuda.HalfTensor | | 8 位整数(无符号） | torch.uint8 | torch.ByteTensor | torch.cuda.ByteTensor | | 8 位整数(有符号） | torch.int8 | torch.CharTensor | torch.cuda.CharTensor | | 16 位整数(有符号） | torch.int16或torch.short | torch.ShortTensor | torch.cuda.ShortTensor | | 32 位整数(有符号） | torch.int32或torch.int | torch.IntTensor | torch.cuda.IntTensor | | 64 位整数(有符号） | torch.int64或torch.long | torch.LongTensor | torch.cuda.LongTensor | | 布尔型 | torch.bool | torch.BoolTensor | torch.cuda.BoolTensor | torch.Tensor 是默认张量类型(torch.FloatTensor）的别名。 可以使用 torch.tensor() 构造函数从 Python list或序列构造张量： >>> torch.tensor([[1., -1.], [1., -1.]]) tensor([[ 1.0000, -1.0000], [ 1.0000, -1.0000]]) >>> torch.tensor(np.array([[1, 2, 3], [4, 5, 6]])) tensor([[ 1, 2, 3], [ 4, 5, 6]]) 警告 torch.tensor() 始终复制data。 如果您具有张量data，而只想更改其requires_grad标志，请使用 requires_grad_() 或 detach() 以避免复制。 如果您有一个 numpy 数组并且想要避免复制，请使用 torch.as_tensor() 。 可以通过将 torch.dtype 和/或 torch.device 传递给构造函数或张量创建操作来构造特定数据类型的张量： >>> torch.zeros([2, 4], dtype=torch.int32) tensor([[ 0, 0, 0, 0], [ 0, 0, 0, 0]], dtype=torch.int32) >>> cuda0 = torch.device('cuda:0') >>> torch.ones([2, 4], dtype=torch.float64, device=cuda0) tensor([[ 1.0000, 1.0000, 1.0000, 1.0000], [ 1.0000, 1.0000, 1.0000, 1.0000]], dtype=torch.float64, device='cuda:0') 张量的内容可以使用 Python 的索引和切片符号来访问和修改： >>> x = torch.tensor([[1, 2, 3], [4, 5, 6]]) >>> print(x[1][2]) tensor(6) >>> x[0][1] = 8 >>> print(x) tensor([[ 1, 8, 3], [ 4, 5, 6]]) 使用 torch.Tensor.item() 从张量中获取包含单个值的 Python 数字： >>> x = torch.tensor([[1]]) >>> x tensor([[ 1]]) >>> x.item() 1 >>> x = torch.tensor(2.5) >>> x tensor(2.5000) >>> x.item() 2.5 可以使用requires_grad=True创建一个张量，以便 torch.autograd 对其进行记录操作以进行自动微分。 >>> x = torch.tensor([[1., -1.], [1., 1.]], requires_grad=True) >>> out = x.pow(2).sum() >>> out.backward() >>> x.grad tensor([[ 2.0000, -2.0000], [ 2.0000, 2.0000]]) 每个张量都有一个关联的torch.Storage，它保存其数据。 张量类提供了存储的多维跨度视图，并定义了数字运算。 注意 有关 torch.Tensor 的 torch.dtype ， torch.device 和 torch.layout 属性的更多信息，请参阅[ Tensor Attributes 。 Note 改变张量的方法用下划线后缀标记。 例如，torch.FloatTensor.abs_()在原位计算绝对值并返回修改后的张量，而torch.FloatTensor.abs()在新张量中计算结果。 Note 要更改现有张量的 torch.device 和/或 torch.dtype ，请考虑在张量上使用 to() 方法。 Warning torch.Tensor 的当前实现引入了内存开销，因此，在具有许多微小张量的应用程序中，它可能导致意外的高内存使用率。 如果是这种情况，请考虑使用一种大型结构。 class torch.Tensor¶ 根据您的用例，创建张量的主要方法有几种。 要使用现有数据创建张量，请使用 torch.tensor() 。 要创建具有特定大小的张量，请使用torch.*张量创建操作(请参见 Creation Ops)。 要创建与另一个张量具有相同大小(和相似类型）的张量，请使用torch.*_like张量创建操作(请参见创建操作）。 要创建与其他张量具有相似类型但大小不同的张量，请使用tensor.new_*创建操作。 new_tensor(data, dtype=None, device=None, requires_grad=False) → Tensor¶ 返回以data作为张量数据的新张量。 默认情况下，返回的张量与此张量具有相同的 torch.dtype 和 torch.device 。 Warning new_tensor() 始终复制data。 如果您有张量data并希望避免复制，请使用 torch.Tensor.requires_grad_() 或 torch.Tensor.detach() 。 如果您有一个 numpy 数组并且想要避免复制，请使用 torch.from_numpy() 。 Warning 当数据是张量 x 时， new_tensor() 从传递的任何数据中读出“数据”，并构造一个叶子变量。 因此，tensor.new_tensor(x)等同于x.clone().detach()，tensor.new_tensor(x, requires_grad=True)等同于x.clone().detach().requires_grad_(True)。 建议使用clone()和detach()的等效项。 参数 数据 (array_like )–返回的张量副本data。 dtype (torch.dtype ，可选）–返回张量的所需类型。 默认值：如果为 None，则与此张量相同的 torch.dtype 。 设备 (torch.device ，可选）–返回张量的所需设备。 默认值：如果为 None，则与此张量相同的 torch.device 。 require_grad (bool ， 可选）–如果 autograd 应该在返回的张量上记录操作。 默认值：False。 例： >>> tensor = torch.ones((2,), dtype=torch.int8) >>> data = [[0, 1], [2, 3]] >>> tensor.new_tensor(data) tensor([[ 0, 1], [ 2, 3]], dtype=torch.int8) new_full(size, fill_value, dtype=None, device=None, requires_grad=False) → Tensor¶ 返回大小为 size 的张量，并用fill_value填充。 默认情况下，返回的张量与此张量具有相同的 torch.dtype 和 torch.device 。 Parameters fill_value (标量）–用来填充输出张量的数字。 dtype (torch.dtype, optional) – the desired type of returned tensor. Default: if None, same torch.dtype as this tensor. device (torch.device, optional) – the desired device of returned tensor. Default: if None, same torch.device as this tensor. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> tensor = torch.ones((2,), dtype=torch.float64) >>> tensor.new_full((3, 4), 3.141592) tensor([[ 3.1416, 3.1416, 3.1416, 3.1416], [ 3.1416, 3.1416, 3.1416, 3.1416], [ 3.1416, 3.1416, 3.1416, 3.1416]], dtype=torch.float64) new_empty(size, dtype=None, device=None, requires_grad=False) → Tensor¶ 返回大小为 size 的张量，其中填充了未初始化的数据。 默认情况下，返回的张量具有与此张量相同的 torch.dtype 和 torch.device 。 Parameters dtype (torch.dtype, optional) – the desired type of returned tensor. Default: if None, same torch.dtype as this tensor. device (torch.device, optional) – the desired device of returned tensor. Default: if None, same torch.device as this tensor. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> tensor = torch.ones(()) >>> tensor.new_empty((2, 3)) tensor([[ 5.8182e-18, 4.5765e-41, -1.0545e+30], [ 3.0949e-41, 4.4842e-44, 0.0000e+00]]) new_ones(size, dtype=None, device=None, requires_grad=False) → Tensor¶ 返回大小为 size 的张量，并用1填充。 默认情况下，返回的张量与此张量具有相同的 torch.dtype 和 torch.device 。 Parameters 大小 (python：int ... )–定义输出张量形状的整数列表，元组或torch.Size。 dtype (torch.dtype, optional) – the desired type of returned tensor. Default: if None, same torch.dtype as this tensor. device (torch.device, optional) – the desired device of returned tensor. Default: if None, same torch.device as this tensor. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> tensor = torch.tensor((), dtype=torch.int32) >>> tensor.new_ones((2, 3)) tensor([[ 1, 1, 1], [ 1, 1, 1]], dtype=torch.int32) new_zeros(size, dtype=None, device=None, requires_grad=False) → Tensor¶ 返回大小为 size 的张量，并用0填充。 默认情况下，返回的张量与此张量具有相同的 torch.dtype 和 torch.device 。 Parameters size (python:int...) – a list, tuple, or torch.Size of integers defining the shape of the output tensor. dtype (torch.dtype, optional) – the desired type of returned tensor. Default: if None, same torch.dtype as this tensor. device (torch.device, optional) – the desired device of returned tensor. Default: if None, same torch.device as this tensor. requires_grad (bool__, optional) – If autograd should record operations on the returned tensor. Default: False. Example: >>> tensor = torch.tensor((), dtype=torch.float64) >>> tensor.new_zeros((2, 3)) tensor([[ 0., 0., 0.], [ 0., 0., 0.]], dtype=torch.float64) is_cuda¶ 如果张量存储在 GPU 上，则为True，否则为False。 device¶ 张量所在的 torch.device 。 grad 此属性默认为None，并在首次调用 backward() 计算self的梯度时成为张量。 然后，该属性将包含计算出的梯度，将来对 backward() 的调用将在其中累积(添加）梯度。 ndim¶ dim() 的别名 T¶ 这个张量的尺寸是否颠倒了吗？ 如果n是x中的尺寸数，则x.T等效于x.permute(n-1, n-2, ..., 0)。 abs() → Tensor¶ 参见 torch.abs() abs_() → Tensor¶ 就地版本的 abs() acos() → Tensor¶ 参见 torch.acos() acos_() → Tensor¶ 就地版本的 acos() add(value) → Tensor¶ add(value = 1，other）->张量 参见 torch.add() add_(value) → Tensor¶ add_(value = 1，other）->张量 就地版本的 add() addbmm(beta=1, alpha=1, batch1, batch2) → Tensor¶ 参见 torch.addbmm() addbmm_(beta=1, alpha=1, batch1, batch2) → Tensor¶ 就地版本的 addbmm() addcdiv(value=1, tensor1, tensor2) → Tensor¶ 参见 torch.addcdiv() addcdiv_(value=1, tensor1, tensor2) → Tensor¶ 就地版本的 addcdiv() addcmul(value=1, tensor1, tensor2) → Tensor¶ 参见 torch.addcmul() addcmul_(value=1, tensor1, tensor2) → Tensor¶ 就地版本的 addcmul() addmm(beta=1, alpha=1, mat1, mat2) → Tensor¶ 参见 torch.addmm() addmm_(beta=1, alpha=1, mat1, mat2) → Tensor¶ 就地版本的 addmm() addmv(beta=1, alpha=1, mat, vec) → Tensor¶ 参见 torch.addmv() addmv_(beta=1, alpha=1, mat, vec) → Tensor¶ 就地版本的 addmv() addr(beta=1, alpha=1, vec1, vec2) → Tensor¶ 参见 torch.addr() addr_(beta=1, alpha=1, vec1, vec2) → Tensor¶ 就地版本的 addr() allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) → Tensor¶ 参见 torch.allclose() angle() → Tensor¶ 参见 torch.angle() apply_(callable) → Tensor¶ 将函数callable应用于张量中的每个元素，并用callable返回的值替换每个元素。 Note 此功能仅适用于 CPU 张量，不应在需要高性能的代码段中使用。 argmax(dim=None, keepdim=False) → LongTensor¶ 参见 torch.argmax() argmin(dim=None, keepdim=False) → LongTensor¶ 参见 torch.argmin() argsort(dim=-1, descending=False) → LongTensor¶ 见：func： torch.argsort asin() → Tensor¶ 参见 torch.asin() asin_() → Tensor¶ 就地版本的 asin() as_strided(size, stride, storage_offset=0) → Tensor¶ 参见 torch.as_strided() atan() → Tensor¶ 参见 torch.atan() atan2(other) → Tensor¶ 参见 torch.atan2() atan2_(other) → Tensor¶ 就地版本的 atan2() atan_() → Tensor¶ 就地版本的 atan() backward(gradient=None, retain_graph=None, create_graph=False) 计算电流张量 w.r.t. 图叶。 该图使用链规则进行区分。 如果张量是非标量的(即其数据具有多个元素）并且需要梯度，则该函数还需要指定gradient。 它应该是匹配类型和位置的张量，其中包含微分函数 w.r.t 的梯度。 self。 此函数在树叶中累积渐变-调用它之前可能需要将它们归零。 Parameters 梯度 (tensor 或 无）–梯度 w.r.t. 张量。 如果它是张量，除非create_graph为 True，否则它将自动转换为不需要 grad 的张量。 无法为标量张量或不需要等级的张量指定任何值。 如果 None 值可以接受，那么此参数是可选的。 keep_graph (bool ， 可选）–如果False，则用于计算等级的图形将被释放。 请注意，几乎在所有情况下都不需要将此选项设置为 True，并且通常可以以更有效的方式解决它。 默认为create_graph的值。 create_graph (bool ， 可选）–如果True，则将构造导数图，从而允许计算高阶导数 产品。 默认为False。 baddbmm(beta=1, alpha=1, batch1, batch2) → Tensor¶ 参见 torch.baddbmm() baddbmm_(beta=1, alpha=1, batch1, batch2) → Tensor¶ 就地版本的 baddbmm() bernoulli(*, generator=None) → Tensor¶ 返回结果张量，其中每个从中独立采样。 self必须具有浮点dtype，结果将具有相同的dtype。 参见 torch.bernoulli() bernoulli_()¶ bernoulli_(p=0.5, *, generator=None) → Tensor 用的独立样本填充self的每个位置。 self可以具有整数dtype。 bernoulli_(p_tensor, *, generator=None) → Tensor p_tensor应该是一个张量，其中包含用于绘制二进制随机数的概率。 self张量的元素将设置为从采样的值。 self可以具有整数dtype，但是p_tensor必须具有浮点dtype。 另请参见 bernoulli() 和 torch.bernoulli() bfloat16() → Tensor¶ self.bfloat16()等效于self.to(torch.bfloat16)。 参见 to() 。 bincount(weights=None, minlength=0) → Tensor¶ 参见 torch.bincount() bitwise_not() → Tensor¶ 参见 torch.bitwise_not() bitwise_not_() → Tensor¶ 就地版本的 bitwise_not() bitwise_xor() → Tensor¶ 参见 torch.bitwise_xor() bitwise_xor_() → Tensor¶ 就地版本的 bitwise_xor() bmm(batch2) → Tensor¶ 参见 torch.bmm() bool() → Tensor¶ self.bool()等效于self.to(torch.bool)。 参见 to() 。 byte() → Tensor¶ self.byte()等效于self.to(torch.uint8)。 参见 to() 。 cauchy_(median=0, sigma=1, *, generator=None) → Tensor¶ 用从柯西分布中得出的数字填充张量： ceil() → Tensor¶ 参见 torch.ceil() ceil_() → Tensor¶ 就地版本的 ceil() char() → Tensor¶ self.char()等效于self.to(torch.int8)。 参见 to() 。 cholesky(upper=False) → Tensor¶ 参见 torch.cholesky() cholesky_inverse(upper=False) → Tensor¶ 参见 torch.cholesky_inverse() cholesky_solve(input2, upper=False) → Tensor¶ 参见 torch.cholesky_solve() chunk(chunks, dim=0) → List of Tensors¶ 参见 torch.chunk() clamp(min, max) → Tensor¶ 参见 torch.clamp() clamp_(min, max) → Tensor¶ 就地版本的 clamp() clone() → Tensor¶ 返回self张量的副本。 该副本的大小和数据类型与self相同。 Note 与 copy_(）不同，此功能记录在计算图中。 传播到克隆张量的渐变将传播到原始张量。 contiguous() → Tensor¶ 返回包含与self张量相同的数据的连续张量。 如果self张量是连续的，则此函数返回self张量。 copy_(src, non_blocking=False) → Tensor¶ 将元素从src复制到self张量并返回self。 src张量必须与self张量一起广播。 它可以具有不同的数据类型，也可以位于不同的设备上。 Parameters src (tensor)–要从中复制的源张量 non_blocking (bool )–如果True并且此副本位于 CPU 和 GPU 之间，则该副本可能相对于主机异步发生。 在其他情况下，此参数无效。 conj() → Tensor¶ 参见 torch.conj() cos() → Tensor¶ 参见 torch.cos() cos_() → Tensor¶ 就地版本的 cos() cosh() → Tensor¶ 参见 torch.cosh() cosh_() → Tensor¶ 就地版本的 cosh() cpu() → Tensor¶ 返回此对象在 CPU 内存中的副本。 如果该对象已经在 CPU 内存中并且在正确的设备上，则不执行任何复制操作并返回原始对象。 cross(other, dim=-1) → Tensor¶ 参见 torch.cross() cuda(device=None, non_blocking=False) → Tensor¶ 返回此对象在 CUDA 内存中的副本。 如果此对象已经在 CUDA 内存中并且在正确的设备上，则不执行任何复制，并返回原始对象。 Parameters 设备 (torch.device)–目标 GPU 设备。 默认为当前 CUDA 设备。 non_blocking (bool )–如果True并且源位于固定内存中，则副本将相对于主机是异步的。 否则，该参数无效。 默认值：False。 cumprod(dim, dtype=None) → Tensor¶ 参见 torch.cumprod() cumsum(dim, dtype=None) → Tensor¶ 参见 torch.cumsum() data_ptr() → int¶ 返回self张量的第一个元素的地址。 dequantize() → Tensor¶ 给定量化的张量，对其进行反量化，然后返回反量化后的浮点张量。 det() → Tensor¶ 参见 torch.det() dense_dim() → int¶ 如果self是稀疏的 COO 张量(即torch.sparse_coo布局），则返回密集尺寸的数量。 否则，将引发错误。 另请参见 Tensor.sparse_dim() 。 detach() 返回与当前图形分离的新 Tensor。 结果将永远不需要渐变。 Note 返回的 Tensor 与原始 Tensor 共享相同的存储。 可以看到对它们中的任何一个的就地修改，并且可能触发正确性检查中的错误。 重要说明：以前，就地大小/步幅/存储更改(例如 resize / resize_as / set / transpose ) 返回的张量也会更新原始张量。 现在，这些就地更改将不再更新原始张量，而将触发错误。 对于稀疏张量：原位索引/值更改(例如 zero / copy / add_ )将不会再更新原始张量， 而是触发错误。 detach_() 从创建它的图形中分离张量，使其成为一片叶子。 视图不能就地分离。 diag(diagonal=0) → Tensor¶ 参见 torch.diag() diag_embed(offset=0, dim1=-2, dim2=-1) → Tensor¶ 参见 torch.diag_embed() diagflat(offset=0) → Tensor¶ 参见 torch.diagflat() diagonal(offset=0, dim1=0, dim2=1) → Tensor¶ 参见 torch.diagonal() fill_diagonal_(fill_value, wrap=False) → Tensor¶ 填充具有至少 2 维的张量的主对角线。 当> 2 变暗时，所有输入尺寸必须相等。 此函数就地修改输入张量，并返回输入张量。 Parameters fill_value (标量）–填充值 包装 (bool )–对角线“包裹”在高列的 N 列之后。 Example: >>> a = torch.zeros(3, 3) >>> a.fill_diagonal_(5) tensor([[5., 0., 0.], [0., 5., 0.], [0., 0., 5.]]) >>> b = torch.zeros(7, 3) >>> b.fill_diagonal_(5) tensor([[5., 0., 0.], [0., 5., 0.], [0., 0., 5.], [0., 0., 0.], [0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]) >>> c = torch.zeros(7, 3) >>> c.fill_diagonal_(5, wrap=True) tensor([[5., 0., 0.], [0., 5., 0.], [0., 0., 5.], [0., 0., 0.], [5., 0., 0.], [0., 5., 0.], [0., 0., 5.]]) digamma() → Tensor¶ 参见 torch.digamma() digamma_() → Tensor¶ 就地版本的 digamma() dim() → int¶ 返回self张量的维数。 dist(other, p=2) → Tensor¶ 参见 torch.dist() div(value) → Tensor¶ 参见 torch.div() div_(value) → Tensor¶ 就地版本的 div() dot(tensor2) → Tensor¶ 参见 torch.dot() double() → Tensor¶ self.double()等效于self.to(torch.float64)。 参见 to() 。 eig(eigenvectors=False) -> (Tensor, Tensor)¶ 参见 torch.eig() element_size() → int¶ 返回单个元素的大小(以字节为单位）。 Example: >>> torch.tensor([]).element_size() 4 >>> torch.tensor([], dtype=torch.uint8).element_size() 1 eq(other) → Tensor¶ 参见 torch.eq() eq_(other) → Tensor¶ 就地版本的 eq() equal(other) → bool¶ 参见 torch.equal() erf() → Tensor¶ 参见 torch.erf() erf_() → Tensor¶ 就地版本的 erf() erfc() → Tensor¶ 参见 torch.erfc() erfc_() → Tensor¶ 就地版本的 erfc() erfinv() → Tensor¶ 参见 torch.erfinv() erfinv_() → Tensor¶ 就地版本的 erfinv() exp() → Tensor¶ 参见 torch.exp() exp_() → Tensor¶ 就地版本的 exp() expm1() → Tensor¶ 参见 torch.expm1() expm1_() → Tensor¶ 就地版本的 expm1() expand(*sizes) → Tensor¶ 返回self张量的新视图，其中单例尺寸扩展为更大的尺寸。 将-1 传递为尺寸的大小表示不更改该尺寸的大小。 Tensor 也可以扩展到更大的尺寸，并且新尺寸将附加在前面。 对于新尺寸，尺寸不能设置为-1。 扩展张量不会分配新的内存，而只会在现有张量上创建一个新视图，其中通过将stride设置为 0，将尺寸为 1 的维扩展为更大的尺寸。尺寸为 1 的任何维都可以扩展为 不分配新内存的任意值。 Parameters *大小(torch大小 或 python：int ... )–所需的扩展大小 Warning 扩展张量的一个以上元素可以引用单个存储位置。 结果，就地操作(尤其是矢量化的操作）可能会导致错误的行为。 如果需要写张量，请先克隆它们。 Example: >>> x = torch.tensor([[1], [2], [3]]) >>> x.size() torch.Size([3, 1]) >>> x.expand(3, 4) tensor([[ 1, 1, 1, 1], [ 2, 2, 2, 2], [ 3, 3, 3, 3]]) >>> x.expand(-1, 4) # -1 means not changing the size of that dimension tensor([[ 1, 1, 1, 1], [ 2, 2, 2, 2], [ 3, 3, 3, 3]]) expand_as(other) → Tensor¶ 将该张量扩展为与other相同的大小。 self.expand_as(other)等效于self.expand(other.size())。 有关expand的更多信息，请参见 expand() 。 Parameters 其他 (torch.Tensor)–结果张量的大小与other相同。 exponential_(lambd=1, *, generator=None) → Tensor¶ 用从指数分布中绘制的元素填充self张量： fft(signal_ndim, normalized=False) → Tensor¶ 参见 torch.fft() fill_(value) → Tensor¶ 用指定值填充self张量。 flatten(input, start_dim=0, end_dim=-1) → Tensor¶ 参见 torch.flatten() flip(dims) → Tensor¶ 参见 torch.flip() float() → Tensor¶ self.float()等效于self.to(torch.float32)。 参见 to() 。 floor() → Tensor¶ 参见 torch.floor() floor_() → Tensor¶ 就地版本的 floor() fmod(divisor) → Tensor¶ 参见 torch.fmod() fmod_(divisor) → Tensor¶ 就地版本的 fmod() frac() → Tensor¶ 参见 torch.frac() frac_() → Tensor¶ 就地版本的 frac() gather(dim, index) → Tensor¶ 参见 torch.gather() ge(other) → Tensor¶ 参见 torch.ge() ge_(other) → Tensor¶ 就地版本的 ge() geometric_(p, *, generator=None) → Tensor¶ 用从几何分布中绘制的元素填充self张量： geqrf() -> (Tensor, Tensor)¶ 参见 torch.geqrf() ger(vec2) → Tensor¶ 参见 torch.ger() get_device() -> Device ordinal (Integer)¶ 对于 CUDA 张量，此函数返回张量所在的 GPU 的设备序号。 对于 CPU 张量，将引发错误。 Example: >>> x = torch.randn(3, 4, 5, device='cuda:0') >>> x.get_device() 0 >>> x.cpu().get_device() # RuntimeError: get_device is not implemented for type torch.FloatTensor gt(other) → Tensor¶ 参见 torch.gt() gt_(other) → Tensor¶ 就地版本的 gt() half() → Tensor¶ self.half()等效于self.to(torch.float16)。 参见 to() 。 hardshrink(lambd=0.5) → Tensor¶ 参见 torch.nn.functional.hardshrink() histc(bins=100, min=0, max=0) → Tensor¶ 参见 torch.histc() ifft(signal_ndim, normalized=False) → Tensor¶ 参见 torch.ifft() imag() → Tensor¶ 参见 torch.imag() index_add_(dim, index, tensor) → Tensor¶ 通过按index中给定的顺序添加索引，将 tensor 的元素累积到self张量中。 例如，如果dim == 0和index[i] == j，则将的第i行tensor 添加到self的第j行。 tensor 的 dim 尺寸必须与index的长度(必须为矢量）的尺寸相同，并且所有其他尺寸必须与self ]，否则将引发错误。 Note 使用 CUDA 后端时，此操作可能会导致不确定的行为，不容易关闭。 有关背景，请参见重现性的注释。 Parameters 暗淡的 (python：int )–索引所沿的维度 索引 (LongTensor )– tensor 的索引 张量 (tensor)–张量包含要添加的值 Example: >>> x = torch.ones(5, 3) >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float) >>> index = torch.tensor([0, 4, 2]) >>> x.index_add_(0, index, t) tensor([[ 2., 3., 4.], [ 1., 1., 1.], [ 8., 9., 10.], [ 1., 1., 1.], [ 5., 6., 7.]]) index_add(dim, index, tensor) → Tensor¶ torch.Tensor.index_add_() 的替代版本 index_copy_(dim, index, tensor) → Tensor¶ 通过按index中给定的顺序选择索引，将 tensor 的元素复制到self张量中。 例如，如果dim == 0和index[i] == j，则将 tensor 的第i行复制到self的第j行。 The dimth dimension of tensor must have the same size as the length of index (which must be a vector), and all other dimensions must match self, or an error will be raised. Parameters dim (python:int) – dimension along which to index index (LongTensor) – indices of tensor to select from 张量 (tensor)–张量包含要复制的值 Example: >>> x = torch.zeros(5, 3) >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float) >>> index = torch.tensor([0, 4, 2]) >>> x.index_copy_(0, index, t) tensor([[ 1., 2., 3.], [ 0., 0., 0.], [ 7., 8., 9.], [ 0., 0., 0.], [ 4., 5., 6.]]) index_copy(dim, index, tensor) → Tensor¶ torch.Tensor.index_copy_() 的替代版本 index_fill_(dim, index, val) → Tensor¶ 通过按index中给定的顺序选择索引，用值val填充self张量的元素。 Parameters dim (python:int) – dimension along which to index 索引 (LongTensor )–填写的self张量索引 val (python：float )–要填充的值 Example:: >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float) >>> index = torch.tensor([0, 2]) >>> x.index_fill_(1, index, -1) tensor([[-1., 2., -1.], [-1., 5., -1.], [-1., 8., -1.]]) index_fill(dim, index, value) → Tensor¶ torch.Tensor.index_fill_() 的替代版本 index_put_(indices, value, accumulate=False) → Tensor¶ 使用在 indices 中指定的索引(张量的元组）将张量value的值放入张量self。 表达式tensor.index_put_(indices, value)等效于tensor[indices] = value。 返回self。 如果accumulate为True，则将 tensor 中的元素添加到self中。 如果 accumulate 为False，则在索引包含重复元素的情况下行为未定义。 Parameters 索引(LongTensor 的元组）–用于索引自身的张量。 值 (tensor)–与自身相同类型的张量。 累积 (bool )–是否累积 index_put(indices, value, accumulate=False) → Tensor¶ index_put_() 的替代版本 index_select(dim, index) → Tensor¶ 参见 torch.index_select() indices() → Tensor¶ 如果self是稀疏的 COO 张量(即torch.sparse_coo布局），则返回包含的索引张量的视图。 否则，将引发错误。 另请参见 Tensor.values() 。 Note 只能在合并的稀疏张量上调用此方法。 有关详细信息，请参见Tensor.coalesce()。 int() → Tensor¶ self.int()等效于self.to(torch.int32)。 参见 to() 。 int_repr() → Tensor¶ 给定量化的 Tensor，self.int_repr()返回以 uint8_t 作为数据类型的 CPU Tensor，该数据类型存储给定 Tensor 的基础 uint8_t 值。 inverse() → Tensor¶ 参见 torch.inverse() irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) → Tensor¶ 参见 torch.irfft() is_contiguous() → bool¶ 如果self张量在内存中以 C 顺序连续，则返回 True。 is_floating_point() → bool¶ 如果self的数据类型是浮点数据类型，则返回 True。 is_leaf 按照惯例，所有具有 requires_grad 即False的张量将是叶张量。 对于具有 requires_grad (即True）的张量，如果它们是由用户创建的，则它们将是叶张量。 这意味着它们不是运算的结果，因此grad_fn为“无”。 在调用 backward() 期间，仅叶子张量会填充其 grad 。 要为非叶张量填充 grad ，可以使用 retain_grad() 。 Example: >>> a = torch.rand(10, requires_grad=True) >>> a.is_leaf True >>> b = torch.rand(10, requires_grad=True).cuda() >>> b.is_leaf False # b was created by the operation that cast a cpu Tensor into a cuda Tensor >>> c = torch.rand(10, requires_grad=True) + 2 >>> c.is_leaf False # c was created by the addition operation >>> d = torch.rand(10).cuda() >>> d.is_leaf True # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine) >>> e = torch.rand(10).cuda().requires_grad_() >>> e.is_leaf True # e requires gradients and has no operations creating it >>> f = torch.rand(10, requires_grad=True, device=\"cuda\") >>> f.is_leaf True # f requires grad, has no operation creating it is_pinned()¶ 如果该张量驻留在固定的内存中，则返回 true。 is_set_to(tensor) → bool¶ 如果此对象引用与 Torch C API 中相同的THTensor对象作为给定张量，则返回 True。 is_shared()¶ 检查张量是否在共享内存中。 CUDA 张量始终为True。 is_signed() → bool¶ 如果self的数据类型是带符号的数据类型，则返回 True。 is_sparse¶ item() → number¶ 返回此张量的值作为标准 Python 数。 这仅适用于具有一个元素的张量。 对于其他情况，请参见 tolist() 。 此操作不可区分。 Example: >>> x = torch.tensor([1.0]) >>> x.item() 1.0 kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)¶ 参见 torch.kthvalue() le(other) → Tensor¶ 参见 torch.le() le_(other) → Tensor¶ 就地版本的 le() lerp(end, weight) → Tensor¶ 参见 torch.lerp() lerp_(end, weight) → Tensor¶ 就地版本的 lerp() lgamma() → Tensor¶ 参见 torch.lgamma() lgamma_() → Tensor¶ 就地版本的 lgamma() log() → Tensor¶ 参见 torch.log() log_() → Tensor¶ 就地版本的 log() logdet() → Tensor¶ 参见 torch.logdet() log10() → Tensor¶ 参见 torch.log10() log10_() → Tensor¶ 就地版本的 log10() log1p() → Tensor¶ 参见 torch.log1p() log1p_() → Tensor¶ 就地版本的 log1p() log2() → Tensor¶ 参见 torch.log2() log2_() → Tensor¶ 就地版本的 log2() log_normal_(mean=1, std=2, *, generator=None)¶ 用对数正态分布中由给定平均值和标准偏差参数化的数字样本填充self张量。 请注意， mean 和 std 是基础正态分布的均值和标准偏差，而不是返回的正态分布： logsumexp(dim, keepdim=False) → Tensor¶ 参见 torch.logsumexp() logical_not() → Tensor¶ 参见 torch.logical_not() logical_not_() → Tensor¶ 就地版本的 logical_not() logical_xor() → Tensor¶ 参见 torch.logical_xor() logical_xor_() → Tensor¶ 就地版本的 logical_xor() long() → Tensor¶ self.long()等效于self.to(torch.int64)。 参见 to() 。 lstsq(A) -> (Tensor, Tensor)¶ 参见 torch.lstsq() lt(other) → Tensor¶ 参见 torch.lt() lt_(other) → Tensor¶ 就地版本的 lt() lu(pivot=True, get_infos=False)¶ 参见 torch.lu() lu_solve(LU_data, LU_pivots) → Tensor¶ 参见 torch.lu_solve() map_(tensor, callable)¶ 对self张量中的每个元素和给定的 tensor 应用callable，并将结果存储在self张量中。 self张量和给定的 tensor 必须是可广播的。 callable应具有签名： def callable(a, b) -> number masked_scatter_(mask, source)¶ 在mask为 True 的位置将元素从source复制到self张量。 mask的形状必须是可广播的，并具有基础张量的形状。 source中的元素数量至少应与mask中的元素数量一样多。 Parameters 掩码 (BoolTensor)–布尔掩码 源 (tensor)–要从中复制的张量 Note mask在self张量上运行，而不是在给定的source张量上运行。 masked_scatter(mask, tensor) → Tensor¶ torch.Tensor.masked_scatter_() 的替代版本 masked_fill_(mask, value)¶ 用value填充self张量的元素，其中mask为 True。 mask的形状必须是可广播的，并具有基础张量的形状。 Parameters mask (BoolTensor) – the boolean mask 值 (python：float )–要填写的值 masked_fill(mask, value) → Tensor¶ torch.Tensor.masked_fill_() 的替代版本 masked_select(mask) → Tensor¶ 参见 torch.masked_select() matmul(tensor2) → Tensor¶ 参见 torch.matmul() matrix_power(n) → Tensor¶ 参见 torch.matrix_power() max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)¶ 参见 torch.max() mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)¶ 参见 torch.mean() median(dim=None, keepdim=False) -> (Tensor, LongTensor)¶ 参见 torch.median() min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)¶ 参见 torch.min() mm(mat2) → Tensor¶ 参见 torch.mm() mode(dim=None, keepdim=False) -> (Tensor, LongTensor)¶ 参见 torch.mode() mul(value) → Tensor¶ 参见 torch.mul() mul_(value)¶ 就地版本的 mul() multinomial(num_samples, replacement=False, *, generator=None) → Tensor¶ 参见 torch.multinomial() mv(vec) → Tensor¶ 参见 torch.mv() mvlgamma(p) → Tensor¶ 参见 torch.mvlgamma() mvlgamma_(p) → Tensor¶ 就地版本的 mvlgamma() narrow(dimension, start, length) → Tensor¶ 参见 torch.narrow() Example: >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) >>> x.narrow(0, 0, 2) tensor([[ 1, 2, 3], [ 4, 5, 6]]) >>> x.narrow(1, 1, 2) tensor([[ 2, 3], [ 5, 6], [ 8, 9]]) narrow_copy(dimension, start, length) → Tensor¶ 与 Tensor.narrow() 相同，只是返回副本而不是共享存储。 这主要用于稀疏张量，它们没有共享存储的窄方法。 用dimemsion &gt; self.sparse_dim()调用narrow_copy`将返回缩小了相关密集尺寸的副本，并相应地更新了self.shape``。 ndimension() → int¶ Alias for dim() ne(other) → Tensor¶ 参见 torch.ne() ne_(other) → Tensor¶ 就地版本的 ne() neg() → Tensor¶ 参见 torch.neg() neg_() → Tensor¶ 就地版本的 neg() nelement() → int¶ numel() 的别名 nonzero() → LongTensor¶ 参见 torch.nonzero() norm(p='fro', dim=None, keepdim=False, dtype=None)¶ 参见 torch.norm() normal_(mean=0, std=1, *, generator=None) → Tensor¶ 用由 mean 和 std 参数化的正态分布的元素样本填充self张量。 numel() → int¶ 参见 torch.numel() numpy() → numpy.ndarray¶ 以 NumPy ndarray的形式返回self张量。 该张量和返回的ndarray共享相同的基础存储。 对self张量的更改将反映在ndarray中，反之亦然。 orgqr(input2) → Tensor¶ 参见 torch.orgqr() ormqr(input2, input3, left=True, transpose=False) → Tensor¶ 参见 torch.ormqr() permute(*dims) → Tensor¶ 置换此张量的尺寸。 Parameters *尺寸 (python：int ... )–所需的尺寸顺序 例 >>> x = torch.randn(2, 3, 5) >>> x.size() torch.Size([2, 3, 5]) >>> x.permute(2, 0, 1).size() torch.Size([5, 2, 3]) pin_memory() → Tensor¶ 将张量复制到固定的内存(如果尚未固定）。 pinverse() → Tensor¶ 参见 torch.pinverse() polygamma(n) → Tensor¶ 参见 torch.polygamma() polygamma_(n) → Tensor¶ 就地版本的 polygamma() pow(exponent) → Tensor¶ 参见 torch.pow() pow_(exponent) → Tensor¶ 就地版本的 pow() prod(dim=None, keepdim=False, dtype=None) → Tensor¶ 参见 torch.prod() put_(indices, tensor, accumulate=False) → Tensor¶ 将 tensor 中的元素复制到索引指定的位置。 为了建立索引，将self张量视为一维张量。 If accumulate is True, the elements in tensor are added to self. If accumulate is False, the behavior is undefined if indices contain duplicate elements. Parameters 索引 (LongTensor )–自身索引 张量 (tensor)–张量包含要复制的值 accumulate (bool) – whether to accumulate into self Example: >>> src = torch.tensor([[4, 3, 5], [6, 7, 8]]) >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10])) tensor([[ 4, 9, 5], [ 10, 7, 8]]) qr(some=True) -> (Tensor, Tensor)¶ 参见 torch.qr() qscheme() → torch.qscheme¶ 返回给定 QTensor 的量化方案。 q_scale() → float¶ 给定一个通过线性(仿射）量化量化的张量，返回基础量化器(）的比例尺。 q_zero_point() → int¶ 给定一个通过线性(仿射）量化量化的张量，返回基础量化器(）的 zero_point。 q_per_channel_scales() → Tensor¶ 给定通过线性(仿射）每通道量化进行量化的张量，返回基础量化器的比例的张量。 它具有与张量的相应尺寸(来自 q_per_channel_axis）匹配的元素数量。 q_per_channel_zero_points() → Tensor¶ 给定一个通过线性(仿射）每通道量化量化的张量，返回基础量化器的 zero_points 张量。 它具有与张量的相应尺寸(来自 q_per_channel_axis）匹配的元素数量。 q_per_channel_axis() → int¶ 给定通过线性(仿射）每通道量化量化的张量，返回在其上应用每通道量化的尺寸索引。 random_(from=0, to=None, *, generator=None) → Tensor¶ 用从[from, to - 1]上的离散均匀分布采样的数字填充self张量。 如果未指定，则这些值通常仅受self张量的数据类型限制。 但是，对于浮点类型，如果未指定，范围将为[0, 2^mantissa]以确保每个值都是可表示的。 例如， torch.tensor(1，dtype = torch.double）.random_(）在[0, 2^53]中将是统一的。 reciprocal() → Tensor¶ 参见 torch.reciprocal() reciprocal_() → Tensor¶ 就地版本的 reciprocal() record_stream(stream)¶ 确保在stream上排队的所有当前工作完成之前，张量存储器不会被其他张量重用。 Note 缓存分配器仅知道分配张量的流。 由于有了这种认识，它已经可以仅在一个流上正确管理张量的生命周期。 但是，如果在与原始流不同的流上使用张量，则分配器可能会意外地重用内存。 调用此方法可让分配器知道哪些流使用了张量。 register_hook(hook) 注册一个倒钩。 每当计算相对于张量的梯度时，都会调用该挂钩。 挂钩应具有以下签名： hook(grad) -> Tensor or None 挂钩不应修改其自变量，但可以选择返回一个新的渐变，该渐变将代替 grad 使用。 此函数返回带有方法handle.remove()的句柄，该方法可将钩子从模块中移除。 Example: >>> v = torch.tensor([0., 0., 0.], requires_grad=True) >>> h = v.register_hook(lambda grad: grad * 2) # double the gradient >>> v.backward(torch.tensor([1., 2., 3.])) >>> v.grad 2 4 6 [torch.FloatTensor of size (3,)] >>> h.remove() # removes the hook remainder(divisor) → Tensor¶ 参见 torch.remainder() remainder_(divisor) → Tensor¶ 就地版本的 remainder() real() → Tensor¶ 参见 torch.real() renorm(p, dim, maxnorm) → Tensor¶ 参见 torch.renorm() renorm_(p, dim, maxnorm) → Tensor¶ 就地版本的 renorm() repeat(*sizes) → Tensor¶ 沿指定尺寸重复此张量。 与 expand() 不同，此功能复制张量的数据。 Warning torch.repeat()的行为与 numpy.repeat 不同，但更类似于 numpy.tile 。 对于类似于 numpy.repeat 的运算符，请参见 torch.repeat_interleave() 。 Parameters 大小(torch大小 或 python：int ... )–在每个维度上重复此张量的次数 Example: >>> x = torch.tensor([1, 2, 3]) >>> x.repeat(4, 2) tensor([[ 1, 2, 3, 1, 2, 3], [ 1, 2, 3, 1, 2, 3], [ 1, 2, 3, 1, 2, 3], [ 1, 2, 3, 1, 2, 3]]) >>> x.repeat(4, 2, 1).size() torch.Size([4, 2, 3]) repeat_interleave(repeats, dim=None) → Tensor¶ 参见 torch.repeat_interleave() 。 requires_grad 如果需要为此张量计算梯度，则为True，否则为False。 Note 需要为张量计算梯度的事实并不意味着将填充 grad 属性，有关更多详细信息，请参见 is_leaf 。 requires_grad_(requires_grad=True) → Tensor¶ 更改 autograd 是否应记录该张量上的操作：适当地设置此张量的 requires_grad 属性。 返回此张量。 requires_grad_() 的主要用例是告诉 autograd 在 Tensor tensor上开始记录操作。 如果tensor具有requires_grad=False(因为它是通过 DataLoader 获得的，或者需要进行预处理或初始化），则tensor.requires_grad_()将其设置为使 autograd 将开始在tensor上记录操作。 Parameters require_grad (bool )–如果 autograd 应该在该张量上记录操作。 默认值：True。 Example: >>> # Let's say we want to preprocess some saved weights and use >>> # the result as new weights. >>> saved_weights = [0.1, 0.2, 0.3, 0.25] >>> loaded_weights = torch.tensor(saved_weights) >>> weights = preprocess(loaded_weights) # some function >>> weights tensor([-0.5503, 0.4926, -2.1158, -0.8303]) >>> # Now, start to record operations done to weights >>> weights.requires_grad_() >>> out = weights.pow(2).sum() >>> out.backward() >>> weights.grad tensor([-1.1007, 0.9853, -4.2316, -1.6606]) reshape(*shape) → Tensor¶ 返回具有与self相同的数据和元素数量但具有指定形状的张量。 如果shape与当前形状兼容，则此方法返回一个视图。 当可以返回视图时，请参见 torch.Tensor.view() 。 参见 torch.reshape() Parameters 形状 (python：ints 的元组 或 python：int ... )–所需的形状 reshape_as(other) → Tensor¶ 以与other相同的形状返回此张量。 self.reshape_as(other)等效于self.reshape(other.sizes())。 如果other.sizes()与当前形状兼容，则此方法返回视图。 何时可以返回视图，请参见 torch.Tensor.view() 。 有关reshape的更多信息，请参见 reshape() 。 Parameters 其他 (torch.Tensor)–结果张量具有与other相同的形状。 resize_(*sizes) → Tensor¶ 将self张量调整为指定大小。 如果元素数量大于当前存储大小，那么将调整基础存储的大小以适合新的元素数量。 如果元素数较小，则基础存储不会更改。 现有元素将保留，但任何新内存均未初始化。 Warning 这是一种底层方法。 将存储重新解释为 C 连续的，而忽略当前步幅(除非目标大小等于当前大小，在这种情况下，张量保持不变）。 对于大多数目的，您将改为使用 view() (检查连续性），或使用 reshape() (如果需要，可复制数据）。 要使用自定义步幅就地更改大小，请参见 set_() 。 Parameters 大小(torch大小 或 python：int ... )–所需大小 Example: >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]]) >>> x.resize_(2, 2) tensor([[ 1, 2], [ 3, 4]]) resize_as_(tensor) → Tensor¶ 将self张量调整为与指定的 tensor 相同的大小。 这等效于self.resize_(tensor.size())。 retain_grad() 为非叶张量启用.grad 属性。 rfft(signal_ndim, normalized=False, onesided=True) → Tensor¶ 参见 torch.rfft() roll(shifts, dims) → Tensor¶ 参见 torch.roll() rot90(k, dims) → Tensor¶ 参见 torch.rot90() round() → Tensor¶ 参见 torch.round() round_() → Tensor¶ 就地版本的 round() rsqrt() → Tensor¶ 参见 torch.rsqrt() rsqrt_() → Tensor¶ 就地版本的 rsqrt() scatter(dim, index, source) → Tensor¶ torch.Tensor.scatter_() 的替代版本 scatter_(dim, index, src) → Tensor¶ 将张量src中的所有值写入index张量中指定的索引处的self中。 对于src中的每个值，其输出索引由dimension != dim的src中的索引以及dimension = dim的index中的相应值指定。 对于 3-D 张量，self更新为： self[index[i][j][k]][j][k] = src[i][j][k] # if dim == 0 self[i][index[i][j][k]][k] = src[i][j][k] # if dim == 1 self[i][j][index[i][j][k]] = src[i][j][k] # if dim == 2 这是 gather() 中描述的方式的相反操作。 self，index和src(如果是张量）应具有相同数量的尺寸。 还要求对于所有尺寸d均为index.size(d) &lt;= src.size(d)，并且对于所有尺寸d != dim均要求index.size(d) &lt;= self.size(d)。 此外，对于 gather() ，index的值必须介于0和self.size(dim) - 1之间，且沿指定尺寸 dim 必须是唯一的。 Parameters 暗淡的 (python：int )–沿其索引的轴 索引 (LongTensor )–要散布的元素的索引可以为空或 src 的大小相同。 如果为空，则操作返回标识 src (tensor)–要散布的源元素，如果未指定值 值 (python：float )–要分散的源元素，如果未指定 src Example: >>> x = torch.rand(2, 5) >>> x tensor([[ 0.3992, 0.2908, 0.9044, 0.4850, 0.6004], [ 0.5735, 0.9006, 0.6797, 0.4152, 0.1732]]) >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x) tensor([[ 0.3992, 0.9006, 0.6797, 0.4850, 0.6004], [ 0.0000, 0.2908, 0.0000, 0.4152, 0.0000], [ 0.5735, 0.0000, 0.9044, 0.0000, 0.1732]]) >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23) >>> z tensor([[ 0.0000, 0.0000, 1.2300, 0.0000], [ 0.0000, 0.0000, 0.0000, 1.2300]]) scatter_add_(dim, index, other) → Tensor¶ 将张量other中的所有值添加到index张量中指定的索引处的self中，其方式与 scatter_() 相似。 对于other中的每个值，将其添加到self中的索引，该索引由dimension != dim中的other中的索引和dimension = dim中的index中的对应值指定。 For a 3-D tensor, self is updated as: self[index[i][j][k]][j][k] += other[i][j][k] # if dim == 0 self[i][index[i][j][k]][k] += other[i][j][k] # if dim == 1 self[i][j][index[i][j][k]] += other[i][j][k] # if dim == 2 self，index和other应具有相同的尺寸数。 还要求对于所有尺寸d均为index.size(d) &lt;= other.size(d)，并且对于所有尺寸d != dim均要求index.size(d) &lt;= self.size(d)。 Note When using the CUDA backend, this operation may induce nondeterministic behaviour that is not easily switched off. Please see the notes on Reproducibility for background. Parameters dim (python:int) – the axis along which to index 索引 (LongTensor )–分散和添加元素的索引，可以为空或 src 大小相同。 为空时，该操作将返回标识。 其他 (tensor)–分散和添加的源元素 Example: >>> x = torch.rand(2, 5) >>> x tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328], [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]]) >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x) tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328], [1.0000, 1.0427, 1.0000, 1.6782, 1.0000], [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]]) scatter_add(dim, index, source) → Tensor¶ torch.Tensor.scatter_add_() 的替代版本 select(dim, index) → Tensor¶ 沿选定维度在给定索引处切片self张量。 该函数返回一个张量，其中给定尺寸被移除。 Parameters 暗淡的 (python：int )–切片的尺寸 索引 (python：int )–要选择的索引 Note select() 相当于切片。 例如，tensor.select(0, index)等效于tensor[index]，tensor.select(2, index)等效于tensor[:,:,index]。 set_(source=None, storage_offset=0, size=None, stride=None) → Tensor¶ 设置基础存储空间，大小和跨度。 如果source是张量，则self张量将与source共享相同的存储空间并具有相同的大小和跨度。 一个张量中元素的变化将反映在另一个张量中。 如果source是Storage，则该方法设置基础存储，偏移，大小和跨度。 Parameters 源 (tensor 或 存储器）–使用的张量或存储器 storage_offset (python：int ， 可选）–存储中的偏移量 大小(torch大小 ， 可选）–所需大小。 默认为源大小。 步幅(元组 ， 可选）–所需的步幅。 默认为 C 连续跨步。 share_memory_()¶ 将基础存储移动到共享内存。 如果基础存储已经在共享内存中并且用于 CUDA 张量，则此操作不可操作。 共享内存中的张量无法调整大小。 short() → Tensor¶ self.short()等效于self.to(torch.int16)。 参见 to() 。 sigmoid() → Tensor¶ 参见 torch.sigmoid() sigmoid_() → Tensor¶ 就地版本的 sigmoid() sign() → Tensor¶ 参见 torch.sign() sign_() → Tensor¶ 就地版本的 sign() sin() → Tensor¶ 参见 torch.sin() sin_() → Tensor¶ 就地版本的 sin() sinh() → Tensor¶ 参见 torch.sinh() sinh_() → Tensor¶ 就地版本的 sinh() size() → torch.Size¶ 返回self张量的大小。 返回的值是tuple的子类。 Example: >>> torch.empty(3, 4, 5).size() torch.Size([3, 4, 5]) slogdet() -> (Tensor, Tensor)¶ 参见 torch.slogdet() solve(A) → Tensor, Tensor¶ 参见 torch.solve() sort(dim=-1, descending=False) -> (Tensor, LongTensor)¶ 参见 torch.sort() split(split_size, dim=0)¶ 参见 torch.split() sparse_mask(input, mask) → Tensor¶ 返回一个新的 SparseTensor，其 Tensor input中的值被mask的索引过滤，并且值被忽略。 input和mask必须具有相同的形状。 Parameters 输入 (tensor)–输入张量 遮罩 (SparseTensor )–我们根据其索引过滤input的 SparseTensor Example: >>> nnz = 5 >>> dims = [5, 5, 2, 2] >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)), torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz) >>> V = torch.randn(nnz, dims[2], dims[3]) >>> size = torch.Size(dims) >>> S = torch.sparse_coo_tensor(I, V, size).coalesce() >>> D = torch.randn(dims) >>> D.sparse_mask(S) tensor(indices=tensor([[0, 0, 0, 2], [0, 1, 4, 3]]), values=tensor([[[ 1.6550, 0.2397], [-0.1611, -0.0779]], [[ 0.2326, -1.0558], [ 1.4711, 1.9678]], [[-0.5138, -0.0411], [ 1.9417, 0.5158]], [[ 0.0793, 0.0036], [-0.2569, -0.1055]]]), size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo) sparse_dim() → int¶ 如果self是稀疏的 COO 张量(即torch.sparse_coo布局），则返回稀疏维度的数量。 否则，将引发错误。 另请参见 Tensor.dense_dim() 。 sqrt() → Tensor¶ 参见 torch.sqrt() sqrt_() → Tensor¶ 就地版本的 sqrt() squeeze(dim=None) → Tensor¶ 参见 torch.squeeze() squeeze_(dim=None) → Tensor¶ 就地版本的 squeeze() std(dim=None, unbiased=True, keepdim=False) → Tensor¶ 参见 torch.std() stft(n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)¶ 参见 torch.stft() Warning 此功能在版本 0.4.1 更改了签名。 使用前一个签名进行调用可能会导致错误或返回错误的结果。 storage() → torch.Storage¶ 返回基础存储。 storage_offset() → int¶ 根据存储元素的数量(不是字节），返回基础存储中的self张量偏移量。 Example: >>> x = torch.tensor([1, 2, 3, 4, 5]) >>> x.storage_offset() 0 >>> x[3:].storage_offset() 3 storage_type() → type¶ 返回基础存储的类型。 stride(dim) → tuple or int¶ 返回self张量的步幅。 跨度是在指定尺寸 dim 中从一个元素跳至下一元素所需的跳跃。 当未传递任何参数时，将返回所有跨度的元组。否则，将返回整数值作为特定维度 dim 中的跨度。 Parameters 暗淡的 (python：int ， 可选）–需要跨度的所需尺寸 Example: >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]) >>> x.stride() (5, 1) >>>x.stride(0) 5 >>> x.stride(-1) 1 sub(value, other) → Tensor¶ 从self张量中减去标量或张量。 如果同时指定了value和other，则在使用前other的每个元素都会按value缩放。 当other是张量时，other的形状必须是可广播的，并具有基础张量的形状。 sub_(x) → Tensor¶ 就地版本的 sub() sum(dim=None, keepdim=False, dtype=None) → Tensor¶ 参见 torch.sum() sum_to_size(*size) → Tensor¶ 将this张量与 size 相加。 size 必须可广播到this张量大小。 Parameters 大小 (python：int ... )–定义输出张量形状的整数序列。 svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)¶ 参见 torch.svd() symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)¶ 参见 torch.symeig() t() → Tensor¶ 参见 torch.t() t_() → Tensor¶ 就地版本的 t() to(*args, **kwargs) → Tensor¶ 执行 Tensor dtype 和/或设备转换。 torch.dtype 和 torch.device 是从self.to(*args, **kwargs)的论点推论出来的。 Note 如果self张量已经具有正确的 torch.dtype 和 torch.device ，则返回self。 否则，返回的张量是self与所需 torch.dtype 和 torch.device 的副本。 以下是调用to的方法： to(dtype, non_blocking=False, copy=False) → Tensor 返回具有指定dtype的张量 to(device=None, dtype=None, non_blocking=False, copy=False) → Tensor 返回具有指定 device 和(可选）dtype的张量。 如果dtype为None，则推断为self.dtype。 当non_blocking时，如果可能，尝试相对于主机进行异步转换，例如，将具有固定内存的 CPU 张量转换为 CUDA 张量。 设置copy时，即使张量已经匹配所需的转换，也会创建新的张量。 to(other, non_blocking=False, copy=False) → Tensor 返回与张量other相同的 torch.dtype 和 torch.device 的张量。 当non_blocking时，如果可能，尝试相对于主机进行异步转换，例如，将具有固定内存的 CPU 张量转换为 CUDA 张量。 设置copy时，即使张量已经与所需的转换匹配，也会创建新的张量。 Example: >>> tensor = torch.randn(2, 2) # Initially dtype=float32, device=cpu >>> tensor.to(torch.float64) tensor([[-0.5044, 0.0005], [ 0.3310, -0.0584]], dtype=torch.float64) >>> cuda0 = torch.device('cuda:0') >>> tensor.to(cuda0) tensor([[-0.5044, 0.0005], [ 0.3310, -0.0584]], device='cuda:0') >>> tensor.to(cuda0, dtype=torch.float64) tensor([[-0.5044, 0.0005], [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0') >>> other = torch.randn((), dtype=torch.float64, device=cuda0) >>> tensor.to(other, non_blocking=True) tensor([[-0.5044, 0.0005], [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0') to_mkldnn() → Tensor¶ 返回torch.mkldnn布局中的张量的副本。 take(indices) → Tensor¶ 参见 torch.take() tan() → Tensor¶ 参见 torch.tan() tan_() → Tensor¶ 就地版本的 tan() tanh() → Tensor¶ 参见 torch.tanh() tanh_() → Tensor¶ 就地版本的 tanh() tolist()¶ ” tolist(）->列表或编号 将张量作为(嵌套的）列表返回。 对于标量，将返回标准 Python 编号，就像 item() 一样。 如有必要，张量会先自动移至 CPU。 This operation is not differentiable. 例子： >>> a = torch.randn(2, 2) >>> a.tolist() [[0.012766935862600803, 0.5415473580360413], [-0.08909505605697632, 0.7729271650314331]] >>> a[0,0].tolist() 0.012766935862600803 topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)¶ 参见 torch.topk() to_sparse(sparseDims) → Tensor¶ 返回张量的稀疏副本。 PyTorch 支持坐标格式的稀疏张量。 Parameters sparseDims (python：int ， 可选）–新稀疏张量中包含的稀疏维数 Example: >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]]) >>> d tensor([[ 0, 0, 0], [ 9, 0, 10], [ 0, 0, 0]]) >>> d.to_sparse() tensor(indices=tensor([[1, 1], [0, 2]]), values=tensor([ 9, 10]), size=(3, 3), nnz=2, layout=torch.sparse_coo) >>> d.to_sparse(1) tensor(indices=tensor([[1]]), values=tensor([[ 9, 0, 10]]), size=(3, 3), nnz=1, layout=torch.sparse_coo) trace() → Tensor¶ 参见 torch.trace() transpose(dim0, dim1) → Tensor¶ 参见 torch.transpose() transpose_(dim0, dim1) → Tensor¶ 就地版本的 transpose() triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)¶ 参见 torch.triangular_solve() tril(k=0) → Tensor¶ 参见 torch.tril() tril_(k=0) → Tensor¶ 就地版本的 tril() triu(k=0) → Tensor¶ 参见 torch.triu() triu_(k=0) → Tensor¶ 就地版本的 triu() trunc() → Tensor¶ 参见 torch.trunc() trunc_() → Tensor¶ 就地版本的 trunc() type(dtype=None, non_blocking=False, **kwargs) → str or Tensor¶ 如果未提供 dtype ，则返回类型，否则将该对象强制转换为指定的类型。 如果它已经是正确的类型，则不执行任何复制，并返回原始对象。 Parameters dtype (python：type 或 字符串）–所需类型 non_blocking (bool )–如果True，并且源位于固定内存中，而目标位于 GPU 上，反之亦然，则相对于主机异步执行复制。 否则，该参数无效。 ** –为兼容起见，可以包含键async来代替non_blocking参数。 不推荐使用async arg。 type_as(tensor) → Tensor¶ 将此张量转换为给定张量的类型。 如果张量已经是正确的类型，则这是无操作的。 相当于self.type(tensor.type()) Parameters 张量 (tensor)–具有所需类型的张量 unbind(dim=0) → seq¶ 参见 torch.unbind() unfold(dimension, size, step) → Tensor¶ 返回一个张量，该张量包含self张量中尺寸为dimension的所有大小为 size 的切片。 两个切片之间的步长由step给出。 如果 sizeim 是self的尺寸dimension的大小，则返回张量中dimension的尺寸将是(sizeim-size）/步长+ 1 。 在返回的张量中附加了尺寸为 size 的附加尺寸。 Parameters 尺寸 (python：int )–发生展开的尺寸 大小 (python：int )–展开的每个切片的大小 步骤 (python：int )–每个切片之间的步骤 Example: >>> x = torch.arange(1., 8) >>> x tensor([ 1., 2., 3., 4., 5., 6., 7.]) >>> x.unfold(0, 2, 1) tensor([[ 1., 2.], [ 2., 3.], [ 3., 4.], [ 4., 5.], [ 5., 6.], [ 6., 7.]]) >>> x.unfold(0, 2, 2) tensor([[ 1., 2.], [ 3., 4.], [ 5., 6.]]) uniform_(from=0, to=1) → Tensor¶ 用从连续均匀分布中采样的数字填充self张量： unique(sorted=True, return_inverse=False, return_counts=False, dim=None)¶ 返回输入张量的唯一元素。 参见 torch.unique() unique_consecutive(return_inverse=False, return_counts=False, dim=None)¶ 从每个连续的等效元素组中除去除第一个元素外的所有元素。 参见 torch.unique_consecutive() unsqueeze(dim) → Tensor¶ 参见 torch.unsqueeze() unsqueeze_(dim) → Tensor¶ 就地版本的 unsqueeze() values() → Tensor¶ 如果self是稀疏的 COO 张量(即torch.sparse_coo布局），则返回包含值张量的视图。 否则，将引发错误。 另请参见 Tensor.indices() 。 Note This method can only be called on a coalesced sparse tensor. See Tensor.coalesce() for details. var(dim=None, unbiased=True, keepdim=False) → Tensor¶ 参见 torch.var() view(*shape) → Tensor¶ 返回具有与self张量相同的数据但具有不同shape的新张量。 返回的张量共享相同的数据，并且必须具有相同数量的元素，但可能具有不同的大小。 要查看张量，新视图尺寸必须与其原始尺寸和步幅兼容，即每个新视图尺寸必须是原始尺寸的子空间，或者仅跨越满足以下条件的原始尺寸 的连续性状 否则，需要先调用 contiguous() 才能查看张量。 另请参见： reshape() ，如果形状兼容则返回一个视图，否则复制(相当于调用 contiguous())。 Parameters 形状(torch大小 或 python：int ... )–所需大小 Example: >>> x = torch.randn(4, 4) >>> x.size() torch.Size([4, 4]) >>> y = x.view(16) >>> y.size() torch.Size([16]) >>> z = x.view(-1, 8) # the size -1 is inferred from other dimensions >>> z.size() torch.Size([2, 8]) >>> a = torch.randn(1, 2, 3, 4) >>> a.size() torch.Size([1, 2, 3, 4]) >>> b = a.transpose(1, 2) # Swaps 2nd and 3rd dimension >>> b.size() torch.Size([1, 3, 2, 4]) >>> c = a.view(1, 3, 2, 4) # Does not change tensor layout in memory >>> c.size() torch.Size([1, 3, 2, 4]) >>> torch.equal(b, c) False view_as(other) → Tensor¶ 将此张量查看为与other相同的大小。 self.view_as(other)等效于self.view(other.size())。 有关view的更多信息，请参见 view() 。 Parameters other (torch.Tensor) – The result tensor has the same size as other. where(condition, y) → Tensor¶ self.where(condition, y)等效于torch.where(condition, self, y)。 参见 torch.where() zero_() → Tensor¶ 用零填充self张量。 class torch.BoolTensor¶ 以下方法是 torch.BoolTensor 独有的。 all()¶ all() → bool 如果张量中的所有元素均为 True，则返回 True，否则返回 False。 Example: >>> a = torch.rand(1, 2).bool() >>> a tensor([[False, True]], dtype=torch.bool) >>> a.all() tensor(False, dtype=torch.bool) all(dim, keepdim=False, out=None) → Tensor 如果张量的每一行中给定维度dim中的所有元素均为 True，则返回 True，否则返回 False。 如果keepdim为True，则输出张量的大小与input相同，但尺寸为dim的大小为 1。否则，将压缩dim(请参见 torch.squeeze())，导致输出张量的尺寸比input小 1。 Parameters 暗淡的 (python：int )–缩小的尺寸 keepdim (bool )–输出张量是否保留dim out (tensor ， 可选）–输出张量 Example: >>> a = torch.rand(4, 2).bool() >>> a tensor([[True, True], [True, False], [True, True], [True, True]], dtype=torch.bool) >>> a.all(dim=1) tensor([ True, False, True, True], dtype=torch.bool) >>> a.all(dim=0) tensor([ True, False], dtype=torch.bool) any()¶ any() → bool 如果张量中的任何元素为 True，则返回 True，否则为 False。 Example: >>> a = torch.rand(1, 2).bool() >>> a tensor([[False, True]], dtype=torch.bool) >>> a.any() tensor(True, dtype=torch.bool) any(dim, keepdim=False, out=None) → Tensor 如果张量的每一行中给定维度dim中的任何元素为 True，则返回 True，否则为 False。 If keepdim is True, the output tensor is of the same size as input except in the dimension dim where it is of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensor having 1 fewer dimension than input. Parameters dim (python:int) – the dimension to reduce keepdim (bool) – whether the output tensor has dim retained or not out (Tensor, optional) – the output tensor Example: >>> a = torch.randn(4, 2) >> a tensor([[ True, True], [False, True], [ True, True], [False, False]]) >>> a.any(1) tensor([ True, True, True, False]) >>> a.any(0) tensor([True, True]) 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:35:31 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"78.html":{"url":"78.html","title":"张量属性","keywords":"","body":"张量属性 原文： https://pytorch.org/docs/stable/tensor_attributes.html 每个torch.Tensor具有 torch.dtype ， torch.device 和 torch.layout 。 torch类型 class torch.dtype¶ torch.dtype 是表示 torch.Tensor 的数据类型的对象。 PyTorch 具有九种不同的数据类型： | 数据类型 | dtype | 张量类型 | | --- | --- | --- | | 32 位浮点 | torch.float32或torch.float | torch.*.FloatTensor | | 64 位浮点 | torch.float64或torch.double | torch.*.DoubleTensor | | 16 位浮点 | torch.float16或torch.half | torch.*.HalfTensor | | 8 位整数(无符号） | torch.uint8 | torch.*.ByteTensor | | 8 位整数(有符号） | torch.int8 | torch.*.CharTensor | | 16 位整数(有符号） | torch.int16或torch.short | torch.*.ShortTensor | | 32 位整数(有符号） | torch.int32或torch.int | torch.*.IntTensor | | 64 位整数(有符号） | torch.int64或torch.long | torch.*.LongTensor | | 布尔型 | torch.bool | torch.*.BoolTensor | 要确定 torch.dtype 是否为浮点数据类型，可以使用属性 is_floating_point ，如果数据类型为浮点数据，则返回True。 类型。 当算术运算的输入 dtypes(加，子， div ， mul )不同时，我们通过寻找最小值来促进 满足以下规则的 dtype： 如果标量操作数的类型比张量操作数(浮动>整数>布尔值）具有更高的类别，则我们将其提升为具有足够大小的类型，以容纳该类别的所有标量操作数。 如果零维张量操作数的类别高于维操作数的类别，我们将提升为具有足够大小和类别的类型，以容纳该类别的所有零维张量操作数。 如果没有更高类别的零维操作数，我们将提升为具有足够大小和类别的类型以容纳所有尺寸的操作数。 浮点标量操作数的 dtype 为 torch.get_default_dtype(），整数非布尔标量操作数的 dtype 为 torch.int64 。 与 numpy 不同，在确定操作数的最小 dtypes 时，我们不检查值。 尚不支持量化和复杂类型。 促销示例： >>> float_tensor = torch.ones(1, dtype=torch.float) >>> double_tensor = torch.ones(1, dtype=torch.double) >>> int_tensor = torch.ones(1, dtype=torch.int) >>> long_tensor = torch.ones(1, dtype=torch.long) >>> uint_tensor = torch.ones(1, dtype=torch.uint8) >>> double_tensor = torch.ones(1, dtype=torch.double) >>> bool_tensor = torch.ones(1, dtype=torch.bool) # zero-dim tensors >>> long_zerodim = torch.tensor(1, dtype=torch.long) >>> int_zerodim = torch.tensor(1, dtype=torch.int) >>> torch.add(5, 5).dtype torch.int64 # 5 is an int64, but does not have higher category than int_tensor so is not considered. >>> (int_tensor + 5).dtype torch.int32 >>> (int_tensor + long_zerodim).dtype torch.int32 >>> (long_tensor + int_tensor).dtype torch.int64 >>> (bool_tensor + long_tensor).dtype torch.int64 >>> (bool_tensor + uint_tensor).dtype torch.uint8 >>> (float_tensor + double_tensor).dtype torch.float64 >>> (bool_tensor + int_tensor).dtype torch.int32 # Since long is a different kind than float, result dtype only needs to be large enough # to hold the float. >>> torch.add(long_tensor, float_tensor).dtype torch.float32 When the output tensor of an arithmetic operation is specified, we allow casting to its dtype except that: 积分输出张量不能接受浮点张量。 布尔输出张量不能接受非布尔张量。 投放示例： # allowed: >>> float_tensor *= double_tensor >>> float_tensor *= int_tensor >>> float_tensor *= uint_tensor >>> float_tensor *= bool_tensor >>> float_tensor *= double_tensor >>> int_tensor *= long_tensor >>> int_tensor *= uint_tensor >>> uint_tensor *= int_tensor # disallowed (RuntimeError: result type can't be cast to the desired output type): >>> int_tensor *= float_tensor >>> bool_tensor *= int_tensor >>> bool_tensor *= uint_tensor torch设备 class torch.device¶ torch.device 是表示在其上或将要分配 torch.Tensor 的设备的对象。 torch.device 包含设备类型('cpu'或'cuda'）和该设备类型的可选设备序号。 如果不存在设备序号，则即使调用 torch.cuda.set_device() ，该对象也始终代表设备类型的当前设备。 例如，用设备'cuda'构造的 torch.Tensor 等效于'cuda:X'，其中 X 是 torch.cuda.current_device() 的结果。 可以通过 Tensor.device 属性访问 torch.Tensor 的设备。 torch.device 可以通过字符串或通过字符串和设备序号构造 通过字符串： >>> torch.device('cuda:0') device(type='cuda', index=0) >>> torch.device('cpu') device(type='cpu') >>> torch.device('cuda') # current cuda device device(type='cuda') 通过字符串和设备序数： >>> torch.device('cuda', 0) device(type='cuda', index=0) >>> torch.device('cpu', 0) device(type='cpu', index=0) 注意 函数中的 torch.device 参数通常可以用字符串替换。 这样可以快速编写代码原型。 >>> # Example of a function that takes in a torch.device >>> cuda1 = torch.device('cuda:1') >>> torch.randn((2,3), device=cuda1) >>> # You can substitute the torch.device with a string >>> torch.randn((2,3), device='cuda:1') Note 出于遗留原因，可以通过单个设备序号(被视为 cuda 设备）构造设备。 这与 Tensor.get_device() 匹配，后者为 cuda 张量返回序数，而 cpu 张量不支持此序数。 >>> torch.device(1) device(type='cuda', index=1) Note 使用设备的方法通常会接受(正确格式化的）字符串或(旧式）整数设备序数，即以下所有等效方法： >>> torch.randn((2,3), device=torch.device('cuda:1')) >>> torch.randn((2,3), device='cuda:1') >>> torch.randn((2,3), device=1) # legacy torch布局 class torch.layout¶ torch.layout 是表示 torch.Tensor 的内存布局的对象。 目前，我们支持torch.strided(密集张量），并为torch.sparse_coo(稀疏 COO 张量）提供实验性支持。 torch.strided代表密集的张量，是最常用的内存布局。 每个跨步张量都有一个关联的torch.Storage，它保存其数据。 这些张量提供了存储的多维跨度视图。 步幅是一个整数列表：第 k 个步幅表示在张量的第 k 个维度中从一个元素到下一个元素所需的内存跳转。 这个概念使得有可能高效地执行许多张量运算。 例： >>> x = torch.Tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]) >>> x.stride() (5, 1) >>> x.t().stride() (1, 5) 有关torch.sparse_coo张量的更多信息，请参见 torch.sparse 。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:46:44 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"79.html":{"url":"79.html","title":"自动差分包-Torch.Autograd","keywords":"","body":"自动差分包-Torch.Autograd 原文： https://pytorch.org/docs/stable/autograd.html torch.autograd提供了实现自动区分任意标量值函数的类和函数。 它需要对现有代码进行最小的更改-您只需要声明Tensor，应使用requires_grad=True关键字为其计算梯度。 torch.autograd.backward(tensors, grad_tensors=None, retain_graph=None, create_graph=False, grad_variables=None)¶ 计算给定张量的梯度总和 w.r.t. 图叶。 该图使用链规则进行区分。 如果tensors中的任何一个都是非标量的(即，其数据具有多个元素）并且需要梯度，则将计算雅可比矢量积，在这种情况下，该函数还需要指定grad_tensors。 它应该是长度匹配的序列，其中包含雅可比向量积中的“向量”，通常是微分函数 w.r.t 的梯度。 相应的张量(对于不需要梯度张量的所有张量，None是可接受的值）。 此函数在树叶中累积渐变-调用它之前可能需要将它们归零。 参数 张量(张量的序列）–将计算其导数的张量。 grad_tensors (( tensor 或 无的序列 ））–雅可比向量积中的“向量”，通常是梯度 wrt 相应张量的每个元素。 无法为标量张量或不需要等级的张量指定任何值。 如果所有 grad_tensor 都可接受 None 值，则此参数是可选的。 keep_graph (bool ， 可选）–如果False，则用于计算等级的图形将被释放。 请注意，几乎在所有情况下都不需要将此选项设置为True，并且通常可以以更有效的方式解决它。 默认为create_graph的值。 create_graph (bool ， 可选）–如果True，则将构造导数图，从而允许计算高阶导数 产品。 默认为False。 torch.autograd.grad(outputs, inputs, grad_outputs=None, retain_graph=None, create_graph=False, only_inputs=True, allow_unused=False)¶ 计算并返回输出 w.r.t 的梯度总和。 输入。 grad_outputs应该是长度匹配的序列output，其中包含 Jacobian 向量积中的“向量”，通常是预先计算的梯度 w.r.t。 每个输出。 如果输出不是 require_grad，则渐变可以为None。 如果only_inputs为True，则该函数将仅返回指定输入的渐变列表。 如果是False，则渐变 w.r.t. 所有剩余的叶子仍将被计算，并将被累积到其.grad属性中。 Parameters 输出(张量的序列）–微分功能的输出。 输入(张量的序列）–输入 w.r.t. 梯度将被返回(而不是累积到.grad中）。 grad_outputs (张量的序列）–雅可比向量积中的“向量”。 通常是渐变色 每个输出。 无法为标量张量或不需要等级的张量指定任何值。 如果所有 grad_tensor 都可接受 None 值，则此参数是可选的。 默认值：无。 retain_graph (bool__, optional) – If False, the graph used to compute the grad will be freed. Note that in nearly all cases setting this option to True is not needed and often can be worked around in a much more efficient way. Defaults to the value of create_graph. create_graph (bool ， 可选）–如果True，则将构造导数图，从而允许计算高阶导数 产品。 默认值：False。 allow_unused (bool ， 可选）–如果为False，则指定在计算输出时未使用的输入(及其等级） 始终为零）是错误。 默认为False。 局部禁用梯度计算 class torch.autograd.no_grad¶ 禁用梯度计算的上下文管理器。 当您确定不会调用Tensor.backward()时，禁用梯度计算对于推断很有用。 它将减少用于具有 require_grad = True 的计算的内存消耗。 在这种模式下，即使输入具有 require_grad = True ，每个计算的结果也将具有 require_grad = False 。 使用 enable_grad 上下文管理器时，此模式无效。 该上下文管理器是线程本地的； 它不会影响其他线程中的计算。 还用作装饰器。 例： >>> x = torch.tensor([1], requires_grad=True) >>> with torch.no_grad(): ... y = x * 2 >>> y.requires_grad False >>> @torch.no_grad() ... def doubler(x): ... return x * 2 >>> z = doubler(x) >>> z.requires_grad False class torch.autograd.enable_grad¶ 启用梯度计算的上下文管理器。 如果已通过 no_grad 或 set_grad_enabled 禁用了梯度计算，则启用梯度计算。 This context manager is thread local; it will not affect computation in other threads. Also functions as a decorator. Example: >>> x = torch.tensor([1], requires_grad=True) >>> with torch.no_grad(): ... with torch.enable_grad(): ... y = x * 2 >>> y.requires_grad True >>> y.backward() >>> x.grad >>> @torch.enable_grad() ... def doubler(x): ... return x * 2 >>> with torch.no_grad(): ... z = doubler(x) >>> z.requires_grad True class torch.autograd.set_grad_enabled(mode)¶ 将渐变计算设置为开或关的上下文管理器。 set_grad_enabled将根据其参数mode启用或禁用 grads。 它可以用作上下文管理器或功能。 使用 enable_grad 上下文管理器时，set_grad_enabled(False)不起作用。 This context manager is thread local; it will not affect computation in other threads. Parameters 模式 (bool )–标记是启用 Grad(True）还是禁用(False）。 这可用于有条件地启用渐变。 Example: >>> x = torch.tensor([1], requires_grad=True) >>> is_train = False >>> with torch.set_grad_enabled(is_train): ... y = x * 2 >>> y.requires_grad False >>> torch.set_grad_enabled(True) >>> y = x * 2 >>> y.requires_grad True >>> torch.set_grad_enabled(False) >>> y = x * 2 >>> y.requires_grad False 张量的就地操作 在 autograd 中支持就地操作很困难，并且在大多数情况下，我们不鼓励使用它们。 Autograd 积极的缓冲区释放和重用使其非常高效，就地操作实际上很少显着降低内存使用量的情况很少。 除非您在高内存压力下进行操作，否则可能永远不需要使用它们。 就地正确性检查 所有Tensor都跟踪对其应用的就地操作，并且如果实现检测到在其中一个函数中保存了一个张量以用于后退，但此后对其进行了修改，则一旦向后进行修改，就会引发错误 通行证开始。 这样可以确保，如果您使用的是就地函数并且没有看到任何错误，则可以确保计算出的梯度是正确的。 变量(不建议使用） 警告 不推荐使用 Variable API：不再需要将变量用于带有张量的 autograd。 Autograd 自动将requires_grad设置为True的张量。 请在下面找到有关更改的快速指南： Variable(tensor)和Variable(tensor, requires_grad)仍能按预期工作，但是它们返回张量而不是变量。 var.data与tensor.data相同。 现在，诸如var.backward(), var.detach(), var.register_hook()之类的方法可以在具有相同方法名称的张量上使用。 此外，现在可以使用 torch.randn() ， torch.zeros() ， torch.ones() 等工厂方法使用requires_grad=True创建张量 下列： autograd_tensor = torch.randn((2, 3, 4), requires_grad=True) 张量自动分级功能 class torch.Tensor grad¶ 此属性默认为None，并在首次调用 backward() 计算self的梯度时成为张量。 然后，该属性将包含计算出的梯度，将来对 backward() 的调用将在其中累积(添加）梯度。 requires_grad¶ 如果需要为此张量计算梯度，则为True，否则为False。 注意 需要为张量计算梯度的事实并不意味着将填充 grad 属性，有关更多详细信息，请参见 is_leaf 。 is_leaf¶ 按照惯例，所有具有 requires_grad 即False的张量将是叶张量。 对于具有 requires_grad (即True）的张量，如果它们是由用户创建的，则它们将是叶张量。 这意味着它们不是运算的结果，因此grad_fn为“无”。 在调用 backward() 期间，仅叶子张量会填充其 grad 。 要为非叶张量填充 grad ，可以使用 retain_grad() 。 Example: >>> a = torch.rand(10, requires_grad=True) >>> a.is_leaf True >>> b = torch.rand(10, requires_grad=True).cuda() >>> b.is_leaf False # b was created by the operation that cast a cpu Tensor into a cuda Tensor >>> c = torch.rand(10, requires_grad=True) + 2 >>> c.is_leaf False # c was created by the addition operation >>> d = torch.rand(10).cuda() >>> d.is_leaf True # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine) >>> e = torch.rand(10).cuda().requires_grad_() >>> e.is_leaf True # e requires gradients and has no operations creating it >>> f = torch.rand(10, requires_grad=True, device=\"cuda\") >>> f.is_leaf True # f requires grad, has no operation creating it backward(gradient=None, retain_graph=None, create_graph=False)¶ 计算电流张量 w.r.t. 图叶。 该图使用链规则进行区分。 如果张量是非标量的(即其数据具有多个元素）并且需要梯度，则该函数还需要指定gradient。 它应该是匹配类型和位置的张量，其中包含微分函数 w.r.t 的梯度。 self。 此函数在树叶中累积渐变-调用它之前可能需要将它们归零。 Parameters 梯度 (tensor 或 无）–梯度 w.r.t. 张量。 如果它是张量，除非create_graph为 True，否则它将自动转换为不需要 grad 的张量。 无法为标量张量或不需要等级的张量指定任何值。 如果 None 值可以接受，那么此参数是可选的。 keep_graph (bool ， 可选）–如果False，则用于计算等级的图形将被释放。 请注意，几乎在所有情况下都不需要将此选项设置为 True，并且通常可以以更有效的方式解决它。 默认为create_graph的值。 create_graph (bool ， 可选）–如果True，则将构造导数图，从而允许计算高阶导数 产品。 默认为False。 detach()¶ 返回与当前图形分离的新 Tensor。 结果将永远不需要渐变。 Note 返回的 Tensor 与原始 Tensor 共享相同的存储。 可以看到对它们中的任何一个的就地修改，并且可能触发正确性检查中的错误。 重要说明：以前，就地大小/步幅/存储更改(例如 resize / resize_as / set / transpose ) 返回的张量也会更新原始张量。 现在，这些就地更改将不再更新原始张量，而将触发错误。 对于稀疏张量：原位索引/值更改(例如 zero / copy / add_ )将不会再更新原始张量， 而是触发错误。 detach_()¶ 从创建它的图形中分离张量，使其成为一片叶子。 视图不能就地分离。 register_hook(hook)¶ 注册一个倒钩。 每当计算相对于张量的梯度时，都会调用该挂钩。 挂钩应具有以下签名： hook(grad) -> Tensor or None 挂钩不应修改其自变量，但可以选择返回一个新的渐变，该渐变将代替 grad 使用。 此函数返回带有方法handle.remove()的句柄，该方法可将钩子从模块中移除。 Example: >>> v = torch.tensor([0., 0., 0.], requires_grad=True) >>> h = v.register_hook(lambda grad: grad * 2) # double the gradient >>> v.backward(torch.tensor([1., 2., 3.])) >>> v.grad 2 4 6 [torch.FloatTensor of size (3,)] >>> h.remove() # removes the hook retain_grad()¶ 为非叶张量启用.grad 属性。 功能 class torch.autograd.Function¶ 记录操作历史并定义用于区分操作的公式。 在Tensor上执行的每个操作都会创建一个新的函数对象，该对象执行计算并记录其发生。 历史记录以 DAG 函数的形式保留，其边缘表示数据依赖性(input &lt;- output）。 然后，当调用向后时，通过调用每个 Function 对象的 backward() 方法，并将返回的梯度传递到下一个，以拓扑顺序处理图形 ] Function s。 通常，用户与函数交互的唯一方法是创建子类并定义新操作。 这是扩展 torch.autograd 的推荐方法。 每个功能对象只能使用一次(在向前传递中）。 例子： >>> class Exp(Function): >>> >>> @staticmethod >>> def forward(ctx, i): >>> result = i.exp() >>> ctx.save_for_backward(result) >>> return result >>> >>> @staticmethod >>> def backward(ctx, grad_output): >>> result, = ctx.saved_tensors >>> return grad_output * result static backward(ctx, *grad_outputs)¶ 定义用于区分操作的公式。 该功能将被所有子类覆盖。 它必须接受上下文ctx作为第一个参数，然后返回 forward() 返回的输出数量，并且它应该返回与 [forward()的输入一样多的张量 。 每个参数都是给定输出的梯度 w.r.t，每个返回值都应该是梯度 w.r.t。 相应的输入。 上下文可用于检索在前向传递过程中保存的张量。 它还具有属性ctx.needs_input_grad，它是一个布尔元组，表示每个输入是否需要渐变。 例如，如果 forward() 的第一个输入需要进行 w.r.t.的梯度计算，则 backward() 将具有ctx.needs_input_grad[0] = True。 输出。 static forward(ctx, *args, **kwargs)¶ 执行操作。 This function is to be overridden by all subclasses. 它必须接受上下文 ctx 作为第一个参数，后跟任意数量的参数(张量或其他类型）。 上下文可用于存储张量，然后可以在向后传递过程中检索这些张量。 上下文方法混合 创建新的 Function 时， ctx 可使用以下方法。 class torch.autograd.function._ContextMethodMixin¶ mark_dirty(*args)¶ 将给定张量标记为在就地操作中已修改。 仅应从 forward() 方法内部调用一次，并且所有自变量均应为输入。 在调用forward()时在原位修改的每个张量都应提供给此函数，以确保检查的正确性。 在修改之前或之后调用该函数都没有关系。 mark_non_differentiable(*args)¶ 将输出标记为不可微分。 仅应从 forward() 方法内部调用一次，并且所有自变量均应为输出。 这会将输出标记为不需要梯度，从而提高了向后计算的效率。 您仍然需要为backward()中的每个输出接受一个渐变，但是它始终将是零张量，其形状与相应输出的形状相同。 例如使用 用于从最大值Function返回的索引。 save_for_backward(*tensors)¶ 保存给定的张量以供将来调用backward()。 最多只能调用一次，并且只能从 forward() 方法内部调用。 以后，可以通过saved_tensors属性访问已保存的张量。 在将它们退还给用户之前，应进行检查以确保未在修改其内容的任何就地操作中使用它们。 参数也可以是None。 数值梯度检查 torch.autograd.gradcheck(func, inputs, eps=1e-06, atol=1e-05, rtol=0.001, raise_exception=True, check_sparse_nnz=False, nondet_tol=0.0)¶ 检查相对于分析梯度 w.r.t 的小有限差分计算出的梯度。 inputs中的浮点类型为requires_grad=True的张量。 在数值梯度和解析梯度之间的检查使用 allclose() 。 Note 默认值是为双精度的input设计的。 如果input的精度较低，例如FloatTensor，则此检查可能会失败。 Warning 如果input中的任何已检查张量具有重叠的内存，即，不同的索引指向相同的内存地址(例如，来自torch.expand()的索引），则此检查可能会失败，因为在这些索引处通过点扰动计算出的数值梯度将改变值 共享相同内存地址的所有其他索引。 Parameters 函数(函数）–一个 Python 函数，接受 Tensor 输入并返回 Tensor 或 Tensors 元组 输入(张量 或 tensor 的元组）–该功能的输入 eps (python：float ， 可选）–有限差分摄动 atol (python：float ， 可选）–绝对公差 rtol (python：float ， 可选）–相对公差 raise_exception (bool ， 可选）–指示如果检查失败，是否引发异常。 该异常提供有关故障确切性质的更多信息。 这在调试 gradchecks 时很有用。 check_sparse_nnz (bool ， 可选）–如果为 True，则 gradcheck 允许输入 SparseTensor，对于输入的任何 SparseTensor，gradcheck 将执行 仅在 nnz 位置检查。 nondet_tol (python：float ， 可选）–对不确定性的容忍度。 通过微分运行相同的输入时，结果必须完全匹配(默认值为 0.0）或在此公差范围内。 退货 如果所有差异均满足全封闭条件，则为真 torch.autograd.gradgradcheck(func, inputs, grad_outputs=None, eps=1e-06, atol=1e-05, rtol=0.001, gen_non_contig_grad_outputs=False, raise_exception=True, nondet_tol=0.0)¶ 检查相对于分析梯度 w.r.t 的，通过小的有限差分计算出的梯度的梯度。 inputs和grad_outputs中的张量是浮点型且带有requires_grad=True的张量。 此函数检查通过向给定grad_outputs计算的梯度进行反向传播是否正确。 The check between numerical and analytical gradients uses allclose(). Note 默认值是为双精度的input和grad_outputs设计的。 如果它们的精度较低，例如FloatTensor，则此检查可能会失败。 Warning 如果input和grad_outputs中的任何已检查张量具有重叠的内存，即指向同一内存地址的不同索引(例如，来自torch.expand()的索引），则此检查可能会失败，因为在这种情况下通过点摄动计算出的数值梯度 索引将更改共享同一内存地址的所有其他索引的值。 Parameters func (function) – a Python function that takes Tensor inputs and returns a Tensor or a tuple of Tensors inputs (tuple of Tensor or Tensor) – inputs to the function grad_outputs (张量元组 或 tensor ， 可选）–相对于函数输出的渐变。 eps (python:float__, optional) – perturbation for finite differences atol (python:float__, optional) – absolute tolerance rtol (python:float__, optional) – relative tolerance gen_non_contig_grad_outputs (bool ， 可选））–如果grad_outputs为None，gen_non_contig_grad_outputs为True，则随机 使生成的梯度输出不连续 raise_exception (bool__, optional) – indicating whether to raise an exception if the check fails. The exception gives more information about the exact nature of the failure. This is helpful when debugging gradchecks. nondet_tol (python：float ， 可选）–对不确定性的容忍度。 通过微分运行相同的输入时，结果必须完全匹配(默认值为 0.0）或在此公差范围内。 注意，梯度中的少量不确定性将导致二阶导数的较大误差。 Returns True if all differences satisfy allclose condition 探查器 Autograd 包括一个探查器，可让您检查模型中不同运算符的成本-包括 CPU 和 GPU。 目前有两种模式-仅使用 profile 的 CPU。 并使用 emit_nvtx 基于 nvprof(注册 CPU 和 GPU 活动）。 class torch.autograd.profiler.profile(enabled=True, use_cuda=False, record_shapes=False)¶ 上下文管理器，用于管理 autograd profiler 状态并保存结果摘要。 在后台，它仅记录正在 C ++中执行的函数的事件，并将这些事件公开给 Python。 您可以将任何代码包装到其中，并且它只会报告 PyTorch 函数的运行时。 Parameters 启用的 (bool ， 可选）–将其设置为 False 会使此上下文管理器变为无操作。 默认值：True。 use_cuda (bool ， 可选）–以及使用 cudaEvent API 启用 CUDA 事件的计时。 每个张量操作会增加大约 4us 的开销。 默认值：False record_shapes (bool ， 可选）–如果设置了形状记录，将收集有关输入尺寸的信息。 这样一来，您可以查看引擎盖下使用了哪些尺寸，并使用 prof.key_averages(group_by_input_shape = True）将它们进一步分组。 请注意，形状记录可能会歪曲您的轮廓数据。 建议使用带有和不带有形状记录的单独运行来验证计时。 对于最底层的事件(在嵌套函数调用的情况下），偏斜很可能会忽略不计。 但是对于较高级别的功能，由于形状收集，可能会人为地增加总的自体 cpu 时间。 例 >>> x = torch.randn((1, 1), requires_grad=True) >>> with torch.autograd.profiler.profile() as prof: >>> for _ in range(100): # any normal python code, really! >>> y = x ** 2 >> y.backward() >>> # NOTE: some columns were removed for brevity >>> print(prof.key_averages().table(sort_by=\"self_cpu_time_total\")) ----------------------------------- --------------- --------------- --------------- Name Self CPU total CPU time avg Number of Calls ----------------------------------- --------------- --------------- --------------- mul 32.048ms 32.048ms 200 pow 27.041ms 27.041ms 200 PowBackward0 9.727ms 55.483ms 100 torch::autograd::AccumulateGrad 9.148ms 9.148ms 100 torch::autograd::GraphRoot 691.816us 691.816us 100 ----------------------------------- --------------- --------------- --------------- export_chrome_trace(path)¶ 将 EventList 导出为 Chrome 跟踪工具文件。 稍后可以在chrome://tracing URL 下加载和检查检查点。 Parameters 路径 (str )–将写入跟踪的路径。 key_averages(group_by_input_shape=False)¶ 平均所有功能事件的键。 @param group_by_input_shapes 该键将变为(事件名称，输入维度），而不仅仅是事件名称。 这对于查看哪个维度对运行时间的贡献最大是很有用的，并且可以帮助进行特定于维度的优化或选择最佳的量化候选对象(也就是拟合屋顶线） Returns 一个包含 FunctionEventAvg 对象的 EventList。 property self_cpu_time_total¶ 返回花费在 CPU 上的总时间，作为所有事件中所有自身时间的总和。 table(sort_by=None, row_limit=100, header=None)¶ 将 EventList 打印为格式正确的表。 Parameters sort_by (str ， 可选）–用于对条目进行排序的属性。 默认情况下，它们以与注册时相同的顺序打印。 有效密钥包括：cpu_time，cuda_time，cpu_time_total，cuda_time_total，count。 Returns 包含表的字符串。 total_average()¶ 平均所有事件。 Returns FunctionEventAvg 对象。 class torch.autograd.profiler.record_function(name)¶ 上下文管理器，在运行 autograd profiler 时将标签添加到 Python 代码块中。 在跟踪代码配置文件时很有用。 Parameters 名称 (str )–分配给代码块的标签。 Example >>> x = torch.randn((1, 1), requires_grad=True) >>> with torch.autograd.profiler.profile() as prof: ... y = x ** 2 ... with torch.autograd.profiler.record_function(\"label-z\"): # label the block ... z = y ** 3 ... y.backward() ... >>> # NOTE: some columns were removed for brevity >>> print(prof.key_averages().table(sort_by=\"self_cpu_time_total\")) ----------------------------------- --------------- --------------- --------------- Name Self CPU total % CPU time avg Number of Calls ----------------------------------- --------------- --------------- --------------- pow 60.77% 47.470us 3 mul 21.73% 25.465us 2 PowBackward0 12.03% 121.891us 1 torch::autograd::AccumulateGrad 2.70% 6.324us 1 label-z 2.13% 12.421us 1 torch::autograd::GraphRoot 0.64% 1.503us 1 ----------------------------------- --------------- --------------- --------------- Self CPU time total: 234.344us CUDA time total: 0.000us class torch.autograd.profiler.emit_nvtx(enabled=True, record_shapes=False)¶ 使每个自动分级操作发出 NXTX 范围的上下文管理器。 在 nvprof 下运行程序时，它很有用： nvprof --profile-from-start off -o trace_name.prof -- 不幸的是，无法强制 nvprof 将收集到的数据刷新到磁盘，因此对于 CUDA 分析，必须使用此上下文管理器注释 nvprof 跟踪并等待进程退出后再检查它们。 然后，可以使用 NVIDIA Visual Profiler(nvvp）可视化时间轴，或者 torch.autograd.profiler.load_nvprof() 可以加载结果以进行检查，例如 在 Python REPL 中。 Parameters 启用 (bool ， 可选 ， 默认= True )–设置enabled=False使此上下文管理器成为禁止操作。 默认值：True。 record_shapes (bool ， 可选 ， 默认=假）–如果record_shapes=True，包装每个 autograd 操作的 nvtx 范围将以以下格式附加有关该操作接收的 Tensor 参数的大小的信息：[[arg0.size(0), arg0.size(1), ...], [arg1.size(0), arg1.size(1), ...], ...]非张量参数将由[]表示。 参数将按照后端操作接收到的顺序列出。 请注意，此顺序可能与在 Python 端传递这些参数的顺序不匹配。 还要注意，形状记录可能会增加 nvtx 范围创建的开销。 Example >>> with torch.cuda.profiler.profile(): ... model(x) # Warmup CUDA memory allocator and profiler ... with torch.autograd.profiler.emit_nvtx(): ... model(x) 前向后相关 当在 Nvidia Visual Profiler 中查看使用 emit_nvtx 创建的配置文件时，将每个后向操作与相应的前向操作相关联可能很困难。 为了简化此任务， emit_nvtx 将序列号信息附加到它生成的范围。 在前进过程中，每个功能范围均以seq=&lt;N&gt;装饰。 seq是一个运行计数器，每次创建一个新的向后功能对象时都将递增并存放以用于向后。 因此，与每个前向功能范围相关联的seq=&lt;N&gt;注释告诉您，如果通过此前向功能创建后向功能对象，则后向对象将接收序列号 N。在后向传递过程中，包装每个 C ++的顶级范围 向后函数的apply()调用装饰有stashed seq=&lt;M&gt;。 M是创建反向对象的序列号。 通过比较后向的stashed seq数字和正向的seq数字，您可以跟踪哪个正向运算符创建了每个向后功能。 向后传递过程中执行的所有功能也都用seq=&lt;N&gt;装饰。 在默认向后(使用create_graph=False）期间，此信息无关紧要，实际上，对于所有此类功能，N可能只是 0。 只有与向后功能对象的apply()方法关联的顶级范围才有用，可以将这些功能对象与更早的向前传递相关联。 双向 另一方面，如果正在进行create_graph=True的向后传递(换句话说，如果您要进行双向后退），则向后执行过程中每个函数的执行都将被赋予非零且有用的seq=&lt;N&gt;。 这些函数本身可以创建 Function 对象，以便稍后在双向后执行时，就像向前传递中的原始函数一样。 向后和双向后之间的关系在概念上与向前和向后之间的关系相同：这些函数仍会发出带有当前序列号标记的范围，它们创建的 Function 对象仍会存储这些序列号，并且在最终 double- 向后，功能对象的apply()范围仍标记有stashed seq数字，可以将其与从后向传递的 seq 数字进行比较。 torch.autograd.profiler.load_nvprof(path)¶ 打开 nvprof 跟踪文件并解析 autograd 批注。 Parameters 路径 (str )– nvprof 跟踪的路径 异常检测 class torch.autograd.detect_anomaly¶ 上下文管理器，可为 autograd 引擎启用异常检测。 这有两件事：-在启用检测的情况下运行正向传递，将允许反向传递打印创建失败的反向函数的正向操作的回溯。 -任何产生“ nan”值的向后计算都会引发错误。 Warning 仅在调试时才应启用此模式，因为不同的测试会减慢程序的执行速度。 Example >>> import torch >>> from torch import autograd >>> class MyFunc(autograd.Function): ... @staticmethod ... def forward(ctx, inp): ... return inp.clone() ... @staticmethod ... def backward(ctx, gO): ... # Error during the backward pass ... raise RuntimeError(\"Some error in backward\") ... return gO.clone() >>> def run_fn(a): ... out = MyFunc.apply(a) ... return out.sum() >>> inp = torch.rand(10, 10, requires_grad=True) >>> out = run_fn(inp) >>> out.backward() Traceback (most recent call last): File \"\", line 1, in File \"/your/pytorch/install/torch/tensor.py\", line 93, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph) File \"/your/pytorch/install/torch/autograd/__init__.py\", line 90, in backward allow_unreachable=True) # allow_unreachable flag File \"/your/pytorch/install/torch/autograd/function.py\", line 76, in apply return self._forward_cls.backward(self, *args) File \"\", line 8, in backward RuntimeError: Some error in backward >>> with autograd.detect_anomaly(): ... inp = torch.rand(10, 10, requires_grad=True) ... out = run_fn(inp) ... out.backward() Traceback of forward call that caused the error: File \"tmp.py\", line 53, in out = run_fn(inp) File \"tmp.py\", line 44, in run_fn out = MyFunc.apply(a) Traceback (most recent call last): File \"\", line 4, in File \"/your/pytorch/install/torch/tensor.py\", line 93, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph) File \"/your/pytorch/install/torch/autograd/__init__.py\", line 90, in backward allow_unreachable=True) # allow_unreachable flag File \"/your/pytorch/install/torch/autograd/function.py\", line 76, in apply return self._forward_cls.backward(self, *args) File \"\", line 8, in backward RuntimeError: Some error in backward class torch.autograd.set_detect_anomaly(mode)¶ 上下文管理器，用于打开或关闭 autograd 引擎的异常检测。 set_detect_anomaly将基于其参数mode启用或禁用自动毕业异常检测。 它可以用作上下文管理器或功能。 有关异常检测行为的详细信息，请参见上面的detect_anomaly。 Parameters 模式 (bool )–标记是启用异常检测(True）还是禁用(False）。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:35:31 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"80.html":{"url":"80.html","title":"torch.cuda","keywords":"","body":"torch.cuda 原文： https://pytorch.org/docs/stable/cuda.html 该软件包增加了对 CUDA 张量类型的支持，该类型实现与 CPU 张量相同的功能，但是它们利用 GPU 进行计算。 它是延迟初始化的，因此您始终可以导入它，并使用 is_available() 确定您的系统是否支持 CUDA。 CUDA 语义具有有关使用 CUDA 的更多详细信息。 torch.cuda.current_blas_handle()¶ 返回 cublasHandle_t 指向当前 cuBLAS 句柄的指针 torch.cuda.current_device()¶ 返回当前所选设备的索引。 torch.cuda.current_stream(device=None)¶ 返回给定设备的当前选择的 Stream 。 参数 设备 (torch设备 或 python：int ， 可选 )–所选设备。 如果 device 为None(默认值），则返回由 current_device() 给定的当前设备当前选择的 Stream 。 torch.cuda.default_stream(device=None)¶ 返回给定设备的默认 Stream 。 Parameters 设备 (torch设备 或 python：int ， 可选 )–所选设备。 如果 device 为None(默认值），则返回由 current_device() 给定的当前设备的默认 Stream 。 class torch.cuda.device(device)¶ 更改所选设备的上下文管理器。 Parameters 设备 (torch设备 或 python：int )–选择的设备索引。 如果此参数为负整数或None，则为空。 torch.cuda.device_count()¶ 返回可用的 GPU 数量。 class torch.cuda.device_of(obj)¶ 将当前设备更改为给定对象的上下文管理器。 您可以将张量和存储都用作参数。 如果未在 GPU 上分配给定对象，则为空操作。 Parameters obj (tensor 或 存储）–在所选设备上分配的对象。 torch.cuda.get_device_capability(device=None)¶ 获取设备的 CUDA 功能。 Parameters 设备 (torch设备 或 python：int ， 可选 )–要为其返回设备功能的设备。 如果此参数为负整数，则此函数为空操作。 如果 device 为None，则使用 current_device() 给定的当前设备。 退货 设备的主要和次要 CUDA 功能 返回类型 元组(int，int） torch.cuda.get_device_name(device=None)¶ 获取设备的名称。 Parameters 设备 (torch设备 或 python：int ， 可选 )–要为其返回名称的设备。 如果此参数为负整数，则此函数为空操作。 如果 device 为None，则使用 current_device() 给定的当前设备。 torch.cuda.init()¶ 初始化 PyTorch 的 CUDA 状态。 如果您通过 PyTorch 的 C API 与 PyTorch 进行交互，则可能需要显式调用此方法，因为在进行初始化之前，CUDA 功能的 Python 绑定才可以。 普通用户不需要此，因为所有 PyTorch 的 CUDA 方法都会自动按需初始化 CUDA 状态。 如果 CUDA 状态已经初始化，则不执行任何操作。 torch.cuda.ipc_collect()¶ CUDA IPC 释放后，Force 将收集 GPU 内存。 注意 检查是否可以从内存中清除任何已发送的 CUDA 张量。 如果没有活动计数器，则强制关闭用于引用计数的共享内存文件。 当生产者进程停止主动发送张量并希望释放未使用的内存时，此选项很有用。 torch.cuda.is_available()¶ 返回一个布尔值，指示 CUDA 当前是否可用。 torch.cuda.is_initialized()¶ 返回 PyTorch 的 CUDA 状态是否已初始化。 torch.cuda.set_device(device)¶ 设置当前设备。 不推荐使用此功能，而推荐使用 device 。 在大多数情况下，最好使用CUDA_VISIBLE_DEVICES环境变量。 Parameters 设备 (torch设备 或 python：int )–选定的设备。 如果此参数为负，则此函数为空操作。 torch.cuda.stream(stream)¶ 选择给定流的上下文管理器。 在其上下文中排队的所有 CUDA 内核都将排队在选定的流上。 Parameters 流 (流)–选择的流。 如果经理是None，则为空手。 Note 流是按设备的。 如果所选的流不在当前设备上，则此功能还将更改当前设备以匹配该流。 torch.cuda.synchronize(device=None)¶ 等待 CUDA 设备上所有流中的所有内核完成。 Parameters 设备 (torch设备 或 python：int ， 可选 )–要同步的设备。 如果 device 为None，则使用 current_device() 给定的当前设备。 随机数发生器 torch.cuda.get_rng_state(device='cuda')¶ 以 ByteTensor 的形式返回指定 GPU 的随机数生成器状态。 Parameters 设备 (torch设备 或 python：int ， 可选 )–返回 RNG 状态的设备。 默认值：'cuda'(即，当前 CUDA 设备torch.device('cuda')）。 警告 该函数会急切地初始化 CUDA。 torch.cuda.get_rng_state_all()¶ 返回表示所有设备的随机数状态的 ByteTensor 元组。 torch.cuda.set_rng_state(new_state, device='cuda')¶ 设置指定 GPU 的随机数生成器状态。 Parameters new_state (torch.ByteTensor )–所需状态 设备 (torch设备 或 python：int ， 可选 )–设置 RNG 状态的设备。 默认值：'cuda'(即，当前 CUDA 设备torch.device('cuda')）。 torch.cuda.set_rng_state_all(new_states)¶ 设置所有设备的随机数生成器状态。 Parameters new_state (Torch.ByteTensor 的元组）–每个设备的所需状态 torch.cuda.manual_seed(seed)¶ 设置种子以为当前 GPU 生成随机数。 如果没有 CUDA，则可以安全地调用此函数； 在这种情况下，它会被静默忽略。 Parameters 种子 (python：int )–所需的种子。 Warning 如果您使用的是多 GPU 模型，则此功能不足以获得确定性。 要播种所有 GPU，请使用 manual_seed_all() 。 torch.cuda.manual_seed_all(seed)¶ 设置用于在所有 GPU 上生成随机数的种子。 如果没有 CUDA，则可以安全地调用此函数； 在这种情况下，它会被静默忽略。 Parameters seed (python:int) – The desired seed. torch.cuda.seed()¶ 将用于生成随机数的种子设置为当前 GPU 的随机数。 如果没有 CUDA，则可以安全地调用此函数； 在这种情况下，它会被静默忽略。 Warning 如果您使用的是多 GPU 模型，则此功能将仅在一个 GPU 上初始化种子。 要初始化所有 GPU，请使用 seed_all() 。 torch.cuda.seed_all()¶ 将在所有 GPU 上生成随机数的种子设置为随机数。 如果没有 CUDA，则可以安全地调用此函数； 在这种情况下，它会被静默忽略。 torch.cuda.initial_seed()¶ 返回当前 GPU 的当前随机种子。 Warning This function eagerly initializes CUDA. 传播集体 torch.cuda.comm.broadcast(tensor, devices)¶ 向多个 GPU 广播张量。 Parameters 张量 (tensor)–张量要广播。 设备(可迭代）–可以在其中广播的设备的可迭代方式。 请注意，它应该像(src，dst1，dst2，…），其第一个元素是要从中广播的源设备。 Returns 包含tensor副本的元组，放置在与devices的索引相对应的设备上。 torch.cuda.comm.broadcast_coalesced(tensors, devices, buffer_size=10485760)¶ 将序列张量广播到指定的 GPU。 首先将小张量合并到缓冲区中以减少同步次数。 Parameters 张量(序列）–要广播的张量。 devices (Iterable) – an iterable of devices among which to broadcast. Note that it should be like (src, dst1, dst2, …), the first element of which is the source device to broadcast from. buffer_size (python：int )–用于合并的缓冲区的最大大小 Returns A tuple containing copies of the tensor, placed on devices corresponding to indices from devices. torch.cuda.comm.reduce_add(inputs, destination=None)¶ 来自多个 GPU 的张量求和。 所有输入应具有匹配的形状。 Parameters 输入(可迭代 [ tensor ] )–可累加的张量 。 目标 (python：int ， 可选）–将放置输出的设备(默认值：当前设备）。 Returns 包含所有输入的元素和的张量，放置在destination设备上。 torch.cuda.comm.scatter(tensor, devices, chunk_sizes=None, dim=0, streams=None)¶ 在多个 GPU 上分散张量。 Parameters 张量 (tensor)–张量散布。 设备(可迭代 [ python：int ] )–可迭代的 int，指定张量在哪个设备中 应该分散。 chunk_sizes (可迭代 [ python：int ] ， 可选））–每个设备上要放置的块的大小。 它的长度应与devices相匹配，并且总和应等于tensor.size(dim)。 如果未指定，则张量将分为相等的块。 暗淡的 (python：int ， 可选）–沿张量分块的尺寸。 Returns 包含tensor块的元组，分布在给定的devices中。 torch.cuda.comm.gather(tensors, dim=0, destination=None)¶ 收集来自多个 GPU 的张量。 与dim不同的所有维度中的张量大小必须匹配。 Parameters 张量(可迭代 [ tensor ] )–张量的可迭代集合。 暗淡的 (python：int )–将张量连接在一起的尺寸。 目标 (python：int ， 可选）–输出设备(-1 表示 CPU，默认值：当前设备） Returns 位于destination设备上的张量，这是tensors与dim并置的结果。 流和事件 class torch.cuda.Stream¶ CUDA 流周围的包装器。 CUDA 流是属于特定设备的线性执行序列，独立于其他流。 有关详细信息，请参见 CUDA 语义。 Parameters 设备 (torch设备 或 python：int ， 可选 )–在其上分配流的设备。 如果 device 为None(默认值）或负整数，则将使用当前设备。 优先级 (python：int ， 可选）–流的优先级。 较低的数字表示较高的优先级。 query()¶ 检查所有提交的工作是否已完成。 Returns 一个布尔值，指示该流中的所有内核是否已完成。 record_event(event=None)¶ 记录事件。 Parameters 事件 (事件 ， 可选）–记录事件。 如果未给出，将分配一个新的。 Returns 记录的事件。 synchronize()¶ 等待此流中的所有内核完成。 Note 这是对cudaStreamSynchronize()的包装：有关更多信息，请参见 CUDA 流文档。 wait_event(event)¶ 使所有将来提交到流的工作都等待事件。 Parameters 事件 (事件)–等待的事件。 Note 这是对cudaStreamWaitEvent()的包装：有关更多信息，请参见 CUDA 流文档。 该函数无需等待event就返回：仅影响以后的操作。 wait_stream(stream)¶ 与另一个流同步。 提交给该流的所有将来的工作将等到调用完成时提交给给定流的所有内核。 Parameters 流 (流)–要同步的流。 Note 该函数返回而无需等待 stream 中当前排队的内核：仅影响将来的操作。 class torch.cuda.Event¶ CUDA 事件的包装器。 CUDA 事件是同步标记，可用于监视设备的进度，准确测量时序并同步 CUDA 流。 当第一次记录该事件或将其导出到另一个进程时，基础 CUDA 事件将被延迟初始化。 创建后，只有同一设备上的流才能记录该事件。 但是，任何设备上的流都可以等待事件。 Parameters enable_timing (bool ， 可选）–指示事件是否应该测量时间(默认值：False） 阻止 (bool ， 可选）–如果True， wait() 将被阻止(默认 ：False） 进程间 (bool )–如果True，则事件可以在进程之间共享(默认值：False） elapsed_time(end_event)¶ 返回记录事件之后到记录 end_event 之前经过的时间(以毫秒为单位）。 classmethod from_ipc_handle(device, handle)¶ 从给定设备上的 IPC 句柄重构事件。 ipc_handle()¶ 返回此事件的 IPC 句柄。 如果尚未录制，则该事件将使用当前设备。 query()¶ 检查事件当前捕获的所有工作是否已完成。 Returns 一个布尔值，指示当前由事件捕获的所有工作是否已完成。 record(stream=None)¶ 在给定的流中记录事件。 如果未指定流，则使用torch.cuda.current_stream()。 流的设备必须与活动的设备匹配。 synchronize()¶ 等待事件完成。 等待直到此事件中当前捕获的所有工作完成。 这样可以防止 CPU 线程在事件完成之前继续执行。 Note 这是cudaEventSynchronize()的包装：有关更多信息，请参见 CUDA 事件文档。 wait(stream=None)¶ 使所有将来提交给定流的工作都等待此事件。 如果未指定流，则使用torch.cuda.current_stream()。 内存管理 torch.cuda.empty_cache()¶ 释放当前由缓存分配器保留的所有未占用的缓存内存，以便这些内存可在其他 GPU 应用程序中使用，并在 nvidia-smi 中可见。 Note empty_cache() 不会增加 PyTorch 可用的 GPU 内存量。 但是，在某些情况下，它可能有助于减少 GPU 内存的碎片。 有关 GPU 内存管理的更多详细信息，请参见内存管理。 torch.cuda.memory_stats(device=None)¶ 返回给定设备的 CUDA 内存分配器统计信息的字典。 此函数的返回值是统计字典，每个字典都是非负整数。 核心统计数据： \"allocated.{all,large_pool,small_pool}.{current,peak,allocated,freed}\"：内存分配器接收到的分配请求数。 \"allocated_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}\"：分配的内存量。 \"segment.{all,large_pool,small_pool}.{current,peak,allocated,freed}\"：来自cudaMalloc()的保留段数。 \"reserved_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}\"：保留的内存量。 \"active.{all,large_pool,small_pool}.{current,peak,allocated,freed}\"：活动存储块的数量。 \"active_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}\"：活动内存量。 \"inactive_split.{all,large_pool,small_pool}.{current,peak,allocated,freed}\"：非活动，不可释放的存储块的数量。 \"inactive_split_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}\"：非活动，不可释放的内存量。 对于这些核心统计信息，值细分如下。 泳池类型： all：所有内存池的组合统计信息。 large_pool：大型分配池的统计信息(截至 2019 年 10 月，>大小= 1MB 分配）。 small_pool：小型分配池的统计信息(截至 2019 年 10 月， 指标类型： current：此度量标准的当前值。 peak：此指标的最大值。 allocated：此指标的历史总数增长。 freed：此指标的历史总数下降。 除了核心统计信息之外，我们还提供了一些简单的事件计数器： \"num_alloc_retries\"：导致高速缓存刷新并重试的cudaMalloc调用失败的次数。 \"num_ooms\"：抛出的内存不足错误数。 Parameters 设备 (torch设备 或 python：int ， 可选 )–所选设备。 如果 device 为None(默认值），则返回由 current_device() 给定的当前设备的统计信息。 Note 有关 GPU 内存管理的更多详细信息，请参见内存管理。 torch.cuda.memory_summary(device=None, abbreviated=False)¶ 返回给定设备的当前内存分配器统计信息的可读记录。 这对于在训练期间或处理内存不足异常时定期显示很有用。 Parameters 设备 (torch设备 或 python：int ， 可选 )–所选设备。 如果 device 为None(默认值），则返回由 current_device() 给定的当前设备的打印输出。 缩写为 (bool ， 可选）–是否返回缩写摘要(默认值：False）。 Note See Memory management for more details about GPU memory management. torch.cuda.memory_snapshot()¶ 返回所有设备上 CUDA 内存分配器状态的快照。 解释此函数的输出需要熟悉内存分配器内部。 Note See Memory management for more details about GPU memory management. torch.cuda.memory_allocated(device=None)¶ 返回给定设备的张量占用的当前 GPU 内存(以字节为单位）。 Parameters 设备 (torch设备 或 python：int ， 可选 )–所选设备。 如果 device 为None(默认值），则返回由 current_device() 给定的当前设备的统计信息。 Note 这可能少于 nvidia-smi 中显示的数量，因为某些未使用的内存可以由缓存分配器保存，并且某些上下文需要在 GPU 上创建。 有关 GPU 内存管理的更多详细信息，请参见内存管理。 torch.cuda.max_memory_allocated(device=None)¶ 返回给定设备的张量占用的最大 GPU 内存(以字节为单位）。 默认情况下，这将返回自此程序开始以来的峰值分配内存。 reset_peak_stats()可用于重置跟踪该指标的起点。 例如，这两个功能可以测量训练循环中每个迭代的峰值分配内存使用量。 Parameters device (torch.device or python:int__, optional) – selected device. Returns statistic for the current device, given by current_device(), if device is None (default). Note See Memory management for more details about GPU memory management. torch.cuda.reset_max_memory_allocated(device=None)¶ 重置用于跟踪给定设备的张量占用的最大 GPU 内存的起点。 有关详细信息，请参见 max_memory_allocated() 。 Parameters device (torch.device or python:int__, optional) – selected device. Returns statistic for the current device, given by current_device(), if device is None (default). Warning 现在，此函数调用reset_peak_memory_stats()，它将重置/ all /峰值内存状态。 Note See Memory management for more details about GPU memory management. torch.cuda.memory_reserved(device=None)¶ 返回给定设备由缓存分配器管理的当前 GPU 内存，以字节为单位。 Parameters device (torch.device or python:int__, optional) – selected device. Returns statistic for the current device, given by current_device(), if device is None (default). Note See Memory management for more details about GPU memory management. torch.cuda.max_memory_reserved(device=None)¶ 返回给定设备的缓存分配器管理的最大 GPU 内存(以字节为单位）。 默认情况下，这将返回自此程序开始以来的峰值缓存内存。 reset_peak_stats()可用于重置跟踪该指标的起点。 例如，这两个功能可以测量训练循环中每次迭代的峰值缓存内存量。 Parameters device (torch.device or python:int__, optional) – selected device. Returns statistic for the current device, given by current_device(), if device is None (default). Note See Memory management for more details about GPU memory management. torch.cuda.memory_cached(device=None)¶ 不推荐使用； 参见 memory_reserved() 。 torch.cuda.max_memory_cached(device=None)¶ 不推荐使用； 参见 max_memory_reserved() 。 torch.cuda.reset_max_memory_cached(device=None)¶ 重置跟踪由给定设备的缓存分配器管理的最大 GPU 内存的起点。 有关详细信息，请参见 max_memory_cached() 。 Parameters device (torch.device or python:int__, optional) – selected device. Returns statistic for the current device, given by current_device(), if device is None (default). Warning This function now calls reset_peak_memory_stats(), which resets /all/ peak memory stats. Note See Memory management for more details about GPU memory management. NVIDIA 工具扩展(NVTX） torch.cuda.nvtx.mark(msg)¶ 描述在某个时刻发生的瞬时事件。 Parameters msg (字符串）–与事件关联的 ASCII 消息。 torch.cuda.nvtx.range_push(msg)¶ 将范围推入嵌套范围跨度的堆栈中。 返回从零开始的范围的深度。 Parameters msg (字符串）–与范围关联的 ASCII 消息 torch.cuda.nvtx.range_pop()¶ 从嵌套范围跨度堆栈中弹出范围。 返回结束范围的从零开始的深度。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"81.html":{"url":"81.html","title":"分布式通讯包-Torch.Distributed","keywords":"","body":"分布式通讯包-Torch.Distributed 原文： https://pytorch.org/docs/stable/distributed.html 后端 torch.distributed支持三个后端，每个后端具有不同的功能。 下表显示了可用于 CPU / CUDA 张量的功能。 MPI 仅在用于构建 PyTorch 的实现支持 CUDA 的情况下才支持 CUDA。 | 后端 | gloo | mpi | nccl | | --- | --- | --- | --- | | 设备 | 中央处理器 | 显卡 | CPU | GPU | CPU | GPU | | --- | --- | --- | --- | --- | --- | --- | | 发送 | ✓ | ✘ | ✓ | ？ | ✘ | ✘ | | 收录 | ✓ | ✘ | ✓ | ? | ✘ | ✘ | | 广播 | ✓ | ✓ | ✓ | ? | ✘ | ✓ | | all_reduce | ✓ | ✓ | ✓ | ? | ✘ | ✓ | | 降低 | ✓ | ✘ | ✓ | ? | ✘ | ✓ | | all_gather | ✓ | ✘ | ✓ | ? | ✘ | ✓ | | 收集 | ✓ | ✘ | ✓ | ? | ✘ | ✘ | | 分散 | ✓ | ✘ | ✓ | ? | ✘ | ✘ | | 屏障 | ✓ | ✘ | ✓ | ? | ✘ | ✓ | PyTorch 随附的后端 当前分发的 PyTorch 仅支持 Linux。 默认情况下，会构建 Gloo 和 NCCL 后端并将其包含在 PyTorch 分布式中(仅在使用 CUDA 进行构建时才为 NCCL）。 MPI 是可选的后端，仅当您从源代码构建 PyTorch 时，才可以包含它。 (例如，在安装了 MPI 的主机上构建 PyTorch。） 使用哪个后端？ 在过去，我们经常被问到：“我应该使用哪个后端？”。 经验法则 使用 NCCL 后端进行分布式 GPU 训练 使用 Gloo 后端进行分布式 CPU 训练。 具有 InfiniBand 互连的 GPU 主机 使用 NCCL，因为它是当前唯一支持 InfiniBand 和 GPUDirect 的后端。 具有以太网互连的 GPU 主机 使用 NCCL，因为它目前提供最佳的分布式 GPU 训练性能，尤其是对于多进程单节点或多节点分布式训练。 如果您在使用 NCCL 时遇到任何问题，请使用 Gloo 作为后备选项。 (请注意，对于 GPU，Gloo 当前的运行速度比 NCCL 慢。） 具有 InfiniBand 互连的 CPU 主机 如果您的 InfiniBand 已启用 IB IP，请使用 Gloo，否则，请使用 MPI。 我们计划在即将发布的版本中增加 InfiniBand 对 Gloo 的支持。 具有以太网互连的 CPU 主机 除非有特殊原因要使用 MPI，否则请使用 Gloo。 常见环境变量 选择要使用的网络接口 默认情况下，NCCL 和 Gloo 后端都将尝试找到要使用的正确网络接口。 如果自动检测到的接口不正确，则可以使用以下环境变量(适用于各自的后端）覆盖它： NCCL_SOCKET_IFNAME ，例如export NCCL_SOCKET_IFNAME=eth0 GLOO_SOCKET_IFNAME ，例如export GLOO_SOCKET_IFNAME=eth0 如果您使用的是 Gloo 后端，则可以用逗号分隔多个接口，例如：export GLOO_SOCKET_IFNAME=eth0,eth1,eth2,eth3。 后端将以循环方式在这些接口之间调度操作。 至关重要的是，所有进程都必须在此变量中指定相同数量的接口。 其他 NCCL 环境变量 NCCL 还提供了许多环境变量以进行微调。 常用的调试工具包括以下内容： export NCCL_DEBUG=INFO export NCCL_DEBUG_SUBSYS=ALL 有关 NCCL 环境变量的完整列表，请参阅 NVIDIA NCCL 的官方文档 基本 torch分布式程序包提供 PyTorch 支持和通信原语，以实现在一台或多台机器上运行的多个计算节点之间的多进程并行性。 类 torch.nn.parallel.DistributedDataParallel() 建立在此功能之上，以提供同步的分布式训练，作为围绕任何 PyTorch 模型的包装。 这与 Multiprocessing 程序包提供的并行性不同– Torch.multiprocessing 和 torch.nn.DataParallel() 支持多个联网的机器，并且用户必须明确启动一个单独的 每个过程的主要训练脚本的副本。 在单机同步情况下，torch分布式或 torch.nn.parallel.DistributedDataParallel() 包装器可能仍比其他数据并行方法(包括 torch.nn.DataParallel())具有优势 ]： 每个过程都维护自己的优化器，并在每次迭代时执行完整的优化步骤。 尽管这看起来可能是多余的，但由于梯度已经被收集在一起并在各个过程之间求平均，因此对于每个过程都是相同的，这意味着不需要参数广播步骤，从而减少了在节点之间传递张量的时间。 每个进程都包含一个独立的 Python 解释器，从而消除了由单个 Python 进程驱动多个执行线程，模型副本或 GPU 所带来的额外解释器开销和“ GIL 颠簸”。 这对于大量使用 Python 运行时的模型尤其重要，包括具有循环层或许多小组件的模型。 初始化 在调用任何其他方法之前，需要使用 torch.distributed.init_process_group() 函数初始化该程序包。 这将阻塞，直到所有进程都已加入。 torch.distributed.init_process_group(backend, init_method=None, timeout=datetime.timedelta(0, 1800), world_size=-1, rank=-1, store=None, group_name='')¶ 初始化默认的分布式进程组，这还将初始化分布式程序包。 There are 2 main ways to initialize a process group: 明确指定store，rank和world_size。 指定init_method(URL 字符串），它指示在何处/如何发现对等方。 (可选）指定rank和world_size，或在 URL 中编码所有必需的参数并忽略它们。 如果两者均未指定，则将init_method假定为“ env：//”。 参数 后端 (str 或 后端)–要使用的后端。 根据构建时配置，有效值包括mpi，gloo和nccl。 该字段应以小写字符串(例如\"gloo\"）形式给出，也可以通过 Backend 属性(例如Backend.GLOO）进行访问。 如果每台具有nccl后端的计算机使用多个进程，则每个进程必须对其使用的每个 GPU 都具有独占访问权限，因为在进程之间共享 GPU 可能会导致死锁。 init_method (str ， 可选）–指定如何初始化进程组的 URL。 如果未指定init_method或store，则默认值为“ env：//”。 与store互斥。 world_size (python：int ， 可选）–参与作业的进程数。 如果指定store，则为必需。 等级 (python：int ， 可选）–当前进程的等级。 如果指定store，则为必需。 存储区(存储区 ， 可选）–所有工作人员均可访问的键/值存储，用于交换连接/地址信息。 与init_method互斥。 超时 (timedelta ， 可选）–针对进程组执行的操作的超时。 默认值等于 30 分钟。 这适用于gloo后端。 对于nccl，仅在环境变量NCCL_BLOCKING_WAIT设置为 1 时适用。 group_name (str ， 可选 ， 不推荐使用）–组名。 要启用backend == Backend.MPI，PyTorch 需要从支持 MPI 的系统上的源代码构建。 NCCL 同样适用。 class torch.distributed.Backend¶ 类似于枚举的可用后端类：GLOO，NCCL 和 MPI。 此类的值是小写字符串，例如\"gloo\"。 可以将它们作为属性来访问，例如Backend.NCCL。 可以直接调用此类来解析字符串，例如Backend(backend_str)将检查backend_str是否有效，如果有效，则返回已解析的小写字符串。 它还接受大写字符串，例如Backend(\"GLOO\")返回\"gloo\"。 注意 条目Backend.UNDEFINED存在，但仅用作某些字段的初始值。 用户既不应直接使用它，也不应该假定它的存在。 torch.distributed.get_backend(group=)¶ 返回给定进程组的后端。 Parameters 组 (ProcessGroup ， 可选）–要处理的过程组。 默认值为常规主流程组。 如果指定了另一个特定组，则调用过程必须是group的一部分。 退货 给定进程组的后端，为小写字符串。 torch.distributed.get_rank(group=)¶ 返回当前进程组的等级 等级是分配给分布式过程组中每个过程的唯一标识符。 它们始终是从 0 到world_size的连续整数。 Parameters 组 (ProcessGroup ， 可选）–要处理的进程组 Returns 进程组-1(如果不属于组）的等级 torch.distributed.get_world_size(group=)¶ 返回当前进程组中的进程数 Parameters group (ProcessGroup__, optional) – The process group to work on Returns 进程组-1 的世界大小，如果不是该组的一部分 torch.distributed.is_initialized()¶ 检查默认进程组是否已初始化 torch.distributed.is_mpi_available()¶ 检查 MPI 后端是否可用。 torch.distributed.is_nccl_available()¶ 检查 NCCL 后端是否可用。 当前支持三种初始化方法： TCP 初始化 有两种使用 TCP 进行初始化的方式，两种方式都需要所有进程都可以访问的网络地址以及所需的world_size。 第一种方法要求指定一个地址，该地址属于等级 0 进程。 此初始化方法要求所有进程都具有手动指定的等级。 请注意，最新的分布式程序包中不再支持多播地址。 group_name也已弃用。 import torch.distributed as dist # Use address of one of the machines dist.init_process_group(backend, init_method='tcp://10.1.1.20:23456', rank=args.rank, world_size=4) 共享文件系统初始化 另一种初始化方法利用了文件系统以及所需的world_size，该文件系统可从组中的所有计算机共享并可见。 该 URL 应该以file://开头，并包含一个指向共享文件系统上不存在的文件(在现有目录中）的路径。 如果文件系统初始化不存在，则会自动创建该文件，但不会删除该文件。 因此，您有责任确保在相同文件路径/名称的下一个 init_process_group() 调用之前清除文件。 请注意，最新的分布式软件包不再支持自动等级分配，并且group_name也已弃用。 警告 此方法假定文件系统支持使用fcntl进行锁定-大多数本地系统和 NFS 都支持它。 Warning 此方法将始终创建文件，并尽力在程序末尾清理并删除文件。 换句话说，使用文件 init 方法进行的每次初始化都需要一个全新的空文件，以使初始化成功。 如果再次使用先前初始化使用的同一文件(碰巧不会被清除），则这是意外行为，通常会导致死锁和失败。 因此，即使此方法将尽最大努力清除文件，但如果自动删除碰巧失败，您有责任确保在训练结束时将文件删除，以防止同一文件被删除。 在下一次再次使用。 如果您计划在同一文件名上多次调用 init_process_group() ，这尤其重要。 换句话说，如果未删除/清除文件，然后对该文件再次调用 init_process_group() ，则可能会失败。 经验法则是，每次调用 init_process_group() 时，请确保文件不存在或为空。 import torch.distributed as dist # rank should always be specified dist.init_process_group(backend, init_method='file:///mnt/nfs/sharedfile', world_size=4, rank=args.rank) 环境变量初始化 该方法将从环境变量中读取配置，从而可以完全自定义如何获取信息。 要设置的变量是： MASTER_PORT-必填； 必须是等级为 0 的计算机上的空闲端口 MASTER_ADDR-必填(0 级除外）； 等级 0 节点的地址 WORLD_SIZE-必填； 可以在此处或在调用 init 函数时进行设置 RANK-必填； 可以在此处或在调用 init 函数时进行设置 等级为 0 的计算机将用于建立所有连接。 这是默认方法，这意味着不必指定init_method(也可以是env://）。 团体 默认情况下，集合体在默认组(也称为世界）上运行，并要求所有进程进入分布式函数调用。 但是，某些工作负载可以从更细粒度的通信中受益。 这是分布式组起作用的地方。 new_group() 功能可用于创建带有所有进程的任意子集的新组。 它返回一个不透明的组句柄，该句柄可以作为group参数提供给所有集合(集合是分布式函数，用于以某些众所周知的编程模式交换信息）。 torch.distributed.new_group(ranks=None, timeout=datetime.timedelta(0, 1800), backend=None)¶ 创建一个新的分布式组。 此功能要求主组中的所有进程(即，属于分布式作业的所有进程）都必须输入此功能，即使它们不会成为该组的成员也是如此。 此外，应在所有过程中以相同顺序创建组。 Parameters 排名(列表 [ python：int ] )–组成员的等级列表。 超时 (timedelta ， 可选）–针对进程组执行的操作的超时。 默认值等于 30 分钟。 这仅适用于gloo后端。 后端 (str 或 后端 ， 可选） –要使用的后端。 根据构建时配置，有效值为gloo和nccl。 默认情况下，使用与全局组相同的后端。 此字段应以小写字符串(例如\"gloo\"）形式给出，也可以通过 Backend 属性(例如Backend.GLOO）进行访问。 Returns 可以分配给集体呼叫的分布式组的句柄。 点对点通讯 torch.distributed.send(tensor, dst, group=, tag=0)¶ 同步发送张量。 Parameters 张量 (tensor)–要发送的张量。 dst (python：int )–目标排名。 group (ProcessGroup__, optional) – The process group to work on 标签 (python：int ， 可选）–与远程 recv 发送匹配的标签 torch.distributed.recv(tensor, src=None, group=, tag=0)¶ 同步接收张量。 Parameters 张量 (tensor)–张量以填充接收到的数据。 src (python：int ， 可选）–源排名。 如果未指定，将从任何进程中接收。 group (ProcessGroup__, optional) – The process group to work on 标记 (python：int ， 可选）–用于将 recv 与远程发送匹配的标记 Returns 发件人等级-1，如果不属于该组 isend() 和 irecv() 在使用时返回分布式请求对象。 通常，此对象的类型是不确定的，因为它们永远不应该手动创建，但是可以保证它们支持两种方法： is_completed()-如果操作完成，则返回 True wait()-将阻止该过程，直到操作完成。 保证is_completed()一旦返回就返回 True。 torch.distributed.isend(tensor, dst, group=, tag=0)¶ 异步发送张量。 Parameters tensor (Tensor) – Tensor to send. dst (python:int) – Destination rank. group (ProcessGroup__, optional) – The process group to work on tag (python:int__, optional) – Tag to match send with remote recv Returns 分布式请求对象。 无，如果不是该组的一部分 torch.distributed.irecv(tensor, src, group=, tag=0)¶ 异步接收张量。 Parameters tensor (Tensor) – Tensor to fill with received data. src (python：int )–源排名。 group (ProcessGroup__, optional) – The process group to work on tag (python:int__, optional) – Tag to match recv with remote send Returns A distributed request object. None, if not part of the group 同步和异步集体操作 每个集体操作功能都支持以下两种操作： 同步操作-async_op设置为 False 时的默认模式。 当函数返回时，可以确保执行了集合操作(​​如果它是 CUDA op，则不一定要完成，因为所有 CUDA ops 都是异步的），并且可以根据集合操作的数据调用任何进一步的函数。 在同步模式下，集合函数不返回任何内容 异步操作-当async_op设置为 True 时。 集合操作函数返回一个分布式请求对象。 通常，您不需要手动创建它，并且可以支持两种方法： is_completed() - returns True if the operation has finished wait()-将阻止该过程，直到操作完成。 集体职能 torch.distributed.broadcast(tensor, src, group=, async_op=False)¶ 向整个组广播张量。 tensor在参与集合的所有进程中必须具有相同数量的元素。 Parameters 张量 (tensor)–如果src是当前进程的等级，则发送数据，否则使用张量保存接收到的数据。 src (python:int) – Source rank. group (ProcessGroup__, optional) – The process group to work on async_op (bool ， 可选）–此 op 是否应为异步 op Returns 异步工作句柄(如果 async_op 设置为 True）。 无，如果不是 async_op 或不是该组的一部分 torch.distributed.all_reduce(tensor, op=ReduceOp.SUM, group=, async_op=False)¶ 减少所有机器上的张量数据，以使所有机器都能得到最终结果。 调用之后，tensor将在所有进程中按位相同。 Parameters 张量 (tensor)–集合的输入和输出。 该功能就地运行。 op (可选）–来自torch.distributed.ReduceOp枚举的值之一。 指定用于逐元素精简的操作。 group (ProcessGroup__, optional) – The process group to work on async_op (bool__, optional) – Whether this op should be an async op Returns Async work handle, if async_op is set to True. None, if not async_op or if not part of the group torch.distributed.reduce(tensor, dst, op=ReduceOp.SUM, group=, async_op=False)¶ 减少所有机器上的张量数据。 只有等级为dst的进程才能收到最终结果。 Parameters tensor (Tensor) – Input and output of the collective. The function operates in-place. dst (python：int )–目标排名 op (optional) – One of the values from torch.distributed.ReduceOp enum. Specifies an operation used for element-wise reductions. group (ProcessGroup__, optional) – The process group to work on async_op (bool__, optional) – Whether this op should be an async op Returns Async work handle, if async_op is set to True. None, if not async_op or if not part of the group torch.distributed.all_gather(tensor_list, tensor, group=, async_op=False)¶ 在列表中收集整个组的张量。 Parameters tensor_list (列表 [ tensor ] )–输出列表。 它应包含正确大小的张量以用于集合的输出。 张量 (tensor)–要从当前进程广播的张量。 group (ProcessGroup__, optional) – The process group to work on async_op (bool__, optional) – Whether this op should be an async op Returns Async work handle, if async_op is set to True. None, if not async_op or if not part of the group torch.distributed.gather(tensor, gather_list=None, dst=0, group=, async_op=False)¶ 在单个过程中收集张量列表。 Parameters 张量 (tensor)–输入张量。 collect_list (列表 [ tensor ] ， 可选）–用于收集数据的适当大小的张量列表(默认为 None，必须在目标等级上指定） dst (python：int ， 可选）–目标排名(默认为 0） group (ProcessGroup__, optional) – The process group to work on async_op (bool__, optional) – Whether this op should be an async op Returns Async work handle, if async_op is set to True. None, if not async_op or if not part of the group torch.distributed.scatter(tensor, scatter_list=None, src=0, group=, async_op=False)¶ 将张量列表分散到组中的所有进程。 每个进程将仅接收一个张量并将其数据存储在tensor参数中。 Parameters 张量 (tensor)–输出张量。 scatter_list (列表 [ tensor ] )–分散的张量列表 (默认为无，必须在源排名上指定） src (python：int )–源排名(默认为 0） group (ProcessGroup__, optional) – The process group to work on async_op (bool__, optional) – Whether this op should be an async op Returns Async work handle, if async_op is set to True. None, if not async_op or if not part of the group torch.distributed.barrier(group=, async_op=False)¶ 同步所有进程。 如果 async_op 为 False，或者在 wait(）上调用了异步工作句柄，则该集合将阻塞进程，直到整个组都进入该函数。 Parameters group (ProcessGroup__, optional) – The process group to work on async_op (bool__, optional) – Whether this op should be an async op Returns Async work handle, if async_op is set to True. None, if not async_op or if not part of the group class torch.distributed.ReduceOp¶ 可用还原操作的类枚举类：SUM，PRODUCT，MIN，MAX，BAND，BOR和BXOR。 此类的值可以作为属性访问，例如ReduceOp.SUM。 它们用于指定减少集合体的策略，例如 reduce() ， all_reduce_multigpu() 等。 成员： 和 产品 最小 最大值 带 BOR 异或 class torch.distributed.reduce_op¶ 减少操作的不推荐枚举类：SUM，PRODUCT，MIN和MAX。 建议改用 ReduceOp 。 多 GPU 集合功能 如果每个节点上有多个 GPU，则在使用 NCCL 和 Gloo 后端时， broadcast_multigpu() all_reduce_multigpu() reduce_multigpu() 和 all_gather_multigpu() 支持在每个节点内的多个 GPU 之间进行分布式集体操作。 这些功能可以潜在地改善整体分布式训练性能，并且可以通过传递张量列表轻松使用。 传递的张量列表中的每个张量必须位于调用该函数的主机的单独 GPU 设备上。 请注意，在所有分布式过程中，张量列表的长度必须相同。 另请注意，当前只有 NCCL 后端支持多 GPU 集合功能。 例如，如果我们用于分布式训练的系统有 2 个节点，每个节点都有 8 个 GPU。 在 16 个 GPU 的每个 GPU 上，都有一个我们想全部减少的张量。 以下代码可以作为参考： 在节点 0 上运行的代码 import torch import torch.distributed as dist dist.init_process_group(backend=\"nccl\", init_method=\"file:///distributed_test\", world_size=2, rank=0) tensor_list = [] for dev_idx in range(torch.cuda.device_count()): tensor_list.append(torch.FloatTensor([1]).cuda(dev_idx)) dist.all_reduce_multigpu(tensor_list) 在节点 1 上运行的代码 import torch import torch.distributed as dist dist.init_process_group(backend=\"nccl\", init_method=\"file:///distributed_test\", world_size=2, rank=1) tensor_list = [] for dev_idx in range(torch.cuda.device_count()): tensor_list.append(torch.FloatTensor([1]).cuda(dev_idx)) dist.all_reduce_multigpu(tensor_list) 调用之后，两个节点上的所有 16 张量将具有全部约简值 16 torch.distributed.broadcast_multigpu(tensor_list, src, group=, async_op=False, src_tensor=0)¶ 将张量广播到整个组，每个节点具有多个 GPU 张量。 tensor在参与集合的所有进程的所有 GPU 中必须具有相同数量的元素。 列表中的每个张量必须在不同的 GPU 上 当前仅支持 nccl 和 gloo 后端张量应仅是 GPU 张量 Parameters tensor_list (列表 [ tensor ] )–参与集体的张量 操作。 如果src是等级，则tensor_list(tensor_list[src_tensor]）的指定src_tensor元素将在 src 进程中广播给所有其他张量(在不同 GPU 上），而在其他非张量中tensor_list的所有张量 -src 进程。 您还需要确保所有调用此函数的分布式进程的len(tensor_list)相同。 src (python:int) – Source rank. group (ProcessGroup__, optional) – The process group to work on async_op (bool__, optional) – Whether this op should be an async op src_tensor (python：int ， 可选）–在tensor_list内的源张量等级 Returns Async work handle, if async_op is set to True. None, if not async_op or if not part of the group torch.distributed.all_reduce_multigpu(tensor_list, op=ReduceOp.SUM, group=, async_op=False)¶ 减少所有机器上的张量数据，以使所有机器都能得到最终结果。 此功能可减少每个节点上的张量数量，而每个张量位于不同的 GPU 上。 因此，张量列表中的输入张量必须是 GPU 张量。 同样，张量列表中的每个张量都需要驻留在不同的 GPU 上。 调用之后，tensor_list中的所有tensor在所有进程中都将按位相同。 当前仅支持 nccl 和 gloo 后端张量应仅是 GPU 张量 Parameters 列表(tensor）–集合的输入和输出张量的列表。 该函数在原位运行，并且要求每个张量都是不同 GPU 上的 GPU 张量。 您还需要确保所有调用此函数的分布式进程的len(tensor_list)相同。 op (optional) – One of the values from torch.distributed.ReduceOp enum. Specifies an operation used for element-wise reductions. group (ProcessGroup__, optional) – The process group to work on async_op (bool__, optional) – Whether this op should be an async op Returns Async work handle, if async_op is set to True. None, if not async_op or if not part of the group torch.distributed.reduce_multigpu(tensor_list, dst, op=ReduceOp.SUM, group=, async_op=False, dst_tensor=0)¶ 减少所有计算机上多个 GPU 上的张量数据。 tensor_list中的每个张量应驻留在单独的 GPU 上 排名为dst的进程中只有tensor_list[dst_tensor]的 GPU 会收到最终结果。 当前仅支持 nccl 后端张量应仅是 GPU 张量 Parameters tensor_list (列表 [ tensor ] )–输入和输出的 GPU 张量 集体。 该功能就地运行。 您还需要确保所有调用此函数的分布式进程的len(tensor_list)相同。 dst (python:int) – Destination rank op (optional) – One of the values from torch.distributed.ReduceOp enum. Specifies an operation used for element-wise reductions. group (ProcessGroup__, optional) – The process group to work on async_op (bool__, optional) – Whether this op should be an async op dst_tensor (python：int ， 可选）– tensor_list中的目标张量等级 Returns 异步工作句柄(如果 async_op 设置为 True）。 无，否则 torch.distributed.all_gather_multigpu(output_tensor_lists, input_tensor_list, group=, async_op=False)¶ 在列表中收集整个组的张量。 tensor_list中的每个张量应驻留在单独的 GPU 上 Only nccl backend is currently supported tensors should only be GPU tensors Parameters output_tensor_lists (列表 [ 列表 [ Tensor [ ] ] )– 输出列表。 它应该在每个 GPU 上包含正确大小的张量，以用于集合的输出，例如 output_tensor_lists[i]包含位于input_tensor_list[i]的 GPU 上的 all_gather 结果。 请注意，output_tensor_lists的每个元素的大小均为world_size * len(input_tensor_list)，因为该函数都从组中的每个 GPU 收集结果。 要解释output_tensor_lists[i]的每个元素，请注意，排名为 k 的input_tensor_list[j]将出现在output_tensor_lists[i][k * world_size + j]中 还要注意，对于所有调用此函数的分布式进程，len(output_tensor_lists)和output_tensor_lists中每个元素的大小(每个元素是一个列表，因此len(output_tensor_lists[i])）必须相同。 input_tensor_list (列表 [ tensor ] )–张量列表(不同） GPU）从当前进程中广播。 注意，对于所有调用此函数的分布式进程，len(input_tensor_list)必须相同。 group (ProcessGroup__, optional) – The process group to work on async_op (bool__, optional) – Whether this op should be an async op Returns Async work handle, if async_op is set to True. None, if not async_op or if not part of the group 启动实用程序 torch.distributed 程序包还在 torch.distributed.launch 中提供了启动实用程序。 此帮助程序实用程序可用于为每个节点启动多个进程以进行分布式训练。 该实用程序还支持 python2 和 python3。 Spawn 实用程序 Multiprocessing 软件包-Torch.multiprocessing 软件包还在 torch.multiprocessing.spawn() 中提供了spawn功能。 此辅助函数可用于产生多个进程。 它通过传入要运行的函数并产生 N 个进程来运行它而起作用。 这也可以用于多进程分布式训练。 有关如何使用它的参考，请参考 PyTorch 示例-ImageNet 实现 请注意，此功能需要 Python 3.4 或更高版本。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"82.html":{"url":"82.html","title":"概率分布-torch分布","keywords":"","body":"概率分布-torch分布 原文： https://pytorch.org/docs/stable/distributions.html distributions程序包包含可参数化的概率分布和采样函数。 这允许构造用于优化的随机计算图和随机梯度估计器。 该软件包通常遵循 TensorFlow Distributions 软件包的设计。 无法直接反向传播随机样本。 但是，有两种主要的方法可以创建可以反向传播的代理功能。 它们是得分函数估计器/似然比估计器/ REINFORCE 和路径导数估计器。 REINFORCE 通常被认为是强化学习中策略梯度方法的基础，而路径派生估计器通常出现在变分自动编码器的重新参数化技巧中。 虽然得分函数仅需要样本的值，但路径导数需要导数。 下一节将在强化学习示例中讨论这两个方面。 有关更多详细信息，请参见使用随机计算图的梯度估计。 评分功能 当概率密度函数的参数可微时，我们只需要sample()和log_prob()即可实现 REINFORCE： 其中是参数，是学习率，是奖励，是在给定策略的状态下在状态下采取行动的概率。 在实践中，我们将从网络的输出中采样一个动作，将该动作应用于环境中，然后使用log_prob构造等效的损失函数。 请注意，由于优化程序使用梯度下降，因此我们使用负值，而上述规则假定梯度上升。 使用分类策略，用于实现 REINFORCE 的代码如下： probs = policy_network(state) # Note that this is equivalent to what used to be called multinomial m = Categorical(probs) action = m.sample() next_state, reward = env.step(action) loss = -m.log_prob(action) * reward loss.backward() 路径导数 实现这些随机/策略梯度的另一种方法是使用rsample()方法中的重新参数化技巧，其中可以通过无参数随机变量的参数化确定性函数构造参数化随机变量。 因此，重新参数化的样本变得可微。 用于实现按路径导数的代码如下： params = policy_network(state) m = Normal(*params) # Any distribution with .has_rsample == True could work based on the application action = m.rsample() next_state, reward = env.step(action) # Assuming that reward is differentiable loss = -reward loss.backward() 分配 class torch.distributions.distribution.Distribution(batch_shape=torch.Size([]), event_shape=torch.Size([]), validate_args=None)¶ 基数：object 分布是概率分布的抽象基类。 property arg_constraints¶ 返回从参数名称到 Constraint 对象的字典，此分布的每个参数都应满足该对象。 不是 tensor 的 Args 不必出现在此字典中。 property batch_shape¶ 返回批处理参数的形状。 cdf(value)¶ 返回以值评估的累积密度/质量函数。 参数 值 (tensor)– entropy()¶ 返回分配的熵，在 batch_shape 中批处理。 退货 形状 batch_shape 的张量。 enumerate_support(expand=True)¶ 返回包含离散分布支持的所有值的张量。 结果将在维度 0 上枚举，因此结果的形状将为(基数）+ batch_shape + event_shape (其中对于单变量分布，其中 event_shape =(））。 注意，这枚举所有以锁步 [[0，0]，[1，1]，…] 组成的张量。 在 expand = False 的情况下，枚举沿暗淡 0 进行，但其余批次尺寸为单例尺寸 [[0]，[1]，.. 。 要遍历整个笛卡尔积，请使用 itertools.product(m.enumerate_support(））。 Parameters 扩展 (bool )–是否扩展对批次暗淡的支持以匹配发行版的 batch_shape 。 Returns 张量在维度 0 上迭代。 property event_shape¶ 返回单个样品的形状(不分批）。 expand(batch_shape, _instance=None)¶ 返回一个新的分发实例(或填充派生类提供的现有实例），其批次尺寸扩展为 batchshape 。 此方法在发行版的参数上调用 expand 。 因此，这不会为扩展的分发实例分配新的内存。 此外，首次创建实例时，此操作不会在 _init.py 中重复任何参数检查或参数广播。 Parameters batch_shape (torch尺寸）–所需的扩展尺寸。 _instance -子类提供的需要重写 .expand 的新实例。 Returns 具有批次尺寸的新分发实例已扩展为 batch_size 。 icdf(value)¶ 返回以值评估的逆累积密度/质量函数。 Parameters value (Tensor) – log_prob(value)¶ 返回以值评估的概率密度/质量函数的对数。 Parameters value (Tensor) – property mean¶ 返回分布的平均值。 perplexity()¶ 返回分配的复杂性，按 batch_shape 批处理。 Returns Tensor of shape batch_shape. rsample(sample_shape=torch.Size([]))¶ 如果分配了分布参数，则生成一个 sample_shape 形状的重新参数化样本或 sample_shape 形状的一批重新参数化样本。 sample(sample_shape=torch.Size([]))¶ 如果分配参数是批处理的，则生成 sample_shape 形状的样本或 sample_shape 形状的样本批。 sample_n(n)¶ 如果分配了分布参数，则生成 n 个样本或 n 个样本批次。 property stddev¶ 返回分布的标准偏差。 property support¶ 返回表示此发行版支持的 Constraint 对象。 property variance¶ 返回分布的方差。 指数家族 class torch.distributions.exp_family.ExponentialFamily(batch_shape=torch.Size([]), event_shape=torch.Size([]), validate_args=None)¶ 碱基： torch.distributions.distribution.Distribution ExponentialFamily 是属于指数族的概率分布的抽象基类，其概率质量/密度函数的形式如下 其中表示自然参数，表示足够的统计量，是给定族的对数归一化函数，是载波测量。 注意 此类是分布类和属于指数家族的分布之间的中介，主要是检查 .entropy(）和分析性 KL 散度方法的正确性。 我们使用此类使用 AD 框架和 Bregman 散度来计算熵和 KL 散度(由 Frank Nielsen 和 Richard Nock 提供，指数族的熵和交叉熵）。 entropy()¶ 使用对数归一化器的 Bregman 散度来计算熵的方法。 伯努利 class torch.distributions.bernoulli.Bernoulli(probs=None, logits=None, validate_args=None)¶ 碱基： torch.distributions.exp_family.ExponentialFamily 创建一个由 probs 或 logits 参数化的伯努利分布(但不能同时包含两者）。 样本为二进制(0 或 1）。 它们以概率 p 取值 1 ，以概率 1 -p 取值 0 。 例： >>> m = Bernoulli(torch.tensor([0.3])) >>> m.sample() # 30% chance 1; 70% chance 0 tensor([ 0.]) Parameters 概率(编号 ， tensor)–采样 1 的概率 对数(编号 ， tensor)–采样的对数奇数 1 arg_constraints = {'logits': Real(), 'probs': Interval(lower_bound=0.0, upper_bound=1.0)}¶ entropy()¶ enumerate_support(expand=True)¶ expand(batch_shape, _instance=None)¶ has_enumerate_support = True¶ log_prob(value)¶ logits¶ property mean¶ property param_shape¶ probs¶ sample(sample_shape=torch.Size([]))¶ support = Boolean()¶ property variance¶ 贝塔 class torch.distributions.beta.Beta(concentration1, concentration0, validate_args=None)¶ Bases: torch.distributions.exp_family.ExponentialFamily 由 concentration1 和 concentration0 参数化的 Beta 分布。 Example: >>> m = Beta(torch.tensor([0.5]), torch.tensor([0.5])) >>> m.sample() # Beta distributed with concentration concentration1 and concentration0 tensor([ 0.1046]) Parameters 浓度 1 (python：float 或 tensor)–分布的第一浓度参数(通常称为浓度参数） α） 浓度 0 (python：float 或 tensor)–分布的第二个浓度参数(通常称为 Beta） arg_constraints = {'concentration0': GreaterThan(lower_bound=0.0), 'concentration1': GreaterThan(lower_bound=0.0)}¶ property concentration0¶ property concentration1¶ entropy()¶ expand(batch_shape, _instance=None)¶ has_rsample = True¶ log_prob(value)¶ property mean¶ rsample(sample_shape=())¶ support = Interval(lower_bound=0.0, upper_bound=1.0)¶ property variance¶ 二项式 class torch.distributions.binomial.Binomial(total_count=1, probs=None, logits=None, validate_args=None)¶ Bases: torch.distributions.distribution.Distribution 创建由total_count和 probs 或 logits (但不是全部）参数化的二项分布。 total_count必须可与 probs / logits 广播。 Example: >>> m = Binomial(100, torch.tensor([0 , .2, .8, 1])) >>> x = m.sample() tensor([ 0., 22., 71., 100.]) >>> m = Binomial(torch.tensor([[5.], [10.]]), torch.tensor([0.5, 0.8])) >>> x = m.sample() tensor([[ 4., 5.], [ 7., 6.]]) Parameters total_count (python：int 或 tensor)–伯努利试验次数 概率 (tensor)–事件概率 logits (tensor)–事件对数 arg_constraints = {'logits': Real(), 'probs': Interval(lower_bound=0.0, upper_bound=1.0), 'total_count': IntegerGreaterThan(lower_bound=0)}¶ enumerate_support(expand=True)¶ expand(batch_shape, _instance=None)¶ has_enumerate_support = True¶ log_prob(value)¶ logits¶ property mean¶ property param_shape¶ probs¶ sample(sample_shape=torch.Size([]))¶ property support¶ property variance¶ 分类的 class torch.distributions.categorical.Categorical(probs=None, logits=None, validate_args=None)¶ Bases: torch.distributions.distribution.Distribution 创建由 probs 或 logits (但不是全部）参数化的分类分布。 Note 等效于 torch.multinomial() 采样的分布。 样本是来自的整数，其中 K 为probs.size(-1)。 如果 probs 为一维且长度为 K ，则每个元素都是在该索引处采样类别的相对概率。 如果 probs 为 2D，则将其视为一批相对概率向量。 Note probs 必须为非负数，有限且总和为非零，并且将其归一化为 1。 另请参见： torch.multinomial() Example: >>> m = Categorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ])) >>> m.sample() # equal probability of 0, 1, 2, 3 tensor(3) Parameters 概率 (tensor)–事件概率 logits (tensor)–事件对数 arg_constraints = {'logits': Real(), 'probs': Simplex()}¶ entropy()¶ enumerate_support(expand=True)¶ expand(batch_shape, _instance=None)¶ has_enumerate_support = True¶ log_prob(value)¶ logits¶ property mean¶ property param_shape¶ probs¶ sample(sample_shape=torch.Size([]))¶ property support¶ property variance¶ 柯西 class torch.distributions.cauchy.Cauchy(loc, scale, validate_args=None)¶ Bases: torch.distributions.distribution.Distribution 来自柯西(洛伦兹）分布的样本。 具有均值 0 的独立正态分布随机变量的比率分布遵循柯西分布。 Example: >>> m = Cauchy(torch.tensor([0.0]), torch.tensor([1.0])) >>> m.sample() # sample from a Cauchy distribution with loc=0 and scale=1 tensor([ 2.3214]) Parameters loc (python：float 或 tensor)–分布的中位数。 比例尺 (python：float 或 tensor)–半宽度为一半的最大值。 arg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}¶ cdf(value)¶ entropy()¶ expand(batch_shape, _instance=None)¶ has_rsample = True¶ icdf(value)¶ log_prob(value)¶ property mean¶ rsample(sample_shape=torch.Size([]))¶ support = Real()¶ property variance¶ 22 class torch.distributions.chi2.Chi2(df, validate_args=None)¶ 碱基： torch.distributions.gamma.Gamma 创建通过形状参数 df 参数化的 Chi2 分布。 这完全等同于Gamma(alpha=0.5*df, beta=0.5) Example: >>> m = Chi2(torch.tensor([1.0])) >>> m.sample() # Chi2 distributed with shape df=1 tensor([ 0.1046]) Parameters df (python：float 或 tensor)–分布的形状参数 arg_constraints = {'df': GreaterThan(lower_bound=0.0)}¶ property df¶ expand(batch_shape, _instance=None)¶ Dirichlet class torch.distributions.dirichlet.Dirichlet(concentration, validate_args=None)¶ Bases: torch.distributions.exp_family.ExponentialFamily 创建通过浓度concentration参数化的 Dirichlet 分布。 Example: >>> m = Dirichlet(torch.tensor([0.5, 0.5])) >>> m.sample() # Dirichlet distributed with concentrarion concentration tensor([ 0.1046, 0.8954]) Parameters 浓度 (tensor)–浓度参数分布(通常称为 alpha） arg_constraints = {'concentration': GreaterThan(lower_bound=0.0)}¶ entropy()¶ expand(batch_shape, _instance=None)¶ has_rsample = True¶ log_prob(value)¶ property mean¶ rsample(sample_shape=())¶ support = Simplex()¶ property variance¶ 指数的 class torch.distributions.exponential.Exponential(rate, validate_args=None)¶ Bases: torch.distributions.exp_family.ExponentialFamily 创建由rate参数化的指数分布。 Example: >>> m = Exponential(torch.tensor([1.0])) >>> m.sample() # Exponential distributed with rate=1 tensor([ 0.1046]) Parameters 比率 (python：float 或 tensor)–比率= 1 /分布范围 arg_constraints = {'rate': GreaterThan(lower_bound=0.0)}¶ cdf(value)¶ entropy()¶ expand(batch_shape, _instance=None)¶ has_rsample = True¶ icdf(value)¶ log_prob(value)¶ property mean¶ rsample(sample_shape=torch.Size([]))¶ property stddev¶ support = GreaterThan(lower_bound=0.0)¶ property variance¶ FisherSnedecor class torch.distributions.fishersnedecor.FisherSnedecor(df1, df2, validate_args=None)¶ Bases: torch.distributions.distribution.Distribution 创建由df1和df2参数化的 Fisher-Snedecor 分布。 Example: >>> m = FisherSnedecor(torch.tensor([1.0]), torch.tensor([2.0])) >>> m.sample() # Fisher-Snedecor-distributed with df1=1 and df2=2 tensor([ 0.2453]) Parameters df1 (python：float 或 tensor)–自由度参数 1 df2 (python：float 或 tensor)–自由度参数 2 arg_constraints = {'df1': GreaterThan(lower_bound=0.0), 'df2': GreaterThan(lower_bound=0.0)}¶ expand(batch_shape, _instance=None)¶ has_rsample = True¶ log_prob(value)¶ property mean¶ rsample(sample_shape=torch.Size([]))¶ support = GreaterThan(lower_bound=0.0)¶ property variance¶ 伽玛 class torch.distributions.gamma.Gamma(concentration, rate, validate_args=None)¶ Bases: torch.distributions.exp_family.ExponentialFamily 创建通过形状concentration和rate参数化的 Gamma 分布。 Example: >>> m = Gamma(torch.tensor([1.0]), torch.tensor([1.0])) >>> m.sample() # Gamma distributed with concentration=1 and rate=1 tensor([ 0.1046]) Parameters 浓度 (python：float 或 tensor)–分布形状参数(通常称为 alpha ) 比率 (python：float 或 tensor)–比率= 1 /分布比例(通常称为 到 beta） arg_constraints = {'concentration': GreaterThan(lower_bound=0.0), 'rate': GreaterThan(lower_bound=0.0)}¶ entropy()¶ expand(batch_shape, _instance=None)¶ has_rsample = True¶ log_prob(value)¶ property mean¶ rsample(sample_shape=torch.Size([]))¶ support = GreaterThan(lower_bound=0.0)¶ property variance¶ 几何 class torch.distributions.geometric.Geometric(probs=None, logits=None, validate_args=None)¶ Bases: torch.distributions.distribution.Distribution 创建由 probs 参数化的几何分布，其中 probs 是伯努利试验成功的概率。 它表示在 Bernoulli 试验中，第一个试验失败后才看到成功的可能性。 样本是非负整数[0，）。 Example: >>> m = Geometric(torch.tensor([0.3])) >>> m.sample() # underlying Bernoulli has 30% chance 1; 70% chance 0 tensor([ 2.]) Parameters 概率(编号 ， tensor)–采样 1 的概率。 必须在范围内(0，1] 对数(编号 ， tensor)–采样的对数奇数 1 。 arg_constraints = {'logits': Real(), 'probs': Interval(lower_bound=0.0, upper_bound=1.0)}¶ entropy()¶ expand(batch_shape, _instance=None)¶ log_prob(value)¶ logits¶ property mean¶ probs¶ sample(sample_shape=torch.Size([]))¶ support = IntegerGreaterThan(lower_bound=0)¶ property variance¶ 古贝尔 class torch.distributions.gumbel.Gumbel(loc, scale, validate_args=None)¶ 碱基： torch.distributions.transformed_distribution.TransformedDistribution 来自 Gumbel 分布的样本。 例子： >>> m = Gumbel(torch.tensor([1.0]), torch.tensor([2.0])) >>> m.sample() # sample from Gumbel distribution with loc=1, scale=2 tensor([ 1.0124]) Parameters loc (python：float 或 tensor)–分布的位置参数 标度 (python：float 或 tensor)–分布的标度参数 arg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}¶ entropy()¶ expand(batch_shape, _instance=None)¶ log_prob(value)¶ property mean¶ property stddev¶ support = Real()¶ property variance¶ 半漂亮 class torch.distributions.half_cauchy.HalfCauchy(scale, validate_args=None)¶ Bases: torch.distributions.transformed_distribution.TransformedDistribution 创建一个以标度为参数的半正态分布，其中： X ~ Cauchy(0, scale) Y = |X| ~ HalfCauchy(scale) Example: >>> m = HalfCauchy(torch.tensor([1.0])) >>> m.sample() # half-cauchy distributed with scale=1 tensor([ 2.3214]) Parameters 比例尺 (python：float 或 tensor)–完整柯西分布的比例 arg_constraints = {'scale': GreaterThan(lower_bound=0.0)}¶ cdf(value)¶ entropy()¶ expand(batch_shape, _instance=None)¶ has_rsample = True¶ icdf(prob)¶ log_prob(value)¶ property mean¶ property scale¶ support = GreaterThan(lower_bound=0.0)¶ property variance¶ 半普通 class torch.distributions.half_normal.HalfNormal(scale, validate_args=None)¶ Bases: torch.distributions.transformed_distribution.TransformedDistribution Creates a half-normal distribution parameterized by scale where: X ~ Normal(0, scale) Y = |X| ~ HalfNormal(scale) Example: >>> m = HalfNormal(torch.tensor([1.0])) >>> m.sample() # half-normal distributed with scale=1 tensor([ 0.1046]) Parameters 标度 (python：float 或 tensor)–完全正态分布的标度 arg_constraints = {'scale': GreaterThan(lower_bound=0.0)}¶ cdf(value)¶ entropy()¶ expand(batch_shape, _instance=None)¶ has_rsample = True¶ icdf(prob)¶ log_prob(value)¶ property mean¶ property scale¶ support = GreaterThan(lower_bound=0.0)¶ property variance¶ 独立 class torch.distributions.independent.Independent(base_distribution, reinterpreted_batch_ndims, validate_args=None)¶ Bases: torch.distributions.distribution.Distribution 将某个分发的一些批次模糊重新解释为事件暗淡。 这对于更改 log_prob() 的结果形状非常有用。 例如，要创建与多变量正态分布具有相同形状的对角正态分布(因此它们是可互换的），您可以： >>> loc = torch.zeros(3) >>> scale = torch.ones(3) >>> mvn = MultivariateNormal(loc, scale_tril=torch.diag(scale)) >>> [mvn.batch_shape, mvn.event_shape] [torch.Size(()), torch.Size((3,))] >>> normal = Normal(loc, scale) >>> [normal.batch_shape, normal.event_shape] [torch.Size((3,)), torch.Size(())] >>> diagn = Independent(normal, 1) >>> [diagn.batch_shape, diagn.event_shape] [torch.Size(()), torch.Size((3,))] Parameters base_distribution (torch.分发。分发。分发)–基本分发 reinterpreted_batch_ndims (python：int )–要重新解释为事件暗淡的批暗淡数量 arg_constraints = {}¶ entropy()¶ enumerate_support(expand=True)¶ expand(batch_shape, _instance=None)¶ property has_enumerate_support¶ property has_rsample¶ log_prob(value)¶ property mean¶ rsample(sample_shape=torch.Size([]))¶ sample(sample_shape=torch.Size([]))¶ property support¶ property variance¶ 拉普拉斯 class torch.distributions.laplace.Laplace(loc, scale, validate_args=None)¶ Bases: torch.distributions.distribution.Distribution 创建由loc和：attr：'scale'参数化的拉普拉斯分布。 Example: >>> m = Laplace(torch.tensor([0.0]), torch.tensor([1.0])) >>> m.sample() # Laplace distributed with loc=0, scale=1 tensor([ 0.1046]) Parameters loc (python：float 或 tensor)–分布的平均值 规模 (python：float 或 tensor)–分布规模 arg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}¶ cdf(value)¶ entropy()¶ expand(batch_shape, _instance=None)¶ has_rsample = True¶ icdf(value)¶ log_prob(value)¶ property mean¶ rsample(sample_shape=torch.Size([]))¶ property stddev¶ support = Real()¶ property variance¶ 对数正态 class torch.distributions.log_normal.LogNormal(loc, scale, validate_args=None)¶ Bases: torch.distributions.transformed_distribution.TransformedDistribution 创建由 loc 和 scale 参数化的对数正态分布，其中： X ~ Normal(loc, scale) Y = exp(X) ~ LogNormal(loc, scale) Example: >>> m = LogNormal(torch.tensor([0.0]), torch.tensor([1.0])) >>> m.sample() # log-normal distributed with mean=0 and stddev=1 tensor([ 0.1046]) Parameters loc (python：float 或 tensor)–分布对数的平均值 比例尺 (python：float 或 tensor)–分布对数的标准偏差 arg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}¶ entropy()¶ expand(batch_shape, _instance=None)¶ has_rsample = True¶ property loc¶ property mean¶ property scale¶ support = GreaterThan(lower_bound=0.0)¶ property variance¶ LowRankMultivariateNormal class torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal(loc, cov_factor, cov_diag, validate_args=None)¶ Bases: torch.distributions.distribution.Distribution 使用协方差矩阵创建具有由cov_factor和cov_diag参数化的低秩形式的多元正态分布： covariance_matrix = cov_factor @ cov_factor.T + cov_diag 例 >>> m = LowRankMultivariateNormal(torch.zeros(2), torch.tensor([1, 0]), torch.tensor([1, 1])) >>> m.sample() # normally distributed with mean=`[0,0]`, cov_factor=`[1,0]`, cov_diag=`[1,1]` tensor([-0.2102, -0.5429]) Parameters loc (tensor)–形状为 batch_shape + event_shape 的分布平均值 cov_factor (tensor)–形状为的协方差矩阵的低秩形式的因子部分 batch_shape + event_shape +(rank，） cov_diag (tensor)–形状为 batch_shape + event_shape 的协方差矩阵的低秩形式的对角线部分 Note 由于伍德伯里矩阵恒等式和 矩阵行列式引理。 由于有了这些公式，我们只需要计算小尺寸“电容”矩阵的行列式和逆式： capacitance = I + cov_factor.T @ inv(cov_diag) @ cov_factor arg_constraints = {'cov_diag': GreaterThan(lower_bound=0.0), 'cov_factor': Real(), 'loc': Real()}¶ covariance_matrix¶ entropy()¶ expand(batch_shape, _instance=None)¶ has_rsample = True¶ log_prob(value)¶ property mean¶ precision_matrix¶ rsample(sample_shape=torch.Size([]))¶ scale_tril¶ support = Real()¶ variance¶ 多项式 class torch.distributions.multinomial.Multinomial(total_count=1, probs=None, logits=None, validate_args=None)¶ Bases: torch.distributions.distribution.Distribution 创建由total_count和 probs 或 logits (但不是全部）参数化的多项式分布。 probs 的最内维度在类别上进行索引。 所有其他尺寸均按批次编制索引。 请注意，如果仅调用 log_prob() ，则无需指定total_count(请参见下面的示例） Note probs 必须为非负数，有限且总和为非零，并且将其归一化为 1。 对于所有参数和样本， sample() 需要一个共享的 total_count 。 log_prob() 允许每个参数和样本使用不同的 total_count 。 Example: >>> m = Multinomial(100, torch.tensor([ 1., 1., 1., 1.])) >>> x = m.sample() # equal probability of 0, 1, 2, 3 tensor([ 21., 24., 30., 25.]) >>> Multinomial(probs=torch.tensor([1., 1., 1., 1.])).log_prob(x) tensor([-4.1338]) Parameters total_count (python：int )–试用次数 probs (Tensor) – event probabilities logits (tensor)–事件日志概率 arg_constraints = {'logits': Real(), 'probs': Simplex()}¶ expand(batch_shape, _instance=None)¶ log_prob(value)¶ property logits¶ property mean¶ property param_shape¶ property probs¶ sample(sample_shape=torch.Size([]))¶ property support¶ property variance¶ 多元正态 class torch.distributions.multivariate_normal.MultivariateNormal(loc, covariance_matrix=None, precision_matrix=None, scale_tril=None, validate_args=None)¶ Bases: torch.distributions.distribution.Distribution 创建由均值向量和协方差矩阵参数化的多元正态(也称为高斯）分布。 可以使用正定协方差矩阵或正定精度矩阵或具有正值对角线项的下三角矩阵来参数化多元正态分布，例如。 该三角矩阵可以通过例如 协方差的 Cholesky 分解。 Example >>> m = MultivariateNormal(torch.zeros(2), torch.eye(2)) >>> m.sample() # normally distributed with mean=`[0,0]` and covariance_matrix=`I` tensor([-0.2102, -0.5429]) Parameters loc (tensor)–分布的均值 covariance_matrix (tensor)–正定协方差矩阵 precision_matrix (tensor)–正定精度矩阵 scale_tril (tensor)–协方差的下三角因子，对角线为正值 Note 只能指定 covariance_matrix 或 precision_matrix 或 scale_tril 中的一个。 使用 scale_tril 会更高效：所有内部计算都基于 scale_tril 。 如果改为通过 covariance_matrix 或 precision_matrix ，则仅用于使用 Cholesky 分解来计算相应的下三角矩阵。 arg_constraints = {'covariance_matrix': PositiveDefinite(), 'loc': RealVector(), 'precision_matrix': PositiveDefinite(), 'scale_tril': LowerCholesky()}¶ covariance_matrix¶ entropy()¶ expand(batch_shape, _instance=None)¶ has_rsample = True¶ log_prob(value)¶ property mean¶ precision_matrix¶ rsample(sample_shape=torch.Size([]))¶ scale_tril¶ support = Real()¶ property variance¶ 负二项式 class torch.distributions.negative_binomial.NegativeBinomial(total_count, probs=None, logits=None, validate_args=None)¶ Bases: torch.distributions.distribution.Distribution 创建负二项式分布，即在total_count失败之前，成功的独立且相同的 Bernoulli 试验次数的分布。 每个伯努利试验成功的概率为 probs 。 Parameters total_count (python：float 或 tensor)–伯努利试验阴性的非负数停止， 尽管该分布对于实际值计数仍然有效 概率 (tensor)–半开放时间间隔[0，1）成功的事件概率 logits (tensor)–成功概率的事件对数 arg_constraints = {'logits': Real(), 'probs': HalfOpenInterval(lower_bound=0.0, upper_bound=1.0), 'total_count': GreaterThanEq(lower_bound=0)}¶ expand(batch_shape, _instance=None)¶ log_prob(value)¶ logits¶ property mean¶ property param_shape¶ probs¶ sample(sample_shape=torch.Size([]))¶ support = IntegerGreaterThan(lower_bound=0)¶ property variance¶ 正常 class torch.distributions.normal.Normal(loc, scale, validate_args=None)¶ Bases: torch.distributions.exp_family.ExponentialFamily 创建由loc和scale参数化的正态(也称为高斯）分布。 Example: >>> m = Normal(torch.tensor([0.0]), torch.tensor([1.0])) >>> m.sample() # normally distributed with loc=0 and scale=1 tensor([ 0.1046]) Parameters loc (python：float 或 tensor)–分布的平均值(通常称为 mu） 标度 (python：float 或 tensor)–分布的标准偏差(通常称为 sigma ) arg_constraints = {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}¶ cdf(value)¶ entropy()¶ expand(batch_shape, _instance=None)¶ has_rsample = True¶ icdf(value)¶ log_prob(value)¶ property mean¶ rsample(sample_shape=torch.Size([]))¶ sample(sample_shape=torch.Size([]))¶ property stddev¶ support = Real()¶ property variance¶ 热门分类 class torch.distributions.one_hot_categorical.OneHotCategorical(probs=None, logits=None, validate_args=None)¶ Bases: torch.distributions.distribution.Distribution 创建由 probs 或 logits 参数化的单热点分类分布。 样本是大小为probs.size(-1)的一键编码矢量。 Note probs 必须为非负数，有限且总和为非零，并且将其归一化为 1。 另请参见：torch.distributions.Categorical()了解 probs 和 logits 的规格。 Example: >>> m = OneHotCategorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ])) >>> m.sample() # equal probability of 0, 1, 2, 3 tensor([ 0., 0., 0., 1.]) Parameters probs (Tensor) – event probabilities logits (Tensor) – event log probabilities arg_constraints = {'logits': Real(), 'probs': Simplex()}¶ entropy()¶ enumerate_support(expand=True)¶ expand(batch_shape, _instance=None)¶ has_enumerate_support = True¶ log_prob(value)¶ property logits¶ property mean¶ property param_shape¶ property probs¶ sample(sample_shape=torch.Size([]))¶ support = Simplex()¶ property variance¶ 帕累托 class torch.distributions.pareto.Pareto(scale, alpha, validate_args=None)¶ Bases: torch.distributions.transformed_distribution.TransformedDistribution 来自帕累托 1 型分布的样本。 Example: >>> m = Pareto(torch.tensor([1.0]), torch.tensor([1.0])) >>> m.sample() # sample from a Pareto distribution with scale=1 and alpha=1 tensor([ 1.5623]) Parameters scale (python:float or Tensor) – Scale parameter of the distribution alpha (python：float 或 tensor)–分布的形状参数 arg_constraints = {'alpha': GreaterThan(lower_bound=0.0), 'scale': GreaterThan(lower_bound=0.0)}¶ entropy()¶ expand(batch_shape, _instance=None)¶ property mean¶ property support¶ property variance¶ 泊松 class torch.distributions.poisson.Poisson(rate, validate_args=None)¶ Bases: torch.distributions.exp_family.ExponentialFamily 创建由rate(速率参数）参数化的泊松分布。 样本是非负整数，pmf 为 Example: >>> m = Poisson(torch.tensor([4])) >>> m.sample() tensor([ 3.]) Parameters 速率(编号 ， tensor)–速率参数 arg_constraints = {'rate': GreaterThan(lower_bound=0.0)}¶ expand(batch_shape, _instance=None)¶ log_prob(value)¶ property mean¶ sample(sample_shape=torch.Size([]))¶ support = IntegerGreaterThan(lower_bound=0)¶ property variance¶ 轻松的伯努利 class torch.distributions.relaxed_bernoulli.RelaxedBernoulli(temperature, probs=None, logits=None, validate_args=None)¶ Bases: torch.distributions.transformed_distribution.TransformedDistribution 创建由 temperature 以及 probs 或 logits (但不是全部）参数化的 RelaxedBernoulli 分布。 这是 Bernoulli 分布的宽松版本，因此值在(0，1）中，并且具有可重新设置参数的样本。 Example: >>> m = RelaxedBernoulli(torch.tensor([2.2]), torch.tensor([0.1, 0.2, 0.3, 0.99])) >>> m.sample() tensor([ 0.2951, 0.3442, 0.8918, 0.9021]) Parameters 温度 (tensor)–松弛温度 probs (Number__, Tensor) – the probability of sampling 1 logits (Number__, Tensor) – the log-odds of sampling 1 arg_constraints = {'logits': Real(), 'probs': Interval(lower_bound=0.0, upper_bound=1.0)}¶ expand(batch_shape, _instance=None)¶ has_rsample = True¶ property logits¶ property probs¶ support = Interval(lower_bound=0.0, upper_bound=1.0)¶ property temperature¶ LogitRelaxed 伯努利 class torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli(temperature, probs=None, logits=None, validate_args=None)¶ Bases: torch.distributions.distribution.Distribution 创建一个以 probs 或 logits (但不是两者）为参数的 LogitRelaxedBernoulli 分布，这是 RelaxedBernoulli 分布的对数。 样本是(0，1）中值的对数。 有关更多详细信息，请参见[1]。 Parameters temperature (Tensor) – relaxation temperature probs (Number__, Tensor) – the probability of sampling 1 logits (Number__, Tensor) – the log-odds of sampling 1 [1]具体分布：离散随机变量的连续松弛(Maddison 等，2017） [2]使用 Gumbel-Softmax 分类重新参数化(Jang 等，2017） arg_constraints = {'logits': Real(), 'probs': Interval(lower_bound=0.0, upper_bound=1.0)}¶ expand(batch_shape, _instance=None)¶ log_prob(value)¶ logits¶ property param_shape¶ probs¶ rsample(sample_shape=torch.Size([]))¶ support = Real()¶ RelaxedOneHot 分类 class torch.distributions.relaxed_categorical.RelaxedOneHotCategorical(temperature, probs=None, logits=None, validate_args=None)¶ Bases: torch.distributions.transformed_distribution.TransformedDistribution 创建一个由 temperature 以及 probs 或 logits 设置参数的 RelaxedOneHotCategorical 分布。 这是OneHotCategorical发行版的宽松版本，因此其示例位于单纯形上，并且可以重新设置参数。 Example: >>> m = RelaxedOneHotCategorical(torch.tensor([2.2]), torch.tensor([0.1, 0.2, 0.3, 0.4])) >>> m.sample() tensor([ 0.1294, 0.2324, 0.3859, 0.2523]) Parameters temperature (Tensor) – relaxation temperature probs (Tensor) – event probabilities 对数 (tensor)–每个事件的对数概率。 arg_constraints = {'logits': Real(), 'probs': Simplex()}¶ expand(batch_shape, _instance=None)¶ has_rsample = True¶ property logits¶ property probs¶ support = Simplex()¶ property temperature¶ 学生 T class torch.distributions.studentT.StudentT(df, loc=0.0, scale=1.0, validate_args=None)¶ Bases: torch.distributions.distribution.Distribution 创建以自由度df，均值loc和小数位数scale为参数的学生 t 分布。 Example: >>> m = StudentT(torch.tensor([2.0])) >>> m.sample() # Student's t-distributed with degrees of freedom=2 tensor([ 0.1046]) Parameters df (python：float 或 tensor)–自由度 loc (python:float or Tensor) – mean of the distribution scale (python:float or Tensor) – scale of the distribution arg_constraints = {'df': GreaterThan(lower_bound=0.0), 'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)}¶ entropy()¶ expand(batch_shape, _instance=None)¶ has_rsample = True¶ log_prob(value)¶ property mean¶ rsample(sample_shape=torch.Size([]))¶ support = Real()¶ property variance¶ 转换分布 class torch.distributions.transformed_distribution.TransformedDistribution(base_distribution, transforms, validate_args=None)¶ Bases: torch.distributions.distribution.Distribution 分发类的扩展，该类将一系列 Transforms 应用于基本分发。 令 f 为所应用转换的组成： X ~ BaseDistribution Y = f(X) ~ TransformedDistribution(BaseDistribution, f) log p(Y) = log p(X) + log |det (dX/dY)| 注意， TransformedDistribution 的.event_shape是其基本分布及其变换的最大形状，因为变换可以在事件之间引入相关性。 TransformedDistribution 的用法示例为： # Building a Logistic Distribution # X ~ Uniform(0, 1) # f = a + b * logit(X) # Y ~ f(X) ~ Logistic(a, b) base_distribution = Uniform(0, 1) transforms = [SigmoidTransform().inv, AffineTransform(loc=a, scale=b)] logistic = TransformedDistribution(base_distribution, transforms) 有关更多示例，请查看 Gumbel ， HalfCauchy ， HalfNormal ， LogNormal 的实现， Pareto ， Weibull ， RelaxedBernoulli 和 RelaxedOneHotCategorical arg_constraints = {}¶ cdf(value)¶ 通过反转变换并计算基本分布的分数来计算累积分布函数。 expand(batch_shape, _instance=None)¶ property has_rsample¶ icdf(value)¶ 使用变换计算逆累积分布函数，并计算基本分布的分数。 log_prob(value)¶ 通过反转变换对样本进行评分，并使用基本分布的分数和 log abs det jacobian 计算分数。 rsample(sample_shape=torch.Size([]))¶ 如果分配了分布参数，则生成一个 sample_shape 形状的重新参数化样本或 sample_shape 形状的一批重新参数化样本。 首先从基本分布中采样，并对列表中的每个变换应用 transform(）。 sample(sample_shape=torch.Size([]))¶ 如果分配参数是批处理的，则生成 sample_shape 形状的样本或 sample_shape 形状的样本批。 首先从基本分布中采样，并对列表中的每个变换应用 transform(）。 property support¶ 制服 class torch.distributions.uniform.Uniform(low, high, validate_args=None)¶ Bases: torch.distributions.distribution.Distribution 从半开间隔[low, high)生成均匀分布的随机样本。 Example: >>> m = Uniform(torch.tensor([0.0]), torch.tensor([5.0])) >>> m.sample() # uniformly distributed in the range [0.0, 5.0) tensor([ 2.3418]) Parameters 低 (python：float 或 tensor)–较低范围(含）。 高 (python：float 或 tensor)–上限(不包括）。 arg_constraints = {'high': Dependent(), 'low': Dependent()}¶ cdf(value)¶ entropy()¶ expand(batch_shape, _instance=None)¶ has_rsample = True¶ icdf(value)¶ log_prob(value)¶ property mean¶ rsample(sample_shape=torch.Size([]))¶ property stddev¶ property support¶ property variance¶ 威布尔 class torch.distributions.weibull.Weibull(scale, concentration, validate_args=None)¶ Bases: torch.distributions.transformed_distribution.TransformedDistribution 来自两参数威布尔分布的样本。 Example >>> m = Weibull(torch.tensor([1.0]), torch.tensor([1.0])) >>> m.sample() # sample from a Weibull distribution with scale=1, concentration=1 tensor([ 0.4784]) Parameters 标度 (python：float 或 tensor)–分布的标度参数(lambda）。 浓度 (python：float 或 tensor)–浓度的浓度参数(k /形状）。 arg_constraints = {'concentration': GreaterThan(lower_bound=0.0), 'scale': GreaterThan(lower_bound=0.0)}¶ entropy()¶ expand(batch_shape, _instance=None)¶ property mean¶ support = GreaterThan(lower_bound=0.0)¶ property variance¶ KL 发散 torch.distributions.kl.kl_divergence(p, q)¶ 计算两个分布之间的 Kullback-Leibler 散度。 Parameters p (分布)–一个Distribution对象。 q (分布)–一个Distribution对象。 Returns 形状为 batch_shape 的一批 KL 散度。 返回类型 张量 Raises NotImplementedError -如果尚未通过 register_kl() 注册分发类型。 torch.distributions.kl.register_kl(type_p, type_q)¶ 装饰器向 kl_divergence() 注册成对功能。 用法： @register_kl(Normal, Normal) def kl_normal_normal(p, q): # insert implementation here 查找返回按子类排序的最特定的(类型，类型）匹配。 如果匹配不明确，则会引发 RuntimeWarning 。 例如解决模棱两可的情况： @register_kl(BaseP, DerivedQ) def kl_version1(p, q): ... @register_kl(DerivedP, BaseQ) def kl_version2(p, q): ... 您应该注册第三个最具体的实现，例如： register_kl(DerivedP, DerivedQ)(kl_version1) # Break the tie. Parameters type_p (python：type )– Distribution的子类。 type_q (python：type )– Distribution的子类。 转换 class torch.distributions.transforms.Transform(cache_size=0)¶ 可计算 log det jacobians 的可逆转换的抽象类。 它们主要用于torch.distributions.TransformedDistribution中。 高速缓存对于反变换代价昂贵或数值不稳定的变换非常有用。 请注意，记住的值必须小心，因为自动刻度图可能会颠倒。 例如，在以下情况下可以使用或不使用缓存： y = t(x) t.log_abs_det_jacobian(x, y).backward() # x will receive gradients. 但是，由于依赖关系反转，在缓存时以下内容将出错： y = t(x) z = t.inv(y) grad(z.sum(), [y]) # error because z is x 派生类应实现_call()或_inverse()中的一个或两个。 设置 bijective = True 的派生类也应实现 log_abs_det_jacobian() 。 Parameters cache_size (python：int )–缓存的大小。 如果为零，则不进行缓存。 如果为 1，则将缓存最新的单个值。 仅支持 0 和 1。 Variables 〜Transform.domain (Constraint)–表示此变换有效输入的约束。 〜Transform.codomain (Constraint)–表示此变换的有效输出的约束，该约束是逆变换的输入。 〜Transform.bijective (bool )–此变换是否为双射的。 对于域中的每个x和共域中的y，变换t是双射 iff t.inv(t(x)) == x和t(t.inv(y)) == y。 非双射的变换至少应保持较弱的伪逆特性t(t.inv(t(x)) == t(x)和t.inv(t(t.inv(y))) == t.inv(y)。 〜Transform.sign (python：int 或 tensor)–对于双射单变量变换，应为 +1 或-1，取决于变换是单调递增还是递减。 〜Transform.event_dim (python：int )–在变换event_shape中相互关联的维数。 对于逐点变换，应为 0；对于联合作用于矢量的变换，应为 1；对于联合作用于矩阵的变换，其应为 2。 property inv¶ 返回此变换的逆数 Transform 。 这应该满足t.inv.inv is t。 property sign¶ 返回雅可比行列式的符号(如果适用）。 通常，这仅对双射变换有意义。 log_abs_det_jacobian(x, y)¶ 计算 log det jacobian log | dy / dx | 给定输入和输出。 class torch.distributions.transforms.ComposeTransform(parts)¶ 组成一个链中的多个变换。 组成的转换负责缓存。 Parameters 部分 (Transform 的列表）–组成变换的列表。 class torch.distributions.transforms.ExpTransform(cache_size=0)¶ 通过映射进行转换。 class torch.distributions.transforms.PowerTransform(exponent, cache_size=0)¶ 通过映射进行转换。 class torch.distributions.transforms.SigmoidTransform(cache_size=0)¶ 通过映射和进行转换。 class torch.distributions.transforms.AbsTransform(cache_size=0)¶ 通过映射进行转换。 class torch.distributions.transforms.AffineTransform(loc, scale, event_dim=0, cache_size=0)¶ 通过逐点仿射映射进行变换。 Parameters loc (tensor 或 python：float )–位置参数。 标度 (tensor 或 python：float )–标度参数。 event_dim (python：int )– event_shape 的可选大小。 对于单变量随机变量，它应该为零；对于矢量的分布，它应该为 1；对于矩阵的分布，它应该为 2。 class torch.distributions.transforms.SoftmaxTransform(cache_size=0)¶ 通过从不受约束的空间转换为单纯形，然后进行规范化。 这不是双射的，不能用于 HMC。 但是，这主要是按坐标方式(最终归一化除外），因此适用于按坐标优化算法。 class torch.distributions.transforms.StickBreakingTransform(cache_size=0)¶ 通过不折断的过程将不受约束的空间转换为一维的单纯形。 该变换以 Dirichlet 分布的小节结构中的迭代 S 形变换形式出现：第一个 logit 通过 S 形变换成第一个概率和所有其他概率，然后过程重复进行。 这是双射的，适合在 HMC 中使用； 但是，它将坐标混合在一起，不太适合优化。 class torch.distributions.transforms.LowerCholeskyTransform(cache_size=0)¶ 从非约束矩阵转换为具有非负对角线项的低三角形矩阵。 这对于根据正定矩阵的 Cholesky 因式分解参数化很有用。 class torch.distributions.transforms.CatTransform(tseq, dim=0, lengths=None)¶ 变换函子，以与兼容的方式，以长度，长度[dim] 为单位，将每个分量的 tseq 变换序列应用于每个子矩阵。 ] torch.cat() 。 Example:: x0 = torch.cat([torch.range(1，10），torch.range(1，10）]，dim = 0）x = torch.cat([x0，x0]，dim = 0）t0 = CatTransform ([ExpTransform(），identity_transform]，dim = 0，长度= [10，10]）t = CatTransform([t0，t0]，dim = 0，长度= [20，20]）y = t(x） class torch.distributions.transforms.StackTransform(tseq, dim=0)¶ 变换函子，以与 torch.stack() 兼容的方式，对暗淡处的每个子矩阵按分量进行变换 tseq 的序列。 Example:: x = torch.stack([torch.range(1，10），torch.range(1，10）]，dim = 1）t = StackTransform([ExpTransform(），identity_transform]，dim = 1）y = t (X） 约束 实现了以下约束： constraints.boolean constraints.cat constraints.dependent constraints.greater_than(lower_bound) constraints.integer_interval(lower_bound, upper_bound) constraints.interval(lower_bound, upper_bound) constraints.lower_cholesky constraints.lower_triangular constraints.nonnegative_integer constraints.positive constraints.positive_definite constraints.positive_integer constraints.real constraints.real_vector constraints.simplex constraints.stack constraints.unit_interval class torch.distributions.constraints.Constraint¶ 约束的抽象基类。 约束对象表示变量有效的区域，例如 在其中可以优化变量。 check(value)¶ 返回 sample_shape + batch_shape 的字节张量，指示值中的每个事件是否满足此约束。 torch.distributions.constraints.dependent_property¶ torch.distributions.constraints._DependentProperty的别名 torch.distributions.constraints.integer_interval¶ torch.distributions.constraints._IntegerInterval的别名 torch.distributions.constraints.greater_than¶ torch.distributions.constraints._GreaterThan的别名 torch.distributions.constraints.greater_than_eq¶ torch.distributions.constraints._GreaterThanEq的别名 torch.distributions.constraints.less_than¶ torch.distributions.constraints._LessThan的别名 torch.distributions.constraints.interval¶ torch.distributions.constraints._Interval的别名 torch.distributions.constraints.half_open_interval¶ torch.distributions.constraints._HalfOpenInterval的别名 torch.distributions.constraints.cat¶ torch.distributions.constraints._Cat的别名 torch.distributions.constraints.stack¶ torch.distributions.constraints._Stack的别名 约束注册表 PyTorch 提供了两个全局 ConstraintRegistry 对象，这些对象将 Constraint 对象链接到 Transform 对象。 这些对象既有输入约束又有返回变换，但对双射性有不同的保证。 biject_to(constraint)查找从constraints.real到给定constraint的双射 Transform 。 保证返回的转换具有.bijective = True并应实现.log_abs_det_jacobian()。 transform_to(constraint)查找从constraints.real到给定constraint的不必要的双射 Transform 。 返回的转换不能保证实现.log_abs_det_jacobian()。 transform_to()注册表可用于对概率分布的受约束参数执行无约束优化，该概率分布由每个分布的.arg_constraints dict 指示。 为了避免旋转，这些变换通常对空间进行了参数化； 因此，它们更适合于像 Adam 这样的坐标优化算法： loc = torch.zeros(100, requires_grad=True) unconstrained = torch.zeros(100, requires_grad=True) scale = transform_to(Normal.arg_constraints['scale'])(unconstrained) loss = -Normal(loc, scale).log_prob(data).sum() biject_to()注册表对于哈密顿量的蒙特卡洛很有用，其中在.support约束下的概率分布中的样本在不受约束的空间中传播，并且算法通常是旋转不变的。 dist = Exponential(rate) unconstrained = torch.zeros(100, requires_grad=True) sample = biject_to(dist.support)(unconstrained) potential_energy = -dist.log_prob(sample).sum() Note transform_to和biject_to不同的一个例子是constraints.simplex：transform_to(constraints.simplex)返回一个 SoftmaxTransform ，该输入简单地对输入进行指数化和归一化； 这是一种便宜的方法，通常适合于像 SVI 这样的算法进行协调操作。 相反，biject_to(constraints.simplex)返回一个 StickBreakingTransform ，它将其输入降低到一维空间； 这是一个更昂贵的数字稳定度较低的变换，但对于 HMC 这样的算法来说是必需的。 可以通过用户定义的约束扩展biject_to和transform_to对象，并使用它们的.register()方法将其转换为单例约束的函数： transform_to.register(my_constraint, my_transform) 或作为参数约束的修饰器： @transform_to.register(MyConstraintClass) def my_factory(constraint): assert isinstance(constraint, MyConstraintClass) return MyTransform(constraint.param1, constraint.param2) 您可以通过创建新的 ConstraintRegistry 对象来创建自己的注册表。 class torch.distributions.constraint_registry.ConstraintRegistry¶ 注册表将约束链接到转换。 register(constraint, factory=None)¶ 在此注册表中注册 Constraint 子类。 用法： @my_registry.register(MyConstraintClass) def construct_transform(constraint): assert isinstance(constraint, MyConstraint) return MyTransform(constraint.arg_constraints) Parameters 约束 (Constraint 的子类）– Constraint 的子类，或所需类的单例对象。 factory (可调用的）–输入约束对象并返回 Transform 对象的可调用对象。__ 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:35:32 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"83.html":{"url":"83.html","title":"torch.hub","keywords":"","body":"torch.hub 原文： https://pytorch.org/docs/stable/hub.html Pytorch Hub 是经过预先训练的模型资料库，旨在促进研究的可重复性。 发布模型 Pytorch Hub 支持通过添加简单的hubconf.py文件将预训练的模型(模型定义和预训练的权重）发布到 github 存储库； hubconf.py可以有多个入口点。 每个入口点都定义为 python 函数(例如：您要发布的经过预先训练的模型）。 def entrypoint_name(*args, **kwargs): # args & kwargs are optional, for models which take positional/keyword arguments. ... 如何实现入口点？ 如果我们扩展pytorch/vision/hubconf.py中的实现，则以下代码段指定了resnet18模型的入口点。 在大多数情况下，在hubconf.py中导入正确的功能就足够了。 在这里，我们仅以扩展版本为例来说明其工作原理。 您可以在 pytorch / vision repo 中看到完整的脚本 dependencies = ['torch'] from torchvision.models.resnet import resnet18 as _resnet18 # resnet18 is the name of entrypoint def resnet18(pretrained=False, **kwargs): \"\"\" # This docstring shows up in hub.help() Resnet18 model pretrained (bool): kwargs, load pretrained weights into the model \"\"\" # Call the model, load pretrained weights model = _resnet18(pretrained=pretrained, **kwargs) return model dependencies变量是加载模型所需的软件包名称的列表。 请注意，这可能与训练模型所需的依赖项稍有不同。 args和kwargs传递给实际的可调用函数。 该函数的文档字符串用作帮助消息。 它解释了模型做什么以及允许的位置/关键字参数是什么。 强烈建议在此处添加一些示例。 Entrypoint 函数可以返回模型(nn.module），也可以返回辅助工具以使用户工作流程更流畅，例如 标记器。 带下划线前缀的可调用项被视为辅助功能，不会在torch.hub.list()中显示。 预训练的权重既可以存储在 github 存储库中，也可以由torch.hub.load_state_dict_from_url()加载。 如果少于 2GB，建议将其附加到项目版本，并使用该版本中的网址。 在上面的示例中，torchvision.models.resnet.resnet18处理pretrained，或者，您可以在入口点定义中添加以下逻辑。 if pretrained: # For checkpoint saved in local github repo, e.g. =weights/save.pth dirname = os.path.dirname(__file__) checkpoint = os.path.join(dirname, ) state_dict = torch.load(checkpoint) model.load_state_dict(state_dict) # For checkpoint saved elsewhere checkpoint = 'https://download.pytorch.org/models/resnet18-5c106cde.pth' model.load_state_dict(torch.hub.load_state_dict_from_url(checkpoint, progress=False)) 重要通知 发布的模型应至少在分支/标签中。 不能是随机提交。 从集线器加载模型 Pytorch Hub 提供了便捷的 API，可通过torch.hub.list()浏览集线器中的所有可用模型，通过torch.hub.help()显示文档字符串和示例，并使用torch.hub.load()加载经过预先​​训练的模型 torch.hub.list(github, force_reload=False)¶ 列出 github hubconf 中可用的所有入口点。 参数 github (字符串）–格式为“ repo_owner / repo_name [：tag_name]”的字符串，带有可选的标记/分支。 如果未指定，则默认分支为主站。 示例：“ pytorch / vision [：hub]” force_reload (bool ， 可选）–是否放弃现有缓存并强制重新下载。 默认值为否。 退货 可用入口点名称的列表 返回类型 入口点 例 >>> entrypoints = torch.hub.list('pytorch/vision', force_reload=True) torch.hub.help(github, model, force_reload=False)¶ 显示入口点模型的文档字符串。 Parameters github (字符串）–格式为主站。 示例：“ pytorch / vision [：hub]” 模型(字符串）–在存储库的 hubconf.py 中定义的入口点名称字符串 force_reload (bool__, optional) – whether to discard the existing cache and force a fresh download. Default is False. Example >>> print(torch.hub.help('pytorch/vision', 'resnet18', force_reload=True)) torch.hub.load(github, model, *args, **kwargs)¶ 使用预训练的权重从 github 存储库加载模型。 Parameters github (string) – a string with format “repo_owner/repo_name[:tag_name]” with an optional tag/branch. The default branch is master if not specified. Example: ‘pytorch/vision[:hub]’ model (string) – a string of entrypoint name defined in repo’s hubconf.py * args (可选）–可调用模型的相应 args。 force_reload (bool ， 可选）–是否无条件强制重新下载 github 存储库。 默认值为否。 详细 (bool ， 可选）–如果为 False，则忽略有关命中本地缓存的消息。 请注意，有关首次下载的消息不能被静音。 默认值为为真。 ** kwargs (可选）–可调用模型的相应 kwargs。 Returns 具有相应预训练权重的单个模型。 Example >>> model = torch.hub.load('pytorch/vision', 'resnet50', pretrained=True) torch.hub.download_url_to_file(url, dst, hash_prefix=None, progress=True)¶ 将给定 URL 上的对象下载到本地路径。 Parameters url (字符串）–要下载的对象的 URL dst (字符串）–保存对象的完整路径，例如 / tmp / temporary_file hash_prefix (字符串 ， 可选））–如果不是 None，则下载的 SHA256 文件应以 hash_prefix 开头。 默认值：无 进度 (bool ， 可选）–是否显示 stderr 的进度条默认值：True Example >>> torch.hub.download_url_to_file('https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth', '/tmp/temporary_file') torch.hub.load_state_dict_from_url(url, model_dir=None, map_location=None, progress=True, check_hash=False)¶ 将 Torch 序列化对象加载到给定的 URL。 如果下载的文件是 zip 文件，它将被自动解压缩。 如果 model_dir 中已经存在该对象，则将其反序列化并返回。 model_dir 的默认值为$TORCH_HOME/checkpoints，其中环境变量$TORCH_HOME的默认值为$XDG_CACHE_HOME/torch。 $XDG_CACHE_HOME遵循 Linux 文件系统布局的 X 设计组规范，如果未设置，则默认值为~/.cache。 Parameters url (string) – URL of the object to download model_dir (字符串 ， 可选）–保存对象的目录 map_location (可选）–指定如何重新映射存储位置的函数或命令(请参见 torch.load） 进度 (bool ， 可选）–是否显示 stderr 进度条。 默认值：True check_hash (bool ， 可选）–如果为 True，则 URL 的文件名部分应遵循命名约定filename-&lt;sha256&gt;.ext，其中[ &lt;sha256&gt;是文件内容的 SHA256 哈希值的前 8 位或更多位。 哈希用于确保唯一的名称并验证文件的内容。 默认值：False Example >>> state_dict = torch.hub.load_state_dict_from_url('https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth') 运行加载的模型： 注意，torch.load()中的*args, **kwargs用于实例化模型。 加载模型后，如何找到可以使用该模型的功能？ 建议的工作流程是 dir(model)查看模型的所有可用方法。 help(model.foo)检查model.foo需要执行哪些参数 为了帮助用户探索而又不来回参考文档，我们强烈建议回购所有者使功能帮助消息清晰明了。 包含一个最小的工作示例也很有帮助。 我下载的模型保存在哪里？ 这些位置按以下顺序使用 呼叫hub.set_dir(&lt;PATH_TO_HUB_DIR&gt;) $TORCH_HOME/hub，如果设置了环境变量TORCH_HOME。 $XDG_CACHE_HOME/torch/hub，如果设置了环境变量XDG_CACHE_HOME。 ~/.cache/torch/hub torch.hub.set_dir(d)¶ (可选）将 hub_dir 设置为本地目录，以保存下载的模型&权重。 如果未调用set_dir，则默认路径为$TORCH_HOME/hub，其中环境变量$TORCH_HOME默认为$XDG_CACHE_HOME/torch。 $XDG_CACHE_HOME遵循 Linux 文件系统布局的 X 设计组规范，如果未设置环境变量，则默认值为~/.cache。 Parameters d (字符串）–本地文件夹的路径，用于保存下载的模型&权重。 缓存逻辑 默认情况下，加载文件后我们不会清理文件。 如果hub_dir中已经存在，则集线器默认使用缓存。 用户可以通过调用hub.load(..., force_reload=True)来强制重新加载。 这将删除现有的 github 文件夹和下载的权重，重新初始化新的下载。 当更新发布到同一分支时，此功能很有用，用户可以跟上最新版本。 已知限制： Torch 集线器通过导入软件包来进行工作，就像安装软件包一样。 在 Python 中导入会带来一些副作用。 例如，您可以在 Python 缓存sys.modules和sys.path_importer_cache中看到新项目，这是正常的 Python 行为。 在这里值得一提的已知限制是用户无法在相同的 python 进程中加载同一存储库的两个不同分支。 就像在 Python 中安装两个具有相同名称的软件包一样，这是不好的。 快取可能会加入聚会，如果您实际尝试的话会给您带来惊喜。 当然，将它们分别加载是完全可以的。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:37:42 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"84.html":{"url":"84.html","title":"torch脚本","keywords":"","body":"torch脚本 原文： https://pytorch.org/docs/stable/jit.html 创建 TorchScript 代码 混合跟踪和脚本编写 迁移到 PyTorch 1.2 递归脚本 API 模块 功能 TorchScript 类 属性 Python 2 常数 变量 TorchScript 语言参考 类型 默认类型 可选类型细化 TorchScript 类 命名为元组 表达式 文字 列表结构 元组结构 字典结构 变量 算术运算符 比较运算符 逻辑运算符 下标和切片 函数调用 方法调用 三元表达式 演员表 访问模块参数 语句 简单分配 模式匹配分配 打印报表 If 语句 While 循环 适用于范围为的循环 用于遍历元组的循环 用于在常量 nn.ModuleList 上循环 中断并继续 返回 可变分辨率 使用 Python 值 功能 Python 模块上的属性查找 Python 定义的常量 模块属性 调试 禁用用于调试的 JIT 检查码 解释图 追踪案例 自动跟踪检查 跟踪器警告 内置函数 常见问题解答 TorchScript 是一种从 PyTorch 代码创建可序列化和可优化模型的方法。 任何 TorchScript 程序都可以从 Python 进程中保存并加载到没有 Python 依赖项的进程中。 我们提供了将模型从纯 Python 程序逐步过渡到可以独立于 Python 运行的 TorchScript 程序的工具，例如在独立的 C ++程序中。 这样就可以使用 Python 中熟悉的工具在 PyTorch 中训练模型，然后通过 TorchScript 将模型导出到生产环境中，在该生产环境中 Python 程序可能由于性能和多线程原因而处于不利地位。 有关 TorchScript 的简要介绍，请参见 TorchScript 简介教程。 有关将 PyTorch 模型转换为 TorchScript 并在 C ++中运行的端到端示例，请参见在 C ++中加载 PyTorch 模型教程。 创建 TorchScript 代码 class torch.jit.ScriptModule¶ property code¶ 返回forward方法的内部图的漂亮打印表示形式(作为有效的 Python 语法）。 有关详细信息，请参见检查代码。 property graph¶ 返回forward方法的内部图形的字符串表示形式。 有关详细信息，请参见解释图。 save(f, _extra_files=ExtraFilesMap{})¶ 有关详细信息，请参见 torch.jit.save 。 class torch.jit.ScriptFunction¶ 功能上与 ScriptModule 等效，但是代表单个功能，没有任何属性或参数。 torch.jit.script(obj)¶ 为函数或nn.Module编写脚本将检查源代码，使用 TorchScript 编译器将其编译为 TorchScript 代码，然后返回 ScriptModule 或 ScriptFunction 。 TorchScript 本身是 Python 语言的子集，因此 Python 并非所有功能都可以使用，但是我们提供了足够的功能来在张量上进行计算并执行与控制有关的操作。 有关完整指南，请参见 TorchScript 语言参考。 torch.jit.script可用作模块和功能的函数，以及 TorchScript 类和功能的修饰器@torch.jit.script。 Scripting a function @torch.jit.script装饰器将通过编译函数的主体来构造 ScriptFunction 。 示例(编写函数）： import torch @torch.jit.script def foo(x, y): if x.max() > y.max(): r = x else: r = y return r print(type(foo)) # torch.jit.ScriptFuncion # See the compiled graph as Python code print(foo.code) # Call the function using the TorchScript interpreter foo(torch.ones(2, 2), torch.ones(2, 2)) Scripting an nn.Module 默认情况下，为nn.Module编写脚本将编译forward方法，并递归编译forward调用的任何方法，子模块和函数。 如果nn.Module仅使用 TorchScript 支持的功能，则无需更改原始模块代码。 script将构建 ScriptModule ，该副本具有原始模块的属性，参数和方法的副本。 示例(使用参数编写简单模块的脚本）： import torch class MyModule(torch.nn.Module): def __init__(self, N, M): super(MyModule, self).__init__() # This parameter will be copied to the new ScriptModule self.weight = torch.nn.Parameter(torch.rand(N, M)) # When this submodule is used, it will be compiled self.linear = torch.nn.Linear(N, M) def forward(self, input): output = self.weight.mv(input) # This calls the `forward` method of the `nn.Linear` module, which will # cause the `self.linear` submodule to be compiled to a `ScriptModule` here output = self.linear(output) return output scripted_module = torch.jit.script(MyModule(2, 3)) 示例(使用跟踪的子模块编写模块脚本）： import torch import torch.nn as nn import torch.nn.functional as F class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() # torch.jit.trace produces a ScriptModule's conv1 and conv2 self.conv1 = torch.jit.trace(nn.Conv2d(1, 20, 5), torch.rand(1, 1, 16, 16)) self.conv2 = torch.jit.trace(nn.Conv2d(20, 20, 5), torch.rand(1, 20, 16, 16)) def forward(self, input): input = F.relu(self.conv1(input)) input = F.relu(self.conv2(input)) return input scripted_module = torch.jit.script(MyModule()) 要编译除forward以外的方法(并递归编译其调用的任何内容），请将 @torch.jit.export 装饰器添加到该方法。 要选择退出编译，请使用 @torch.jit.ignore 。 示例(模块中的导出方法和忽略方法）： import torch import torch.nn as nn class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() @torch.jit.export def some_entry_point(self, input): return input + 10 @torch.jit.ignore def python_only_fn(self, input): # This function won't be compiled, so any # Python APIs can be used import pdb pdb.set_trace() def forward(self, input): if self.training: self.python_only_fn(input) return input * 99 scripted_module = torch.jit.script(MyModule()) print(scripted_module.some_entry_point(torch.randn(2, 2))) print(scripted_module(torch.randn(2, 2))) torch.jit.trace(func, example_inputs, optimize=None, check_trace=True, check_inputs=None, check_tolerance=1e-5)¶ 跟踪一个函数并返回将使用即时编译进行优化的可执行文件或 ScriptFunction 。 对于仅在Tensor和Tensor的列表，字典和元组上运行的代码，跟踪是理想的选择。 使用torch.jit.trace和 torch.jit.trace_module ，您可以将现有模块或 Python 函数转换为 TorchScript ScriptFunction 或 ScriptModule 。 您必须提供示例输入，然后我们运行该函数，记录在所有张量上执行的操作。 独立功能的最终记录将产生 ScriptFunction 。 nn.Module或nn.Module的forward功能的所得记录产生 ScriptModule 。 该模块还包含原始模块也具有的任何参数。 警告 跟踪仅正确记录不依赖数据的功能和模块(例如，对张量中的数据没有条件）并且不包含任何未跟踪的外部依赖项(例如，执行输入/输出或访问全局变量）。 跟踪仅记录在给定张量上运行给定函数时执行的操作。 因此，返回的 ScriptModule 将始终在任何输入上运行相同的跟踪图。 当期望模块根据输入和/或模块状态运行不同的操作集时，这具有重要意义。 例如， 跟踪将不会记录任何控制流，例如 if 语句或循环。 当整个模块的控制流恒定时，这很好，并且通常内联控制流决策。 但是有时控制流实际上是模型本身的一部分。 例如，循环网络是输入序列(可能是动态）长度上的循环。 在返回的 ScriptModule 中，在training和eval模式下具有不同行为的操作将始终像在跟踪过程中一样处于运行状态，无论是哪种模式 ] ScriptModule 已插入。 在这种情况下，跟踪是不合适的， scripting 是更好的选择。 如果跟踪此类模型，则可能在随后的模型调用中静默地得到不正确的结果。 在执行可能会导致产生不正确跟踪的操作时，跟踪器将尝试发出警告。 参数 函数(可调用的或 torch.nn.Module)– Python 函数或torch.nn.Module 与example_inputs一起运行。 func的参数和返回值必须是张量或包含张量的(可能是嵌套的）元组。 将模块传递到 torch.jit.trace 时，仅运行并跟踪forward方法(有关详细信息，请参见 torch.jit.trace)。 example_inputs (tuple )–示例输入的元组，将在跟踪时传递给函数。 假设跟踪的操作支持这些类型和形状，则可以使用不同类型和形状的输入来运行结果跟踪。 example_inputs也可以是单个张量，在这种情况下，它会自动包装在元组中。 Keyword Arguments check_trace (bool，可选）–检查通过跟踪代码运行的相同输入是否产生相同的输出。 默认值：True。 例如，如果您的网络包含不确定性操作，或者即使检查程序失败，但您确定网络正确，则可能要禁用此功能。 check_inputs (元组列表 ， 可选）–输入参数的元组列表，应使用这些元组来检查跟踪内容 是期待。 每个元组等效于example_inputs中指定的一组输入参数。 为了获得最佳结果，请传递一组检查输入，这些输入代表您希望网络看到的形状和输入类型的空间。 如果未指定，则使用原始的example_inputs进行检查 check_tolerance (python：float ， 可选）–在检查程序中使用的浮点比较公差。 如果结果由于已知原因(例如操作员融合）而在数值上出现差异，则可以使用此方法来放松检查器的严格性。 退货 如果callable是nn.Module的nn.Module或forward，则trace将使用包含跟踪代码的单个forward方法返回 ScriptModule 对象。 返回的 ScriptModule 将具有与原始nn.Module相同的子模块和参数集。 如果callable是独立功能，则trace返回 ScriptFunction 示例(跟踪函数）： import torch def foo(x, y): return 2 * x + y # Run `foo` with the provided inputs and record the tensor operations traced_foo = torch.jit.trace(foo, (torch.rand(3), torch.rand(3))) # `traced_foo` can now be run with the TorchScript interpreter or saved # and loaded in a Python-free environment 示例(跟踪现有模块）： import torch import torch.nn as nn class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv = nn.Conv2d(1, 1, 3) def forward(self, x): return self.conv(x) n = Net() example_weight = torch.rand(1, 1, 3, 3) example_forward_input = torch.rand(1, 1, 3, 3) # Trace a specific method and construct `ScriptModule` with # a single `forward` method module = torch.jit.trace(n.forward, example_forward_input) # Trace a module (implicitly traces `forward`) and construct a # `ScriptModule` with a single `forward` method module = torch.jit.trace(n, example_forward_input) torch.jit.trace_module(mod, inputs, optimize=None, check_trace=True, check_inputs=None, check_tolerance=1e-5)¶ 跟踪模块并返回可执行文件 ScriptModule ，该文件将使用即时编译进行优化。 将模块传递到 torch.jit.trace 时，仅运行并跟踪forward方法。 使用trace_module，您可以指定方法名称的字典作为示例输入，以跟踪下面的参数(请参见example_inputs）。 有关跟踪的更多信息，请参见 torch.jit.trace 。 Parameters mod (Torch.nn.Module)–一种torch.nn.Module，其中包含名称在example_inputs中指定的方法。 给定的方法将被编译为单个 ScriptModule 的一部分。 example_inputs (dict )–包含样本输入的字典，该样本输入由mod中的方法名称索引。 输入将在跟踪时传递给名称与输入键对应的方法。 { 'forward' : example_forward_input, 'method2': example_method2_input} Keyword Arguments check_trace (bool, optional) – Check if the same inputs run through traced code produce the same outputs. Default: True. You might want to disable this if, for example, your network contains non- deterministic ops or if you are sure that the network is correct despite a checker failure. check_inputs (字典列表 ， 可选）–输入参数的字典列表，用于检查跟踪内容 是期待。 每个元组等效于example_inputs中指定的一组输入参数。 为了获得最佳结果，请传递一组检查输入，这些输入代表您希望网络看到的形状和输入类型的空间。 如果未指定，则使用原始的example_inputs进行检查 check_tolerance (python:float__, optional) – Floating-point comparison tolerance to use in the checker procedure. This can be used to relax the checker strictness in the event that results diverge numerically for a known reason, such as operator fusion. Returns 具有单个forward方法的 ScriptModule 对象，其中包含跟踪的代码。 当func是torch.nn.Module时，返回的 ScriptModule 将具有与func相同的子模块和参数集。 示例(使用多种方法跟踪模块）： import torch import torch.nn as nn class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv = nn.Conv2d(1, 1, 3) def forward(self, x): return self.conv(x) def weighted_kernel_sum(self, weight): return weight * self.conv.weight n = Net() example_weight = torch.rand(1, 1, 3, 3) example_forward_input = torch.rand(1, 1, 3, 3) # Trace a specific method and construct `ScriptModule` with # a single `forward` method module = torch.jit.trace(n.forward, example_forward_input) # Trace a module (implicitly traces `forward`) and construct a # `ScriptModule` with a single `forward` method module = torch.jit.trace(n, example_forward_input) # Trace specific methods on a module (specified in `inputs`), constructs # a `ScriptModule` with `forward` and `weighted_kernel_sum` methods inputs = {'forward' : example_forward_input, 'weighted_kernel_sum' : example_weight} module = torch.jit.trace_module(n, inputs) torch.jit.save(m, f, _extra_files=ExtraFilesMap{})¶ 保存此模块的脱机版本以在单独的过程中使用。 保存的模块将序列化此模块的所有方法，子模块，参数和属性。 可以使用torch::jit::load(filename)将其加载到 C ++ API 中，或者使用 torch.jit.load 加载到 Python API 中。 为了能够保存模块，它不得对本地 Python 函数进行任何调用。 这意味着所有子模块也必须是torch.jit.ScriptModule的子类。 危险 所有模块，无论使用哪种设备，都始终在加载期间加载到 CPU 中。 这与 load 的语义不同，并且将来可能会发生变化。 Parameters m –要保存的 ScriptModule。 f –类似于文件的对象(必须实现写入和刷新）或包含文件名的字符串。 _extra_files -从文件名映射到将作为“ f”的一部分存储的内容。 Warning 如果您使用的是 Python 2，torch.jit.save不支持StringIO.StringIO作为有效的类似文件的对象。 这是因为 write 方法应返回写入的字节数； StringIO.write()不这样做。 请改用io.BytesIO之类的东西。 例： import torch import io class MyModule(torch.nn.Module): def forward(self, x): return x + 10 m = torch.jit.script(MyModule()) # Save to file torch.jit.save(m, 'scriptmodule.pt') # This line is equivalent to the previous m.save(\"scriptmodule.pt\") # Save to io.BytesIO buffer buffer = io.BytesIO() torch.jit.save(m, buffer) # Save with extra files extra_files = torch._C.ExtraFilesMap() extra_files['foo.txt'] = 'bar' torch.jit.save(m, 'scriptmodule.pt', _extra_files=extra_files) torch.jit.load(f, map_location=None, _extra_files=ExtraFilesMap{})¶ 加载先前用 torch.jit.save 保存的 ScriptModule 或 ScriptFunction 之前保存的所有模块，无论使用何种设备，都首先加载到 CPU 中，然后再移动到保存它们的设备上。 如果失败(例如，因为运行时系统没有某些设备），则会引发异常。 Parameters f –类似于文件的对象(必须实现读取，读取行，告诉和查找），或包含文件名的字符串 map_location (字符串 或 torch设备)– torch.save中map_location的简化版本 用于动态地将存储重新映射到另一组设备。 _extra_files (文件名到内容的字典）–映射中给定的多余文件名将被加载，其内容将存储在提供的映射中。 Returns ScriptModule 对象。 Example: import torch import io torch.jit.load('scriptmodule.pt') # Load ScriptModule from io.BytesIO object with open('scriptmodule.pt', 'rb') as f: buffer = io.BytesIO(f.read()) # Load all tensors to the original device torch.jit.load(buffer) # Load all tensors onto CPU, using a device buffer.seek(0) torch.jit.load(buffer, map_location=torch.device('cpu')) # Load all tensors onto CPU, using a string buffer.seek(0) torch.jit.load(buffer, map_location='cpu') # Load with extra files. extra_files = torch._C.ExtraFilesMap() extra_files['foo.txt'] = 'bar' torch.jit.load('scriptmodule.pt', _extra_files=extra_files) print(extra_files['foo.txt']) 混合跟踪和脚本编写 在许多情况下，将模型转换为 TorchScript 都可以使用跟踪或脚本编写。 可以组成跟踪和脚本以适合模型一部分的特定要求。 脚本函数可以调用跟踪函数。 当您需要在简单的前馈模型周围使用控制流时，这特别有用。 例如，序列到序列模型的波束搜索通常将用脚本编写，但是可以调用使用跟踪生成的编码器模块。 示例(在脚本中调用跟踪的函数）： import torch def foo(x, y): return 2 * x + y traced_foo = torch.jit.trace(foo, (torch.rand(3), torch.rand(3))) @torch.jit.script def bar(x): return traced_foo(x, x) 跟踪的函数可以调用脚本函数。 即使大部分模型只是前馈网络，当模型的一小部分需要一些控制流时，这也很有用。 跟踪函数调用的脚本函数内部的控制流已正确保留。 示例(在跟踪函数中调用脚本函数）： import torch @torch.jit.script def foo(x, y): if x.max() > y.max(): r = x else: r = y return r def bar(x, y, z): return foo(x, y) + z traced_bar = torch.jit.trace(bar, (torch.rand(3), torch.rand(3), torch.rand(3))) 此组合也适用于nn.Module，在这里它可用于通过跟踪来生成子模块，该跟踪可以从脚本模块的方法中调用。 示例(使用跟踪模块）： import torch import torchvision class MyScriptModule(torch.nn.Module): def __init__(self): super(MyScriptModule, self).__init__() self.means = torch.nn.Parameter(torch.tensor([103.939, 116.779, 123.68]) .resize_(1, 3, 1, 1)) self.resnet = torch.jit.trace(torchvision.models.resnet18(), torch.rand(1, 3, 224, 224)) def forward(self, input): return self.resnet(input - self.means) my_script_module = torch.jit.script(MyScriptModule()) 迁移到 PyTorch 1.2 递归脚本 API 本节详细介绍了 PyTorch 1.2 中对 TorchScript 的更改。 如果您不熟悉 TorchScript，则可以跳过本节。 PyTorch 1.2 对 TorchScript API 进行了两个主要更改。 1. torch.jit.script 现在将尝试递归编译遇到的函数，方法和类。 调用torch.jit.script后，编译将是“选择退出”，而不是“选择加入”。 2.现在torch.jit.script(nn_module_instance)是创建 ScriptModule 的首选方法，而不是从torch.jit.ScriptModule继承。 这些更改组合在一起，提供了一个更简单易用的 API，可将您的nn.Module转换为 ScriptModule ，可以在非 Python 环境中进行优化和执行。 新用法如下所示： import torch import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x)) return F.relu(self.conv2(x)) my_model = Model() my_scripted_model = torch.jit.script(my_model) 该模块的forward是默认编译的。 从forward调用的方法将按照在forward中使用的顺序进行延迟编译。 要编译未从forward调用的forward以外的方法，请添加@torch.jit.export。 要停止编译器编译方法，请添加 @torch.jit.ignore 或 @torch.jit.unused 。 @ignore离开 方法作为对 python 的调用，并且@unused将其替换为异常。 @ignored无法导出； @unused可以。 可以推断大多数属性类型，因此不需要torch.jit.Attribute。 对于空容器类型，请使用 PEP 526 样式类注释对其类型进行注释。 可以使用Final类注释来标记常量，而不是将成员的名称添加到__constants__中。 可以使用 Python 3 类型提示代替torch.jit.annotate As a result of these changes, the following items are considered deprecated and should not appear in new code: @torch.jit.script_method装饰器 继承自torch.jit.ScriptModule的类 torch.jit.Attribute包装器类 __constants__数组 torch.jit.annotate功能 模块 Warning @torch.jit.ignore 注释的行为在 PyTorch 1.2 中发生了变化。 在 PyTorch 1.2 之前，@ ignore 装饰器用于使函数或方法可从导出的代码中调用。 要恢复此功能，请使用@torch.jit.unused()。 @torch.jit.ignore现在等同于@torch.jit.ignore(drop=False)。 有关详细信息，请参见 @torch.jit.ignore 和 @torch.jit.unused 。 当传递给 torch.jit.script 函数时，torch.nn.Module的数据将复制到 ScriptModule ，然后 TorchScript 编译器将编译该模块。 该模块的forward默认为编译状态。 从forward调用的方法以及它们在forward中使用的顺序都是按延迟顺序编译的。 torch.jit.export(fn)¶ 此修饰符指示nn.Module上的方法用作 ScriptModule 的入口点，应进行编译。 forward隐式地假定为入口点，因此不需要此装饰器。 从forward调用的函数和方法在编译器看到的情况下进行编译，因此它们也不需要此装饰器。 示例(在方法上使用@torch.jit.export）： import torch import torch.nn as nn class MyModule(nn.Module): def implicitly_compiled_method(self, x): return x + 99 # `forward` is implicitly decorated with `@torch.jit.export`, # so adding it here would have no effect def forward(self, x): return x + 10 @torch.jit.export def another_forward(self, x): # When the compiler sees this call, it will compile # `implicitly_compiled_method` return self.implicitly_compiled_method(x) def unused_method(self, x): return x - 20 # `m` will contain compiled methods: # `forward` # `another_forward` # `implicitly_compiled_method` # `unused_method` will not be compiled since it was not called from # any compiled methods and wasn't decorated with `@torch.jit.export` m = torch.jit.script(MyModule()) 功能 功能没有太大变化，可以根据需要用 @torch.jit.ignore 或 torch.jit.unused 装饰。 # Same behavior as pre-PyTorch 1.2 @torch.jit.script def some_fn(): return 2 # Marks a function as ignored, if nothing # ever calls it then this has no effect @torch.jit.ignore def some_fn2(): return 2 # As with ignore, if nothing calls it then it has no effect. # If it is called in script it is replaced with an exception. @torch.jit.unused def some_fn3(): import pdb; pdb.set_trace() return 4 # Doesn't do anything, this function is already # the main entry point @torch.jit.export def some_fn4(): return 2 TorchScript 类 默认情况下，将导出用户定义的 TorchScript 类中的所有内容，可以根据需要用 @torch.jit.ignore 修饰功能。 属性 TorchScript 编译器需要知道模块属性的类型。 大多数类型可以从成员的值推断出来。 空列表和字典不能推断其类型，而必须使用 PEP 526 样式类注释来注释其类型。 如果无法推断类型并且未对显式类型进行注释，则不会将其作为属性添加到结果 ScriptModule 旧 API： from typing import Dict import torch class MyModule(torch.jit.ScriptModule): def __init__(self): super(MyModule, self).__init__() self.my_dict = torch.jit.Attribute({}, Dict[str, int]) self.my_int = torch.jit.Attribute(20, int) m = MyModule() 新 API： from typing import Dict class MyModule(torch.nn.Module): my_dict: Dict[str, int] def __init__(self): super(MyModule, self).__init__() # This type cannot be inferred and must be specified self.my_dict = {} # The attribute type here is inferred to be `int` self.my_int = 20 def forward(self): pass m = torch.jit.script(MyModule()) Python 2 如果您受制于 Python 2 并且无法使用类注释语法，则可以使用__annotations__类成员直接应用类型注释。 from typing import Dict class MyModule(torch.jit.ScriptModule): __annotations__ = {'my_dict': Dict[str, int]} def __init__(self): super(MyModule, self).__init__() self.my_dict = {} self.my_int = 20 常数 Final类型的构造函数可用于将成员标记为常量。 如果成员未标记为常量，则将其复制为结果 ScriptModule 作为属性。 如果已知该值是固定的，则使用Final可以进行优化，并提供附加的类型安全性。 Old API: class MyModule(torch.jit.ScriptModule): __constants__ = ['my_constant'] def __init__(self): super(MyModule, self).__init__() self.my_constant = 2 def forward(self): pass m = MyModule() New API: try: from typing_extensions import Final except: # If you don't have `typing_extensions` installed, you can use a # polyfill from `torch.jit`. from torch.jit import Final class MyModule(torch.nn.Module): my_constant: Final[int] def __init__(self): super(MyModule, self).__init__() self.my_constant = 2 def forward(self): pass m = torch.jit.script(MyModule()) 变量 假定容器的类型为Tensor，并且是非可选的(有关更多信息，请参见默认类型）。 以前，torch.jit.annotate用来告诉 TorchScript 编译器类型是什么。 现在支持 Python 3 样式类型提示。 import torch from typing import Dict, Optional @torch.jit.script def make_dict(flag: bool): x: Dict[str, int] = {} x['hi'] = 2 b: Optional[int] = None if flag: b = 2 return x, b TorchScript 语言参考 TorchScript 是 Python 的静态类型子集，可以直接编写(使用 @torch.jit.script 装饰器），也可以通过跟踪从 Python 代码自动生成。 使用跟踪时，通过仅在张量上记录实际的运算符并简单地执行和丢弃其他周围的 Python 代码，代码会自动转换为 Python 的此子集。 使用@torch.jit.script装饰器直接编写 TorchScript 时，程序员只能使用 TorchScript 支持的 Python 子集。 本节记录了 TorchScript 支持的功能，就像它是独立语言的语言参考一样。 本参考中未提及的 Python 的任何功能都不属于 TorchScript。 有关可用的 Pytorch 张量方法，模块和功能的完整参考，请参见内置函数。 作为 Python 的子集，任何有效的 TorchScript 函数也是有效的 Python 函数。 这样就可以禁用 TorchScript 并使用pdb之类的标准 Python 工具调试该功能。 反之则不成立：有许多有效的 Python 程序不是有效的 TorchScript 程序。 相反，TorchScript 特别专注于表示 PyTorch 中的神经网络模型所需的 Python 功能。 类型 TorchScript 与完整的 Python 语言之间的最大区别是 TorchScript 仅支持表达神经网络模型所需的一小部分类型。 特别是，TorchScript 支持： | 类型 | 描述 | | --- | --- | | Tensor | 任何 dtype，尺寸或后端的 PyTorch 张量 | | Tuple[T0, T1, ...] | 包含子类型T0，T1等(例如Tuple[Tensor, Tensor]）的元组 | | bool | 布尔值 | | int | 标量整数 | | float | 标量浮点数 | | str | 一串 | | List[T] | 所有成员均为T类型的列表 | | Optional[T] | 无或输入T的值 | | Dict[K, V] | 键类型为K而值类型为V的字典。 只能将str，int和float作为密​​钥类型。 | | T | 一个 TorchScript 类 | | NamedTuple[T0, T1, ...] | collections.namedtuple元组类型 | 与 Python 不同，TorchScript 函数中的每个变量都必须具有一个静态类型。 这使优化 TorchScript 函数变得更加容易。 示例(类型不匹配） import torch @torch.jit.script def an_error(x): if x: r = torch.rand(1) else: r = 4 return r Traceback (most recent call last): ... RuntimeError: ... Type mismatch: r is set to type Tensor in the true branch and type int in the false branch: @torch.jit.script def an_error(x): if x: ~~~~~... 默认类型 默认情况下，TorchScript 函数的所有参数均假定为 Tensor。 要指定 TorchScript 函数的参数是其他类型，可以使用上面列出的类型使用 MyPy 样式的类型注释。 import torch @torch.jit.script def foo(x, tup): # type: (int, Tuple[Tensor, Tensor]) -> Tensor t0, t1 = tup return t0 + t1 + x print(foo(3, (torch.rand(3), torch.rand(3)))) 注意 也可以使用typing模块中的 Python 3 类型提示来注释类型。 import torch from typing import Tuple @torch.jit.script def foo(x: int, tup: Tuple[torch.Tensor, torch.Tensor]) -> torch.Tensor: t0, t1 = tup return t0 + t1 + x print(foo(3, (torch.rand(3), torch.rand(3)))) 在我们的示例中，我们使用基于注释的类型提示来确保 Python 2 的兼容性。 假定空列表为List[Tensor]，空字典为Dict[str, Tensor]。 要实例化其他类型的空列表或字典，请使用 Python 3 类型提示。 如果您使用的是 Python 2，则可以使用torch.jit.annotate。 示例(Python 3 的类型注释）： import torch import torch.nn as nn from typing import Dict, List, Tuple class EmptyDataStructures(torch.nn.Module): def __init__(self): super(EmptyDataStructures, self).__init__() def forward(self, x: torch.Tensor) -> Tuple[List[Tuple[int, float]], Dict[str, int]]: # This annotates the list to be a `List[Tuple[int, float]]` my_list: List[Tuple[int, float]] = [] for i in range(10): my_list.append((i, x.item())) my_dict: Dict[str, int] = {} return my_list, my_dict x = torch.jit.script(EmptyDataStructures()) 示例(适用于 Python 2 的torch.jit.annotate）： import torch import torch.nn as nn from typing import Dict, List, Tuple class EmptyDataStructures(torch.nn.Module): def __init__(self): super(EmptyDataStructures, self).__init__() def forward(self, x): # type: (Tensor) -> Tuple[List[Tuple[int, float]], Dict[str, int]] # This annotates the list to be a `List[Tuple[int, float]]` my_list = torch.jit.annotate(List[Tuple[int, float]], []) for i in range(10): my_list.append((i, float(x.item()))) my_dict = torch.jit.annotate(Dict[str, int], {}) return my_list, my_dict x = torch.jit.script(EmptyDataStructures()) 可选类型细化 在 if 语句的条件内或在assert中检查与None的比较时，TorchScript 将优化Optional[T]类型的变量的类型。 编译器可以推理与and，or和not结合的多个None检查。 对于未明确编写的 if 语句的 else 块，也会进行优化。 None检查必须在 if 语句的条件内； 将None检查分配给变量，并在 if 语句的条件下使用它，将不会优化检查中的变量类型。 仅局部变量将被细化，self.x之类的属性将不会且必须分配给要细化的局部变量。 示例(优化参数和局部变量的类型）： import torch import torch.nn as nn from typing import Optional class M(nn.Module): z: Optional[int] def __init__(self, z): super(M, self).__init__() # If `z` is None, its type cannot be inferred, so it must # be specified (above) self.z = z def forward(self, x, y, z): # type: (Optional[int], Optional[int], Optional[int]) -> int if x is None: x = 1 x = x + 1 # Refinement for an attribute by assigning it to a local z = self.z if y is not None and z is not None: x = y + z # Refinement via an `assert` assert z is not None x += z return x module = torch.jit.script(M(2)) module = torch.jit.script(M(None)) TorchScript 类 如果 Python 类使用 @torch.jit.script 注释，则可以在 TorchScript 中使用，类似于声明 TorchScript 函数的方式： @torch.jit.script class Foo: def __init__(self, x, y): self.x = x def aug_add_x(self, inc): self.x += inc 此子集受限制： 所有函数必须是有效的 TorchScript 函数(包括__init__()）。 这些类必须是新型类，因为我们使用__new__()和 pybind11 来构造它们。 TorchScript 类是静态类型的。 只能通过在__init__()方法中分配给 self 来声明成员。 > 例如，在__init__()方法之外分配给self： > > &gt; @torch.jit.script &gt; class Foo: &gt; def assign_x(self): &gt; self.x = torch.rand(2, 3) &gt; &gt; > > 将导致： > > &gt; RuntimeError: &gt; Tried to set nonexistent attribute: x. Did you forget to initialize it in __init__()?: &gt; def assign_x(self): &gt; self.x = torch.rand(2, 3) &gt; ~~~~~~~~~~~~~~~~~~~~~~~~ &lt;--- HERE &gt; &gt; 类的主体中不允许使用除方法定义之外的任何表达式。 除了从object继承以指定新样式类外，不支持继承或任何其他多态策略。 定义了一个类之后，就可以像其他任何 TorchScript 类型一样在 TorchScript 和 Python 中互换使用该类： # Declare a TorchScript class @torch.jit.script class Pair: def __init__(self, first, second): self.first = first self.second = second @torch.jit.script def sum_pair(p): # type: (Pair) -> Tensor return p.first + p.second p = Pair(torch.rand(2, 3), torch.rand(2, 3)) print(sum_pair(p)) 命名为元组 collections.namedtuple产生的类型可以在 TorchScript 中使用。 import torch import collections Point = collections.namedtuple('Point', ['x', 'y']) @torch.jit.script def total(point): # type: (Point) -> Tensor return point.x + point.y p = Point(x=torch.rand(3), y=torch.rand(3)) print(total(p)) 表达式 支持以下 Python 表达式。 文字 True False None 'string literals' \"string literals\" 3 # interpreted as int 3.4 # interpreted as a float 列表结构 假定一个空列表具有List[Tensor]类型。 其他列表文字的类型是从成员的类型派生的。 有关更多详细信息，请参见默认类型。 [3, 4] [] [torch.rand(3), torch.rand(4)] 元组结构 (3, 4) (3,) 字典结构 假定一个空字典为Dict[str, Tensor]类型。 其他 dict 文字的类型是从成员的类型派生的。 有关更多详细信息，请参见默认类型。 {'hello': 3} {} {'a': torch.rand(3), 'b': torch.rand(4)} 变量 有关如何解析变量的信息，请参见变量分辨率。 my_variable_name 算术运算符 a + b a - b a * b a / b a ^ b a @ b 比较运算符 a == b a != b a b a = b 逻辑运算符 a and b a or b not b 下标和切片 t[0] t[-1] t[0:2] t[1:] t[:1] t[:] t[0, 1] t[0, 1:2] t[0, :1] t[-1, 1:, 0] t[1:, -1, 0] t[i:j, i] 函数调用 调用内置函数 torch.rand(3, dtype=torch.int) 调用其他脚本函数： import torch @torch.jit.script def foo(x): return x + 1 @torch.jit.script def bar(x): return foo(x) 方法调用 调用诸如张量之类的内置类型的方法：x.mm(y) 在模块上，必须先编译方法才能调用它们。 TorchScript 编译器以递归方式编译在编译其他方法时看到的方法。 默认情况下，编译从forward方法开始。 将编译forward调用的任何方法，以及这些方法调用的任何方法，依此类推。 要以forward以外的方法开始编译，请使用 @torch.jit.export 装饰器(forward隐式标记为@torch.jit.export）。 直接调用子模块(例如self.resnet(input)）等效于调用其forward方法(例如self.resnet.forward(input)）。 import torch import torch.nn as nn import torchvision class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() means = torch.tensor([103.939, 116.779, 123.68]) self.means = torch.nn.Parameter(means.resize_(1, 3, 1, 1)) resnet = torchvision.models.resnet18() self.resnet = torch.jit.trace(resnet, torch.rand(1, 3, 224, 224)) def helper(self, input): return self.resnet(input - self.means) def forward(self, input): return self.helper(input) # Since nothing in the model calls `top_level_method`, the compiler # must be explicitly told to compile this method @torch.jit.export def top_level_method(self, input): return self.other_helper(input) def other_helper(self, input): return input + 10 # `my_script_module` will have the compiled methods `forward`, `helper`, # `top_level_method`, and `other_helper` my_script_module = torch.jit.script(MyModule()) 三元表达式 x if x > y else y 演员表 float(ten) int(3.5) bool(ten) str(2)`` 访问模块参数 self.my_parameter self.my_submodule.my_parameter 语句 TorchScript 支持以下类型的语句： 简单分配 a = b a += b # short-hand for a = a + b, does not operate in-place on a a -= b 模式匹配分配 a, b = tuple_or_list a, b, *c = a_tuple 多项分配 a = b, c = tup 打印报表 print(\"the result of an add:\", a + b) If 语句 if a 除布尔值外，浮点数，整数和张量还可以在条件中使用，并将隐式转换为布尔值。 While 循环 a = 0 while a 适用于范围为的循环 x = 0 for i in range(10): x *= i 用于遍历元组的循环 这些展开循环，为元组的每个成员生成一个主体。 主体必须对每个成员进行正确的类型检查。 tup = (3, torch.rand(4)) for x in tup: print(x) 用于在常量 nn.ModuleList 上循环 要在已编译方法中使用nn.ModuleList，必须通过将属性名称添加到__constants__列表中的类型来将其标记为常量。 nn.ModuleList上的 for 循环将在编译时展开循环的主体，并使用常量模块列表的每个成员。 class SubModule(torch.nn.Module): def __init__(self): super(SubModule, self).__init__() self.weight = nn.Parameter(torch.randn(2)) def forward(self, input): return self.weight + input class MyModule(torch.nn.Module): __constants__ = ['mods'] def __init__(self): super(MyModule, self).__init__() self.mods = torch.nn.ModuleList([SubModule() for i in range(10)]) def forward(self, v): for module in self.mods: v = module(v) return v m = torch.jit.script(MyModule()) 中断并继续 for i in range(5): if i == 1: continue if i == 3: break print(i) 返回 return a, b 可变分辨率 TorchScript 支持 Python 的可变分辨率(即作用域）规则的子集。 局部变量的行为与 Python 中的相同，不同之处在于，在通过函数的所有路径上，变量必须具有相同的类型。 如果变量在 if 语句的不同分支上具有不同的类型，则在 if 语句结束后使用它是错误的。 同样，如果沿函数的某些路径仅将定义为，则不允许使用该变量。 Example: @torch.jit.script def foo(x): if x Traceback (most recent call last): ... RuntimeError: ... y is not defined in the false branch... @torch.jit.script... def foo(x): if x 定义函数时，会在编译时将非局部变量解析为 Python 值。 然后使用 Python 值使用中描述的规则将这些值转换为 TorchScript 值。 使用 Python 值 为了使编写 TorchScript 更加方便，我们允许脚本代码引用周围范围中的 Python 值。 例如，任何时候只要引用torch，当声明函数时，TorchScript 编译器实际上就会将其解析为torch Python 模块。 这些 Python 值不是 TorchScript 的一流部分。 而是在编译时将它们分解为 TorchScript 支持的原始类型。 这取决于编译发生时引用的 Python 值的动态类型。 本节介绍在 TorchScript 中访问 Python 值时使用的规则。 功能 TorchScript 可以调用 Python 函数。 当将模型逐步转换为 TorchScript 时，此功能非常有用。 可以将模型逐函数移至 TorchScript，而对 Python 函数的调用保留在原处。 这样，您可以在进行过程中逐步检查模型的正确性。 torch.jit.ignore(drop=False, **kwargs)¶ 该装饰器向编译器指示应忽略函数或方法，而将其保留为 Python 函数。 这使您可以将代码保留在尚未与 TorchScript 兼容的模型中。 具有忽略功能的模型无法导出； 请改用 torch.jit.unused。 示例(在方法上使用@torch.jit.ignore）： import torch import torch.nn as nn class MyModule(nn.Module): @torch.jit.ignore def debugger(self, x): import pdb pdb.set_trace() def forward(self, x): x += 10 # The compiler would normally try to compile `debugger`, # but since it is `@ignore`d, it will be left as a call # to Python self.debugger(x) return x m = torch.jit.script(MyModule()) # Error! The call `debugger` cannot be saved since it calls into Python m.save(\"m.pt\") 示例(在方法上使用@torch.jit.ignore(drop=True)）： import torch import torch.nn as nn class MyModule(nn.Module): @torch.jit.ignore(drop=True) def training_method(self, x): import pdb pdb.set_trace() def forward(self, x): if self.training: self.training_method(x) return x m = torch.jit.script(MyModule()) # This is OK since `training_method` is not saved, the call is replaced # with a `raise`. m.save(\"m.pt\") torch.jit.unused(fn)¶ 此装饰器向编译器指示应忽略函数或方法，并用引发异常的方法代替。 这样，您就可以在尚不兼容 TorchScript 的模型中保留代码，并仍然可以导出模型。 示例(在方法上使用@torch.jit.unused）： import torch import torch.nn as nn class MyModule(nn.Module): def __init__(self, use_memory_efficent): super(MyModule, self).__init__() self.use_memory_efficent = use_memory_efficent @torch.jit.unused def memory_efficient(self, x): import pdb pdb.set_trace() return x + 10 def forward(self, x): # Use not-yet-scriptable memory efficient mode if self.use_memory_efficient: return self.memory_efficient(x) else: return x + 10 m = torch.jit.script(MyModule(use_memory_efficent=False)) m.save(\"m.pt\") m = torch.jit.script(MyModule(use_memory_efficient=True)) # exception raised m(torch.rand(100)) torch.jit.is_scripting()¶ 在编译时返回 True 的函数，否则返回 False 的函数。 这对于使用@unused 装饰器尤其有用，可以将尚不兼容 TorchScript 的代码保留在模型中。 .. testcode： import torch @torch.jit.unused def unsupported_linear_op(x): return x def linear(x): if not torch.jit.is_scripting(): return torch.linear(x) else: return unsupported_linear_op(x) Python 模块上的属性查找 TorchScript 可以在模块上查找属性。 像torch.add这样的内置功能可以通过这种方式访问​​。 这使 TorchScript 可以调用其他模块中定义的函数。 Python 定义的常量 TorchScript 还提供了一种使用 Python 中定义的常量的方法。 这些可用于将超参数硬编码到函数中，或定义通用常量。 有两种指定 Python 值应视为常量的方式。 查找为模块属性的值假定为常量： import math import torch @torch.jit.script def fn(): return math.pi 可以通过使用Final[T]注释 ScriptModule 的属性来将其标记为常量。 import torch import torch.nn as nn class Foo(nn.Module): # `Final` from the `typing_extensions` module can also be used a : torch.jit.Final[int] def __init__(self): super(Foo, self).__init__() self.a = 1 + 4 def forward(self, input): return self.a + input f = torch.jit.script(Foo()) 支持的常量 Python 类型是 int float bool torch.device torch.layout torch.dtype 包含受支持类型的元组 torch.nn.ModuleList可以在 TorchScript for 循环中使用 Note 如果您使用的是 Python 2，则可以通过将属性名称添加到类的__constants__属性中来将其标记为常量： import torch import torch.nn as nn class Foo(nn.Module): __constants__ = ['a'] def __init__(self): super(Foo, self).__init__() self.a = 1 + 4 def forward(self, input): return self.a + input f = torch.jit.script(Foo()) 模块属性 torch.nn.Parameter包装器和register_buffer可用于将张量分配给模块。 如果可以推断出其他类型的值，则分配给已编译模块的其他值将添加到已编译模块中。 TorchScript 中可用的所有类型都可以用作模块属性。 张量属性在语义上与缓冲区相同。 空列表和字典的类型以及None值无法推断，必须通过 PEP 526 样式类注释指定。 如果无法推断出类型并且未对其进行显式注释，则不会将其作为属性添加到结果 ScriptModule 中。 Example: from typing import List, Dict class Foo(nn.Module): # `words` is initialized as an empty list, so its type must be specified words: List[str] # The type could potentially be inferred if `a_dict` (below) was not # empty, but this annotation ensures `some_dict` will be made into the # proper type some_dict: Dict[str, int] def __init__(self, a_dict): super(Foo, self).__init__() self.words = [] self.some_dict = a_dict # `int`s can be inferred self.my_int = 10 def forward(self, input): # type: (str) -> int self.words.append(input) return self.some_dict[input] + self.my_int f = torch.jit.script(Foo({'hi': 2})) Note 如果您使用的是 Python 2，则可以通过将属性的类型添加到__annotations__类属性中作为属性名字典来标记属性的类型 from typing import List, Dict class Foo(nn.Module): __annotations__ = {'words': List[str], 'some_dict': Dict[str, int]} def __init__(self, a_dict): super(Foo, self).__init__() self.words = [] self.some_dict = a_dict # `int`s can be inferred self.my_int = 10 def forward(self, input): # type: (str) -> int self.words.append(input) return self.some_dict[input] + self.my_int f = torch.jit.script(Foo({'hi': 2})) 调试 禁用用于调试的 JIT PYTORCH_JIT¶ 设置环境变量PYTORCH_JIT=0将禁用所有脚本和跟踪注释。 如果您的 TorchScript 模型之一存在难以调试的错误，则可以使用此标志来强制一切都使用本机 Python 运行。 由于此标志禁用了 TorchScript(脚本编写和跟踪），因此可以使用pdb之类的工具来调试模型代码。 给定一个示例脚本： @torch.jit.script def scripted_fn(x : torch.Tensor): for i in range(12): x = x + x return x def fn(x): x = torch.neg(x) import pdb; pdb.set_trace() return scripted_fn(x) traced_fn = torch.jit.trace(fn, (torch.rand(4, 5),)) traced_fn(torch.rand(3, 4)) 除调用，@torch.jit.script，函数外，使用pdb调试此脚本是可行的。 我们可以全局禁用 JIT，以便我们可以将 @torch.jit.script 函数作为普通的 Python 函数调用，而不进行编译。 如果上述脚本称为disable_jit_example.py，我们可以这样调用它： $ PYTORCH_JIT=0 python disable_jit_example.py 并且我们将能够像普通的 Python 函数一样进入 @torch.jit.script 函数。 要为特定功能禁用 TorchScript 编译器，请参见 @torch.jit.ignore 。 检查码 TorchScript 为所有 ScriptModule 实例提供了代码漂亮的打印机。 这个漂亮的打印机可以将脚本方法的代码解释为有效的 Python 语法。 例如： @torch.jit.script def foo(len): # type: (int) -> torch.Tensor rv = torch.zeros(3, 4) for i in range(len): if i 具有单个forward方法的 ScriptModule 将具有属性code，您可以使用该属性检查 ScriptModule 的代码。 如果 ScriptModule 具有多个方法，则需要在方法本身而非模块上访问.code。 我们可以通过访问.foo.code在 ScriptModule 上检查名为foo的方法的代码。 上面的示例产生以下输出： def foo(len: int) -> Tensor: rv = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None) rv0 = rv for i in range(len): if torch.lt(i, 10): rv1 = torch.sub(rv0, 1., 1) else: rv1 = torch.add(rv0, 1., 1) rv0 = rv1 return rv0 这是 TorchScript 对forward方法的代码的编译。 您可以使用它来确保 TorchScript(跟踪或脚本）正确捕获了模型代码。 解释图 TorchScript 还以 IR 图的形式在比代码漂亮打印机更低的层次上进行表示。 TorchScript 使用静态单分配(SSA）中间表示(IR）表示计算。 这种格式的指令由 ATen(PyTorch 的 C ++后端）运算符和其他原始运算符组成，包括用于循环和条件的控制流运算符。 举个例子： @torch.jit.script def foo(len): # type: (int) -> torch.Tensor rv = torch.zeros(3, 4) for i in range(len): if i graph遵循检查代码部分中关于forward方法查找所述的相同规则。 上面的示例脚本生成图形： graph(%len.1 : int): %24 : int = prim::Constant[value=1]() %17 : bool = prim::Constant[value=1]() # test.py:10:5 %12 : bool? = prim::Constant() %10 : Device? = prim::Constant() %6 : int? = prim::Constant() %1 : int = prim::Constant[value=3]() # test.py:9:22 %2 : int = prim::Constant[value=4]() # test.py:9:25 %20 : int = prim::Constant[value=10]() # test.py:11:16 %23 : float = prim::Constant[value=1]() # test.py:12:23 %4 : int[] = prim::ListConstruct(%1, %2) %rv.1 : Tensor = aten::zeros(%4, %6, %6, %10, %12) # test.py:9:10 %rv : Tensor = prim::Loop(%len.1, %17, %rv.1) # test.py:10:5 block0(%i.1 : int, %rv.14 : Tensor): %21 : bool = aten::lt(%i.1, %20) # test.py:11:12 %rv.13 : Tensor = prim::If(%21) # test.py:11:9 block0(): %rv.3 : Tensor = aten::sub(%rv.14, %23, %24) # test.py:12:18 -> (%rv.3) block1(): %rv.6 : Tensor = aten::add(%rv.14, %23, %24) # test.py:14:18 -> (%rv.6) -> (%17, %rv.13) return (%rv) 以指令%rv.1 : Tensor = aten::zeros(%4, %6, %6, %10, %12) # test.py:9:10为例。 %rv.1 : Tensor表示我们将输出分配给一个名为rv.1的(唯一）值，该值是Tensor类型，并且我们不知道其具体形状。 aten::zeros是运算符(与torch.zeros等效），输入列表(%4, %6, %6, %10, %12)指定范围中的哪些值应作为输入传递。 可以在内置函数中找到aten::zeros等内置函数的模式。 # test.py:9:10是生成此指令的原始源文件中的位置。 在这种情况下，它是第 9 行和字符 10 处名为 test.py 的文件。 请注意，运算符也可以具有关联的blocks，即prim::Loop和prim::If运算符。 在图形打印输出中，这些运算符被格式化以反映其等效的源代码形式，以方便进行调试。 如下图所示，可以检查图表以确认 ScriptModule 所描述的计算是正确的，无论是自动方式还是手动方式。 追踪案例 在某些极端情况下，给定 Python 函数/模块的跟踪不会代表基础代码。 这些情况可以包括： 跟踪取决于输入的控制流(例如张量形状） 跟踪张量视图的就地操作(例如，分配左侧的索引） 请注意，这些情况实际上将来可能是可追溯的。 自动跟踪检查 自动捕获跟踪中许多错误的一种方法是使用torch.jit.trace() API 上的check_inputs。 check_inputs提取输入元组的列表，这些列表将用于重新追踪计算并验证结果。 例如： def loop_in_traced_fn(x): result = x[0] for i in range(x.size(0)): result = result * x[i] return result inputs = (torch.rand(3, 4, 5),) check_inputs = [(torch.rand(4, 5, 6),), (torch.rand(2, 3, 4),)] traced = torch.jit.trace(loop_in_traced_fn, inputs, check_inputs=check_inputs) 为我们提供以下诊断信息： ERROR: Graphs differed across invocations! Graph diff: graph(%x : Tensor) { %1 : int = prim::Constant[value=0]() %2 : int = prim::Constant[value=0]() %result.1 : Tensor = aten::select(%x, %1, %2) %4 : int = prim::Constant[value=0]() %5 : int = prim::Constant[value=0]() %6 : Tensor = aten::select(%x, %4, %5) %result.2 : Tensor = aten::mul(%result.1, %6) %8 : int = prim::Constant[value=0]() %9 : int = prim::Constant[value=1]() %10 : Tensor = aten::select(%x, %8, %9) - %result : Tensor = aten::mul(%result.2, %10) + %result.3 : Tensor = aten::mul(%result.2, %10) ? ++ %12 : int = prim::Constant[value=0]() %13 : int = prim::Constant[value=2]() %14 : Tensor = aten::select(%x, %12, %13) + %result : Tensor = aten::mul(%result.3, %14) + %16 : int = prim::Constant[value=0]() + %17 : int = prim::Constant[value=3]() + %18 : Tensor = aten::select(%x, %16, %17) - %15 : Tensor = aten::mul(%result, %14) ? ^ ^ + %19 : Tensor = aten::mul(%result, %18) ? ^ ^ - return (%15); ? ^ + return (%19); ? ^ } 此消息向我们表明，在我们第一次追踪它和使用check_inputs追踪它之间，计算有所不同。 实际上，loop_in_traced_fn主体内的循环取决于输入x的形状，因此，当我们尝试另一种形状不同的x时，迹线会有所不同。 在这种情况下，可以使用 torch.jit.script() 来捕获类似于数据的控制流： def fn(x): result = x[0] for i in range(x.size(0)): result = result * x[i] return result inputs = (torch.rand(3, 4, 5),) check_inputs = [(torch.rand(4, 5, 6),), (torch.rand(2, 3, 4),)] scripted_fn = torch.jit.script(fn) print(scripted_fn.graph) #print(str(scripted_fn.graph).strip()) for input_tuple in [inputs] + check_inputs: torch.testing.assert_allclose(fn(*input_tuple), scripted_fn(*input_tuple)) 产生： graph(%x : Tensor) { %5 : bool = prim::Constant[value=1]() %1 : int = prim::Constant[value=0]() %result.1 : Tensor = aten::select(%x, %1, %1) %4 : int = aten::size(%x, %1) %result : Tensor = prim::Loop(%4, %5, %result.1) block0(%i : int, %7 : Tensor) { %10 : Tensor = aten::select(%x, %1, %i) %result.2 : Tensor = aten::mul(%7, %10) -> (%5, %result.2) } return (%result); } 跟踪器警告 跟踪器会针对跟踪计算中的几种有问题的模式生成警告。 举个例子，追踪一个在 Tensor 的切片(视图）上包含就地分配的函数： def fill_row_zero(x): x[0] = torch.rand(*x.shape[1:2]) return x traced = torch.jit.trace(fill_row_zero, (torch.rand(3, 4),)) print(traced.graph) 产生几个警告和一个仅返回输入的图形： fill_row_zero.py:4: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe. x[0] = torch.rand(*x.shape[1:2]) fill_row_zero.py:6: TracerWarning: Output nr 1\\. of the traced function does not match the corresponding output of the Python function. Detailed error: Not within tolerance rtol=1e-05 atol=1e-05 at input[0, 1] (0.09115803241729736 vs. 0.6782537698745728) and 3 other locations (33.00%) traced = torch.jit.trace(fill_row_zero, (torch.rand(3, 4),)) graph(%0 : Float(3, 4)) { return (%0); } 我们可以通过修改代码来解决此问题，使其不使用就地更新，而是使用torch.cat来错位构建结果张量： def fill_row_zero(x): x = torch.cat((torch.rand(1, *x.shape[1:2]), x[1:2]), dim=0) return x traced = torch.jit.trace(fill_row_zero, (torch.rand(3, 4),)) print(traced.graph) 内置函数 TorchScript 支持 PyTorch 提供的内置张量和神经网络功能的子集。 Tensor 上的大多数方法以及torch名称空间中的函数，torch.nn.functional中的所有函数以及torch.nn中的所有模块在 TorchScript 中均受支持，下表中没有列出。 对于不支持的模块，建议使用 torch.jit.trace() 。 不支持的torch.nn模块 torch.nn.modules.adaptive.AdaptiveLogSoftmaxWithLoss torch.nn.modules.normalization.CrossMapLRN2d torch.nn.modules.rnn.RNN 有关支持的功能的完整参考，请参见 TorchScript 内置函数。 常见问题解答 问：我想在 GPU 上训练模型并在 CPU 上进行推理。 最佳做法是什么？ 首先将模型从 GPU 转换为 CPU，然后将其保存，如下所示： cpu_model = gpu_model.cpu() sample_input_cpu = sample_input_gpu.cpu() traced_cpu = torch.jit.trace(traced_cpu, sample_input_cpu) torch.jit.save(traced_cpu, \"cpu.pth\") traced_gpu = torch.jit.trace(traced_gpu, sample_input_gpu) torch.jit.save(traced_gpu, \"gpu.pth\") # ... later, when using the model: if use_gpu: model = torch.jit.load(\"gpu.pth\") else: model = torch.jit.load(\"cpu.pth\") model(input) 推荐这样做是因为跟踪器可能会在特定设备上见证张量的创建，因此强制转换已加载的模型可能会产生意想不到的效果。 在保存之前对模型进行转换可确保跟踪器具有正确的设备信息。 问：如何在 ScriptModule 上存储属性？ 说我们有一个像这样的模型： class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.x = 2 def forward(self): return self.x m = torch.jit.script(Model()) 如果实例化Model，则将导致编译错误，因为编译器不了解x。 有四种方法可以通知编译器 ScriptModule 的属性： 1. nn.Parameter-包装在nn.Parameter中的值将像在nn.Module上一样工作 2. register_buffer-包装在register_buffer中的值将像在nn.Module上一样工作。 这等效于Tensor类型的属性(请参见 4）。 3.常量-将类成员注释为Final(或在类定义级别将其添加到名为__constants__的列表中）会将包含的名称标记为常量。 常数直接保存在模型代码中。 有关详细信息，请参见 Python 定义的常量。 4.属性-可以将支持的类型的值添加为可变属性。 可以推断大多数类型，但可能需要指定一些类型，有关详细信息，请参见模块属性。 问：我想跟踪模块的方法，但一直出现此错误： RuntimeError: Cannot insert a Tensor that requires grad as a constant. Consider making it a parameter or input, or detaching the gradient 此错误通常表示您要跟踪的方法使用模块的参数，并且您正在传递模块的方法而不是模块实例(例如my_module_instance.forward与my_module_instance）。 > 使用模块的方法调用trace会将模块参数(可能需要渐变）捕获为常量。 >>> 另一方面，使用模块实例(例如my_module）调用trace会创建一个新模块，并将参数正确复制到新模块中，以便在需要时可以累积梯度。 要跟踪模块上的特定方法，请参见 torch.jit.trace_module 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:25:18 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"85.html":{"url":"85.html","title":"torch.nn.init","keywords":"","body":"torch.nn.init 原文： https://pytorch.org/docs/stable/nn.init.html torch.nn.init.calculate_gain(nonlinearity, param=None)¶ 返回给定非线性函数的推荐增益值。 取值如下： | 非线性 | 获得 | | --- | --- | | 线性/身份 | | | 转换{1,2,3} D | | | 乙状结肠 | | | h | | | ReLU | | | 泄漏的露露 | | 参数 非线性 –非线性函数 (nn.functional 名称） 参数 –非线性功能的可选参数 例子 >>> gain = nn.init.calculate_gain('leaky_relu', 0.2) # leaky_relu with negative_slope=0.2 torch.nn.init.uniform_(tensor, a=0.0, b=1.0)¶ 用从均匀分布中得出的值填充输入张量。 Parameters 张量 – n 维torch.张量 a –均匀分布的下限 b –均匀分布的上限 Examples >>> w = torch.empty(3, 5) >>> nn.init.uniform_(w) torch.nn.init.normal_(tensor, mean=0.0, std=1.0)¶ 使用从正态分布中得出的值填充输入张量。 Parameters tensor – an n-dimensional torch.Tensor 平均值 –正态分布的平均值 std –正态分布的标准偏差 Examples >>> w = torch.empty(3, 5) >>> nn.init.normal_(w) torch.nn.init.constant_(tensor, val)¶ 用值填充输入张量。 Parameters tensor – an n-dimensional torch.Tensor val –用张量填充张量的值 Examples >>> w = torch.empty(3, 5) >>> nn.init.constant_(w, 0.3) torch.nn.init.ones_(tensor)¶ 用标量值 1 填充输入张量。 Parameters tensor – an n-dimensional torch.Tensor Examples >>> w = torch.empty(3, 5) >>> nn.init.ones_(w) torch.nn.init.zeros_(tensor)¶ 用标量值 0 填充输入张量。 Parameters tensor – an n-dimensional torch.Tensor Examples >>> w = torch.empty(3, 5) >>> nn.init.zeros_(w) torch.nn.init.eye_(tensor)¶ 用单位矩阵填充二维输入张量。 在线性层中保留输入的身份，在该层中将保留尽可能多的输入。 Parameters 张量 –二维torch.张量 Examples >>> w = torch.empty(3, 5) >>> nn.init.eye_(w) torch.nn.init.dirac_(tensor)¶ 使用 Dirac delta 函数填充{3，4，5}维输入张量。 保留卷积层中输入的身份，其中保留尽可能多的输入通道。 Parameters 张量 – {3，4，5}维的torch.张量 Examples >>> w = torch.empty(3, 16, 5, 5) >>> nn.init.dirac_(w) torch.nn.init.xavier_uniform_(tensor, gain=1.0)¶ 根据中所述的方法，用值填充输入张量的值。了解训练深度前馈神经网络的难度-Glorot，X。& Bengio，Y.(2010），使用 均匀分布。 结果张量将具有从采样的值，其中 也称为 Glorot 初始化。 Parameters tensor – an n-dimensional torch.Tensor 增益 –可选的比例因子 Examples >>> w = torch.empty(3, 5) >>> nn.init.xavier_uniform_(w, gain=nn.init.calculate_gain('relu')) torch.nn.init.xavier_normal_(tensor, gain=1.0)¶ 根据中所述的方法，用值填充输入张量。了解训练深度前馈神经网络的难度-Glorot，X。& Bengio，Y.(2010），使用 正态分布。 结果张量将具有从采样的值，其中 Also known as Glorot initialization. Parameters tensor – an n-dimensional torch.Tensor gain – an optional scaling factor Examples >>> w = torch.empty(3, 5) >>> nn.init.xavier_normal_(w) torch.nn.init.kaiming_uniform_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')¶ 根据中描述的方法，用值填充输入张量的值。深入研究整流器：在 ImageNet 分类上超越人类水平的性能-He，K.等。 (2015），使用均匀分布。 结果张量将具有从采样的值，其中 也称为 He 初始化。 Parameters tensor – an n-dimensional torch.Tensor a –在该层之后使用的整流器的负斜率(仅 with'leaky_relu'）(使用了）– 模式 – 'fan_in'(默认）或'fan_out'。 选择'fan_in'会保留前向传递中权重差异的大小。 选择'fan_out'可以保留反向传递的幅度。 非线性 –非线性函数(为功能性名称），建议仅与'relu'或'leaky_relu'(默认）一起使用。 Examples >>> w = torch.empty(3, 5) >>> nn.init.kaiming_uniform_(w, mode='fan_in', nonlinearity='relu') torch.nn.init.kaiming_normal_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')¶ 根据中描述的方法，用值填充输入张量的值。深入研究整流器：在 ImageNet 分类上超越人类水平的性能-He，K.等。 (2015），使用正态分布。 结果张量将具有从采样的值，其中 Also known as He initialization. Parameters tensor – an n-dimensional torch.Tensor a – the negative slope of the rectifier used after this layer (only with 'leaky_relu') (used) – mode – either 'fan_in' (default) or 'fan_out'. Choosing 'fan_in' preserves the magnitude of the variance of the weights in the forward pass. Choosing 'fan_out' preserves the magnitudes in the backwards pass. nonlinearity – the non-linear function (nn.functional name), recommended to use only with 'relu' or 'leaky_relu' (default). Examples >>> w = torch.empty(3, 5) >>> nn.init.kaiming_normal_(w, mode='fan_out', nonlinearity='relu') torch.nn.init.orthogonal_(tensor, gain=1)¶ 用(半）正交矩阵填充输入的张量，如中所述，用于深度线性神经网络中学习的非线性动力学的精确解-Saxe，A.等。 (2013）。 输入张量必须至少具有 2 个维度，对于 2 个以上的张量，尾随维度将被展平。 Parameters 张量 – n 维torch张量，其中 增益 –可选比例因子 Examples >>> w = torch.empty(3, 5) >>> nn.init.orthogonal_(w) torch.nn.init.sparse_(tensor, sparsity, std=0.01)¶ 将 2D 输入张量填充为稀疏矩阵，其中将从正态分布提取非零元素，如通过无麻木优化的深度学习中所述- Martens，J.(2010 年）。 Parameters tensor – an n-dimensional torch.Tensor 稀疏性 –每列中要设置为零的元素比例 std –用于生成非零值的正态分布的标准偏差 Examples >>> w = torch.empty(3, 5) >>> nn.init.sparse_(w, sparsity=0.1) 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:25:18 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"86.html":{"url":"86.html","title":"torch.onnx","keywords":"","body":"torch.onnx 原文： https://pytorch.org/docs/stable/onnx.html 示例：从 PyTorch 到 ONNX 的端到端 AlexNet 跟踪与脚本编写 局限性 支持的运营商 添加对运营商的支持 ATen 运算符 非 ATen 运营商 定制运算符 常见问题解答 功能 示例：从 PyTorch 到 ONNX 的端到端 AlexNet 这是一个简单的脚本，可以将 Torchvision 中定义的经过预训练的 AlexNet 导出到 ONNX 中。 它运行一轮推断，然后将生成的跟踪模型保存到alexnet.onnx： import torch import torchvision dummy_input = torch.randn(10, 3, 224, 224, device='cuda') model = torchvision.models.alexnet(pretrained=True).cuda() # Providing input and output names sets the display names for values # within the model's graph. Setting these does not change the semantics # of the graph; it is only for readability. # # The inputs to the network consist of the flat list of inputs (i.e. # the values you would pass to the forward() method) followed by the # flat list of parameters. You can partially specify names, i.e. provide # a list here shorter than the number of inputs to the model, and we will # only set that subset of names, starting from the beginning. input_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ] output_names = [ \"output1\" ] torch.onnx.export(model, dummy_input, \"alexnet.onnx\", verbose=True, input_names=input_names, output_names=output_names) 生成的alexnet.onnx是二进制 protobuf 文件，其中包含您导出的模型的网络结构和参数(在本例中为 AlexNet）。 关键字参数verbose=True使导出程序打印出人类可读的网络表示形式： # These are the inputs and parameters to the network, which have taken on # the names we specified earlier. graph(%actual_input_1 : Float(10, 3, 224, 224) %learned_0 : Float(64, 3, 11, 11) %learned_1 : Float(64) %learned_2 : Float(192, 64, 5, 5) %learned_3 : Float(192) # ---- omitted for brevity ---- %learned_14 : Float(1000, 4096) %learned_15 : Float(1000)) { # Every statement consists of some output tensors (and their types), # the operator to be run (with its attributes, e.g., kernels, strides, # etc.), its input tensors (%actual_input_1, %learned_0, %learned_1) %17 : Float(10, 64, 55, 55) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[11, 11], pads=[2, 2, 2, 2], strides=[4, 4]](%actual_input_1, %learned_0, %learned_1), scope: AlexNet/Sequential[features]/Conv2d[0] %18 : Float(10, 64, 55, 55) = onnx::Relu(%17), scope: AlexNet/Sequential[features]/ReLU[1] %19 : Float(10, 64, 27, 27) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%18), scope: AlexNet/Sequential[features]/MaxPool2d[2] # ---- omitted for brevity ---- %29 : Float(10, 256, 6, 6) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%28), scope: AlexNet/Sequential[features]/MaxPool2d[12] # Dynamic means that the shape is not known. This may be because of a # limitation of our implementation (which we would like to fix in a # future release) or shapes which are truly dynamic. %30 : Dynamic = onnx::Shape(%29), scope: AlexNet %31 : Dynamic = onnx::Slice[axes=[0], ends=[1], starts=[0]](%30), scope: AlexNet %32 : Long() = onnx::Squeeze[axes=[0]](%31), scope: AlexNet %33 : Long() = onnx::Constant[value={9216}](), scope: AlexNet # ---- omitted for brevity ---- %output1 : Float(10, 1000) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%45, %learned_14, %learned_15), scope: AlexNet/Sequential[classifier]/Linear[6] return (%output1); } 您还可以使用 ONNX 库来验证 protobuf。 您可以使用 conda 安装ONNX： conda install -c conda-forge onnx 然后，您可以运行： import onnx # Load the ONNX model model = onnx.load(\"alexnet.onnx\") # Check that the IR is well formed onnx.checker.check_model(model) # Print a human readable representation of the graph onnx.helper.printable_graph(model.graph) 要使用 caffe2 运行导出的脚本，您将需要安装 caffe2 ：如果尚未安装，请按照安装说明进行操作。 一旦安装了这些，就可以将后端用于 Caffe2： # ...continuing from above import caffe2.python.onnx.backend as backend import numpy as np rep = backend.prepare(model, device=\"CUDA:0\") # or \"CPU\" # For the Caffe2 backend: # rep.predict_net is the Caffe2 protobuf for the network # rep.workspace is the Caffe2 workspace for the network # (see the class caffe2.python.onnx.backend.Workspace) outputs = rep.run(np.random.randn(10, 3, 224, 224).astype(np.float32)) # To run networks with more than one input, pass a tuple # rather than a single numpy ndarray. print(outputs[0]) 您还可以使用 ONNX Runtime 运行导出的模型，您将需要安装 ONNX Runtime ：请按照这些说明进行操作。 一旦安装了这些，就可以将后端用于 ONNX Runtime： # ...continuing from above import onnxruntime as ort ort_session = ort.InferenceSession('alexnet.onnx') outputs = ort_session.run(None, {'actual_input_1': np.random.randn(10, 3, 224, 224).astype(np.float32)}) print(outputs[0]) 这是将 SuperResolution 模型导出到 ONNX 的另一本教程。 。 将来，其他框架也会有后端。 跟踪与脚本编写 ONNX 导出器可以是基于跟踪的和基于脚本的导出器。 基于跟踪的表示它通过执行一次模型并导出在此运行期间实际运行的运算符进行操作。 这意味着如果您的模型是动态的，例如根据输入数据更改行为，则导出将不准确。 同样，跟踪可能仅对特定的输入大小才有效(这是我们在跟踪时需要显式输入的原因之一。）我们建议检查模型跟踪并确保所跟踪的运算符看起来合理。 如果您的模型包含控制循环(如 for 循环）和 if 条件，则基于基于跟踪的导出器将展开循环以及 if 条件，并导出与此运行完全相同的静态图形。 如果要使用动态控制流导出模型，则需要使用基于脚本的导出器。 基于脚本的表示您要导出的模型是 ScriptModule 。 ScriptModule 是 TorchScript 中的核心数据结构， TorchScript 是 Python 语言的子集，可从 PyTorch 代码创建可序列化和可优化的模型。 我们允许混合跟踪和脚本编写。 您可以组合跟踪和脚本以适合模型部分的特定要求。 看看这个例子： import torch # Trace-based only class LoopModel(torch.nn.Module): def forward(self, x, y): for i in range(y): x = x + i return x model = LoopModel() dummy_input = torch.ones(2, 3, dtype=torch.long) loop_count = torch.tensor(5, dtype=torch.long) torch.onnx.export(model, (dummy_input, loop_count), 'loop.onnx', verbose=True) 使用基于跟踪的导出器，我们得到结果 ONNX 图，该图展开了 for 循环： graph(%0 : Long(2, 3), %1 : Long()): %2 : Tensor = onnx::Constant[value={1}]() %3 : Tensor = onnx::Add(%0, %2) %4 : Tensor = onnx::Constant[value={2}]() %5 : Tensor = onnx::Add(%3, %4) %6 : Tensor = onnx::Constant[value={3}]() %7 : Tensor = onnx::Add(%5, %6) %8 : Tensor = onnx::Constant[value={4}]() %9 : Tensor = onnx::Add(%7, %8) return (%9) 为了利用基于脚本的导出器捕获动态循环，我们可以在脚本中编写循环，然后从常规 nn.Module 中调用它： # Mixing tracing and scripting @torch.jit.script def loop(x, y): for i in range(int(y)): x = x + i return x class LoopModel2(torch.nn.Module): def forward(self, x, y): return loop(x, y) model = LoopModel2() dummy_input = torch.ones(2, 3, dtype=torch.long) loop_count = torch.tensor(5, dtype=torch.long) torch.onnx.export(model, (dummy_input, loop_count), 'loop.onnx', verbose=True, input_names=['input_data', 'loop_range']) 现在，导出的 ONNX 图变为： graph(%input_data : Long(2, 3), %loop_range : Long()): %2 : Long() = onnx::Constant[value={1}](), scope: LoopModel2/loop %3 : Tensor = onnx::Cast[to=9](%2) %4 : Long(2, 3) = onnx::Loop(%loop_range, %3, %input_data), scope: LoopModel2/loop # custom_loop.py:240:5 block0(%i.1 : Long(), %cond : bool, %x.6 : Long(2, 3)): %8 : Long(2, 3) = onnx::Add(%x.6, %i.1), scope: LoopModel2/loop # custom_loop.py:241:13 %9 : Tensor = onnx::Cast[to=9](%2) -> (%9, %8) return (%4) 动态控制流已正确捕获。 我们可以在具有不同循环范围的后端进行验证。 import caffe2.python.onnx.backend as backend import numpy as np import onnx model = onnx.load('loop.onnx') rep = backend.prepare(model) outputs = rep.run((dummy_input.numpy(), np.array(9).astype(np.int64))) print(outputs[0]) #[[37 37 37] # [37 37 37]] import onnxruntime as ort ort_sess = ort.InferenceSession('loop.onnx') outputs = ort_sess.run(None, {'input_data': dummy_input.numpy(), 'loop_range': np.array(9).astype(np.int64)}) print(outputs) #[array([[37, 37, 37], # [37, 37, 37]], dtype=int64)] 局限性 导出中目前不支持张量就地索引分配，例如 data [index] = new_data 。 解决此类问题的一种方法是使用运算符散布，显式更新原始张量。 data = torch.zeros(3, 4) index = torch.tensor(1) new_data = torch.arange(4).to(torch.float32) # Assigning to left hand side indexing is not supported in exporting. # class InPlaceIndexedAssignment(torch.nn.Module): # def forward(self, data, index, new_data): # data[index] = new_data # return data class InPlaceIndexedAssignmentONNX(torch.nn.Module): def forward(self, data, index, new_data): new_data = new_data.unsqueeze(0) index = index.expand(1, new_data.size(1)) data.scatter_(0, index, new_data) return data out = InPlaceIndexedAssignmentONNX()(data, index, new_data) torch.onnx.export(InPlaceIndexedAssignmentONNX(), (data, index, new_data), 'inplace_assign.onnx') # caffe2 import caffe2.python.onnx.backend as backend import onnx onnx_model = onnx.load('inplace_assign.onnx') rep = backend.prepare(onnx_model) out_caffe2 = rep.run((torch.zeros(3, 4).numpy(), index.numpy(), new_data.numpy())) assert torch.all(torch.eq(out, torch.tensor(out_caffe2))) # onnxruntime import onnxruntime sess = onnxruntime.InferenceSession('inplace_assign.onnx') out_ort = sess.run(None, { sess.get_inputs()[0].name: torch.zeros(3, 4).numpy(), sess.get_inputs()[1].name: index.numpy(), sess.get_inputs()[2].name: new_data.numpy(), }) assert torch.all(torch.eq(out, torch.tensor(out_ort))) ONNX 中没有张量列表的概念。 没有这个概念，很难导出消耗或产生张量列表的运算符，尤其是在导出时不知道张量列表的长度的情况下。 x = torch.tensor([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]]) # This is not exportable class Model(torch.nn.Module): def forward(self, x): return x.unbind(0) # This is exportable. # Note that in this example we know the split operator will always produce exactly three outputs, # Thus we can export to ONNX without using tensor list. class AnotherModel(torch.nn.Module): def forward(self, x): return [torch.squeeze(out, 0) for out in torch.split(x, [1,1,1], dim=0)] 仅将元组，列表和变量作为 JIT 输入/输出支持。 也接受字典和字符串，但不建议使用它们。 用户需要仔细验证自己的字典输入，并记住动态查询不可用。 PyTorch 和 ONNX 后端(Caffe2，ONNX 运行时等）通常具有一些数字差异的运算符实现。 根据模型结构的不同，这些差异可能可以忽略不计，但是它们也可能导致行为上的重大差异(尤其是在未经训练的模型上。）我们允许 Caffe2 直接调用运算符的 Torch 实现，以在精度很重要时帮助您消除这些差异。 ，并记录这些差异。 支持的运营商 支持以下运算符： 批量标准 ConstantPadNd 转换 退出 嵌入(不支持可选参数） FeatureDropout(不支持训练模式） 指数 MaxPool1d MaxPool2d MaxPool3d RNN 腹肌 阿科斯 adaptive_avg_pool1d adaptive_avg_pool2d adaptive_avg_pool3d adaptive_max_pool1d adaptive_max_pool2d adaptive_max_pool3d 添加(不支持非零 Alpha） addmm 和 范围 argmax 精氨酸 阿辛 晒黑 avg_pool1d avg_pool2d avg_pool2d avg_pool3d Baddbmm 猫 细胞 钳 最大钳位 最小钳位 康卡特 cos cumsum 暗淡的 div 退出 lu 空的 空的喜欢 当量 埃尔夫 经验值 扩大 expand_as 展平 地板 frobenius_norm 充分 满喜欢 收集 ge 格鲁 谷氨酸 gt Hardtanh index_copy index_fill index_select instance_norm 插 伊斯南 layer_norm 乐 leaky_relu 日志 log1p 日志 2 log_sigmoid log_softmax 对数表达式 lt masked_fill 最大值 意思 分 毫米 多 多项式 狭窄 NE 负数 非零 规范 那些 喜欢 要么 置换 pixel_shuffle 战俘 prelu(不支持输入通道之间共享的单个权重） 产品 兰德 兰德 randn_like 倒数 Reflection_pad 露露 重复 复制垫 重塑 reshape_as 回合 雷雷鲁 rsqrt 订阅 分散 scatter_add 选择 塞卢 乙状结肠 标志 罪 尺寸 切片 软最大 软加 分类 分裂 sqrt 挤 堆 性病 子(不支持非零 Alpha） 和 Ť 棕褐色 谭 阈值(不支持非零阈值/非零值） 至 托普 转置 type_as 展开(与 ATen-Caffe2 集成的实验支持） 独特 松开 upsample_nearest1d upsample_nearest2d upsample_nearest3d 视图 哪里 零 zeros_like 上面设置的运算符足以导出以下模型： 亚历克斯网 DCGAN 密集网 初始阶段(警告：此模型对操作员实施的更改高度敏感） ResNet 超分辨率 VGG word_language_model 添加对运营商的支持 为操作员添加导出支持是的高级用法。 为此，开发人员需要触摸 PyTorch 的源代码。 请按照说明从源代码安装 PyTorch。 如果所需的运算符在 ONNX 中已标准化，则应该容易添加对导出此类运算符的支持(为该运算符添加符号功能）。 要确认操作员是否标准化，请检查 ONNX 操作员列表。 ATen 运算符 如果该运算符是 ATen 运算符，则意味着您可以在torch/csrc/autograd/generated/VariableType.h中找到该函数的声明(可在 PyTorch 安装目录的生成代码中找到），您应在torch/onnx/symbolic_opset&lt;version&gt;.py中添加符号函数，并按照以下说明进行操作 ： 在torch/onnx/symbolic_opset&lt;version&gt;.py中定义符号功能，例如 torch / onnx / symbolic_opset9.py 。 确保函数具有与VariableType.h中定义的 ATen 运算符/函数相同的名称。 第一个参数始终是导出的 ONNX 图。 参数名称必须与VariableType.h中的名称完全匹配，因为分配是通过关键字参数完成的。 参数排序不一定与VariableType.h中的匹配，张量(输入）始终是第一个，然后是非张量参数。 在符号功能中，如果运算符已经在 ONNX 中进行了标准化，我们只需要创建一个节点即可在图中表示 ONNX 运算符。 如果输入参数是张量，但 ONNX 要求标量，则必须显式进行转换。 辅助函数_scalar可以将标量张量转换为 python 标量，_if_scalar_type_as可以将 Python 标量转换为 PyTorch 张量。 非 ATen 运营商 如果该运算符是非 ATen 运算符，则必须在相应的 PyTorch Function 类中添加符号函数。 请阅读以下说明： 在相应的 Function 类中创建一个名为symbolic的符号函数。 第一个参数始终是导出的 ONNX 图。 除第一个参数名称外，参数名称必须与forward中的名称完全匹配。 输出元组大小必须与forward的输出匹配。 在符号功能中，如果运算符已经在 ONNX 中进行了标准化，我们只需要创建一个节点即可在图中表示 ONNX 运算符。 符号函数应在 Python 中实现。 所有这些功能都与通过 C ++-Python 绑定实现的 Python 方法进行交互，但是直观地讲，它们提供的接口如下所示： def operator/symbolic(g, *inputs): \"\"\" Modifies Graph (e.g., using \"op\"), adding the ONNX operations representing this PyTorch function, and returning a Value or tuple of Values specifying the ONNX outputs whose values correspond to the original PyTorch return values of the autograd Function (or None if an output is not supported by ONNX). Arguments: g (Graph): graph to write the ONNX representation into inputs (Value...): list of values representing the variables which contain the inputs for this function \"\"\" class Value(object): \"\"\"Represents an intermediate tensor value computed in ONNX.\"\"\" def type(self): \"\"\"Returns the Type of the value.\"\"\" class Type(object): def sizes(self): \"\"\"Returns a tuple of ints representing the shape of a tensor this describes.\"\"\" class Graph(object): def op(self, opname, *inputs, **attrs): \"\"\" Create an ONNX operator 'opname', taking 'args' as inputs and attributes 'kwargs' and add it as a node to the current graph, returning the value representing the single output of this operator (see the `outputs` keyword argument for multi-return nodes). The set of operators and the inputs/attributes they take is documented at https://github.com/onnx/onnx/blob/master/docs/Operators.md Arguments: opname (string): The ONNX operator name, e.g., `Abs` or `Add`. args (Value...): The inputs to the operator; usually provided as arguments to the `symbolic` definition. kwargs: The attributes of the ONNX operator, with keys named according to the following convention: `alpha_f` indicates the `alpha` attribute with type `f`. The valid type specifiers are `f` (float), `i` (int), `s` (string) or `t` (Tensor). An attribute specified with type float accepts either a single float, or a list of floats (e.g., you would say `dims_i` for a `dims` attribute that takes a list of integers). outputs (int, optional): The number of outputs this operator returns; by default an operator is assumed to return a single output. If `outputs` is greater than one, this functions returns a tuple of output `Value`, representing each output of the ONNX operator in positional. \"\"\" ONNX 图形 C ++定义在torch/csrc/jit/ir.h中。 这是处理elu运算符缺失的符号函数的示例。 我们尝试导出模型，并看到如下错误消息： UserWarning: ONNX export failed on elu because torch.onnx.symbolic_opset9.elu does not exist RuntimeError: ONNX export failed: Couldn't export operator elu 导出失败，因为 PyTorch 不支持导出elu运算符。 我们在VariableType.h中找到virtual Tensor elu(const Tensor & input, Scalar alpha, bool inplace) const override;。 这意味着elu是 ATen 运算符。 我们检查 ONNX 操作员列表，并确认Elu在 ONNX 中已标准化。 我们在symbolic_opset9.py中添加以下行： def elu(g, input, alpha, inplace=False): return g.op(\"Elu\", input, alpha_f=_scalar(alpha)) 现在，PyTorch 能够导出elu运算符。 symbolic_opset9.py 和 symbolic_opset10.py 中还有更多示例。 用于指定操作员定义的界面是实验性的； 冒险的用户应注意，API 可能会在将来的界面中更改。 定制运算符 按照本教程使用自定义 C ++运算符扩展[TorchScript] 之后，您可以在 PyTorch 中创建并注册自己的自定义 ops 实现。 将这种模型导出到 ONNX 的方法如下： # Create custom symbolic function from torch.onnx.symbolic_helper import parse_args @parse_args('v', 'v', 'f', 'i') def symbolic_foo_forward(g, input1, input2, attr1, attr2): return g.op(\"Foo\", input1, input2, attr1_f=attr1, attr2_i=attr2) # Register custom symbolic function from torch.onnx import register_custom_op_symbolic register_custom_op_symbolic('custom_ops::foo_forward', symbolic_foo_forward, 9) class FooModel(torch.nn.Module): def __init__(self, attr1, attr2): super(FooModule, self).__init__() self.attr1 = attr1 self.attr2 = attr2 def forward(self, input1, input2): # Calling custom op return torch.ops.custom_ops.foo_forward(input1, input2, self.attr1, self.attr2) model = FooModel(attr1, attr2) torch.onnx.export(model, (dummy_input1, dummy_input2), 'model.onnx') 根据自定义运算符的不同，您可以将其导出为现有 ONNX 操作之一或组合。 您也可以将其导出为 ONNX 中的自定义操作。 在这种情况下，您将需要通过匹配的自定义操作实现来扩展选择的后端，例如 Caffe2 定制操作， ONNX Runtime 定制操作。 常见问题解答 问：我已经导出了我的 lstm 模型，但是它的输入大小似乎是固定的？ 跟踪器将示例输入形状记录在图中。 如果模型应接受动态形状的输入，则可以在导出 api 中使用参数 dynamic_axes 。 layer_count = 4 model = nn.LSTM(10, 20, num_layers=layer_count, bidirectional=True) model.eval() with torch.no_grad(): input = torch.randn(5, 3, 10) h0 = torch.randn(layer_count * 2, 3, 20) c0 = torch.randn(layer_count * 2, 3, 20) output, (hn, cn) = model(input, (h0, c0)) # default export torch.onnx.export(model, (input, (h0, c0)), 'lstm.onnx') onnx_model = onnx.load('lstm.onnx') # input shape [5, 3, 10] print(onnx_model.graph.input[0]) # export with `dynamic_axes` torch.onnx.export(model, (input, (h0, c0)), 'lstm.onnx', input_names=['input', 'h0', 'c0'], output_names=['output', 'hn', 'cn'], dynamic_axes={'input': {0: 'sequence'}, 'output': {0: 'sequence'}}) onnx_model = onnx.load('lstm.onnx') # input shape ['sequence', 3, 10] print(onnx_model.graph.input[0]) 问：如何导出带有循环的模型？ 请签出跟踪与脚本编写。 问：ONNX 是否支持隐式标量数据类型转换？ 不，但是出口商将尝试处理该部分。 标量在 ONNX 中转换为恒定张量。 导出器将尝试找出标量的正确数据类型。 但是，对于无法执行此操作的情况，您将需要手动提供数据类型信息。 这通常发生在脚本模型中，其中未记录数据类型。 我们正在尝试改进数据类型在导出器中的传播，以便将来不再需要手动更改。 class ImplicitCastType(torch.jit.ScriptModule): @torch.jit.script_method def forward(self, x): # Exporter knows x is float32, will export '2' as float32 as well. y = x + 2 # Without type propagation, exporter doesn't know the datatype of y. # Thus '3' is exported as int64 by default. return y + 3 # The following will export correctly. # return y + torch.tensor([3], dtype=torch.float32) x = torch.tensor([1.0], dtype=torch.float32) torch.onnx.export(ImplicitCastType(), x, 'models/implicit_cast.onnx', example_outputs=ImplicitCastType()(x)) 功能 torch.onnx.export(model, args, f, export_params=True, verbose=False, training=False, input_names=None, output_names=None, aten=False, export_raw_ir=False, operator_export_type=None, opset_version=None, _retain_param_name=True, do_constant_folding=False, example_outputs=None, strip_doc_string=True, dynamic_axes=None, keep_initializers_as_inputs=None)¶ 将模型导出为 ONNX 格式。 这个导出器运行一次您的模型，以便跟踪要导出的模型执行情况。 目前，它支持一组有限的动态模型(例如 RNN）。 参数 模型 (torch.nn.Module)–要导出的模型。 参数(参数元组）–模型的输入，例如，使得model(*args)是模型的有效调用。 任何非 Tensor 参数将被硬编码到导出的模型中； 任何 Tensor 参数将按照在 args 中出现的顺序成为导出模型的输入。 如果 args 是一个 Tensor，则相当于用该 Tensor 的 1 元元组调用了它。 (注意：当前不支持将关键字参数传递给模型。如果需要，请给我们喊叫。） f –类似于文件的对象(必须实现返回文件描述符的 fileno）或包含文件名的字符串。 二进制 Protobuf 将被写入此文件。 export_params (布尔 ， 默认为 True )–如果指定，将导出所有参数。 如果要导出未经训练的模型，请将其设置为 False。 在这种情况下，导出的模型将首先以其所有参数作为参数，顺序由model.state_dict().values()指定 详细 (bool ， 默认为 False )–如果指定，我们将打印出导出跟踪的调试描述。 训练 (bool ， 默认为 False )–以训练模式导出模型。 目前，ONNX 仅面向导出模型以进行推理，因此通常不需要将其设置为 True。 input_names (字符串列表 ， 默认空列表）–依次分配给图形输入节点的名称 output_names (字符串列表 ， 默认空列表）–依次分配给图形输出节点的名称 和 (bool ， 默认为 False )– [不推荐使用。 使用 operator_export_type]以 aten 模式导出模型。 如果使用 aten 模式，则 symbolic_opset .py 中的函数所导出的所有 ops 原始文件都将作为 ATen ops 导出。 export_raw_ir (布尔 ， 默认为 False )– [不建议使用。 使用 operator_export_type]直接导出内部 IR，而不是将其转换为 ONNX ops。 operator_export_type (枚举 ， 默认 OperatorExportTypes.ONNX )– OperatorExportTypes.ONNX：所有操作均作为常规 ONNX 操作导出。 OperatorExportTypes.ONNX_ATEN：所有操作均导出为 ATen 操作。 OperatorExportTypes.ONNX_ATEN_FALLBACK：如果缺少符号，请使用 ATen op。 OperatorExportTypes.RAW：导出原始 ir。 opset_version (python：int ， 默认为 9 )–默认情况下，我们将模型导出到 onnx 子模块的 opset 版本。 由于 ONNX 的最新 opset 可能会在下一个稳定版本之前发展，因此默认情况下，我们会导出到一个稳定的 opset 版本。 目前，受支持的稳定 opset 版本为 9。opset_version 必须为 _onnx_master_opset 或在 torch / onnx / symbolic_helper.py 中定义的 _onnx_stable_opsets 中。 do_constant_folding (bool ， 默认 False )–如果为 True，则在导出期间将恒定折叠优化应用于模型。 常量折叠优化将用预先计算的常量节点替换一些具有所有常量输入的操作。 example_outputs (张量元组 ， 默认无）–导出 ScriptModule 或 TorchScript 函数时必须提供 example_outputs。 strip_doc_string (bool ， 默认 True )–如果为 True，则从导出的模型中删除字段“ doc_string”，有关 堆栈跟踪。 example_outputs –正在导出的模型的示例输出。 dynamic_axes (dict ， dict ， 字符串 > > 或 dict ， 列表 ( python：int ） > ， 默认为空字典）– 一个字典，用于指定输入/输出的动态轴，例如：-KEY：输入和/或输出名称-VALUE：给定键的动态轴的索引，以及可能用于导出动态轴的名称。 通常，该值是根据以下方式之一或两者的组合定义的：(1）。 指定提供的输入的动态轴的整数列表。 在这种情况下，将在导出过程中自动生成名称并将其应用于提供的输入/输出的动态轴。 或(2）。 一个内部字典，该字典指定从对应的输入/输出中的动态轴的索引到在导出过程中希望在此输入/输出的该轴上应用的名称的映射。 例。 如果我们的输入和输出具有以下形状： shape(input_1) = ('b', 3, 'w', 'h') and shape(input_2) = ('b', 4) and shape(output) = ('b', 'd', 5) Then dynamic axes can be defined either as: (a). ONLY INDICES: dynamic_axes = {'input_1'：[0，2，3]，'input_2'：[0]，'output'：[0，1]} 其中将为导出的动态轴生成自动名称 (b). INDICES WITH CORRESPONDING NAMES: dynamic_axes = {'input_1'：{0：'batch'，1：'width'，2：'height'}，'input_2'：{0：'batch'}，'output'：{0：'batch'， 1：“检测”} 提供的名称将应用于导出的动态轴 (c). MIXED MODE OF (a) and (b) dynamic_axes = {'input_1'：[0，2，3]，'input_2'：{0：'batch'}，'output'：[0,1]} keep_initializers_as_inputs (bool ， 默认值 None )–如果为 True，则导出的图中的所有初始化程序(通常对应于参数）也将 被添加为图形的输入。 如果为 False，则不会将初始化程序添加为图形的输入，而仅将非参数输入添加为输入。 通过执行这些图形的后端/运行时，这可以允许进行更好的优化(例如恒定折叠等）。 如果未指定(默认为“无”），则按以下方式自动选择行为。 如果 operator_export_type 为 OperatorExportTypes.ONNX，则该行为等效于将此参数设置为 False。 对于 operator_export_type 的其他值，此行为等同于将此参数设置为 True。 请注意，对于 ONNX opset 版本 torch.onnx.register_custom_op_symbolic(symbolic_name, symbolic_fn, opset_version)¶ torch.onnx.operators.shape_as_tensor(x)¶ torch.onnx.set_training(model, mode)¶ 上下文管理器将“模型”的训练模式临时设置为“模式”，当我们退出 with 块时将其重置。 如果模式为“无”，则为无操作。 torch.onnx.is_in_onnx_export()¶ 检查它是否在 ONNX 导出的中间。 此函数在 torch.onnx.export(）的中间返回 True。 torch.onnx.export 应该使用单线程执行。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:37:53 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"87.html":{"url":"87.html","title":"torch.optim","keywords":"","body":"torch.optim 原文： https://pytorch.org/docs/stable/optim.html torch.optim 是实现各种优化算法的软件包。 已经支持最常用的方法，并且接口足够通用，因此将来也可以轻松集成更复杂的方法。 如何使用优化器 要使用 torch.optim ，您必须构造一个优化器对象，该对象将保持当前状态并根据计算出的梯度更新参数。 构造它 要构建 Optimizer ，您必须为其提供一个包含参数的可迭代项(所有参数应为Variable）以进行优化。 然后，您可以指定优化器特定的选项，例如学习率，权重衰减等。 注意 如果您需要通过.cuda()将模型移至 GPU，请在为其构建优化器之前执行此操作。 .cuda()之后的模型参数将与调用之前的参数不同。 通常，在构造和使用优化器时，应确保优化的参数位于一致的位置。 例： optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) optimizer = optim.Adam([var1, var2], lr=0.0001) 每个参数选项 Optimizer 也支持指定每个参数选项。 为此，不要传递Variable的迭代器，而是传递dict的迭代器。 它们每个都将定义一个单独的参数组，并且应包含一个params键，其中包含属于它的参数列表。 其他键应与优化器接受的关键字参数匹配，并将用作该组的优化选项。 Note 您仍然可以将选项作为关键字参数传递。 在未覆盖它们的组中，它们将用作默认值。 当您只想改变一个选项，同时使所有其他参数组保持一致时，这很有用。 例如，当要指定每层学习率时，这非常有用： optim.SGD([ {'params': model.base.parameters()}, {'params': model.classifier.parameters(), 'lr': 1e-3} ], lr=1e-2, momentum=0.9) 这意味着model.base的参数将使用默认的学习率1e-2，model.classifier的参数将使用1e-3的学习率，并且动量0.9会用于所有参数。 采取优化步骤 所有优化器均实现 step() 方法，该方法可更新参数。 它可以以两种方式使用： optimizer.step() 这是大多数优化程序支持的简化版本。 一旦使用例如计算出梯度，就可以调用该函数。 backward()。 Example: for input, target in dataset: optimizer.zero_grad() output = model(input) loss = loss_fn(output, target) loss.backward() optimizer.step() optimizer.step(closure) 某些优化算法(例如共轭梯度和 LBFGS）需要多次重新评估函数，因此您必须传递闭包以允许它们重新计算模型。 闭合应清除梯度，计算损耗，然后将其返回。 Example: for input, target in dataset: def closure(): optimizer.zero_grad() output = model(input) loss = loss_fn(output, target) loss.backward() return loss optimizer.step(closure) 演算法 class torch.optim.Optimizer(params, defaults)¶ 所有优化程序的基类。 警告 需要将参数指定为具有确定性顺序的集合，这些顺序在两次运行之间是一致的。 不满足这些属性的对象的示例是字典值的集合和迭代器。 参数 参数(迭代）– torch.Tensor 或dict s 的迭代。 指定应优化哪些张量。 默认值为 –(dict）：包含优化选项默认值的 dict(在参数组未指定优化选项时使用）。 add_param_group(param_group)¶ 将参数组添加到 Optimizer 的 param_groups 中。 当对预训练的网络进行微调时，这很有用，因为可以使冻结层成为可训练的，并随着训练的进行而添加到 Optimizer 中。 Parameters param_group (dict )–指定应与组一起优化哪些张量 优化选项。 (特定于）– load_state_dict(state_dict)¶ 加载优化器状态。 Parameters state_dict (dict )–优化器状态。 应该是从对 state_dict() 的调用返回的对象。 state_dict()¶ 以dict的形式返回优化器的状态。 它包含两个条目： state - a dict holding current optimization state. Its content 优化器类之间有所不同。 param_groups-包含所有参数组的字典 step(closure)¶ 执行单个优化步骤(参数更新）。 Parameters 闭合(可调用的）–重新评估模型并返回损失的闭合。 对于大多数优化程序是可选的。 zero_grad()¶ 清除所有优化的 torch.Tensor 的梯度。 class torch.optim.Adadelta(params, lr=1.0, rho=0.9, eps=1e-06, weight_decay=0)¶ 实现 Adadelta 算法。 在 ADADELTA 中提出了一种：自适应学习率方法。 Parameters 参数(可迭代）–参数可迭代以优化或命令定义参数组 rho (python：float ， 可选）–用于计算平方梯度的移动平均值的系数(默认值：0.9） eps (python：float ， 可选）–分母添加到分母以提高数值稳定性(默认值：1e-6） lr (python：float ， 可选）–在将增量应用于参数之前对其进行缩放的系数(默认值：1.0） weight_decay (python：float ， 可选）–权重衰减(L2 惩罚）(默认值：0） step(closure=None)¶ 执行一个优化步骤。 Parameters 闭合(可调用的， 可选）–重新评估模型并返回损失的闭合。 class torch.optim.Adagrad(params, lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)¶ 实现 Adagrad 算法。 它已在在线学习和随机优化的自适应次梯度方法中提出。 Parameters params (iterable) – iterable of parameters to optimize or dicts defining parameter groups lr (python：float ， 可选）–学习率(默认值：1e-2） lr_decay (python：float ， 可选）–学习速率衰减(默认值：0） weight_decay (python:float__, optional) – weight decay (L2 penalty) (default: 0) eps (python：float ， 可选）–分母添加到分母以提高数值稳定性(默认值：1e-10） step(closure=None)¶ Performs a single optimization step. Parameters closure (callable__, optional) – A closure that reevaluates the model and returns the loss. class torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)¶ 实现亚当算法。 在 Adam 中提出了一种随机优化方法。 Parameters params (iterable) – iterable of parameters to optimize or dicts defining parameter groups lr (python：float ， 可选）–学习率(默认值：1e-3） Betas (Tuple [ python：float ， python：float ] ， 可选）–用于计算梯度及其平方的移动平均值的系数(默认值：(0.9，0.999）） eps (python：float ， 可选）–分母添加到分母以提高数值稳定性(默认值：1e-8） weight_decay (python:float__, optional) – weight decay (L2 penalty) (default: 0) amsgrad (布尔值 ， 可选）–是否使用论文上该算法的 AMSGrad 变体 Adam and Beyond (默认值：False） step(closure=None)¶ Performs a single optimization step. Parameters closure (callable__, optional) – A closure that reevaluates the model and returns the loss. class torch.optim.AdamW(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)¶ 实现 AdamW 算法。 最初的 Adam 算法是在 Adam：随机优化方法中提出的。 AdamW 变体在去耦权重衰减正则化中提出。 Parameters params (iterable) – iterable of parameters to optimize or dicts defining parameter groups lr (python:float__, optional) – learning rate (default: 1e-3) betas (Tuple[python:float__, python:float], optional) – coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999)) eps (python:float__, optional) – term added to the denominator to improve numerical stability (default: 1e-8) weight_decay (python：float ， 可选）–权重衰减系数(默认值：1e-2） amsgrad (boolean__, optional) – whether to use the AMSGrad variant of this algorithm from the paper On the Convergence of Adam and Beyond (default: False) step(closure=None)¶ Performs a single optimization step. Parameters closure (callable__, optional) – A closure that reevaluates the model and returns the loss. class torch.optim.SparseAdam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08)¶ 实现适用于稀疏张量的 Adam 算法的惰性版本。 在此变体中，仅显示出现在渐变中的力矩，并且仅将渐变的那些部分应用于参数。 Parameters params (iterable) – iterable of parameters to optimize or dicts defining parameter groups lr (python:float__, optional) – learning rate (default: 1e-3) betas (Tuple[python:float__, python:float], optional) – coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999)) eps (python:float__, optional) – term added to the denominator to improve numerical stability (default: 1e-8) step(closure=None)¶ Performs a single optimization step. Parameters closure (callable__, optional) – A closure that reevaluates the model and returns the loss. class torch.optim.Adamax(params, lr=0.002, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)¶ 实现 Adamax 算法(基于无穷范数的 Adam 的变体）。 It has been proposed in Adam: A Method for Stochastic Optimization. Parameters params (iterable) – iterable of parameters to optimize or dicts defining parameter groups lr (python：float ， 可选）–学习率(默认值：2e-3） Betas (Tuple [ python：float ， python：float ] ， 可选）–用于计算梯度及其平方的移动平均值的系数 eps (python:float__, optional) – term added to the denominator to improve numerical stability (default: 1e-8) weight_decay (python:float__, optional) – weight decay (L2 penalty) (default: 0) step(closure=None)¶ Performs a single optimization step. Parameters closure (callable__, optional) – A closure that reevaluates the model and returns the loss. class torch.optim.ASGD(params, lr=0.01, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)¶ 实施平均随机梯度下降。 在通过平均对随机逼近的加速中提出。 Parameters params (iterable) – iterable of parameters to optimize or dicts defining parameter groups lr (python:float__, optional) – learning rate (default: 1e-2) lambd (python：float ， 可选）–衰减项(默认值：1e-4） alpha (python：float ， 可选）– eta 更新的电源(默认值：0.75） t0 (python：float ， 可选）–开始平均的点(默认值：1e6） weight_decay (python:float__, optional) – weight decay (L2 penalty) (default: 0) step(closure=None)¶ Performs a single optimization step. Parameters closure (callable__, optional) – A closure that reevaluates the model and returns the loss. class torch.optim.LBFGS(params, lr=1, max_iter=20, max_eval=None, tolerance_grad=1e-07, tolerance_change=1e-09, history_size=100, line_search_fn=None)¶ 实现 L-BFGS 算法，该算法受到 minFunc https://www.cs.ubc.ca/~schmidtm/Software/minFunc.html > 的启发。 Warning 此优化器不支持每个参数的选项和参数组(只能有一个）。 Warning 现在，所有参数都必须在单个设备上。 将来会有所改善。 Note 这是一个非常占用内存的优化器(它需要额外的param_bytes * (history_size + 1)字节）。 如果内存不足，请尝试减小历史记录的大小，或使用其他算法。 Parameters lr (python：float )–学习率(默认值：1） max_iter (python：int )–每个优化步骤的最大迭代次数(默认值：20） max_eval (python：int )–每个优化步骤的最大函数求值数(默认值：max_iter * 1.25）。 tolerance_grad (python：float )–一阶最优的终止公差(默认值：1e-5）。 tolerance_change (python：float )–函数值/参数更改的终止公差(默认值：1e-9）。 history_size (python：int )–更新历史记录大小(默认值：100）。 line_search_fn (str )–“ strong_wolfe”或“无”(默认值：无）。 step(closure)¶ Performs a single optimization step. Parameters 闭合(可调用的）–重新评估模型并返回损失的闭合。 class torch.optim.RMSprop(params, lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)¶ 实现 RMSprop 算法。 由 G. Hinton 在他的课程中提出。 居中版本首先出现在中，并使用递归神经网络生成序列。 这里的实现在添加 epsilon 之前取梯度平均值的平方根(请注意，TensorFlow 会互换这两个操作）。 因此，有效学习率是，其中是计划的学习率，是平方梯度的加权移动平均值。 Parameters params (iterable) – iterable of parameters to optimize or dicts defining parameter groups lr (python:float__, optional) – learning rate (default: 1e-2) 动量 (python：float ， 可选）–动量因子(默认值：0） alpha (python：float ， 可选）–平滑常数(默认值：0.99） eps (python:float__, optional) – term added to the denominator to improve numerical stability (default: 1e-8) 以为中心的 (bool ， 可选）–如果True来计算居中的 RMSProp，则通过对其斜率的估计对其进行归一化 方差 weight_decay (python:float__, optional) – weight decay (L2 penalty) (default: 0) step(closure=None)¶ Performs a single optimization step. Parameters closure (callable__, optional) – A closure that reevaluates the model and returns the loss. class torch.optim.Rprop(params, lr=0.01, etas=(0.5, 1.2), step_sizes=(1e-06, 50))¶ 实现弹性反向传播算法。 Parameters params (iterable) – iterable of parameters to optimize or dicts defining parameter groups lr (python:float__, optional) – learning rate (default: 1e-2) etas (元组 [ python：float ， python：float ] ， 可选）–对(增加，减少）(增加，减少）(默认值：(0.5，1.2）） step_sizes (元组 [ python：float ， python：float ] ， 可选）–一对最小和最大允许步长(默认值：(1e-6，50）） step(closure=None)¶ Performs a single optimization step. Parameters closure (callable__, optional) – A closure that reevaluates the model and returns the loss. class torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False)¶ 实现随机梯度下降(可选带动量）。 Nesterov 动量基于中关于初始化和动量在深度学习中的重要性的公式。 Parameters params (iterable) – iterable of parameters to optimize or dicts defining parameter groups lr (python：float )–学习率 momentum (python:float__, optional) – momentum factor (default: 0) weight_decay (python:float__, optional) – weight decay (L2 penalty) (default: 0) 衰减 (python：float ， 可选）–衰减动量(默认值：0） nesterov (bool ， 可选）–启用 Nesterov 动量(默认：False） 例 >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9) >>> optimizer.zero_grad() >>> loss_fn(model(input), target).backward() >>> optimizer.step() Note 用 Momentum / Nesterov 实施 SGD 与 Sutskever 等人的方法有所不同。 等 以及其他一些框架中的实现。 考虑到动量的具体情况，可以将更新写为 其中，p，g，v 和分别表示参数，梯度，速度和动量。 这与 Sutskever 等人相反。 等 和其他使用表格更新的框架 Nesterov 版本进行了类似的修改。 step(closure=None)¶ Performs a single optimization step. Parameters closure (callable__, optional) – A closure that reevaluates the model and returns the loss. 如何调整学习率 torch.optim.lr_scheduler提供了几种根据时期数来调整学习率的方法。 torch.optim.lr_scheduler.ReduceLROnPlateau 允许基于某些验证度量来降低动态学习率。 优化器更新后应应用学习率安排； 例如，您应该以这种方式编写代码： >>> scheduler = ... >>> for epoch in range(100): >>> train(...) >>> validate(...) >>> scheduler.step() Warning 在 PyTorch 1.1.0 之前，学习率调度程序应在优化程序更新之前调用； 1.1.0 改变了这种行为，打破了 BC。 如果您在优化程序更新之前(调用optimizer.step()）使用学习率计划程序(调用scheduler.step()），则会跳过学习率计划的第一个值。 如果升级到 PyTorch 1.1.0 后无法重现结果，请检查是否在错误的时间调用了scheduler.step()。 class torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=-1)¶ 将每个参数组的学习率设置为给定函数的初始 lr 倍。 当 last_epoch = -1 时，将初始 lr 设置为 lr。 Parameters 优化器 (优化器)–包装的优化器。 lr_lambda (函数 或 列表）–一个给定整数参数纪元的乘法因子或此类函数列表的函数 ，对于 optimizer.param_groups 中的每个组一个。 last_epoch (python：int )–最后一个纪元的索引。 默认值：-1。 Example >>> # Assuming optimizer has two groups. >>> lambda1 = lambda epoch: epoch // 30 >>> lambda2 = lambda epoch: 0.95 ** epoch >>> scheduler = LambdaLR(optimizer, lr_lambda=[lambda1, lambda2]) >>> for epoch in range(100): >>> train(...) >>> validate(...) >>> scheduler.step() load_state_dict(state_dict)¶ 加载调度程序状态。 Parameters state_dict (dict )–调度程序状态。 应该是从对 state_dict() 的调用返回的对象。 state_dict()¶ 返回调度程序的状态为dict。 它包含 self . dict 中不是优化程序的每个变量的条目。 学习率 lambda 函数仅在它们是可调用对象时才被保存，而在它们是函数或 lambda 时才被保存。 class torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda, last_epoch=-1)¶ 将每个参数组的学习率乘以指定函数中给定的因子。 当 last_epoch = -1 时，将初始 lr 设置为 lr。 Parameters optimizer (Optimizer) – Wrapped optimizer. lr_lambda (function or list) – A function which computes a multiplicative factor given an integer parameter epoch, or a list of such functions, one for each group in optimizer.param_groups. last_epoch (python:int) – The index of last epoch. Default: -1. Example >>> # Assuming optimizer has two groups. >>> lmbda = lambda epoch: 0.95 >>> scheduler = LambdaLR(optimizer, lr_lambda=lmbda) >>> for epoch in range(100): >>> train(...) >>> validate(...) >>> scheduler.step() load_state_dict(state_dict)¶ Loads the schedulers state. Parameters state_dict (dict )–调度程序状态。 应该是从对 state_dict() 的调用返回的对象。 state_dict()¶ Returns the state of the scheduler as a dict. It contains an entry for every variable in self.dict which is not the optimizer. The learning rate lambda functions will only be saved if they are callable objects and not if they are functions or lambdas. class torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=0.1, last_epoch=-1)¶ 在每个 step_size 时期，通过 gamma 降低每个参数组的学习率。 注意，这种衰减可能与此调度程序外部的学习速率的其他更改同时发生。 当 last_epoch = -1 时，将初始 lr 设置为 lr。 Parameters optimizer (Optimizer) – Wrapped optimizer. step_size (python：int )–学习率衰减的周期。 伽玛 (python：float )–学习率衰减的乘法因子。 默认值：0.1 last_epoch (python:int) – The index of last epoch. Default: -1. Example >>> # Assuming optimizer uses lr = 0.05 for all groups >>> # lr = 0.05 if epoch >> # lr = 0.005 if 30 >> # lr = 0.0005 if 60 >> # ... >>> scheduler = StepLR(optimizer, step_size=30, gamma=0.1) >>> for epoch in range(100): >>> train(...) >>> validate(...) >>> scheduler.step() class torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1, last_epoch=-1)¶ 一旦历元数达到其中一个里程碑，则通过伽马衰减每个参数组的学习率。 注意，这种衰减可能与此调度程序外部的学习速率的其他更改同时发生。 当 last_epoch = -1 时，将初始 lr 设置为 lr。 Parameters optimizer (Optimizer) – Wrapped optimizer. 里程碑(列表）–时期索引列表。 必须增加。 gamma (python:float) – Multiplicative factor of learning rate decay. Default: 0.1. last_epoch (python:int) – The index of last epoch. Default: -1. Example >>> # Assuming optimizer uses lr = 0.05 for all groups >>> # lr = 0.05 if epoch >> # lr = 0.005 if 30 >> # lr = 0.0005 if epoch >= 80 >>> scheduler = MultiStepLR(optimizer, milestones=[30,80], gamma=0.1) >>> for epoch in range(100): >>> train(...) >>> validate(...) >>> scheduler.step() class torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma, last_epoch=-1)¶ 在每个时期以伽马衰减每个参数组的学习率。 当 last_epoch = -1 时，将初始 lr 设置为 lr。 Parameters optimizer (Optimizer) – Wrapped optimizer. 伽玛 (python：float )–学习率衰减的乘法因子。 last_epoch (python:int) – The index of last epoch. Default: -1. class torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=0, last_epoch=-1)¶ 使用余弦退火进度表设置每个参数组的学习率，其中设置为初始 lr，是自 SGDR 上次重新启动以来的时期数： 当 last_epoch = -1 时，将初始 lr 设置为 lr。 注意，由于调度是递归定义的，因此其他操作员可以在此调度器外部同时修改学习率。 如果学习率仅由此调度程序设置，则每个步骤的学习率变为： 它已在 SGDR：具有暖重启的随机梯度下降中提出。 请注意，这仅实现 SGDR 的余弦退火部分，而不实现重新启动。 Parameters optimizer (Optimizer) – Wrapped optimizer. T_max (python：int )–最大迭代次数。 eta_min (python：float )–最低学习率。 默认值：0 last_epoch (python:int) – The index of last epoch. Default: -1. class torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=False, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)¶ 当指标停止改善时，降低学习率。 一旦学习停滞，模型通常会受益于将学习率降低 2-10 倍。 该调度程序读取一个指标数量，如果在“耐心”时期没有看到改善，则学习速度会降低。 Parameters optimizer (Optimizer) – Wrapped optimizer. 模式 (str )– min ， max 中的一种。 在 min 模式下，当监视的数量停止减少时，lr 将减小； 在 max 模式下，当监视的数量停止增加时，它将减少。 默认值：“分钟”。 因子 (python：float )–将降低学习率的因子。 new_lr = lr *因子。 默认值：0.1 耐心 (python：int )–没有改善的时期数，之后学习率将降低。 例如，如果耐心= 2 ，那么我们将忽略前两个时期，而没有改善，并且如果损失仍然没有改善，则只会在第三个时期之后降低 LR。 默认值：10 详细 (bool )–如果True，则为每次更新向 stdout 打印一条消息。 默认值：False。 阈值 (python：float )–用于测量新最优值的阈值，仅关注重大变化。 默认值：1e-4。 threshold_mode (str )– 相对， abs 之一。 在相对于模式下，dynamic_threshold =最佳(1 +阈值）在“最大”模式下，最佳(1-阈值）在 min 模式下。 在绝对模式下，dynamic_threshold =最佳+ max 模式下的阈值，或 best-阈值 min 模式下的阈值。 默认值：“ rel”。 冷却时间 (python：int )–减少 lr 后恢复正常运行之前要等待的时期数。 默认值：0 min_lr (python：float 或 列表）–标量或标量列表。 所有参数组或每个组的学习率的下限。 默认值：0 eps (python：float )–应用于 lr 的最小衰减。 如果新旧 lr 之间的差异小于 eps，则忽略该更新。 默认值：1e-8。 Example >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9) >>> scheduler = ReduceLROnPlateau(optimizer, 'min') >>> for epoch in range(10): >>> train(...) >>> val_loss = validate(...) >>> # Note that step should be called after validate() >>> scheduler.step(val_loss) class torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr, max_lr, step_size_up=2000, step_size_down=None, mode='triangular', gamma=1.0, scale_fn=None, scale_mode='cycle', cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=-1)¶ 根据周期学习率策略(CLR）设置每个参数组的学习率。 该策略以恒定的频率在两个边界之间循环学习率，如论文训练神经网络的循环学习率中所述。 两个边界之间的距离可以在每个迭代或每个周期的基础上缩放。 周期性学习率策略会在每批之后更改学习率。 在将一批用于训练之后，应调用步骤。 如本文所述，该类具有三个内置策略： “三角形”：没有幅度缩放的基本三角形周期。 “ triangular2”：一个基本的三角形周期，它将每个周期的初始幅度缩放一半。 “ exp_range”：一个在每次循环迭代中按缩放初始幅度的循环。 此实现改编自 github 存储库： bckenstler / CLR Parameters optimizer (Optimizer) – Wrapped optimizer. base_lr (python：float 或 列表）–初始学习速率，它是每个参数组循环的下限。 max_lr (python：float 或 列表）–每个参数组在循环中的较高学习率边界。 从功能上讲，它定义了循环幅度(max_lr-base_lr）。 任何周期的 lr 是 base_lr 与振幅的一定比例之和； 因此，取决于缩放函数，可能实际上无法达到 max_lr。 step_size_up (python：int )–周期递增的一半中的训练迭代次数。 默认值：2000 step_size_down (python：int )–减少周期的一半内的训练迭代次数。 如果 step_size_down 为 None，则将其设置为 step_size_up。 默认值：无 模式 (str )– {triangle，trial2，exp_range}中的一种。 值与上面详述的策略相对应。 如果 scale_fn 不为 None，则忽略此参数。 默认值：“三角形” 伽玛 (python：float )–'exp_range'缩放函数中的常量：gamma **(循环迭代）默认值：1.0 scale_fn (函数）–由单个参数 lambda 函数定义的自定义缩放策略，其中对于所有 x > = 0 scale_mode (str )– {“周期”，“迭代次数”}。 定义是否在循环数或循环迭代(自循环开始后的训练迭代）中评估 scale_fn。 默认值：“循环” cycle_momentum (bool )–如果True，则动量与学习速率成反比地在“ base_momentum”和“ max_momentum”之间循环。 默认值：True base_momentum (python：float 或 列表）–每个参数组的循环动量边界较低。 注意，动量与学习速度成反比。 在一个周期的最高峰，动量为“ base_momentum”，学习速率为“ max_lr”。 默认值：0.8 max_momentum (python：float 或 列表）–每个参数组在循环中的较高动量边界。 从功能上讲，它定义了循环幅度(max_momentum-base_momentum）。 任何周期的动量都是 max_momentum 与振幅的一定比例之差； 因此，取决于缩放功能，实际上可能无法达到 base_momentum。 注意，动量与学习速度成反比。 在周期开始时，动量为“ max_momentum”，学习率为“ base_lr”默认值：0.9 last_epoch (python：int )–最后一批的索引。 恢复训练作业时使用此参数。 由于 step(）应该在每个批处理之后而不是在每个时期之后调用，因此该数字表示所计算的批次的总数，而不是所计算的时期总数。 当 last_epoch = -1 时，调度将从头开始。 默认值：-1 Example >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9) >>> scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1) >>> data_loader = torch.utils.data.DataLoader(...) >>> for epoch in range(10): >>> for batch in data_loader: >>> train_batch(...) >>> scheduler.step() get_lr()¶ 计算批次索引的学习率。 此函数将 self.last_epoch 视为最后一批索引。 如果 self.cycle_momentum 为True，则此功能具有更新优化器动量的副作用。 class torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, total_steps=None, epochs=None, steps_per_epoch=None, pct_start=0.3, anneal_strategy='cos', cycle_momentum=True, base_momentum=0.85, max_momentum=0.95, div_factor=25.0, final_div_factor=10000.0, last_epoch=-1)¶ 根据 1cycle 学习率策略设置每个参数组的学习率。 1 周期策略将学习速率从初始学习速率退火到某个最大学习速率，然后从该最大学习速率退火到某个远低于初始学习速率的最小学习速率。 最初在论文超融合：使用大学习率的超快速神经网络训练中描述了此策略。 1 周期学习率策略每批更改一次学习率。 在将一批用于训练之后，应调用步骤。 此调度程序不可链接。 还请注意，可以用以下两种方法之一确定循环中的步骤总数(按优先顺序列出）： 明确提供了 total_steps 的值。 提供了多个时期(epoch）和每个时期的步骤数(steps_per_epoch）。 在这种情况下，总步数由 total_steps = epochs * steps_per_epoch 推断 您必须为 total_steps 提供一个值，或者为纪元和 steps_per_epoch 提供一个值。 Parameters optimizer (Optimizer) – Wrapped optimizer. max_lr (python：float 或 列表）–每个参数组在循环中的较高学习率边界。 total_steps (python：int )–循环中的总步数。 请注意，如果此处提供了一个值，则必须通过为 epochs 和 steps_per_epoch 提供一个值来进行推断。 默认值：无 纪元 (python：int )–要训练的纪元数。 如果未提供 total_steps 的值，则将其与 steps_per_epoch 一起使用以推断循环中的步骤总数。 默认值：无 steps_per_epoch (python：int )–每个纪元要训练的步数。 如果未提供 total_steps 的值，则将其与历元一起使用以推断循环中的总步数。 默认值：无 pct_start (python：float )–花费的周期百分比(步数）提高了学习率。 默认值：0.3 anneal_strategy (str )– {'cos'，'linear'}指定退火策略：余弦退火为“ cos”，线性退火为“ linear”。 默认值：“ cos” cycle_momentum (bool) – If True, momentum is cycled inversely to learning rate between ‘base_momentum’ and ‘max_momentum’. Default: True base_momentum (python：float 或 列表）–每个参数组的循环动量边界较低。 注意，动量与学习速度成反比。 在一个周期的最高峰，动量为“ base_momentum”，学习速率为“ max_lr”。 默认值：0.85 max_momentum (python：float 或 列表）–每个参数组在循环中的较高动量边界。 从功能上讲，它定义了循环幅度(max_momentum-base_momentum）。 注意，动量与学习速度成反比。 在周期开始时，动量为“ max_momentum”，学习率为“ base_lr”默认值：0.95 div_factor (python：float )–通过 initial_lr = max_lr / div_factor 确定初始学习率默认值：25 final_div_factor (python：float )–通过 min_lr = initial_lr / final_div_factor 确定最小学习率默认值：1e4 last_epoch (python:int) – The index of the last batch. This parameter is used when resuming a training job. Since step() should be invoked after each batch instead of after each epoch, this number represents the total number of batches computed, not the total number of epochs computed. When last_epoch=-1, the schedule is started from the beginning. Default: -1 Example >>> data_loader = torch.utils.data.DataLoader(...) >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9) >>> scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(data_loader), epochs=10) >>> for epoch in range(10): >>> for batch in data_loader: >>> train_batch(...) >>> scheduler.step() class torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0, T_mult=1, eta_min=0, last_epoch=-1)¶ 使用余弦退火进度表设置每个参数组的学习率，其中设置为初始 lr，是自上次重启以来的时期数，是两次暖启动之间的时期数 在 SGDR 中： 当时，设置。 重新启动后时，设置。 它已在 SGDR：具有暖重启的随机梯度下降中提出。 Parameters optimizer (Optimizer) – Wrapped optimizer. T_0 (python：int )–首次重启的迭代次数。 T_mult (python：int ， 可选）–重新启动后，因素会增加。 默认值：1。 eta_min (python：float ， 可选）–最低学习率。 默认值：0 last_epoch (python：int ， 可选）–最后一个纪元的索引。 默认值：-1。 step(epoch=None)¶ 每次批量更新后都可以调用该步骤 Example >>> scheduler = CosineAnnealingWarmRestarts(optimizer, T_0, T_mult) >>> iters = len(dataloader) >>> for epoch in range(20): >>> for i, sample in enumerate(dataloader): >>> inputs, labels = sample['inputs'], sample['labels'] >>> scheduler.step(epoch + i / iters) >>> optimizer.zero_grad() >>> outputs = net(inputs) >>> loss = criterion(outputs, labels) >>> loss.backward() >>> optimizer.step() 可以交错方式调用此函数。 Example >>> scheduler = CosineAnnealingWarmRestarts(optimizer, T_0, T_mult) >>> for epoch in range(20): >>> scheduler.step() >>> scheduler.step(26) >>> scheduler.step() # scheduler.step(27), instead of scheduler(20) 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:25:18 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"88.html":{"url":"88.html","title":"量化","keywords":"","body":"量化 原文： https://pytorch.org/docs/stable/quantization.html 量化导论 量化是指用于执行计算并以低于浮点精度的位宽存储张量的技术。 量化模型对张量使用整数而不是浮点值执行部分或全部运算。 这允许更紧凑的模型表示，并在许多硬件平台上使用高性能矢量化操作。 与典型的 FP32 型号相比，PyTorch 支持 INT8 量化，从而可将模型大小减少 4 倍，并将内存带宽要求减少 4 倍。 与 FP32 计算相比，对 INT8 计算的硬件支持通常快 2 到 4 倍。 量化主要是一种加速推理的技术，并且量化算子仅支持前向传递。 PyTorch 支持多种方法来量化深度学习模型。 在大多数情况下，该模型在 FP32 中训练，然后将模型转换为 INT8。 此外，PyTorch 还支持量化意识训练，该训练使用伪量化模块对前向和后向传递中的量化误差进行建模。 注意，整个计算是在浮点数中进行的。 在量化意识训练结束时，PyTorch 提供转换功能，将训练后的模型转换为较低的精度。 在较低级别，PyTorch 提供了一种表示量化张量并对其执行操作的方法。 它们可用于直接构建以较低的精度执行全部或部分计算的模型。 提供了更高级别的 API，这些 API 合并了将 FP32 模型转换为较低精度并降低精度损失的典型工作流程。 如今，PyTorch 支持以下后端以有效地运行量化运算符： 具有 AVX2 支持或更高版本的 x86 CPU(在没有 AVX2 的情况下，某些操作的执行效率较低） ARM CPU(通常在移动/嵌入式设备中找到） 相应的实现是根据 PyTorch 构建模式自动选择的。 注意 PyTorch 1.3 尚未在 CUDA 上提供量化的操作员实施-这是未来工作的方向。 将模型移至 CPU，以测试量化功能。 量化感知训练(通过 FakeQuantize)支持 CPU 和 CUDA。 Note 在准备量化模型时，有必要确保 qconfig 和用于量化计算的引擎与将在其上执行模型的后端匹配。 量化目前支持两个后端：fbgemm(用于 x86， https://github.com/pytorch/FBGEMM)和 qnnpack(用于 ARM QNNPACK 库 https://github.com）。 com / pytorch / QNNPACK)。 例如，如果您对量化要在 ARM 上运行的模型感兴趣，建议通过调用以下命令设置 qconfig： qconfig = torch.quantization.get_default_qconfig('qnnpack') 用于后期训练量化和 qconfig = torch.quantization.get_default_qat_qconfig('qnnpack') 用于量化意识训练。 另外，torch.backends.quantized.engine 参数应设置为与后端匹配。 为了使用 qnnpack 进行推理，将后端设置为 qnnpack，如下所示 torch.backends.quantized.engine = 'qnnpack' 量化张量 PyTorch 支持每个张量和每个通道非对称线性量化。 每个张量意味着张量内的所有值都以相同的方式缩放。 每通道意味着对于每个尺寸(通常是张量的通道尺寸），张量中的值都按比例缩放并偏移一个不同的值(实际上，比例和偏移成为矢量）。 这样可以在将张量转换为量化值时减少误差。 通过使用以下命令转换浮点张量来执行映射 注意，我们确保在量化后浮点中的零表示没有错误，从而确保诸如填充之类的操作不会引起额外的量化误差。 为了在 PyTorch 中进行量化，我们需要能够在 Tensor 中表示量化数据。 量化张量允许存储量化数据(表示为 int8 / uint8 / int32）以及诸如 scale 和 zero_point 之类的量化参数。 量化张量除了允许以量化格式序列化数据外，还允许许多有用的操作使量化算术变得容易。 经营范围 量化张量支持常规全精度张量的有限数据处理方法子集。 (请参阅下面的列表） 对于 PyTorch 中包含的 NN 运算符，我们将支持范围限制为： 8 位权重(data_type = qint8） 8 位激活(data_type = quint8） 请注意，运算符实现目前仅支持转换和线性运算符的权重的每个通道量化。 此外，将输入数据的最小值和最大值线性映射到量化数据类型的最小值和最大值，以使零表示时没有量化误差。 可以通过定制运算符机制实现其他数据类型和量化方案。 在与torch或torch.nn中的全浮点版本相同的 API 下，可以使用许多量化张量操作。 torch.nn.quantized中提供了执行重新量化的 NN 模块的量化版本。 这些操作在操作签名中显式采用输出量化参数(scale 和 zero_point）。 另外，我们还支持与影响量化的常见融合模式相对应的融合版本：torch.nn.intrinsic.quantized。 对于量化意识训练，我们在 torch.nn.qat 和 torch.nn.intrinsic.qat 支持支持量化意识训练的模块 当前的量化操作列表足以覆盖典型的 CNN 和 RNN 模型： 量化torch.Tensor操作 可从torch命名空间获得的操作或作为 Tensor 上用于量化张量的方法的操作： quantize_per_tensor() -将浮点张量转换为具有每个张量标度和零点的量化张量 quantize_per_channel() -使用每通道标度和零点将浮点张量转换为量化张量 基于视图的操作，例如 view() ， as_strided() ， expand() ， flatten() ， select() ，python 风格的索引等-与常规张量一样工作(如果不是按通道量化） Comparators ne() -不相等 eq() -相等 ge() -大于或等于 le() -小于或等于 gt() -更大 lt() -少 copy_() -将 src 复制到原位 clone() -返回传入张量的深层副本 dequantize() -将量化张量转换为浮点张量 equal() -比较两个张量，如果量化参数和所有整数元素相同，则返回 true int_repr() -打印量化张量的基础整数表示 max() -返回张量的最大值(仅减小） mean() -均值功能。 支持的变体：缩小，变暗，变暗 min() -返回张量的最小值(仅减小） q_scale() -返回每个张量量化张量的小数位数 q_zero_point() -返回每个张量量化零点的 zero_point q_per_channel_scales() -返回每通道量化张量的小数位数 q_per_channel_zero_points() -返回每通道量化张量的零点 q_per_channel_axis() -返回每通道量化张量的通道轴 resize_() -就地调整大小 sort() -对张量进行排序 topk() -返回张量的 k 个最大值 torch.nn.functional 支持基本激活。 relu() -整流线性单位(副本） relu_() -整流线性单位(就位） max_pool2d() -最大池 adaptive_avg_pool2d() -自适应平均池 avg_pool2d() -平均池 interpolate() -插值 upsample() -上采样 upsample_bilinear() -双线性上采样 upsample_nearest() -最近的升采样 torch.nn.intrinsic 提供融合模块以用于 CNN 中的常见模式。 将多个运算(例如卷积和 relu）组合在一起可以实现更好的量化精度 torch.nn.intrinsic — float versions of the modules, can be swapped with quantized version 1 to 1 ConvBn2d -Conv2d + BatchNorm ConvBnReLU2d -Conv2d + BatchNorm + ReLU ConvReLU2d — Conv2d + ReLU ConvReLU3d — Conv3d + ReLU LinearReLU -线性+ ReLU torch.nn.intrinsic.qat — versions of layers for quantization-aware training ConvBn2d -Conv2d + BatchNorm ConvBnReLU2d -Conv2d + BatchNorm + ReLU ConvReLU2d — Conv2d + ReLU LinearReLU -线性+ ReLU torch.nn.intrinsic.quantized — quantized version of fused layers for inference (no BatchNorm variants as it’s usually folded into convolution for inference) LinearReLU -线性+ ReLU ConvReLU2d — 2D 卷积+ ReLU ConvReLU3d — 3D 卷积+ ReLU torch.nn.qat 量化意识训练的层次 Linear -线性(完全连接）层 Conv2d — 2D 卷积 torch.quantization Functions for quantization add_observer_() -为叶子模块添加观察者(如果提供了量化配置） add_quant_dequant() -使用 QuantWrapper 包装叶子子模块 convert() -将具有观察者的 float 模块转换为其量化的对应物。 必须具有量化配置 get_observer_dict() -遍历模块子级并将所有观察者收集到dict中 prepare() -准备模型的副本以进行量化 prepare_qat() -准备用于量化意识训练的模型副本 propagate_qconfig_() -通过模块层次结构传播量化配置，并将其分配给每个叶模块 quantize() -将 float 模块转换为量化版本 quantize_dynamic() -将 float 模块转换为动态量化版本 quantize_qat() -将浮点模块转换为用于量化意识训练的量化版本 swap_module() -交换模块及其量化的对应对象(如果量化并且具有观察者） default_eval_fn() - torch.quantization.quantize() 使用的默认评估功能 fuse_modules() FakeQuantize -用于在训练时模拟量化/去量化的模块 Default Observers. The rest of observers are available from torch.quantization.observer default_observer-与MinMaxObserver.with_args(reduce_range=True)相同 default_weight_observer-与MinMaxObserver.with_args(dtype=torch.qint8, qscheme=torch.per_tensor_symmetric)相同 Observer —观察者的抽象基类 Quantization configurations QConfig -量化配置类 default_qconfig —与QConfig(activation=default_observer, weight=default_weight_observer)相同(请参阅QConfig） default_qat_qconfig —与QConfig(activation=default_fake_quant, weight=default_weight_fake_quant)相同(请参阅QConfig） default_dynamic_qconfig —与QConfigDynamic(weight=default_weight_observer)相同(请参阅QConfigDynamic） float16_dynamic_qconfig —与QConfigDynamic(weight=NoopObserver.with_args(dtype=torch.float16))相同(请参阅QConfigDynamic） Stubs DeQuantStub -浮点型模型中用于 dequantize(）操作的占位符模块 QuantStub -用于浮点值模型中的 quantize(）操作的占位符模块 QuantWrapper -包装要量化的模块。 插入 QuantStub 和 DeQuantStub 观察者，用于计算量化参数 MinMaxObserver -从观察到的张量输入的运行最小值和最大值(每个张量变量）得出量化参数 MovingAverageMinMaxObserver -从观测到的张量输入的最大值和最小值的运行平均值(每个张量变量）得出量化参数 PerChannelMinMaxObserver -从观测到的张量输入的运行最小值和最大值得出量化参数(每个通道变量） MovingAveragePerChannelMinMaxObserver -从观测到的张量输入的最小值和最大值的运行平均值(每个通道变量）得出量化参数 HistogramObserver -通过创建运行最小值和最大值的直方图来得出量化参数。 Observers that do not compute the quantization parameters: RecordingObserver -记录所有传入的张量。 仅用于调试。 NoopObserver -直通观察器。 用于没有量化参数(即量化为float16）的情况 torch.nn.quantized 标准 NN 层的量化版本。 Quantize -量化层，用于自动替换 QuantStub DeQuantize -脱层层，用于替换 DeQuantStub FloatFunctional —包装器类，使无状态的浮点操作成为有状态的，以便可以用量化版本替换它们 QFunctional -包装类，用于无状态操作(例如`torch.add）的量化版本 Conv2d — 2D 卷积 Conv3d — 3D 卷积 Linear -线性(完全连接）层 MaxPool2d -2D 最大合并 ReLU -整流线性单元 ReLU6 -校正后的线性单位，其量化表示为 6 torch.nn.quantized.dynamic 动态量化模型中使用的图层(即仅根据权重进行量化） Linear -线性(完全连接）层 LSTM —长期内存 RNN 模块 torch.nn.quantized.functional 量化 NN 层的功能版本(其中许多接受显式的量化输出参数） adaptive_avg_pool2d() —二维自适应平均池 avg_pool2d() -2D 平均池 conv2d() — 2D 卷积 conv3d() — 3D 卷积 interpolate() -下/上采样器 linear() -线性(完全连接）运算 max_pool2d() -2D 最大合并 relu() -整流线性单元 upsample() -上采样器。 将不推荐使用 interpolate() upsample_bilinear() -双镜头上采样器。 将不推荐使用 interpolate() upsample_nearest() -最近的邻居上采样器。 将不推荐使用 interpolate() 量化 dtype 和量化方案 torch.qscheme — Type to describe the quantization scheme of a tensor. Supported types: torch.per_tensor_affine-每个张量，不对称 torch.per_channel_affine-每个通道，不对称 torch.per_tensor_symmetric-每个张量，对称 torch.per_channel_symmetric-每个张量，对称 torch.dtype — Type to describe the data. Supported types: torch.quint8-8 位无符号整数 torch.qint8 — 8 位有符号整数 torch.qint32 — 32 位有符号整数 量化工作流程 PyTorch 提供了三种量化模型的方法。 训练后动态量化：这是最简单的量化形式，其中权重被提前量化，而激活在推理过程中被动态量化。 这用于以下情况：模型执行时间主要由从内存中加载权重而不是计算矩阵乘法来决定。 对于小批量的 LSTM 和 Transformer 类型的模型，这是正确的。 只需调用一次 torch.quantization.quantize_dynamic() ，即可将动态量化应用于整个模型。 请参阅量化教程 训练后静态量化：这是最常用的量化形式，其中权重是提前量化的，并且基于观察校准过程中模型的行为来预先计算激活张量的比例因子和偏差。 训练后量化通常是在内存带宽和计算节省都很重要的情况下进行的，而 CNN 是典型的用例。 进行训练后量化的一般过程是： 准备模型： 通过添加 QuantStub 和 DeQuantStub 模块，指定在何处明确量化激活和量化数量。 b。 确保不重复使用模块。 C。 将所有需要重新量化的操作转换为模块 将诸如 conv + relu 或 conv + batchnorm + relu 之类的保险丝操作融合在一起，以提高模型的准确性和性能。 指定'97 量化方法的配置，例如选择对称或非对称量化以及 MinMax 或 L2Norm 校准技术。 使用 torch.quantization.prepare() 插入将在校准期间观察激活张量的模块 通过对校准数据集进行推断来校准模型 最后，使用 torch.quantization.convert(）方法转换模型本身。 这可以做几件事：它量化权重，计算并存储要在每个激活张量中使用的比例和偏差值，并替换关键运算符的量化实现。 请参阅量化教程 量化意识训练：在极少数情况下，训练后量化不能提供足够的准确性，可以使用 torch.quantization.FakeQuantize 通过模拟量化来进行训练。 计算将在 FP32 中进行，但将值取整并四舍五入以模拟 INT8 量化的效果。 步骤的顺序非常相似。 步骤(1）和(2）相同。 指定伪量化方法'97 的配置，例如选择对称或非对称量化以及 MinMax 或移动平均或 L2Norm 校准技术。 使用 torch.quantization.prepare_qat() 插入将在训练过程中模拟量化的模块。 训练或微调模型。 与步骤(6）相同，用于训练后量化 See the quantization tutorials 虽然提供了根据观察到的张量数据选择比例因子和偏差的观察者的默认实现，但开发人员可以提供自己的量化功能。 量化可以选择性地应用于模型的不同部分，也可以针对模型的不同部分进行不同的配置。 我们还为 conv2d(）， conv3d(）和 linear(）的每个通道量化提供支持 量化工作流程通过在模型的模块层次结构中添加(例如，将观察者添加为.observer子模块）或替换(例如，将nn.Conv2d转换为nn.quantized.Conv2d）来工作。 这意味着该模型在整个过程中都将保留基于常规nn.Module的实例，因此可以与其他 PyTorch API 一起使用。 量化的模型准备 当前有必要在量化之前对模型定义进行一些修改。 这是因为当前量化在逐个模块的基础上进行。 具体来说，对于所有量化技术，用户需要： 将需要输出重新量化(因此具有其他参数）的所有操作从功能转换为模块形式。 通过在子模块上分配`.qconfig属性或通过指定qconfig_dict，指定需要量化模型的哪些部分 对于量化激活的静态量化技术，用户还需要执行以下操作： 指定对激活进行量化和反量化的位置。 这是使用 QuantStub 和 DeQuantStub 模块完成的。 使用 torch.nn.quantized.FloatFunctional 将需要特殊处理以将量化量化的张量操作包装到模块中。 例如add和cat之类的操作，需要特殊处理才能确定输出量化参数。 保险丝模块：将操作/模块组合为一个模块，以获得更高的精度和性能。 这是通过 torch.quantization.fuse_modules() API 完成的，该 API 接收要融合的模块列表。 我们目前支持以下融合：[Conv，Relu]，[Conv，BatchNorm]，[Conv，BatchNorm，Relu]，[Linear，Relu] torch量化 该模块实现您直接调用的功能，以将模型从 FP32 转换为量化形式。 例如， prepare() 用于后期训练量化，以为校准步骤准备模型，而 convert() 实际上将权重转换为 int8，并用其量化的对等物替换运算 。 还有其他帮助程序功能，例如对模型的输入进行量化以及执行 conv + relu 等关键融合。 顶级量化 API torch.quantization.quantize(model, run_fn, run_args, mapping=None, inplace=False)¶ 将浮点模型转换为量化模型。 首先，它将准备进行校准或训练的模型，然后调用 run_fn ，它将运行校准步骤或训练步骤，之后我们将调用 convert ，它将模型转换为 量化模型。 参数 模型 –输入模型 run_fn –用于评估准备好的模型的函数，可以是仅运行准备好的模型或训练循环的函数 run_args – run_fn 的位置参数 就地 –就地进行模型转换，原始模块已变异 映射 –原始模块类型与量化对应项之间的对应关系 退货 量化模型。 torch.quantization.quantize_dynamic(model, qconfig_spec=None, dtype=torch.qint8, mapping=None, inplace=False)¶ 将浮动模型转换为动态(即仅权重）量化模型。 用仅动态权重的量化版本替换指定的模块，然后输出量化的模型。 对于最简单的用法，请提供 dtype 参数，该参数可以是 float16 或 qint8。 默认情况下，仅对权重较大的图层(即线性和 RNN 变体）执行仅权重量化。 通过 qconfig 和映射的细粒度控制是可能的，它们的作用类似于 Quantize(）。 如果提供了 qconfig ，则将忽略 dtype 参数。 Parameters 模块 –输入模型 qconfig_spec – 要么： 从子模块的名称或类型映射到量化配置的字典，qconfig 适用于给定模块的所有子模块，除非为子模块指定了 qconfig(当子模块已经具有 qconfig 属性时）。 字典中的条目必须是 QConfigDynamic 实例。 一组类型和/或子模块名称，用于对其进行动态量化，在这种情况下， dtype 自变量用于指定位宽 inplace – carry out model transformations in-place, the original module is mutated 映射 –将子模块的类型映射到需要替换子模块的对应动态量化版本的类型 torch.quantization.quantize_qat(model, run_fn, run_args, inplace=False)¶ 进行量化意识训练并输出量化模型 Parameters model – input model run_fn –用于评估准备好的模型的函数，可以是仅运行准备好的模型或训练循环的函数 run_args – positional arguments for run_fn Returns Quantized model. torch.quantization.prepare(model, qconfig_dict=None, inplace=False)¶ 为量化校准或量化意识训练准备模型的副本。 量化配置可以作为 qconfig_dict 传递，也可以抢先分配给 .qconfig 属性中的各个子模块。 该模型将附加观察者或伪造的 quant 模块，并传播 qconfig。 Parameters 模型-要就地修改的输入模型 qconfig_dict –从子模块的名称或类型映射到量化配置的字典，除非指定了子模块的 qconfig，否则 qconfig 适用于给定模块的所有子模块(当子模块已经具有 qconfig 属性时） inplace – carry out model transformations in-place, the original module is mutated torch.quantization.prepare_qat(model, mapping=None, inplace=False)¶ 为量化校准或量化意识训练准备模型的副本，并将其转换为量化版本。 量化配置可以作为 qconfig_dict 传递，也可以抢先分配给 .qconfig 属性中的各个子模块。 Parameters model – input model to be modified in-place 映射 –将浮点模块映射到要替换的量化模块的字典。 就地 –就地进行模型转换，原始模块已变异 torch.quantization.convert(module, mapping=None, inplace=False)¶ 将带有观察者的 float 模块(我们可以在其中获得量化参数）转换为量化模块。 Parameters 模块 –带有观察者的校准模块 映射 –从浮点模块类型映射到量化模块类型的字典，可以重写以允许交换用户定义的模块 inplace – carry out model transformations in-place, the original module is mutated class torch.quantization.QConfig¶ 描述如何通过分别提供激活和权重的设置(观察者类）来量化网络的一部分或一部分。 请注意，QConfig 需要包含观察者类(如 MinMaxObserver）或一个可调用的可调用对象，该可调用对象在调用时返回实例，而不是具体的观察者实例本身。 量化准备功能将为每个层多次实例化观察者。 观察者类通常具有合理的默认参数，但是可以使用 with_args 方法(行为类似于 functools.partial）来覆盖它们： my_qconfig = QConfig(激活= MinMaxObserver.with_args(dtype = torch.qint8），权重= default_observer.with_args(dtype = torch.qint8）） class torch.quantization.QConfigDynamic¶ 描述如何通过提供权重设置(观察者类别）动态量化网络的一部分或一部分。 就像 QConfig，但用于动态量化。 请注意，QConfigDynamic 需要包含观察者类(如 MinMaxObserver）或一个可调用的可调用对象，该调用可在调用时返回实例，而不是具体的观察者实例本身。 量化功能将为每个层多次实例化观察者。 Observer classes have usually reasonable default arguments, but they can be overwritten with with_args method (that behaves like functools.partial): my_qconfig = QConfigDynamic(权重= default_observer.with_args(dtype = torch.qint8）） 准备量化模型 torch.quantization.fuse_modules(model, modules_to_fuse, inplace=False, fuser_func=)¶ 将模块列表融合到一个模块中 仅融合以下模块序列： 转换，bn 转换，bn，relu 转换，relu 线性，相对 所有其他序列保持不变。 对于这些序列，将列表中的第一项替换为融合模块，并将其余模块替换为 identity。 Parameters 模型 –包含要融合的模块的模型 modules_to_fuse –要融合的模块名称列表的列表。 如果只有一个要融合的模块列表，则也可以是字符串列表。 就位 –布尔值指定是否在模型上发生融合，默认情况下会返回新模型 fuser_func –接收模块列表并输出相同长度的融合模块列表的功能。 例如，fuser_func([convModule，BNModule]）返回列表[ConvBNModule，nn.Identity(）]默认为 torch.quantization.fuse_known_modules Returns 融合模块的模型。 如果 inplace = True，则创建一个新副本。 例子： >>> m = myModel() >>> # m is a module containing the sub-modules below >>> modules_to_fuse = [ ['conv1', 'bn1', 'relu1'], ['submodule.conv', 'submodule.relu']] >>> fused_m = torch.quantization.fuse_modules(m, modules_to_fuse) >>> output = fused_m(input) >>> m = myModel() >>> # Alternately provide a single list of modules to fuse >>> modules_to_fuse = ['conv1', 'bn1', 'relu1'] >>> fused_m = torch.quantization.fuse_modules(m, modules_to_fuse) >>> output = fused_m(input) class torch.quantization.QuantStub(qconfig=None)¶ 量化存根模块，在校准之前，与观察者相同，将被交换为 nnq。在中将转换为。 Parameters qconfig -张量的量化配置，如果未提供 qconfig，我们将从父模块获取 qconfig class torch.quantization.DeQuantStub¶ 消除存根模块，在校准之前，它与标识相同，将交换为 nnq.DeQuantize 中的转换为。 class torch.quantization.QuantWrapper(module)¶ 包装器类，用于包装输入模块，添加 QuantStub 和 DeQuantStub 并将对模块的调用与对 Quant 和 Dequant 模块的调用包围。 量化实用程序功能使用此函数添加量化和反量化模块，然后转换函数 QuantStub 只是观察者，它观察输入张量，之后 转换为， QuantStub 将交换为 nnq.Quantize 进行实际量化。 对于类似地，DeQuantStub 也是如此。 torch.quantization.add_quant_dequant(module)¶ 如果叶子模块具有有效的 qconfig，则将其包装在 QuantWrapper 中。请注意，此函数将就地修改模块的子模块，并且它可以返回一个新的模块，该模块也将输入模块包装起来。 Parameters 模块 –具有所有叶子模块的 qconfig 属性的输入模块 我们要量化(等于）– Returns 使用基于 qconfig 的 QuantWrapper 中包装有子模块的就地修改模块，或包装输入模块的新 QuantWrapper 模块，后一种情况仅在输入模块是叶模块且 我们要量化它。 实用功能 torch.quantization.add_observer_(module)¶ 为模块的叶子添加观察者。 此函数将观察者模块插入具有有效 qconfig 属性的所有叶子模块。 Parameters 模块 –具有要配置的所有叶子模块的 qconfig 属性的输入模块 Returns 无，通过添加观察者模块和 forward_hooks 来就地修改模块 torch.quantization.swap_module(mod, mapping)¶ 如果模块具有量化的对应项并且连接了观察器，则交换该模块。 Parameters mod –输入模块 映射 –从 nn 模块映射到 nnq 模块的字典 Returns mod 的相应量化模块 torch.quantization.propagate_qconfig_(module, qconfig_dict=None)¶ 通过模块层次结构传播 qconfig 并在每个叶子模块上分配 qconfig 属性 Parameters 模块 –输入模块 qconfig_dict –从子模块的名称或类型映射到量化配置的字典，除非指定了子模块的 qconfig，否则 qconfig 适用于给定模块的所有子模块(当子模块已经具有 qconfig 属性时） Returns 无，模块已附加 qconfig 进行就地修改 torch.quantization.default_eval_fn(model, calib_data)¶ 默认评估函数采用 torch.utils.data.Dataset 或输入张量列表，并在数据集上运行模型 观察者 class torch.quantization.MinMaxObserver(dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False)¶ 观察器模块，用于基于运行的最小值和最大值来计算量化参数。 该观察者使用张量最小/最大统计量来计算量化参数。 该模块记录输入张量的运行最小值和最大值，并使用此统计信息计算量化参数。 Parameters dtype –量化数据类型 qscheme –要使用的量化方案 reduce_range –将量化数据类型的范围缩小 1 位 给定最小/最大值为和，标度和零点计算为： 最小/最大运行时间计算如下： 其中是观察到的张量。 然后，将比例和零点计算为： 其中和是量化数据类型的最小值和最大值。 警告 仅适用于torch.per_tensor_symmetric量化方案 Warning dtype只能使用torch.qint8或torch.quint8。 Note 如果运行最小值等于运行最大值，则将 scale 和 zero_point 设置为 1.0 和 0。 class torch.quantization.MovingAverageMinMaxObserver(averaging_constant=0.01, dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False)¶ 观察器模块，用于根据最小值和最大值的移动平均值来计算量化参数。 该观察者根据传入张量的最小值和最大值的移动平均值来计算量化参数。 该模块记录输入张量的平均最小值和最大值，并使用此统计信息计算量化参数。 Parameters averaging_constant -最小/最大的平均常数。 dtype – Quantized data type qscheme – Quantization scheme to be used reduce_range – Reduces the range of the quantized data type by 1 bit 最小/最大移动平均值计算如下 其中是运行平均最小值/最大值，是传入张量，是averaging_constant。 然后按MinMaxObserver中的比例和零点进行计算。 Note 仅适用于torch.per_tensor_affine量化模式。 Note If the running minimum equals to the running maximum, the scale and zero_point are set to 1.0 and 0. class torch.quantization.PerChannelMinMaxObserver(ch_axis=0, dtype=torch.quint8, qscheme=torch.per_channel_affine, reduce_range=False)¶ 观察器模块，用于基于每个通道的运行最小值和最大值来计算量化参数。 该观察者使用张量最小/最大统计量来计算每个通道的量化参数。 该模块记录输入张量的运行最小值和最大值，并使用此统计信息计算量化参数。 Parameters ch_axis –通道轴 dtype – Quantized data type qscheme – Quantization scheme to be used reduce_range – Reduces the range of the quantized data type by 1 bit 量化参数的计算方法与MinMaxObserver中的计算方法相同，不同之处在于，每个通道都存储运行的最小/最大值。 因此，每个通道也可以计算比例和零点。 Note 如果运行最小值等于运行最大值，则将 scales 和 zero_points 设置为 1.0 和 0。 class torch.quantization.MovingAveragePerChannelMinMaxObserver(averaging_constant=0.01, ch_axis=0, dtype=torch.quint8, qscheme=torch.per_channel_affine, reduce_range=False)¶ Observer module for computing the quantization parameters based on the running per channel min and max values. This observer uses the tensor min/max statistics to compute the per channel quantization parameters. The module records the running minimum and maximum of incoming tensors, and uses this statistic to compute the quantization parameters. Parameters averaging_constant – Averaging constant for min/max. ch_axis – Channel axis dtype – Quantized data type qscheme – Quantization scheme to be used reduce_range – Reduces the range of the quantized data type by 1 bit 量化参数的计算方法与MovingAverageMinMaxObserver中的计算方法相同，不同之处在于，每个通道都存储运行的最小/最大值。 因此，每个通道也可以计算比例和零点。 Note If the running minimum equals to the running maximum, the scales and zero_points are set to 1.0 and 0. class torch.quantization.HistogramObserver(bins=2048, upsample_rate=128, dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False)¶ 该模块记录张量值以及最小/最大值的运行直方图。 calculate_qparams将计算比例和 zero_point。 Parameters bins –直方图使用的 bin 数 upsample_rate –直方图被上采样的因子，用于对观测值变化范围内的直方图进行插值 dtype – Quantized data type qscheme – Quantization scheme to be used reduce_range – Reduces the range of the quantized data type by 1 bit 标度和零点计算如下： Create the histogram of the incoming inputs. 直方图是连续计算的，每个 bin 的范围随观察到的每个新张量而变化。 Search the distribution in the histogram for optimal min/max values. 搜索最小值/最大值可确保相对于浮点模型的量化误差最小。 Compute the scale and zero point the same way as in the MinMaxObserver class torch.quantization.FakeQuantize(observer=, quant_min=0, quant_max=255, **observer_kwargs)¶ 在训练时间内模拟量化和反量化操作。 该模块的输出由下式给出 x_out =(钳位(round(x / scale + zero_point），quant_min，quant_max）-zero_point）*比例 scale定义用于量化的比例因子。 zero_point指定浮点数 0 映射到的量化值 quant_min指定最小允许量化值。 quant_max指定最大允许量化值。 fake_quant_enable控制伪量化在张量上的应用，请注意统计信息仍然可以更新。 observer_enable控制张量的统计信息收集 dtype specifies the quantized dtype that is being emulated with fake-quantization, 允许的值为 torch.qint8 和 torch.quint8。 应该选择 quant_min 和 quant_max 的值与 dtype 一致 Parameters 观察器(模块）–用于观察输入张量的统计信息并计算刻度和零点的模块。 quant_min (python：int )–最小允许量化值。 quant_max (python：int )–允许的最大量化值。 viewer_kwargs (可选）–观察者模块的参数 Variables 〜FakeQuantize.observer (模块)–用户提供的模块，用于收集输入张量的统计信息，并提供一种计算标度和零点的方法。 class torch.quantization.NoopObserver(dtype=torch.float16)¶ 观察者什么也不做，只是将其配置传递给量化模块的.from_float()。 主要用于量化为 float16，不需要确定范围。 Parameters dtype – Quantized data type 调试工具 torch.quantization.get_observer_dict(mod, target_dict, prefix='')¶ 遍历模块并将所有观察者保存到 dict 中。 这主要用于量化精度调试：param mod：我们要保存所有观察者的顶层模块：param prefix：当前模块的前缀：param target_dict：用于保存所有观察者的字典 class torch.quantization.RecordingObserver(**kwargs)¶ 该模块主要用于调试，并在运行时记录张量值。 Parameters dtype – Quantized data type qscheme – Quantization scheme to be used reduce_range – Reduces the range of the quantized data type by 1 bit torch 此模块实现组合(融合）模块 conv + relu，然后可以对其进行量化。 ConvBn2d class torch.nn.intrinsic.ConvBn2d(conv, bn)¶ 这是一个顺序容器，称为 Conv 2d 和 Batch Norm 2d 模块。 在量化过程中，它将被相应的融合模块替换。 ConvBnReLU2d class torch.nn.intrinsic.ConvBnReLU2d(conv, bn, relu)¶ 这是一个顺序容器，称为 Conv 2d，Batch Norm 2d 和 ReLU 模块。 在量化过程中，它将被相应的融合模块替换。 转化率 class torch.nn.intrinsic.ConvReLU2d(conv, relu)¶ 这是一个顺序容器，调用 Conv 2d 和 ReLU 模块。 在量化过程中，它将被相应的融合模块替换。 ConvReLU3d class torch.nn.intrinsic.ConvReLU3d(conv, relu)¶ 这是一个顺序容器，调用 Conv 3d 和 ReLU 模块。 在量化过程中，它将被相应的融合模块替换。 线性 ReLU class torch.nn.intrinsic.LinearReLU(linear, relu)¶ 这是一个顺序容器，调用 Linear 和 ReLU 模块。 在量化过程中，它将被相应的融合模块替换。 torch.nn.instrinsic.qat 该模块实现了量化意识训练所需的那些融合操作的版本。 ConvBn2d class torch.nn.intrinsic.qat.ConvBn2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)¶ ConvBn2d 模块是由 Conv2d 和 BatchNorm2d 融合而成的模块，附加了 FakeQuantize 模块以用于输出激活和权重，用于量化意识训练。 我们结合了 torch.nn.Conv2d 和 torch.nn.BatchNorm2d 的接口。 实施细节： https://arxiv.org/pdf/1806.08342.pdf 第 3.2.2 节 与 torch.nn.Conv2d 相似，其中 FakeQuantize 模块已初始化为默认值。 Variables 〜ConvBn2d.freeze_bn – 〜ConvBn2d.activation_post_process –用于输出激活的伪量化模块 〜ConvBn2d.weight_fake_quant –伪造的权重量化模块 classmethod from_float(mod, qconfig=None)¶ 从 float 模块或 qparams_dict 创建一个 qat 模块 Args： mod 一个浮点模块，由 torch.quantization 实用程序生成或直接从用户获取 ConvBnReLU2d class torch.nn.intrinsic.qat.ConvBnReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)¶ ConvBnReLU2d 模块是由 Conv2d，BatchNorm2d 和 ReLU 融合而成的模块，附加了 FakeQuantize 模块以用于输出激活和权重，用于量化意识训练。 我们组合了 torch.nn.Conv2d 和 torch.nn.BatchNorm2d 和 torch.nn.ReLU 的接口。 实施细节： https://arxiv.org/pdf/1806.08342.pdf 与 torch.nn.Conv2d 相似，其中 FakeQuantize 模块已初始化为默认值。 Variables 〜ConvBnReLU2d.observer –用于激活输出的虚假量化模块，称为观察员，与后期训练流程保持一致 〜ConvBnReLU2d.weight_fake_quant –伪造的权重量化模块 ConvReLU2d class torch.nn.intrinsic.qat.ConvReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)¶ ConvReLU2d 模块是 Conv2d 和 ReLU 的融合模块，附加了 FakeQuantize 模块，用于输出激活和权重，以进行量化感知训练。 我们结合了 Conv2d 和 BatchNorm2d 的接口。 Variables 〜ConvReLU2d.activation_post_process –用于输出激活的伪量化模块 〜ConvReLU2d.weight_fake_quant –伪造的权重量化模块 LinearReLU class torch.nn.intrinsic.qat.LinearReLU(in_features, out_features, bias=True, qconfig=None)¶ 由 Linear 和 ReLU 模块融合而成的 LinearReLU 模块，与 FakeQuantize 模块相连，用于输出激活和权重，用于量化意识训练。 我们采用与 torch.nn.Linear 相同的接口。 与 torch.nn.intrinsic.LinearReLU 相似，其中 FakeQuantize 模块已初始化为默认值。 Variables 〜LinearReLU.activation_post_process –用于输出激活的伪量化模块 〜LinearReLU.weight –伪造的权重量化模块 Examples: >>> m = nn.qat.LinearReLU(20, 30) >>> input = torch.randn(128, 20) >>> output = m(input) >>> print(output.size()) torch.Size([128, 30]) torch nn 本征量化 该模块实现了诸如 conv + relu 之类的融合操作的量化实现。 ConvReLU2d class torch.nn.intrinsic.quantized.ConvReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')¶ ConvReLU2d 模块是 Conv2d 和 ReLU 的融合模块 我们采用与 torch.nn.quantized.Conv2d 相同的接口。 Variables as torch.nn.quantized.Conv2d (Same )– ConvReLU3d class torch.nn.intrinsic.quantized.ConvReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')¶ ConvReLU3d 模块是 Conv3d 和 ReLU 的融合模块 我们采用与 torch.nn.quantized.Conv3d 相同的接口。 属性：与 torch.nn.quantized.Conv3d 相同 LinearReLU class torch.nn.intrinsic.quantized.LinearReLU(in_features, out_features, bias=True)¶ 由 Linear 和 ReLU 模块融合而成的 LinearReLU 模块 我们采用与 torch.nn.quantized.Linear 相同的接口。 Variables 为 torch.nn.quantized.Linear (相同）– Examples: >>> m = nn.intrinsic.LinearReLU(20, 30) >>> input = torch.randn(128, 20) >>> output = m(input) >>> print(output.size()) torch.Size([128, 30]) torch 此模块实现了关键 nn 模块 Conv2d(）和 Linear(）的版本，这些版本在 FP32 中运行，但四舍五入以模拟 INT8 量化的效果。 转换 2d class torch.nn.qat.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)¶ 随附有 FakeQuantize 模块的 Conv2d 模块，用于输出激活和权重，用于量化意识训练。 我们采用与 torch.nn.Conv2d 相同的界面，请参阅 https://pytorch.org/docs/stable/nn.html?highlight=conv2d#torch.nn.Conv2d 获取文档。 Similar to torch.nn.Conv2d, with FakeQuantize modules initialized to default. Variables 〜Conv2d.activation_post_process –用于输出激活的伪量化模块 〜Conv2d.weight_fake_quant –伪造的权重量化模块 classmethod from_float(mod, qconfig=None)¶ Create a qat module from a float module or qparams_dict Args: mod a float module, either produced by torch.quantization utilities or directly from user 线性的 class torch.nn.qat.Linear(in_features, out_features, bias=True, qconfig=None)¶ 附带有 FakeQuantize 模块的线性模块，用于输出激活和权重，用于量化意识训练。 我们采用与 torch.nn.Linear 相同的接口，请参阅 https://pytorch.org/docs/stable/nn.html#torch.nn.Linear 以获取文档。 类似于 torch.nn.Linear ，其中 FakeQuantize 模块已初始化为默认值。 Variables 〜Linear.activation_post_process –用于输出激活的伪量化模块 〜Linear.weight –伪造的权重量化模块 classmethod from_float(mod, qconfig=None)¶ Create a qat module from a float module or qparams_dict Args: mod a float module, either produced by torch.quantization utilities or directly from user torch量化 此模块实现 nn 层的量化版本，例如 Conv2d 和 ReLU 。 功能界面 功能界面(已量化）。 torch.nn.quantized.functional.relu(input, inplace=False) → Tensor¶ 按元素应用整流线性单位函数。 有关更多详细信息，请参见 ReLU 。 Parameters 输入 –量化输入 就地 –就地执行计算 torch.nn.quantized.functional.linear(input, weight, bias=None, scale=None, zero_point=None)¶ 对输入的量化数据进行线性变换：。 参见 Linear Note 当前的实现在每个调用中都包含权重，这会降低性能。 如果要避免开销，请使用 Linear 。 Parameters 输入 (tensor)–类型为 Torch.quint8 的量化输入 重量 (tensor)–类型 Torch.qint8 的量化重量 偏差 (tensor)–类型为 Torch.float 的无或 fp32 偏差。 标度(双）–输出标度。 如果为无，则从输入比例得出 zero_point (python：long )–输出零点。 如果为 None，则从输入 zero_point 派生 Shape: 输入：其中 * 表示任意数量的附加尺寸 重量： 偏差： 输出： torch.nn.quantized.functional.conv2d(input, weight, bias, stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', scale=1.0, zero_point=0, dtype=torch.quint8)¶ 在由多个输入平面组成的量化 2D 输入上应用 2D 卷积。 有关详细信息和输出形状，请参见 Conv2d 。 Parameters 输入 –形状为的量化输入张量 权重 –形状为的量化滤波器 偏置 – 非量化的形状为的偏置张量。 张量类型必须为 torch.float 。 步幅 –卷积内核的步幅。 可以是单个数字或元组(sH，sW）。 默认值：1 填充 –输入两侧的隐式填充。 可以是单个数字或元组(padH，padW）。 默认值：0 膨胀 –内核元素之间的间距。 可以是单个数字或元组(dH，dW）。 默认值：1 组 –将输入分成组，应该可被组数整除。 默认值：1 padding_mode –要使用的填充模式。 目前仅对量化卷积支持“零”。 默认值：“零” 标度 –输出的量化标度。 默认值：1.0 zero_point -输出的量化 zero_point。 默认值：0 dtype –要使用的量化数据类型。 默认值：torch.quint8 Examples: >>> from torch.nn.quantized import functional as qF >>> filters = torch.randn(8, 4, 3, 3, dtype=torch.float) >>> inputs = torch.randn(1, 4, 5, 5, dtype=torch.float) >>> bias = torch.randn(4, dtype=torch.float) >>> >>> scale, zero_point = 1.0, 0 >>> dtype = torch.quint8 >>> >>> q_filters = torch.quantize_per_tensor(filters, scale, zero_point, dtype) >>> q_inputs = torch.quantize_per_tensor(inputs, scale, zero_point, dtype) >>> qF.conv2d(q_inputs, q_filters, bias, scale, zero_point, padding=1) torch.nn.quantized.functional.conv3d(input, weight, bias, stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', scale=1.0, zero_point=0, dtype=torch.quint8)¶ 在由多个输入平面组成的量化 3D 输入上应用 3D 卷积。 有关详细信息和输出形状，请参见 Conv3d 。 Parameters 输入 –形状为的量化输入张量 权重 –形状为的量化滤波器 偏置 – 非量化的形状为的偏置张量。 张量类型必须为 torch.float 。 步幅 –卷积内核的步幅。 可以是单个数字或元组(sD，sH，sW）。 默认值：1 填充 –输入两侧的隐式填充。 可以是单个数字或元组(padD，padH，padW）。 默认值：0 膨胀 –内核元素之间的间距。 可以是单个数字或元组(dD，dH，dW）。 默认值：1 组 –将输入分成组，应该可被组数整除。 默认值：1 padding_mode –要使用的填充模式。 目前仅对量化卷积支持“零”。 默认值：“零” scale – quantization scale for the output. Default: 1.0 zero_point – quantization zero_point for the output. Default: 0 dtype – quantization data type to use. Default: torch.quint8 Examples: >>> from torch.nn.quantized import functional as qF >>> filters = torch.randn(8, 4, 3, 3, 3, dtype=torch.float) >>> inputs = torch.randn(1, 4, 5, 5, 5, dtype=torch.float) >>> bias = torch.randn(4, dtype=torch.float) >>> >>> scale, zero_point = 1.0, 0 >>> dtype = torch.quint8 >>> >>> q_filters = torch.quantize_per_tensor(filters, scale, zero_point, dtype) >>> q_inputs = torch.quantize_per_tensor(inputs, scale, zero_point, dtype) >>> qF.conv3d(q_inputs, q_filters, bias, scale, zero_point, padding=1) torch.nn.quantized.functional.max_pool2d(input, kernel_size, stride=None, padding=0, dilation=1, ceil_mode=False, return_indices=False)¶ 在由几个量化输入平面组成的量化输入信号上应用 2D max 合并。 Note 输入量化参数传播到输出。 有关详细信息，请参见MaxPool2d。 torch.nn.quantized.functional.adaptive_avg_pool2d(input, output_size)¶ 在由几个量化输入平面组成的量化输入信号上应用 2D 自适应平均池。 Note 输入量化参数传播到输出。 有关详细信息和输出形状，请参见AdaptiveAvgPool2d。 Parameters output_size –目标输出大小(单整数或双整数元组） torch.nn.quantized.functional.avg_pool2d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)¶ 以步长步长在区域中应用 2D 平均合并操作。 输出要素的数量等于输入平面的数量。 Note 输入量化参数传播到输出。 有关详细信息和输出形状，请参见AvgPool2d。 Parameters 输入 –量化输入张量 kernel_size –池区域的大小。 可以是单个数字或元组(kH，kW） 跨度 –合并操作的跨度。 可以是单个数字或元组(sH，sW）。 默认值：kernel_size 填充 –输入两侧的隐式零填充。 可以是单个数字或元组(padH，padW）。 默认值：0 ceil_mode –为 True 时，将在公式中使用 ceil 而不是 floor 计算输出形状。 默认值：False count_include_pad –为 True 时，将在平均计算中包括零填充。 默认值：True divisor_override –如果指定，它将用作除数，否则将使用池化区域的大小。 默认值：无 torch.nn.quantized.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None)¶ 向下/向上采样输入给定size或给定scale_factor的输入 有关实现的详细信息，请参见 torch.nn.functional.interpolate() 。 输入尺寸以以下形式解释：微型批处理 x 通道 x [可选深度] x [可选高度] x 宽度。 Note The input quantization parameters propagate to the output. Note 量化输入仅支持 2D 输入 Note 量化输入仅支持以下模式： 双线性 最近的 Parameters 输入 (tensor)–输入张量 大小 (python：int 或 元组 [ python：int ]或 元组 [ python：int ， python：int ]或 元组 [ python：int ， python：int ， python：int ] )–输出空间大小。 scale_factor (python：float 或 元组 [ python：float ] )–空间大小的乘数。 如果是元组，则必须匹配输入大小。 模式 (str )–用于上采样的算法：'nearest' | 'bilinear' align_corners (布尔 ， 可选）–在几何上，我们将输入和输出的像素视为正方形而不是点。 如果设置为True，则输入和输出张量将按其角点像素的中心对齐，并保留角点像素处的值。 如果设置为False，则输入和输出张量按其角点像素的角点对齐，并且插值对边界值使用边缘值填充，从而使此操作独立于输入 scale_factor保持相同时的尺寸。 仅当mode为'bilinear'时才有效。 默认值：False torch.nn.quantized.functional.upsample(input, size=None, scale_factor=None, mode='nearest', align_corners=None)¶ 将输入上采样到给定的size或给定的scale_factor Warning 不推荐使用此功能，而推荐使用 torch.nn.quantized.functional.interpolate() 。 与nn.quantized.functional.interpolate(...)等效。 See torch.nn.functional.interpolate() for implementation details. The input dimensions are interpreted in the form: mini-batch x channels x [optional depth] x [optional height] x width. Note The input quantization parameters propagate to the output. Note Only 2D input is supported for quantized inputs Note Only the following modes are supported for the quantized inputs: bilinear nearest Parameters 输入 (tensor)–量化输入张量 size (python:int or Tuple[python:int__] or Tuple[python:int__, python:int__] or Tuple[python:int__, python:int__, python:int__]) – output spatial size. scale_factor (python：float 或 元组 [ python：float ] )–空间大小的乘数。 必须是整数。 模式(字符串）–用于上采样的算法：'nearest' | 'bilinear' align_corners (bool__, optional) – Geometrically, we consider the pixels of the input and output as squares rather than points. If set to True, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels. If set to False, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when scale_factor is kept the same. This only has an effect when mode is 'bilinear'. Default: False Warning 使用align_corners = True时，线性插值模式(双线性）不会按比例对齐输出像素和输入像素，因此输出值可能取决于输入大小。 这是这些模式(0.3.1 版之前）的默认行为。 从那时起，默认行为是align_corners = False。 有关如何影响输出的具体示例，请参见 Upsample 。 torch.nn.quantized.functional.upsample_bilinear(input, size=None, scale_factor=None)¶ 使用双线性上采样对输入进行上采样。 Warning 不推荐使用此功能，而推荐使用 torch.nn.quantized.functional.interpolate() 。 与nn.quantized.functional.interpolate(..., mode='bilinear', align_corners=True)等效。 Note The input quantization parameters propagate to the output. Note 仅支持 2D 输入 Parameters 输入 (tensor)–量化输入 大小 (python：int 或 元组 [ python：int ， python：int ] )–输出空间大小。 scale_factor (python：int 或 元组 [ python：int ， python：int ] )–空间大小的乘数 torch.nn.quantized.functional.upsample_nearest(input, size=None, scale_factor=None)¶ 使用最近邻的像素值对输入进行上采样。 Warning 不推荐使用此功能，而推荐使用 torch.nn.quantized.functional.interpolate() 。 与nn.quantized.functional.interpolate(..., mode='nearest')等效。 Note The input quantization parameters propagate to the output. Note Only 2D inputs are supported Parameters input (Tensor) – quantized input 大小 (python：int 或 元组 [ python：int ， python：int ]或 元组 [ python：int ， python：int ， python：int ] )–输出空间大小。 scale_factor (python：int )–空间大小的乘数。 必须是整数。 ReLU class torch.nn.quantized.ReLU(inplace=False)¶ 按元素应用量化整流线性单位函数： ，其中是零点。 有关 ReLU 的更多文档，请参见 https://pytorch.org/docs/stable/nn.html#torch.nn.ReLU 。 Parameters 就地 –(当前不支持）可以选择就地进行操作。 Shape: 输入：其中 * 表示任意数量的附加尺寸 输出：，形状与输入相同 Examples: >>> m = nn.quantized.ReLU() >>> input = torch.randn(2) >>> input = torch.quantize_per_tensor(input, 1.0, 0, dtype=torch.qint32) >>> output = m(input) ReLU6 class torch.nn.quantized.ReLU6(inplace=False)¶ 应用逐元素函数： ，其中是 zero_point，是数字 6 的量化表示。 Parameters 就地 –可以选择就地进行操作。 默认值：False Shape: Input: where * means, any number of additional dimensions Output: , same shape as the input Examples: >>> m = nn.quantized.ReLU6() >>> input = torch.randn(2) >>> input = torch.quantize_per_tensor(input, 1.0, 0, dtype=torch.qint32) >>> output = m(input) Conv2d class torch.nn.quantized.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')¶ 在由多个量化输入平面组成的量化输入信号上应用 2D 卷积。 有关输入参数，参数和实现的详细信息，请参见 Conv2d 。 Note padding_mode参数仅支持零。 Note 输入数据类型仅支持 torch.quint8 。 Variables 〜Conv2d.weight (tensor)–从可学习的权重参数得出的压缩张量。 〜Conv2d.scale (tensor)–输出比例的标量 〜Conv2d.zero_point (tensor)–输出零点的标量 有关其他属性，请参见 Conv2d 。 Examples: >>> # With square kernels and equal stride >>> m = nn.quantized.Conv2d(16, 33, 3, stride=2) >>> # non-square kernels and unequal stride and with padding >>> m = nn.quantized.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2)) >>> # non-square kernels and unequal stride and with padding and dilation >>> m = nn.quantized.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1)) >>> input = torch.randn(20, 16, 50, 100) >>> # quantize input to qint8 >>> q_input = torch.quantize_per_tensor(input, scale=1.0, zero_point=0, dtype=torch.qint32) >>> output = m(input) classmethod from_float(mod)¶ 从 float 模块或 qparams_dict 创建量化模块。 Parameters mod (模块)–浮点模块，由 Torch.quantization 实用程序生产或由用户提供 转换 3d class torch.nn.quantized.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')¶ 在由几个量化输入平面组成的量化输入信号上应用 3D 卷积。 有关输入参数，参数和实现的详细信息，请参见 Conv3d 。 Note Only zeros is supported for the padding_mode argument. Note Only torch.quint8 is supported for the input data type. Variables 〜Conv3d.weight (tensor)–从可学习的重量参数得出的压缩张量。 〜Conv3d.scale (tensor)–输出比例的标量 〜Conv3d.zero_point (tensor)–输出零点的标量 有关其他属性，请参见 Conv3d 。 Examples: >>> # With square kernels and equal stride >>> m = nn.quantized.Conv3d(16, 33, 3, stride=2) >>> # non-square kernels and unequal stride and with padding >>> m = nn.quantized.Conv3d(16, 33, (3, 5, 5), stride=(1, 2, 2), padding=(1, 2, 2)) >>> # non-square kernels and unequal stride and with padding and dilation >>> m = nn.quantized.Conv3d(16, 33, (3, 5, 5), stride=(1, 2, 2), padding=(1, 2, 2), dilation=(1, 2, 2)) >>> input = torch.randn(20, 16, 56, 56, 56) >>> # quantize input to qint8 >>> q_input = torch.quantize_per_tensor(input, scale=1.0, zero_point=0, dtype=torch.qint32) >>> output = m(input) classmethod from_float(mod)¶ Creates a quantized module from a float module or qparams_dict. Parameters mod (Module) – a float module, either produced by torch.quantization utilities or provided by the user 浮动功能 class torch.nn.quantized.FloatFunctional¶ 浮点运算符的状态收集器类。 在某些操作中，可以使用此类的实例代替torch.前缀。 请参阅下面的示例用法。 Note 此类不提供forward挂钩。 相反，您必须使用基础功能之一(例如add）。 Examples: >>> f_add = FloatFunctional() >>> a = torch.tensor(3.0) >>> b = torch.tensor(4.0) >>> f_add.add(a, b) # Equivalent to ``torch.add(3, 4) Valid operation names: 加 猫 多 add_relu add_scalar mul_scalar Q 功能 class torch.nn.quantized.QFunctional¶ 量化运算符的包装器类。 可以使用此类的实例代替torch.ops.quantized前缀。 请参阅下面的示例用法。 Note This class does not provide a forward hook. Instead, you must use one of the underlying functions (e.g. add). Examples: >>> q_add = QFunctional('add') >>> a = torch.quantize_per_tensor(torch.tensor(3.0), 1.0, 0, torch.qint32) >>> b = torch.quantize_per_tensor(torch.tensor(4.0), 1.0, 0, torch.qint32) >>> q_add.add(a, b) # Equivalent to ``torch.ops.quantized.add(3, 4) Valid operation names: add cat mul add_relu add_scalar mul_scalar 量化 class torch.nn.quantized.Quantize(scale, zero_point, dtype)¶ 量化传入张量 Parameters 标度 –输出量化张量的标度 zero_point –输出量化张量的 zero_point dtype –输出量化张量的数据类型 Variables zero_point，dtype (scale 和）– Examples:: >>> t = torch.tensor([[1., -1.], [1., -1.]]) >>> scale, zero_point, dtype = 1.0, 2, torch.qint8 >>> qm = Quantize(scale, zero_point, dtype) >>> qt = qm(t) >>> print(qt) tensor([[ 1., -1.], [ 1., -1.]], size=(2, 2), dtype=torch.qint8, scale=1.0, zero_point=2) 解量化 class torch.nn.quantized.DeQuantize¶ 使进入的张量均衡化 Examples:: >>> input = torch.tensor([[1., -1.], [1., -1.]]) >>> scale, zero_point, dtype = 1.0, 2, torch.qint8 >>> qm = Quantize(scale, zero_point, dtype) >>> quantized_input = qm(input) >>> dqm = DeQuantize() >>> dequantized = dqm(quantized_input) >>> print(dequantized) tensor([[ 1., -1.], [ 1., -1.]], dtype=torch.float32) Linear class torch.nn.quantized.Linear(in_features, out_features, bias_=True)¶ 具有量化张量作为输入和输出的量化线性模块。 我们采用与 torch.nn.Linear 相同的接口，请参阅 https://pytorch.org/docs/stable/nn.html#torch.nn.Linear 以获取文档。 与 Linear 类似，属性将在模块创建时随机初始化，稍后将被覆盖 Variables 〜线性权重 (tensor)–形状为的模块的不可学习的量化权重。 〜线性偏差 (tensor)–形状为的模块的不可学习的偏差。 如果bias为True，则值将初始化为零。 〜线性比例 – 比例输出量化张量的参数，类型：double 〜Linear.zero_point – zero_point 输出量化张量的参数，类型：long Examples: >>> m = nn.quantized.Linear(20, 30) >>> input = torch.randn(128, 20) >>> input = torch.quantize_per_tensor(input, 1.0, 0, torch.quint8) >>> output = m(input) >>> print(output.size()) torch.Size([128, 30]) classmethod from_float(mod)¶ 从 float 模块或 qparams_dict 创建量化模块 Parameters mod (Module) – a float module, either produced by torch.quantization utilities or provided by the user torch量化的动态 Linear class torch.nn.quantized.dynamic.Linear(in_features, out_features, bias_=True)¶ 具有量化张量作为输入和输出的动态量化线性模块。 我们采用与 torch.nn.Linear 相同的接口，请参阅 https://pytorch.org/docs/stable/nn.html#torch.nn.Linear 以获取文档。 与 torch.nn.Linear 类似，属性将在模块创建时随机初始化，稍后将被覆盖 Variables 〜线性权重 (tensor)–形状为的模块的不可学习的量化权重。 ~Linear.bias (Tensor) – the non-learnable bias of the module of shape . If bias is True, the values are initialized to zero. Examples: >>> m = nn.quantized.dynamic.Linear(20, 30) >>> input = torch.randn(128, 20) >>> output = m(input) >>> print(output.size()) torch.Size([128, 30]) classmethod from_float(mod)¶ 从 float 模块或 qparams_dict 创建动态量化模块 Parameters mod (Module) – a float module, either produced by torch.quantization utilities or provided by the user LSTM class torch.nn.quantized.dynamic.LSTM(*args, **kwargs)¶ 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"89.html":{"url":"89.html","title":"分布式 RPC 框架","keywords":"","body":"分布式 RPC 框架 原文： https://pytorch.org/docs/stable/rpc.html 分布式 RPC 框架通过一组原语提供了用于多机器模型训练的机制，以允许进行远程通信；还提供了高级 API，以自动区分在多台机器之间划分的模型。 警告 RPC API 是试验性的，随时可能更改。 RPC 和 RRef 框架 在使用 RPC 和分布式 autograd 原语之前，必须进行初始化。 要初始化 RPC 框架，我们需要使用 init_rpc() 来初始化 RPC 框架，RRef 框架和分布式 autograd。 默认情况下，这还将初始化 ProcessGroup (init_process_group())后端，以进行 RPC 通信。 ProcessGroup 后端在内部使用 gloo 进行通信。 torch.distributed.rpc.init_rpc(name, backend=BackendType.PROCESS_GROUP, rank=-1, world_size=None, rpc_backend_options=None)¶ 初始化 RPC 原语，例如本地 RPC 代理和分布式 autograd。 初始化本地 RPC 代理，该代理立即使当前进程准备好发送和接收 RPC。 此方法还可以正确初始化使用 gloo 进行集体通信的默认进程组后端。 参数 后端(枚举）– RPC 后端实现的类型。 当前，进程组后端是唯一可用的后端实现。 (默认：RpcBackend.PROCESS_GROUP）。 名称 (str )–此节点的全局唯一名称。 (例如Trainer3，ParameterServer2，Master和Worker1）名称只能包含数字，字母，下划线和/或破折号，并且必须少于 128 个字符。 等级 (python：int )–此节点的全局唯一 ID /等级。 world_size (python：int )–组中的工人数。 rpc_backend_options (RpcBackendOptions )–传递给 RpcAgent 构造函数的选项。 参考 RRef (远程引用）是对远程工作人员上某个类型 T (例如张量）的值的引用。 该句柄使引用的远程值在所有者上保持活动状态，但不暗示该值将来会转移给本地工作人员。 通过保留对其他工作人员中存在的 nn.Modules 的引用，并在训练期间调用适当的函数来检索或修改其参数，可以将 RRef 用于多机训练。 有关更多详细信息，请参见远程参考协议。 class torch.distributed.rpc.RRef¶ 在远程工作器上封装对某个类型的值的引用的类。 该句柄将使引用的远程值在工作程序上保持活动状态。 is_owner(self: torch.distributed.rpc.RRef) → bool¶ 返回当前节点是否是此RRef的所有者。 local_value(self: torch.distributed.rpc.RRef) → object¶ 如果当前节点是所有者，则返回对本地值的引用。 否则，引发异常。 owner(self: torch.distributed.rpc.RRef) → torch.distributed.rpc.WorkerInfo¶ 返回拥有此RRef的节点的工作程序信息。 to_here(self: torch.distributed.rpc.RRef) → object¶ 将 RRef 的值从所有者复制到本地节点并返回它的阻塞调用。 如果当前节点是所有者，则返回对本地值的引用。 RPC 和 RRef 原语 该库提供了原语，允许用户创建和修改对远程数据的引用(RRef）以及远程执行功能。 torch.distributed.rpc.rpc_sync(to, func, args=None, kwargs=None)¶ 进行 RPC 阻塞调用以在 worker to上运行函数func。 RPC 消息的发送和接收与 Python 代码的执行并行。 此方法是线程安全的。 Parameters 到 (str 或 WorkerInfo )–目标工作线程的 ID 或名称。 函数(可调用的）–任何可调用的函数。 内置函数(例如 torch.add())可以更有效地通过 RPC 发送。 args (元组）– func调用的参数元组。 kwargs (dict )–是func调用的关键字参数的字典。 退货 返回在args和kwargs上运行func的结果。 例： On worker 0: >>> import torch.distributed.rpc as rpc >>> rpc.init_rpc(\"worker0\", rank=0, world_size=2) >>> ret = rpc.rpc_sync(\"worker1\", torch.add, args=(torch.ones(2), 3)) >>> rpc.shutdown() On worker 1: >>> import torch.distributed.rpc as rpc >>> rpc.init_rpc(\"worker1\", rank=1, world_size=2) >>> rpc.shutdown() torch.distributed.rpc.rpc_async(to, func, args=None, kwargs=None)¶ 进行非阻塞 RPC 调用以在 worker to上运行函数func。 RPC 消息的发送和接收与 Python 代码的执行并行。 此方法是线程安全的。 此方法将立即返回可以等待的torch.distributed.FutureMessage。 Parameters to (str or WorkerInfo) – id or name of the destination worker. func (callable) – any callable function. builtin functions (like torch.add()) can be sent over RPC more efficiently. args (tuple) – the argument tuple for the func invocation. kwargs (dict) – is a dictionary of keyword arguments for the func invocation. Returns 返回可以等待的torch.distributed.FutureMessage对象。 完成后，可以从FutureMessage对象中检索args和kwargs上func的返回值。 Example: On worker 0: >>> import torch.distributed.rpc as rpc >>> rpc.init_rpc(\"worker0\", rank=0, world_size=2) >>> fut1 = rpc.rpc_async(\"worker1\", torch.add, args=(torch.ones(2), 3)) >>> fut2 = rpc.rpc_async(\"worker1\", min, args=(1, 2)) >>> result = fut1.wait() + fut2.wait() >>> rpc.shutdown() On worker 1: >>> import torch.distributed.rpc as rpc >>> rpc.init_rpc(\"worker1\", rank=1, world_size=2) >>> rpc.shutdown() torch.distributed.rpc.remote(to, func, args=None, kwargs=None)¶ 进行远程调用以在工作线程to上运行func，并立即将 RRef 返回到结果值。 工人to将是返回的 RRef 的所有者，而调用remote的工人是用户。 所有者管理其 RRef 的全局引用计数，而所有者 RRef 仅在全局上没有活动引用时被销毁。 Parameters to (str or WorkerInfo) – id or name of the destination worker. 函数(可调用的）–内置函数(例如 torch.add())。 args (tuple) – the argument tuple for the func invocation. kwargs (dict) – is a dictionary of keyword arguments for the func invocation. Returns 用户 RRef 实例到结果值。 使用阻塞 API torch.distributed.rpc.RRef.to_here() 在本地检索结果值。 Example: On worker 0: >>> import torch.distributed.rpc as rpc >>> rpc.init_rpc(\"worker0\", rank=0, world_size=2) >>> rref1 = rpc.remote(\"worker1\", torch.add, args=(torch.ones(2), 3)) >>> rref2 = rpc.remote(\"worker1\", torch.add, args=(torch.ones(2), 1)) >>> x = rref1.to_here() + rref2.to_here() >>> rpc.shutdown() On worker 1: >>> import torch.distributed.rpc as rpc >>> rpc.init_rpc(\"worker1\", rank=1, world_size=2) >>> rpc.shutdown() torch.distributed.rpc.get_worker_info(worker_name=None)¶ 获取给定工人名称的WorkerInfo。 使用此WorkerInfo可以避免在每次调用时传递昂贵的字符串。 Parameters worker_name (str )–工人的字符串名称。 如果None，则返回当前工作程序的 ID。 (默认None） Returns 如果worker_name为None，则给定当前工作程序的worker_name或WorkerInfo的WorkerInfo实例。 torch.distributed.rpc.shutdown(graceful=True)¶ 关闭 RPC 代理，然后销毁 RPC 代理。 这将阻止本地代理接受未完成的请求，并通过终止所有 RPC 线程来关闭 RPC 框架。 如果 graceful = True，则它将阻塞，直到所有本地和远程 RPC 进程都到达此方法并等待所有未完成的工作完成。 否则，如果 graceful = False，则这是本地关闭，并且它不等待其他 RPC 进程到达此方法。 Parameters 正常 (bool )–是否进行正常关机。 如果为 True，它将阻塞直到所有本地和远程 RPC 进程都达到此方法并等待所有未完成的工作完成。 Example: On worker 0: >>> import torch.distributed.rpc as rpc >>> rpc.init_rpc(\"worker0\", rank=0, world_size=2) >>> # do some work >>> result = rpc.rpc_sync(\"worker1\", torch.add, args=(torch.ones(1), 1)) >>> # ready to shutdown >>> rpc.shutdown() On worker 1: >>> import torch.distributed.rpc as rpc >>> rpc.init_rpc(\"worker1\", rank=1, world_size=2) >>> # wait for worker 0 to finish work, and then shutdown. >>> rpc.shutdown() 分布式 Autograd 框架 此模块提供了一个基于 RPC 的分布式 autograd 框架，该框架可用于模型并行训练等应用程序。 简而言之，应用程序可以通过 RPC 发送和接收梯度记录张量。 在前向传递中，我们记录何时通过 RPC 发送梯度记录张量，而在后向传递过程中，我们使用此信息使用 RPC 执行分布式后向传递。 有关更多详细信息，请参见分布式 Autograd 设计。 class torch.distributed.autograd.context¶ 使用分布式 autograd 时要环绕前进和后退传递的上下文对象。 需要with语句中生成的context_id来唯一标识所有工作程序上的分布式反向传递。 每个工作人员都存储与此context_id关联的元数据，这是正确执行分布式自动毕业证件所必需的。 Example: >> import torch.distributed.autograd as dist_autograd >> with dist_autograd.context() as context_id: >> t1 = torch.rand((3, 3), requires_grad=True) >> t2 = torch.rand((3, 3), requires_grad=True) >> loss = rpc.rpc_sync(\"worker1\", torch.add, args=(t1, t2)).sum() >> dist_autograd.backward([loss]) torch.distributed.autograd.backward(roots: List[Tensor]) → None¶ 使用提供的根启动分布式反向传递。 当前，这实现了 FAST 模式算法，该算法假设在反向传递过程中，跨工作程序在同一分布式 autograd 上下文中发送的所有 RPC 消息将是 autograd 图的一部分。 我们使用提供的根来发现 autograd 图并计算适当的依赖关系。 该方法将阻塞，直到完成整个 autograd 计算。 我们在每个节点上的适当 torch.distributed.autograd.context 中累积梯度。 当调用 torch.distributed.autograd.backward() 时，使用的 autograd 上下文是该节点的当前 autograd 上下文。 如果没有有效的 autograd 上下文，我们将引发错误。 您可以使用 get_gradients() API 检索累积的梯度。 Parameters 根(列表）–代表自动梯度计算根的张量。 所有张量应为标量。 Example: >> import torch.distributed.autograd as dist_autograd >> with dist_autograd.context() as context_id: >> pred = model.forward() >> loss = loss_func(pred, loss) >> dist_autograd.backward(loss) torch.distributed.autograd.get_gradients(context_id: int) → Dict[Tensor, Tensor]¶ 从张量检索映射，以获取在提供的context_id中作为累积的 autograd 向后传递的一部分的张量所对应的张量。 Parameters context_id (python：int )–我们应为其检索梯度的 autograd 上下文 ID。 Returns 一个映射，其中键是张量，值是该张量的关联渐变。 Example: >> import torch.distributed.autograd as dist_autograd >> with dist_autograd.context() as context_id: >> t1 = torch.rand((3, 3), requires_grad=True) >> t2 = torch.rand((3, 3), requires_grad=True) >> loss = t1 + t2 >> dist_autograd.backward([loss.sum()]) >> grads = dist_autograd.get_gradients(context_id) >> print (grads[t1]) >> print (grads[t2]) 分布式优化器 torch.distributed.optim 公开 DistributedOptimizer，后者获取远程参数列表 (RRef)，并在参数所在的工作线程中本地运行优化器。 分布式优化器可以使用任何本地优化器算法来将梯度应用于每个工作者。 class torch.distributed.optim.DistributedOptimizer(optimizer_class, params_rref, *args, **kwargs)¶ DistributedOptimizer 远程引用分散在工作程序中的参数，并为每个参数在本地应用给定的优化器。 此类使用 get_gradients() 来检索特定参数的梯度。 来自同一客户端或不同客户端的对 step() 的并发调用将在每个工作人员上进行序列化-因为每个工作人员的优化程序一次只能处理一组渐变。 但是，不能保证完整的前向后向优化程序序列将一次为一个客户端执行。 这意味着所应用的渐变可能不对应于在给定工人上执行的最新前向通过。 此外，也不能保证在所有工人之间订购。 Parameters optimizer_class (optim.Optimizer)–在每个 worker 上实例化的优化器的类。 params_rref (列表 [ RRef ] )–本地或本地参考的 RRef 列表 远程参数进行优化。 args –传递给每个工作程序上的优化器构造函数的参数。 kwargs –传递给每个工作程序上的优化器构造函数的参数。 Example: >> import torch.distributed.autograd as dist_autograd >> import torch.distributed.rpc as rpc >> from torch import optim >> from torch.distributed.optim import DistributedOptimizer >> >> with dist_autograd.context() as context_id: >> # Forward pass. >> rref1 = rpc.remote(\"worker1\", torch.add, args=(torch.ones(2), 3)) >> rref2 = rpc.remote(\"worker1\", torch.add, args=(torch.ones(2), 1)) >> loss = rref1.to_here() + rref2.to_here() >> >> # Backward pass. >> dist_autograd.backward([loss.sum()]) >> >> # Optimizer. >> dist_optim = DistributedOptimizer( >> optim.SGD, >> [rref1, rref2], >> lr=0.05, >> ) >> dist_optim.step() step()¶ 执行一个优化步骤。 这将在每个包含要优化参数的工作程序上调用 torch.optim.Optimizer.step() ，并将阻塞直到所有工作程序返回。 当前的分布式 autograd context 将在全球范围内使用。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"90.html":{"url":"90.html","title":"torch随机","keywords":"","body":"torch随机 原文： https://pytorch.org/docs/stable/random.html torch.random.fork_rng(devices=None, enabled=True, _caller='fork_rng', _devices_kw='devices')¶ 分叉 RNG，以便在您返回时将 RNG 重置为之前的状态。 参数 设备(可迭代的 CUDA ID 的）–派生 RNG 的 CUDA 设备。 CPU RNG 状态始终为分叉。 默认情况下， fork_rng() 可在所有设备上运行，但是如果您的计算机上有很多设备，则将发出警告，因为在这种情况下此功能运行非常缓慢。 如果您明确指定设备，该警告将被取消 启用的 (bool )–如果False，则不分叉 RNG。 这是一个方便的参数，用于轻松禁用上下文管理器，而不必删除它并取消其下的 Python 代码的缩进。 torch.random.get_rng_state()¶ 以 torch.ByteTensor 的形式返回随机数生成器状态。 torch.random.initial_seed()¶ 返回长为 Python long 的用于生成随机数的初始种子。 torch.random.manual_seed(seed)¶ 设置用于生成随机数的种子。 返回一个torch.生成器对象。 Parameters 种子 (python：int )–所需的种子。 torch.random.seed()¶ 将用于生成随机数的种子设置为不确定的随机数。 返回用于播种 RNG 的 64 位数字。 torch.random.set_rng_state(new_state)¶ 设置随机数生成器状态。 Parameters new_state (torch.ByteTensor )–所需状态 随机数发生器 torch.random.get_rng_state() Returns the random number generator state as a torch.ByteTensor. torch.random.set_rng_state(new_state) Sets the random number generator state. Parameters new_state (torch.ByteTensor) – The desired state torch.random.manual_seed(seed) Sets the seed for generating random numbers. Returns a torch.Generator object. Parameters seed (python:int) – The desired seed. torch.random.seed() Sets the seed for generating random numbers to a non-deterministic random number. Returns a 64 bit number used to seed the RNG. torch.random.initial_seed() Returns the initial seed for generating random numbers as a Python long. torch.random.fork_rng(devices=None, enabled=True, _caller='fork_rng', _devices_kw='devices') Forks the RNG, so that when you return, the RNG is reset to the state that it was previously in. Parameters devices (iterable of CUDA IDs) – CUDA devices for which to fork the RNG. CPU RNG state is always forked. By default, fork_rng() operates on all devices, but will emit a warning if your machine has a lot of devices, since this function will run very slowly in that case. If you explicitly specify devices, this warning will be suppressed enabled (bool) – if False, the RNG is not forked. This is a convenience argument for easily disabling the context manager without having to delete it and unindent your Python code under it. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:25:18 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"91.html":{"url":"91.html","title":"torch稀疏","keywords":"","body":"torch稀疏 原文： https://pytorch.org/docs/stable/sparse.html 警告 该 API 目前处于实验阶段，可能会在不久的将来进行更改。 Torch 支持 COO(rdinate）格式的稀疏张量，该稀疏张量可以有效地存储和处理大多数元素为零的张量。 稀疏张量表示为一对密集张量：一个值张量和一个 2D 索引张量。 可以通过提供这两个张量以及稀疏张量的大小(无法从这些张量推断出）来构造稀疏张量假设我们要定义一个稀疏张量，其入口 3 位于位置(0，2） ，位置(1、0）处的条目 4 和位置(1、2）处的条目 5。 然后我们将写： >>> i = torch.LongTensor([[0, 1, 1], [2, 0, 2]]) >>> v = torch.FloatTensor([3, 4, 5]) >>> torch.sparse.FloatTensor(i, v, torch.Size([2,3])).to_dense() 0 0 3 4 0 5 [torch.FloatTensor of size 2x3] 请注意，LongTensor 的输入不是索引元组的列表。 如果要以这种方式编写索引，则应在将索引传递给稀疏构造函数之前进行转置： >>> i = torch.LongTensor([[0, 2], [1, 0], [1, 2]]) >>> v = torch.FloatTensor([3, 4, 5 ]) >>> torch.sparse.FloatTensor(i.t(), v, torch.Size([2,3])).to_dense() 0 0 3 4 0 5 [torch.FloatTensor of size 2x3] 您还可以构造混合稀疏张量，其中仅前 n 个维是稀疏的，其余维是密集的。 >>> i = torch.LongTensor([[2, 4]]) >>> v = torch.FloatTensor([[1, 3], [5, 7]]) >>> torch.sparse.FloatTensor(i, v).to_dense() 0 0 0 0 1 3 0 0 5 7 [torch.FloatTensor of size 5x2] 可以通过指定大小来构造一个空的稀疏张量： >>> torch.sparse.FloatTensor(2, 3) SparseFloatTensor of size 2x3 with indices: [torch.LongTensor with no dimension] and values: [torch.FloatTensor with no dimension] SparseTensor has the following invariants: sparse_dim + density_dim = len(SparseTensor.shape） SparseTensor._indices(）。shape =(sparse_dim，nnz） SparseTensor._values(）。shape =(nnz，SparseTensor.shape [sparse_dim：]） 由于 SparseTensor._indices(）始终是 2D 张量，因此最小的 sparse_dim =1。因此，sparse_dim = 0 的 SparseTensor 的表示只是一个密集的张量。 注意 我们的稀疏张量格式允许不分众的稀疏张量，其中索引中可能有重复的坐标； 在这种情况下，解释是该索引处的值是所有重复值条目的总和。 张量张量允许我们更有效地实施某些运算符。 在大多数情况下，您不必担心稀疏张量是否合并，因为在合并或未合并稀疏张量的情况下，大多数操作都可以相同地工作。 但是，在两种情况下，您可能需要注意。 首先，如果您反复执行可能产生重复项的操作(例如 torch.sparse.FloatTensor.add())，则应偶尔合并稀疏张量以防止它们变得太大。 其次，某些运算符会根据是否合并而产生不同的值(例如 torch.sparse.FloatTensor._values() 和 torch.sparse.FloatTensor._indices() 以及 torch.Tensor.sparse_mask())。 这些运算符以下划线作为前缀，表示它们揭示了内部实现细节，因此应谨慎使用，因为与合并的稀疏张量一起使用的代码可能不适用于未合并的稀疏张量； 一般来说，与这些运营商合作之前，明确合并是最安全的。 例如，假设我们想通过直接在 torch.sparse.FloatTensor._values() 上进行操作来实现一个运算符。 标量乘法可以很明显地实现，因为乘法分布在加法上。 但是，平方根不能直接实现，因为sqrt(a + b) != sqrt(a) + sqrt(b)(如果给定非张量的张量，将计算出平方根）。 class torch.sparse.FloatTensor¶ add()¶ add_()¶ clone()¶ dim()¶ div()¶ div_()¶ get_device()¶ hspmm()¶ mm()¶ mul()¶ mul_()¶ narrow_copy()¶ resizeAs_()¶ size()¶ spadd()¶ spmm()¶ sspaddmm()¶ sspmm()¶ sub()¶ sub_()¶ t_()¶ to_dense()¶ transpose()¶ transpose_()¶ zero_()¶ coalesce()¶ is_coalesced()¶ _indices()¶ _values()¶ _nnz()¶ 功能 torch.sparse.addmm(mat, mat1, mat2, beta=1, alpha=1)¶ 该函数与 torch.addmm() 的功能完全相同，只是它支持稀疏矩阵mat1的向后功能。 mat1需要具有 sparse_dim = 2 。 请注意，mat1的梯度是合并的稀疏张量。 参数 垫 (tensor)–要添加的密集矩阵 mat1 (SparseTensor )–要相乘的稀疏矩阵 mat2 (tensor)–密矩阵相乘 beta (数字 ， 可选）– mat(）的乘数 alpha (编号 ， 可选）– (）的乘数 torch.sparse.mm(mat1, mat2)¶ 对稀疏矩阵mat1与密集矩阵mat2进行矩阵乘法。 与 torch.mm() 相似，如果mat1是张量，mat2是张量，则输出将是密集张量。 mat1需要具有 sparse_dim = 2 。 此功能还支持两个矩阵的向后。 请注意，mat1的梯度是合并的稀疏张量。 Parameters mat1 (SparseTensor )–第一个要相乘的稀疏矩阵 mat2 (tensor)–要相乘的第二个密集矩阵 例： >>> a = torch.randn(2, 3).to_sparse().requires_grad_(True) >>> a tensor(indices=tensor([[0, 0, 0, 1, 1, 1], [0, 1, 2, 0, 1, 2]]), values=tensor([ 1.5901, 0.0183, -0.6146, 1.8061, -0.0112, 0.6302]), size=(2, 3), nnz=6, layout=torch.sparse_coo, requires_grad=True) >>> b = torch.randn(3, 2, requires_grad=True) >>> b tensor([[-0.6479, 0.7874], [-1.2056, 0.5641], [-1.1716, -0.9923]], requires_grad=True) >>> y = torch.sparse.mm(a, b) >>> y tensor([[-0.3323, 1.8723], [-1.8951, 0.7904]], grad_fn=) >>> y.sum().backward() >>> a.grad tensor(indices=tensor([[0, 0, 0, 1, 1, 1], [0, 1, 2, 0, 1, 2]]), values=tensor([ 0.1394, -0.6415, -2.1639, 0.1394, -0.6415, -2.1639]), size=(2, 3), nnz=6, layout=torch.sparse_coo) torch.sparse.sum(input, dim=None, dtype=None)¶ 返回给定维度dim中 SparseTensor input每行的总和。 如果dim是尺寸列表，请缩小所有尺寸。 当对所有sparse_dim求和时，此方法返回张量而不是 SparseTensor。 压缩所有求和的dim(请参见 torch.squeeze())，从而使输出张量的尺寸比input小。 在向后期间，仅input的nnz位置处的梯度将传播回去。 注意，input的梯度是合并的。 Parameters 输入 (tensor)–输入 SparseTensor 暗淡的 (python：int 或 python：ints 的元组）–一个要减小的尺寸或尺寸列表。 默认值：减少所有暗淡。 dtype (torch.dtype，可选）–返回的 Tensor 的所需数据类型。 默认值：input的 dtype。 Example: >>> nnz = 3 >>> dims = [5, 5, 2, 3] >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)), torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz) >>> V = torch.randn(nnz, dims[2], dims[3]) >>> size = torch.Size(dims) >>> S = torch.sparse_coo_tensor(I, V, size) >>> S tensor(indices=tensor([[2, 0, 3], [2, 4, 1]]), values=tensor([[[-0.6438, -1.6467, 1.4004], [ 0.3411, 0.0918, -0.2312]], [[ 0.5348, 0.0634, -2.0494], [-0.7125, -1.0646, 2.1844]], [[ 0.1276, 0.1874, -0.6334], [-1.9682, -0.5340, 0.7483]]]), size=(5, 5, 2, 3), nnz=3, layout=torch.sparse_coo) # when sum over only part of sparse_dims, return a SparseTensor >>> torch.sparse.sum(S, [1, 3]) tensor(indices=tensor([[0, 2, 3]]), values=tensor([[-1.4512, 0.4073], [-0.8901, 0.2017], [-0.3183, -1.7539]]), size=(5, 2), nnz=3, layout=torch.sparse_coo) # when sum over all sparse dim, return a dense Tensor # with summed dims squeezed >>> torch.sparse.sum(S, [0, 1, 3]) tensor([-2.6596, -1.1450]) 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:35:32 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"92.html":{"url":"92.html","title":"torch存储","keywords":"","body":"torch存储 原文： https://pytorch.org/docs/stable/storage.html torch.Storage是单个数据类型的连续一维数组。 每个 torch.Tensor 都有对应的相同数据类型的存储。 class torch.FloatStorage¶ bfloat16()¶ 将此存储空间转换为 bfloat16 类型 bool()¶ 将此存储转换为布尔型 byte()¶ 将此存储空间转换为字节类型 char()¶ 将此存储空间转换为 char 类型 clone()¶ 返回此存储的副本 copy_()¶ cpu()¶ 返回此存储的 CPU 副本(如果尚未在 CPU 上） cuda(device=None, non_blocking=False, **kwargs)¶ 返回此对象在 CUDA 内存中的副本。 如果此对象已经在 CUDA 内存中并且在正确的设备上，则不执行任何复制，并返回原始对象。 参数 设备 (python：int )–目标 GPU ID。 默认为当前设备。 non_blocking (bool )–如果True并且源位于固定内存中，则副本将相对于主机是异步的。 否则，该参数无效。 ** –为兼容起见，可以包含键async来代替non_blocking参数。 data_ptr()¶ device¶ double()¶ 将此存储空间转换为双精度类型 dtype¶ element_size()¶ fill_()¶ float()¶ 将此存储转换为浮动类型 static from_buffer()¶ static from_file(filename, shared=False, size=0) → Storage¶ 如果共享的为为，则在所有进程之间共享内存。 所有更改都将写入文件。 如果共享的为假，则存储上的更改不会影响该文件。 大小是存储中元素的数量。 如果共享的为假，则文件必须至少包含 size * sizeof(Type）个字节 (Type 是存储类型 )。 如果共享的为 True ，则将根据需要创建文件。 Parameters 文件名 (str )–要映射的文件名 共享的 (bool )–是否共享内存 大小 (python：int )–存储中的元素数 half()¶ 将此存储空间转换为一半类型 int()¶ 将此存储空间转换为 int 类型 is_cuda = False¶ is_pinned()¶ is_shared()¶ is_sparse = False¶ long()¶ 将此存储空间转换为长型 new()¶ pin_memory()¶ 将存储复制到固定的内存(如果尚未固定）。 resize_()¶ share_memory_()¶ 将存储移动到共享内存。 对于共享内存中已存在的存储和 CUDA 存储(对于跨进程共享无需移动的 CUDA 存储），此操作不起作用。 共享内存中的存储无法调整大小。 返回：自我 short()¶ 将此存储空间转换为短型 size()¶ tolist()¶ 返回包含此存储元素的列表 type(dtype=None, non_blocking=False, **kwargs)¶ 如果未提供 dtype ，则返回类型，否则将该对象强制转换为指定的类型。 如果它已经是正确的类型，则不执行任何复制，并返回原始对象。 Parameters dtype (python：type 或 字符串）–所需类型 non_blocking (bool )–如果True，并且源位于固定内存中，而目标位于 GPU 上，反之亦然，则相对于主机异步执行复制。 否则，该参数无效。 ** –为兼容起见，可以包含键async来代替non_blocking参数。 不推荐使用async arg。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:25:18 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"93.html":{"url":"93.html","title":"torch.utils.bottleneck","keywords":"","body":"torch.utils.bottleneck 原文： https://pytorch.org/docs/stable/bottleneck.html torch.utils.bottleneck 是可以用作调试程序瓶颈的第一步的工具。 它使用 Python 分析器和 PyTorch 的 autograd 分析器总结了脚本的运行。 使用以下命令在命令行上运行 python -m torch.utils.bottleneck /path/to/source/script.py [args] 其中[args]是 script.py 的任意数量的参数，或者运行python -m torch.utils.bottleneck -h以获取更多使用说明。 警告 因为您的脚本将被分析，所以请确保它在有限的时间内退出。 Warning 由于 CUDA 内核的异步特性，当针对 CUDA 代码运行时，cProfile 输出和 CPU 模式自动分级探查器可能无法显示正确的计时：报告的 CPU 时间报告了用于启动内核的时间量，但不包括时间 除非操作进行了同步，否则内核将花费在 GPU 上执行。 在常规的 CPU 模式分析器下，进行同步的操作似乎非常昂贵。 在这些时间不正确的情况下，CUDA 模式自动毕业分析器可能会有所帮助。 注意 要确定要查看哪个(仅 CPU 模式或 CUDA 模式）autograd Profiler 输出，您应该首先检查脚本是否受 CPU 限制(“ CPU 总时间远大于 CUDA 总时间”）。 如果它是 CPU 绑定的，则查看 CPU 模式的 autograd profiler 的结果将有所帮助。 另一方面，如果您的脚本将其大部分时间都花在 GPU 上执行，则有必要在 CUDA 模式 autograd profiler 的输出中开始寻找负责任的 CUDA 运算符。 当然，实际情况要复杂得多，根据您要评估的模型部分，您的脚本可能不会处于这两种极端情况之一。 如果分析器输出无济于事，则可以尝试使用nvprof查看 torch.autograd.profiler.emit_nvtx() 的结果。 但是，请考虑到 NVTX 开销非常高，并且通常会出现严重偏差的时间表。 Warning 如果您正在分析 CUDA 代码，则运行bottleneck的第一个分析器(cProfile）将在其时间报告中包括 CUDA 启动时间(CUDA 缓冲区分配成本）。 瓶颈是否导致代码比 CUDA 启动时间慢得多，这无关紧要。 有关探查器的更复杂用法(例如在多 GPU 情况下），请参阅 https://docs.python.org/3/library/profile.html 或 torch.autograd.profiler.profile() 了解更多信息。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:38:51 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"94.html":{"url":"94.html","title":"torch.utils.checkpoint","keywords":"","body":"torch.utils.checkpoint 原文： https://pytorch.org/docs/stable/checkpoint.html 注意 通过在反向过程中为每个检查点段重新运行一个正向通过段来实现检查点。 这可能会导致像 RNG 状态这样的持久状态比没有检查点的状态更先进。 默认情况下，检查点包括处理 RNG 状态的逻辑，以便与非检查点通过相比，使用 RNG(例如，通过丢弃）的检查点通过具有确定的输出。 根据检查点操作的运行时间，存储和恢复 RNG 状态的逻辑可能会导致性能下降。 如果不需要与非检查点通过相比确定的输出，则在每个检查点期间向checkpoint或checkpoint_sequential提供preserve_rng_state=False，以忽略存储和恢复 RNG 状态。 隐藏逻辑将当前设备以及所有 cuda Tensor 参数的设备的 RNG 状态保存并恢复到run_fn。 但是，该逻辑无法预料用户是否将张量移动到run_fn本身内的新设备。 因此，如果在run_fn中将张量移动到新设备(“新”表示不属于[当前设备+张量参数的设备的集合]），则与非检查点传递相比，确定性输出将永远无法保证。 torch.utils.checkpoint.checkpoint(function, *args, **kwargs)¶ 检查点模型或模型的一部分 检查点通过将计算交换为内存来工作。 检查点部分没有存储整个计算图的所有中间激活以进行向后计算，而是由而不是保存中间激活，而是在向后传递时重新计算它们。 它可以应用于模型的任何部分。 具体而言，在前向传递中，function将以torch.no_grad()方式运行，即不存储中间激活。 相反，前向传递保存输入元组和function参数。 在向后遍历中，检索保存的输入和function，并再次在function上计算正向遍历，现在跟踪中间激活，然后使用这些激活值计算梯度。 警告 检查点不适用于 torch.autograd.grad() ，而仅适用于 torch.autograd.backward() 。 Warning 如果后退期间的function调用与前退期间的调用有任何不同，例如，由于某些全局变量，则检查点版本将不相等，很遗憾，无法检测到该版本。 参数 函数 –描述在模型的正向传递中或模型的一部分中运行的内容。 它还应该知道如何处理作为元组传递的输入。 例如，在 LSTM 中，如果用户通过(activation, hidden)，则function应正确使用第一个输入作为activation，第二个输入作为hidden reserve_rng_state (bool ， 可选 ， 默认= True 在每个检查点期间恢复 RNG 状态。 args –包含function输入的元组 退货 在*args上运行function的输出 torch.utils.checkpoint.checkpoint_sequential(functions, segments, *inputs, **kwargs)¶ 用于检查点顺序模型的辅助功能。 顺序模型按顺序(依次）执行模块/功能列表。 因此，我们可以将这样的模型划分为不同的段，并在每个段上检查点。 除最后一个段外，所有段都将以torch.no_grad()方式运行，即不存储中间激活。 将保存每个检查点线段的输入，以便在后向传递中重新运行该线段。 有关检查点的工作方式，请参见 checkpoint() 。 Warning Checkpointing doesn’t work with torch.autograd.grad(), but only with torch.autograd.backward(). Parameters 功能 –一个 torch.nn.Sequential 或要顺序运行的模块或功能列表(包含模型）。 段 –在模型中创建的块数 输入 –张量元组，它们是functions的输入 preserve_rng_state (bool__, optional__, default=True) – Omit stashing and restoring the RNG state during each checkpoint. Returns 在*inputs上顺序运行functions的输出 例 >>> model = nn.Sequential(...) >>> input_var = checkpoint_sequential(model, chunks, input_var) 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:25:18 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"95.html":{"url":"95.html","title":"torch.utils.cpp_extension","keywords":"","body":"torch.utils.cpp_extension 原文： https://pytorch.org/docs/stable/cpp_extension.html torch.utils.cpp_extension.CppExtension(name, sources, *args, **kwargs)¶ 为 C ++创建一个setuptools.Extension。 一种便捷方法，它使用最少的(但通常是足够的）参数创建setuptools.Extension来构建 C ++扩展。 所有参数都转发到setuptools.Extension构造函数。 例 >>> from setuptools import setup >>> from torch.utils.cpp_extension import BuildExtension, CppExtension >>> setup( name='extension', ext_modules=[ CppExtension( name='extension', sources=['extension.cpp'], extra_compile_args=['-g']), ], cmdclass={ 'build_ext': BuildExtension }) torch.utils.cpp_extension.CUDAExtension(name, sources, *args, **kwargs)¶ 为 CUDA / C ++创建一个setuptools.Extension。 一种便捷方法，它使用最少的(但通常是足够的）参数创建setuptools.Extension，以构建 CUDA / C ++扩展。 这包括 CUDA 包含路径，库路径和运行时库。 All arguments are forwarded to the setuptools.Extension constructor. Example >>> from setuptools import setup >>> from torch.utils.cpp_extension import BuildExtension, CUDAExtension >>> setup( name='cuda_extension', ext_modules=[ CUDAExtension( name='cuda_extension', sources=['extension.cpp', 'extension_kernel.cu'], extra_compile_args={'cxx': ['-g'], 'nvcc': ['-O2']}) ], cmdclass={ 'build_ext': BuildExtension }) torch.utils.cpp_extension.BuildExtension(*args, **kwargs)¶ 自定义setuptools构建扩展。 这个setuptools.build_ext子类负责传递所需的最低编译器标志(例如-std=c++11）以及混合的 C ++ / CUDA 编译(并通常支持 CUDA 文件）。 使用 BuildExtension 时，可以提供extra_compile_args(而不是通常的列表）的字典，该字典从语言(cxx或nvcc）映射到其他编译器标志的列表 提供给编译器。 这样就可以在混合编译期间向 C ++和 CUDA 编译器提供不同的标志。 torch.utils.cpp_extension.load(name, sources, extra_cflags=None, extra_cuda_cflags=None, extra_ldflags=None, extra_include_paths=None, build_directory=None, verbose=False, with_cuda=None, is_python_module=True)¶ 即时加载 PyTorch C ++扩展(JIT）。 要加载扩展，将发出 Ninja 构建文件，该文件用于将给定的源编译到动态库中。 随后将该库作为模块加载到当前的 Python 进程中，并从此函数返回，以供使用。 默认情况下，生成文件的发布目录和编译到的结果库为&lt;tmp&gt;/torch_extensions/&lt;name&gt;，其中&lt;tmp&gt;是当前平台上的临时文件夹，&lt;name&gt;是扩展名。 可以通过两种方式覆盖此位置。 首先，如果设置了TORCH_EXTENSIONS_DIR环境变量，它将替换&lt;tmp&gt;/torch_extensions，所有扩展名都将编译到该目录的子文件夹中。 第二，如果提供了此函数的build_directory参数，它将覆盖整个路径，即库将直接编译到该文件夹​​中。 要编译源，使用默认的系统编译器(c++），可以通过设置CXX环境变量来覆盖它。 要将其他参数传递给编译过程，可以提供extra_cflags或extra_ldflags。 例如，要使用优化来编译扩展，请传递extra_cflags=['-O3']。 您也可以使用extra_cflags传递更多的包含目录。 提供带有混合编译的 CUDA 支持。 只需将 CUDA 源文件(.cu或.cuh）与其他源一起传递即可。 将使用 nvcc 而不是 C ++编译器检测并编译此类文件。 这包括将 CUDA lib64 目录作为库目录传递，并链接cudart。 您可以通过extra_cuda_cflags将其他标志传递给 nvcc，就像 C ++的extra_cflags一样。 使用各种启发式方法来查找 CUDA 安装目录，通常可以正常工作。 否则，设置CUDA_HOME环境变量是最安全的选择。 参数 名称 –要构建的扩展名。 该名称必须与 pybind11 模块的名称相同！ 源 – C ++源文件的相对或绝对路径的列表。 extra_cflags –编译器标志的可选列表，以转发到构建。 extra_cuda_cflags –生成 CUDA 源时转发到 nvcc 的编译器标志的可选列表。 extra_ldflags –链接标志的可选列表，以转发到构建。 extra_include_paths –包含目录的可选列表，以转发到构建。 build_directory –用作构建工作区的可选路径。 verbose –如果True，则打开加载步骤的详细日志记录。 with_cuda –确定是否将 CUDA 标头和库添加到构建中。 如果设置为None(默认值），则根据sources中是否存在.cu或.cuh自动确定该值。 将其设置为 True` 以强制包含 CUDA 标头和库。 is_python_module –如果为True(默认），则将生成的共享库作为 Python 模块导入。 如果为False，则将其作为纯动态库加载到进程中。 退货 如果is_python_module为True，则将加载的 PyTorch 扩展名作为 Python 模块返回。 如果is_python_module为False，则什么都不返回(作为副作用，共享库已加载到进程中）。 Example >>> from torch.utils.cpp_extension import load >>> module = load( name='extension', sources=['extension.cpp', 'extension_kernel.cu'], extra_cflags=['-O2'], verbose=True) torch.utils.cpp_extension.load_inline(name, cpp_sources, cuda_sources=None, functions=None, extra_cflags=None, extra_cuda_cflags=None, extra_ldflags=None, extra_include_paths=None, build_directory=None, verbose=False, with_cuda=None, is_python_module=True, with_pytorch_error_handling=True)¶ 从字符串源实时加载 PyTorch C ++扩展(JIT）。 此函数的行为与 load() 完全相同，但是将其源作为字符串而不是文件名使用。 这些字符串存储到构建目录中的文件中，之后 load_inline() 的行为与 load() 相同。 有关使用此功能的良好示例，请参见测试。 源可能会省略典型的非内联 C ++扩展的两个必需部分：必需的头文件以及(pybind11）绑定代码。 更准确地说，首先将传递给cpp_sources的字符串连接到单个.cpp文件中。 该文件然后以#include &lt;torch/extension.h&gt;开头。 此外，如果提供functions参数，则将为指定的每个函数自动生成绑定。 functions可以是函数名称列表，也可以是从函数名称到文档字符串的字典映射。 如果给出了列表，则将每个函数的名称用作其文档字符串。 cuda_sources中的源被连接到单独的.cu文件中，并以torch/types.h，cuda.h和cuda_runtime.h包括在内。 .cpp和.cu文件是分别编译的，但最终链接到一个库中。 注意，cuda_sources本身不为函数生成任何绑定。 要绑定到 CUDA 内核，您必须创建一个调用它的 C ++函数，并在cpp_sources之一中声明或定义此 C ++函数(并在functions中包括其名称）。 有关以下省略的自变量的说明，请参见 load() 。 Parameters cpp_sources –包含 C ++源代码的字符串或字符串列表。 cuda_sources –包含 CUDA 源代码的字符串或字符串列表。 函数 –为其生成函数绑定的函数名称列表。 如果提供了字典，则应将函数名称映射到文档字符串(否则仅是函数名称）。 with_cuda –确定是否将 CUDA 标头和库添加到构建中。 如果设置为None(默认），则根据是否提供cuda_sources自动确定该值。 将其设置为True以强制包含 CUDA 标头和库。 with_pytorch_error_handling –确定 pytorch 而不是 pybind 处理 pytorch 错误和警告宏。 为此，每个功能foo都通过中间_safe_foo功能调用。 这种重定向在 cpp 晦涩的情况下可能会引起问题。 当此重定向导致问题时，应将此标志设置为False。 Example >>> from torch.utils.cpp_extension import load_inline >>> source = ''' at::Tensor sin_add(at::Tensor x, at::Tensor y) { return x.sin() + y.sin(); } ''' >>> module = load_inline(name='inline_extension', cpp_sources=[source], functions=['sin_add']) torch.utils.cpp_extension.include_paths(cuda=False)¶ 获取构建 C ++或 CUDA 扩展所需的包含路径。 Parameters cuda -如果为真，则包含特定于 CUDA 的包含路径。 Returns 包含路径字符串的列表。 torch.utils.cpp_extension.check_compiler_abi_compatibility(compiler)¶ 验证给定的编译器是否与 PyTorch 兼容。 Parameters 编译器 (str )–要检查的编译器可执行文件名称(例如g++）。 必须在 Shell 进程中可执行。 Returns 如果编译器(可能）与 PyTorch 不兼容，则为 False，否则为 True。 torch.utils.cpp_extension.verify_ninja_availability()¶ 如果系统上有 ninja 构建系统，则返回True。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:25:18 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"96.html":{"url":"96.html","title":"torch.utils.data","keywords":"","body":"torch.utils.data 原文： https://pytorch.org/docs/stable/data.html PyTorch 数据加载实用程序的核心是 torch.utils.data.DataLoader 类。 它表示可在数据集上迭代的 Python，并支持 地图样式和可迭代样式的数据集， 自定义数据加载顺序， 自动配料， 单进程和多进程数据加载， 自动内存固定。 这些选项由 DataLoader 的构造函数参数配置，该参数具有签名： DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None) 以下各节详细介绍了这些选项的效果和用法。 数据集类型 DataLoader 构造函数的最重要参数是dataset，它指示要从中加载数据的数据集对象。 PyTorch 支持两种不同类型的数据集： 地图样式数据集， 迭代式数据集。 地图样式数据集 映射样式数据集是一种实现__getitem__()和__len__()协议的数据集，它表示从(可能是非整数）索引/关键字到数据样本的映射。 例如，当使用dataset[idx]访问时，此类数据集可以从磁盘上的文件夹中读取第idx张图像及其对应的标签。 有关更多详细信息，请参见 Dataset 。 迭代式数据集 可迭代样式的数据集是 IterableDataset 子类的实例，该子类实现了__iter__()协议，并表示数据样本上的可迭代。 这种类型的数据集特别适用于随机读取价格昂贵甚至不大可能，并且批处理大小取决于所获取数据的情况。 例如，这种数据集称为iter(dataset)时，可以返回从数据库，远程服务器甚至实时生成的日志中读取的数据流。 有关更多详细信息，请参见 IterableDataset 。 注意 当将 IterableDataset 与一起使用时，多进程数据加载。 在每个工作进程上都复制相同的数据集对象，因此必须对副本进行不同的配置，以避免重复的数据。 有关如何实现此功能的信息，请参见 IterableDataset 文档。 数据加载顺序和 Sampler 对于迭代式数据集，数据加载顺序完全由用户定义的迭代器控制。 这样可以更轻松地实现块读取和动态批次大小的实现(例如，通过每次生成一个批次的样本）。 本节的其余部分涉及地图样式数据集的情况。 torch.utils.data.Sampler 类用于指定数据加载中使用的索引/键的顺序。 它们代表数据集索引上的可迭代对象。 例如，在具有随机梯度体面(SGD）的常见情况下， Sampler 可以随机排列一列索引，一次生成每个索引，或者为小批量生成少量索引 新币。 基于 DataLoader 的shuffle参数，将自动构建顺序采样或混洗的采样器。 或者，用户可以使用sampler参数指定一个自定义 Sampler 对象，该对象每次都会产生要提取的下一个索引/关键字。 可以一次生成批量索引列表的自定义 Sampler 作为batch_sampler参数传递。 也可以通过batch_size和drop_last参数启用自动批处理。 有关更多详细信息，请参见下一部分的。 Note sampler和batch_sampler都不与可迭代样式的数据集兼容，因为此类数据集没有键或索引的概念。 加载批处理和非批处理数据 DataLoader 支持通过参数batch_size，drop_last和batch_sampler将各个提取的数据样本自动整理为批次。 自动批处理(默认） 这是最常见的情况，对应于获取一小批数据并将其整理为批处理的样本，即包含张量，其中一维为批处理维度(通常是第一维）。 当batch_size(默认1）不是None时，数据加载器将生成批处理的样本，而不是单个样本。 batch_size和drop_last参数用于指定数据加载器如何获取数据集密钥的批处理。 对于地图样式的数据集，用户可以选择指定batch_sampler，它一次生成一个键列表。 Note batch_size和drop_last自变量本质上用于从sampler构造batch_sampler。 对于地图样式的数据集，sampler由用户提供或基于shuffle参数构造。 对于可迭代样式的数据集，sampler是一个虚拟的无限数据集。 有关采样器的更多详细信息，请参见本节。 Note 当从可重复样式数据集进行多重处理提取时，drop_last参数会删除每个工作人员数据集副本的最后一个非完整批次。 使用来自采样器的索引获取样本列表后，作为collate_fn参数传递的函数用于将样本列表整理为批次。 在这种情况下，从地图样式数据集加载大致等效于： for indices in batch_sampler: yield collate_fn([dataset[i] for i in indices]) 从可迭代样式的数据集加载大致等效于： dataset_iter = iter(dataset) for indices in batch_sampler: yield collate_fn([next(dataset_iter) for _ in indices]) 自定义collate_fn可用于自定义排序规则，例如，将顺序数据填充到批处理的最大长度。 有关collate_fn的更多信息，请参见本部分。 禁用自动批处理 在某些情况下，用户可能希望以数据集代码手动处理批处理，或仅加载单个样本。 例如，直接加载批处理的数据(例如，从数据库中批量读取或读取连续的内存块）可能更便宜，或者批处理大小取决于数据，或者该程序设计为可处理单个样本。 在这种情况下，最好不要使用自动批处理(其中collate_fn用于整理样本），而应让数据加载器直接返回dataset对象的每个成员。 当batch_size和batch_sampler均为None时(batch_sampler的默认值已为None），自动批处理被禁用。 从dataset获得的每个样本都将作为collate_fn参数传递的函数进行处理。 禁用自动批处理时，默认值collate_fn仅将 NumPy 数组转换为 PyTorch 张量，而其他所有内容均保持不变。 In this case, loading from a map-style dataset is roughly equivalent with: for index in sampler: yield collate_fn(dataset[index]) and loading from an iterable-style dataset is roughly equivalent with: for data in iter(dataset): yield collate_fn(data) 有关collate_fn的更多信息，请参见本部分。 使用collate_fn 启用或禁用自动批处理时，collate_fn的使用略有不同。 禁用自动批处理时，将对每个单独的数据样本调用collate_fn，并且从数据加载器迭代器产生输出。 在这种情况下，默认的collate_fn仅转换 PyTorch 张量中的 NumPy 数组。 启用自动批处理时，会每次调用collate_fn并带有数据样本列表。 期望将输入样本整理为一批，以便从数据加载器迭代器中获得收益。 本节的其余部分描述了这种情况下默认collate_fn的行为。 例如，如果每个数据样本都包含一个 3 通道图像和一个整体类标签，即数据集的每个元素返回一个元组(image, class_index)，则默认值collate_fn将此类元组的列表整理为一个元组 批处理图像张量和批处理类标签 Tensor。 特别是，默认collate_fn具有以下属性： 它始终将新维度添加为批次维度。 它会自动将 NumPy 数组和 Python 数值转换为 PyTorch 张量。 它保留了数据结构，例如，如果每个样本都是一个字典，它将输出一个具有相同键集但将批处理 Tensors 作为值的字典(如果无法将这些值转换为 Tensors，则将其列出）。 与list，tuple，namedtuple等相同。 用户可以使用自定义的collate_fn来实现自定义批处理，例如，沿除第一个维度之外的其他维度进行校对，各种长度的填充序列或添加对自定义数据类型的支持。 单进程和多进程数据加载 默认情况下， DataLoader 使用单进程数据加载。 在 Python 进程中，全局解释器锁定(GIL）阻止了跨线程真正的完全并行化 Python 代码。 为了避免在加载数据时阻塞计算代码，PyTorch 提供了一个简单的开关，只需将参数num_workers设置为正整数即可执行多进程数据加载。 单进程数据加载(默认） 在此模式下，以与初始化 DataLoader 相同的过程完成数据提取。 因此，数据加载可能会阻止计算。 然而，当用于在进程之间共享数据的资源(例如，共享存储器，文件描述符）受到限制时，或者当整个数据集很小并且可以完全加载到存储器中时，该模式可能是优选的。 此外，单进程加载通常显示更多可读的错误跟踪，因此对于调试很有用。 多进程数据加载 将参数num_workers设置为正整数将打开具有指定数量的加载程序工作进程的多进程数据加载。 在此模式下，每次创建 DataLoader 的迭代器时(例如，当您调用enumerate(dataloader)时），都会创建num_workers工作进程。 此时，dataset，collate_fn和worker_init_fn被传递给每个工作程序，在这里它们被用来初始化和获取数据。 这意味着数据集访问及其内部 IO 转换(包括collate_fn）在工作进程中运行。 torch.utils.data.get_worker_info() 在工作进程中返回各种有用的信息(包括工作 ID，数据集副本，初始种子等），并在主进程中返回None。 用户可以在数据集代码和/或worker_init_fn中使用此功能来分别配置每个数据集副本，并确定代码是否正在工作进程中运行。 例如，这在分片数据集时特别有用。 对于地图样式的数据集，主过程使用sampler生成索引并将其发送给工作人员。 因此，任何随机播放都是在主过程中完成的，该过程通过为索引分配索引来引导加载。 对于可迭代样式的数据集，由于每个工作进程都获得dataset对象的副本，因此幼稚的多进程加载通常会导致数据重复。 用户可以使用 torch.utils.data.get_worker_info() 和/或worker_init_fn独立配置每个副本。 (有关如何实现此操作的信息，请参见 IterableDataset 文档。）出于类似的原因，在多进程加载中，drop_last参数删除每个工作程序的可迭代样式数据集副本的最后一个非完整批次。 一旦迭代结束或迭代器被垃圾回收，工作器将关闭。 警告 通常不建议在多进程加载中返回 CUDA 张量，因为在使用 CUDA 和在并行处理中共享 CUDA 张量时存在很多微妙之处(请参见在并行处理中的 CUDA)。 相反，我们建议使用自动内存固定(即，设置pin_memory=True），该功能可以将数据快速传输到支持 CUDA 的 GPU。 平台特定的行为 由于工作程序依赖于 Python multiprocessing，因此与 Unix 相比，Windows 上的工作程序启动行为有所不同。 在 Unix 上，fork()是默认的multiprocessing启动方法。 使用fork()，童工通常可以直接通过克隆的地址空间访问dataset和 Python 参数函数。 在 Windows 上，spawn()是默认的multiprocessing启动方法。 使用spawn()启动另一个解释器，该解释器运行您的主脚本，然后运行内部工作程序函数，该函数通过序列化pickle接收dataset，collate_fn和其他参数。 这种独立的序列化意味着您应该采取两个步骤来确保在使用多进程数据加载时与 Windows 兼容： 将您的大部分主脚本代码包装在if __name__ == '__main__':块中，以确保在启动每个工作进程时，该脚本不会再次运行(很可能会产生错误）。 您可以在此处放置数据集和 DataLoader 实例创建逻辑，因为它不需要在 worker 中重新执行。 确保在__main__检查之外将任何自定义collate_fn，worker_init_fn或dataset代码声明为顶级定义。 这样可以确保它们在工作进程中可用。 (这是必需的，因为将函数仅作为引用而不是bytecode进行腌制。） 多进程数据加载中的随机性 默认情况下，每个工作人员的 PyTorch 种子将设置为base_seed + worker_id，其中base_seed是主进程使用其 RNG 生成的长整数(因此，强制使用 RNG 状态）。 但是，初始化工作程序(例如 NumPy）时，可能会复制其他库的种子，导致每个工作程序返回相同的随机数。 (请参阅 FAQ 中的本部分。） 在worker_init_fn中，您可以使用 torch.utils.data.get_worker_info().seed 或 torch.initial_seed() 访问每个工作人员的 PyTorch 种子集，并在加载数据之前使用它为其他库提供种子。 内存固定 主机到 GPU 副本源自固定(页面锁定）内存时，速度要快得多。 有关通常何时以及如何使用固定内存的更多详细信息，请参见使用固定内存缓冲区。 对于数据加载，将pin_memory=True传递到 DataLoader 将自动将获取的数据张量放置在固定内存中，从而更快地将数据传输到启用 CUDA 的 GPU。 默认的内存固定逻辑仅识别张量以及包含张量的映射和可迭代对象。 默认情况下，如果固定逻辑看到一个自定义类型的批处理(如果您有一个collate_fn返回自定义批处理类型，则会发生），或者如果该批处理的每个元素都是自定义类型，则固定逻辑将 无法识别它们，它将返回该批处理(或那些元素）而不固定内存。 要为自定义批处理或数据类型启用内存固定，请在自定义类型上定义pin_memory()方法。 请参见下面的示例。 例： class SimpleCustomBatch: def __init__(self, data): transposed_data = list(zip(*data)) self.inp = torch.stack(transposed_data[0], 0) self.tgt = torch.stack(transposed_data[1], 0) # custom memory pinning method on custom type def pin_memory(self): self.inp = self.inp.pin_memory() self.tgt = self.tgt.pin_memory() return self def collate_wrapper(batch): return SimpleCustomBatch(batch) inps = torch.arange(10 * 5, dtype=torch.float32).view(10, 5) tgts = torch.arange(10 * 5, dtype=torch.float32).view(10, 5) dataset = TensorDataset(inps, tgts) loader = DataLoader(dataset, batch_size=2, collate_fn=collate_wrapper, pin_memory=True) for batch_ndx, sample in enumerate(loader): print(sample.inp.is_pinned()) print(sample.tgt.is_pinned()) class torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None, multiprocessing_context=None)¶ 数据加载器。 组合数据集和采样器，并在给定的数据集上提供可迭代的。 DataLoader 支持地图样式和可迭代样式的数据集，具有单进程或多进程加载，自定义加载顺序以及可选的自动批处理(归类）和内存固定。 有关更多详细信息，请参见 torch.utils.data 文档页面。 参数 数据集 (数据集)–要从中加载数据的数据集。 batch_size (python：int ， 可选）–每批次要加载多少个样本(默认值：1）。 随机播放 (bool ， 可选）–设置为True以使数据在每个时间段都重新随机播放(默认值：False )。 采样器 (采样器 ， 可选）–定义了从数据集中抽取样本的策略。 如果指定，则shuffle必须为False。 batch_sampler (采样器 ， 可选）–类似sampler，但在 时间。 与batch_size，shuffle，sampler和drop_last互斥。 num_workers (python：int ， 可选）–多少个子进程用于数据加载。 0表示将在主进程中加载​​数据。 (默认：0） collat​​e_fn (可调用的， 可选）–合并样本列表以形成张量的小批量。 在从地图样式数据集中使用批量加载时使用。 pin_memory (bool ， 可选）–如果True，则数据加载器将张量复制到 CUDA 固定的内存中，然后返回。 如果您的数据元素是自定义类型，或者您的collate_fn返回的是自定义类型的批次，请参见下面的示例。 drop_last (布尔 ， 可选）–设置为True以删除最后不完整的批次，如果数据集大小不可分割 按批次大小。 如果False并且数据集的大小不能被批次大小整除，那么最后一批将较小。 (默认：False） 超时(数字 ， 可选）–如果为正，则表示从工作人员处收集批次的超时值。 应始终为非负数。 (默认：0） worker_init_fn (可调用 ， 可选）–如果不是None，则将在每个具有工作人员 ID (在播种之后和数据加载之前，将[0, num_workers - 1]中的 int 作为输入。 (默认：None） Warning 如果使用spawn启动方法，则worker_init_fn不能是不可拾取的对象，例如 lambda 函数。 有关 PyTorch 中与并行处理有关的更多详细信息，请参见并行处理最佳实践。 Note len(dataloader)启发式方法基于所用采样器的长度。 当dataset是 IterableDataset 时，无论多进程加载配置如何，都将返回len(dataset)(如果实现），因为 PyTorch 信任用户dataset代码可以正确处理多进程加载 避免重复数据。 有关这两种类型的数据集以及 IterableDataset 如何与多进程数据加载交互的更多详细信息，请参见数据集类型。 class torch.utils.data.Dataset¶ 表示 Dataset 的抽象类。 代表从键到数据样本的映射的所有数据集都应将其子类化。 所有子类都应该覆盖__getitem__()，支持为给定键获取数据样本。 子类还可以选择覆盖__len__()，它有望通过许多 Sampler 实现以及 DataLoader 的默认选项返回数据集的大小。 Note 默认情况下， DataLoader 构造一个索引采样器，该采样器产生整数索引。 要使其与具有非整数索引/键的地图样式数据集一起使用，必须提供自定义采样器。 class torch.utils.data.IterableDataset¶ 可迭代的数据集。 代表可迭代数据样本的所有数据集都应将其子类化。 当数据来自流时，这种形式的数据集特别有用。 所有子类都应覆盖__iter__()，这将返回此数据集中的样本迭代器。 当子类与 DataLoader 一起使用时，数据集中的每个项目都将由 DataLoader 迭代器产生。 当num_workers &gt; 0时，每个工作进程将具有数据集对象的不同副本，因此通常需要独立配置每个副本，以避免从工作进程返回重复的数据。 get_worker_info() 在工作程序进程中调用时，返回有关工作程序的信息。 可以在数据集的__iter__()方法或 DataLoader 的worker_init_fn选项中使用它来修改每个副本的行为。 示例 1：在__iter__()中将工作负载分配给所有工作人员： >>> class MyIterableDataset(torch.utils.data.IterableDataset): ... def __init__(self, start, end): ... super(MyIterableDataset).__init__() ... assert end > start, \"this example code only works with end >= start\" ... self.start = start ... self.end = end ... ... def __iter__(self): ... worker_info = torch.utils.data.get_worker_info() ... if worker_info is None: # single-process data loading, return the full iterator ... iter_start = self.start ... iter_end = self.end ... else: # in a worker process ... # split workload ... per_worker = int(math.ceil((self.end - self.start) / float(worker_info.num_workers))) ... worker_id = worker_info.id ... iter_start = self.start + worker_id * per_worker ... iter_end = min(iter_start + per_worker, self.end) ... return iter(range(iter_start, iter_end)) ... >>> # should give same set of data as range(3, 7), i.e., [3, 4, 5, 6]. >>> ds = MyIterableDataset(start=3, end=7) >>> # Single-process loading >>> print(list(torch.utils.data.DataLoader(ds, num_workers=0))) [3, 4, 5, 6] >>> # Mult-process loading with two worker processes >>> # Worker 0 fetched [3, 4]. Worker 1 fetched [5, 6]. >>> print(list(torch.utils.data.DataLoader(ds, num_workers=2))) [3, 5, 4, 6] >>> # With even more workers >>> print(list(torch.utils.data.DataLoader(ds, num_workers=20))) [3, 4, 5, 6] 示例 2：使用worker_init_fn在所有工作人员之间分配工作量： >>> class MyIterableDataset(torch.utils.data.IterableDataset): ... def __init__(self, start, end): ... super(MyIterableDataset).__init__() ... assert end > start, \"this example code only works with end >= start\" ... self.start = start ... self.end = end ... ... def __iter__(self): ... return iter(range(self.start, self.end)) ... >>> # should give same set of data as range(3, 7), i.e., [3, 4, 5, 6]. >>> ds = MyIterableDataset(start=3, end=7) >>> # Single-process loading >>> print(list(torch.utils.data.DataLoader(ds, num_workers=0))) [3, 4, 5, 6] >>> >>> # Directly doing multi-process loading yields duplicate data >>> print(list(torch.utils.data.DataLoader(ds, num_workers=2))) [3, 3, 4, 4, 5, 5, 6, 6] >>> # Define a `worker_init_fn` that configures each dataset copy differently >>> def worker_init_fn(worker_id): ... worker_info = torch.utils.data.get_worker_info() ... dataset = worker_info.dataset # the dataset copy in this worker process ... overall_start = dataset.start ... overall_end = dataset.end ... # configure the dataset to only process the split workload ... per_worker = int(math.ceil((overall_end - overall_start) / float(worker_info.num_workers))) ... worker_id = worker_info.id ... dataset.start = overall_start + worker_id * per_worker ... dataset.end = min(dataset.start + per_worker, overall_end) ... >>> # Mult-process loading with the custom `worker_init_fn` >>> # Worker 0 fetched [3, 4]. Worker 1 fetched [5, 6]. >>> print(list(torch.utils.data.DataLoader(ds, num_workers=2, worker_init_fn=worker_init_fn))) [3, 5, 4, 6] >>> # With even more workers >>> print(list(torch.utils.data.DataLoader(ds, num_workers=20, worker_init_fn=worker_init_fn))) [3, 4, 5, 6] class torch.utils.data.TensorDataset(*tensors)¶ 数据集包装张量。 每个样本将通过沿第一维索引张量来检索。 Parameters *张量 (tensor)–具有与第一维相同大小的张量。 class torch.utils.data.ConcatDataset(datasets)¶ 数据集是多个数据集的串联。 此类对于组装不同的现有数据集很有用。 Parameters 数据集(序列）–要连接的数据集列表 class torch.utils.data.ChainDataset(datasets)¶ 用于链接多个 IterableDataset 的数据集。 此类对于组装不同的现有数据集流很有用。 链接操作是即时完成的，因此将大型数据集与此类连接起来将非常有效。 Parameters 数据集(IterableDataset 的可迭代）–链接在一起的数据集 class torch.utils.data.Subset(dataset, indices)¶ 指定索引处的数据集子集。 Parameters 数据集 (数据集)–整个数据集 索引(序列）–为子集选择的整个集合中的索引 torch.utils.data.get_worker_info()¶ 返回有关当前 DataLoader 迭代器工作进程的信息。 在工作线程中调用时，此方法返回一个保证具有以下属性的对象： id：当前工作人员 ID。 num_workers：工人总数。 seed：当前工作程序的随机种子集。 该值由主进程 RNG 和工作程序 ID 确定。 有关更多详细信息，请参见 DataLoader 的文档。 dataset：此流程在中的数据集对象的副本。 请注意，在不同的过程中，这将是与主过程中的对象不同的对象。 在主进程中调用时，将返回None。 Note 在传递给 DataLoader 的worker_init_fn中使用时，此方法可用于不同地设置每个工作进程，例如，使用worker_id将dataset对象配置为仅读取 分片数据集的特定部分，或使用seed播种数据集代码中使用的其他库(例如 NumPy）。 torch.utils.data.random_split(dataset, lengths)¶ 将数据集随机拆分为给定长度的不重叠的新数据集。 Parameters 数据集 (数据集)–要拆分的数据集 长度(序列）–要产生的分割的长度 class torch.utils.data.Sampler(data_source)¶ 所有采样器的基类。 每个 Sampler 子类都必须提供__iter__()方法(提供一种对数据集元素的索引进行迭代的方法）和__len__()方法，该方法返回返回的迭代器的长度。 Note DataLoader 并非严格要求__len__()方法，但在涉及 DataLoader 长度的任何计算中都应采用。 class torch.utils.data.SequentialSampler(data_source)¶ 始终以相同顺序顺序采样元素。 Parameters data_source (数据集)–要从中采样的数据集 class torch.utils.data.RandomSampler(data_source, replacement=False, num_samples=None)¶ 随机采样元素。 如果不进行替换，则从经过改组的数据集中采样。 如果要更换，则用户可以指定num_samples进行绘制。 Parameters data_source (Dataset) – dataset to sample from 替换 (bool )–如果True为默认值，则替换为True num_samples (python：int )–要绘制的样本数，默认为 len(dataset）。 仅当替换为True时才应指定此参数。 class torch.utils.data.SubsetRandomSampler(indices)¶ 从给定的索引列表中随机抽样元素，而无需替换。 Parameters 索引(序列）–索引序列 class torch.utils.data.WeightedRandomSampler(weights, num_samples, replacement=True)¶ 以给定的概率(权重）从[0,..,len(weights)-1]中采样元素。 Parameters 权重(序列）–权重序列，不必累加一个 num_samples (python：int )–要绘制的样本数 替代品 (bool )–如果True，则抽取替代品抽取样品。 如果没有，则它们将被替换而不会被绘制，这意味着当为一行绘制样本索引时，无法为该行再次绘制它。 例 >>> list(WeightedRandomSampler([0.1, 0.9, 0.4, 0.7, 3.0, 0.6], 5, replacement=True)) [0, 0, 0, 1, 0] >>> list(WeightedRandomSampler([0.9, 0.4, 0.05, 0.2, 0.3, 0.1], 5, replacement=False)) [0, 1, 4, 3, 2] class torch.utils.data.BatchSampler(sampler, batch_size, drop_last)¶ 包装另一个采样器以产生一个小批量的索引。 Parameters 采样器 (采样器)–基本采样器。 batch_size (python：int )–迷你批量的大小。 drop_last (bool )–如果为True，则采样器将丢弃最后一批，如果其大小小于batch_size Example >>> list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False)) [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] >>> list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=True)) [[0, 1, 2], [3, 4, 5], [6, 7, 8]] class torch.utils.data.distributed.DistributedSampler(dataset, num_replicas=None, rank=None, shuffle=True)¶ 将数据加载限制为数据集子集的采样器。 与 torch.nn.parallel.DistributedDataParallel 结合使用时特别有用。 在这种情况下，每个进程都可以将 DistributedSampler 实例作为 DataLoader 采样器传递，并加载原始数据集的专有子集。 Note 假定数据集大小恒定。 Parameters 数据集 –用于采样的数据集。 num_replicas (可选）–参与分布式训练的进程数。 等级(可选）–当前进程在 num_replicas 中的等级。 随机播放(可选）–如果为 true(默认值），采样器将随机播放索引 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 14:14:29 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"97.html":{"url":"97.html","title":"torch.utils.dlpack","keywords":"","body":"torch.utils.dlpack 原文： https://pytorch.org/docs/stable/dlpack.html torch.utils.dlpack.from_dlpack(dlpack) → Tensor¶ 将 DLPack 解码为张量。 参数 dlpack –具有 dltensor 的 PyCapsule 对象 张量将与 dlpack 中表示的对象共享内存。 请注意，每个 dlpack 只能使用一次。 torch.utils.dlpack.to_dlpack(tensor) → PyCapsule¶ 返回表示张量的 DLPack。 Parameters 张量 –要导出的张量 dlpack 共享张量内存。 请注意，每个 dlpack 只能使用一次。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:25:18 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"98.html":{"url":"98.html","title":"torch.utils.model_zoo","keywords":"","body":"torch.utils.model_zoo 原文： https://pytorch.org/docs/stable/model_zoo.html 移至 torch.hub 。 torch.utils.model_zoo.load_url(url, model_dir=None, map_location=None, progress=True, check_hash=False)¶ 将 Torch 序列化对象加载到给定的 URL。 如果下载的文件是 zip 文件，它将被自动解压缩。 如果 model_dir 中已经存在该对象，则将其反序列化并返回。 model_dir 的默认值为$TORCH_HOME/checkpoints，其中环境变量$TORCH_HOME的默认值为$XDG_CACHE_HOME/torch。 $XDG_CACHE_HOME遵循 Linux 文件系统布局的 X 设计组规范，如果未设置，则默认值为~/.cache。 参数 url (字符串）–要下载的对象的 URL model_dir (字符串 ， 可选）–保存对象的目录 map_location (可选）–指定如何重新映射存储位置的函数或命令(请参见 torch.load） 进度 (bool ， 可选）–是否显示 stderr 进度条。 默认值：True check_hash (bool ， 可选）–如果为 True，则 URL 的文件名部分应遵循命名约定filename-&lt;sha256&gt;.ext，其中[ &lt;sha256&gt;是文件内容的 SHA256 哈希值的前 8 位或更多位。 哈希用于确保唯一的名称并验证文件的内容。 默认值：False 例 >>> state_dict = torch.hub.load_state_dict_from_url('https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth') 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:25:18 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"99.html":{"url":"99.html","title":"torch.utils.tensorboard","keywords":"","body":"torch.utils.tensorboard 原文： https://pytorch.org/docs/stable/tensorboard.html 在继续之前，可以在 https://www.tensorflow.org/tensorboard/ 上找到有关 TensorBoard 的更多详细信息。 安装 TensorBoard 后，这些实用程序使您可以将 PyTorch 模型和指标记录到目录中，以便在 TensorBoard UI 中进行可视化。 PyTorch 模型和张量以及 Caffe2 网络和 Blob 均支持标量，图像，直方图，图形和嵌入可视化。 SummaryWriter 类是您用来登录数据以供 TensorBoard 使用和可视化的主要条目。 例如： import torch import torchvision from torch.utils.tensorboard import SummaryWriter from torchvision import datasets, transforms # Writer will output to ./runs/ directory by default writer = SummaryWriter() transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) trainset = datasets.MNIST('mnist_train', train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) model = torchvision.models.resnet50(False) # Have ResNet model take in grayscale rather than RGB model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False) images, labels = next(iter(trainloader)) grid = torchvision.utils.make_grid(images) writer.add_image('images', grid, 0) writer.add_graph(model, images) writer.close() 然后可以使用 TensorBoard 对其进行可视化，该 TensorBoard 应该可通过以下方式安装和运行： pip install tensorboard tensorboard --logdir=runs 一个实验可以记录很多信息。 为了避免 UI 混乱和更好地将结果聚类，我们可以通过对图进行分层命名来对图进行分组。 例如，“损失/火车”和“损失/测试”将被分组在一起，而“准确性/火车”和“准确性/测试”将在 TensorBoard 界面中分别分组。 from torch.utils.tensorboard import SummaryWriter import numpy as np writer = SummaryWriter() for n_iter in range(100): writer.add_scalar('Loss/train', np.random.random(), n_iter) writer.add_scalar('Loss/test', np.random.random(), n_iter) writer.add_scalar('Accuracy/train', np.random.random(), n_iter) writer.add_scalar('Accuracy/test', np.random.random(), n_iter) 预期结果： class torch.utils.tensorboard.writer.SummaryWriter(log_dir=None, comment='', purge_step=None, max_queue=10, flush_secs=120, filename_suffix='')¶ 将条目直接写入 log_dir 中的事件文件，以供 TensorBoard 使用。 SummaryWriter 类提供了一个高级 API，用于在给定目录中创建事件文件并向其中添加摘要和事件。 该类异步更新文件内容。 这允许训练程序从训练循环中调用直接将数据添加到文件的方法，而不会减慢训练速度。 __init__(log_dir=None, comment='', purge_step=None, max_queue=10, flush_secs=120, filename_suffix='')¶ 创建一个 SummaryWriter ，它将事件和摘要写到事件文件中。 参数 log_dir (字符串）–保存目录位置。 默认值为运行次数/ CURRENT_DATETIME_HOSTNAME ，每次运行后都会更改。 使用分层文件夹结构可以轻松比较运行情况。 例如 为每个新实验传递“ runs / exp1”，“ runs / exp2”等，以便在它们之间进行比较。 注释(字符串）–注释 log_dir 后缀附加到默认值log_dir。 如果分配了log_dir，则此参数无效。 purge_step (python：int )–当日志记录在步骤崩溃并在步骤重新启动时，将清除 global_step 大于或等于的所有事件， 隐藏在 TensorBoard 中。 请注意，崩溃的实验和恢复的实验应具有相同的log_dir。 max_queue (python：int )–在“添加”调用之一强行刷新到磁盘之前，未决事件和摘要的队列大小。 默认值为十个项目。 flush_secs (python：int )–将挂起的事件和摘要刷新到磁盘的频率(以秒为单位）。 默认值为每两分钟一次。 filename_suffix (字符串）–后缀添加到 log_dir 目录中的所有事件文件名中。 在 tensorboard.summary.writer.event_file_writer.EventFileWriter 中有关文件名构造的更多详细信息。 例子： from torch.utils.tensorboard import SummaryWriter # create a summary writer with automatically generated folder name. writer = SummaryWriter() # folder location: runs/May04_22-14-54_s-MacBook-Pro.local/ # create a summary writer using the specified folder name. writer = SummaryWriter(\"my_experiment\") # folder location: my_experiment # create a summary writer with comment appended. writer = SummaryWriter(comment=\"LR_0.1_BATCH_16\") # folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/ add_scalar(tag, scalar_value, global_step=None, walltime=None)¶ 将标量数据添加到摘要中。 Parameters 标记(字符串）–数据标识符 标量值 (python：float 或 字符串/名称）–要保存的值 global_step (python：int )–要记录的全局步长值 walltime (python：float )–可选，以事件发生后的秒数覆盖默认的 walltime(time.time(）） Examples: from torch.utils.tensorboard import SummaryWriter writer = SummaryWriter() x = range(100) for i in x: writer.add_scalar('y=2x', i * 2, i) writer.close() Expected result: add_scalars(main_tag, tag_scalar_dict, global_step=None, walltime=None)¶ 将许多标量数据添加到摘要中。 请注意，此函数还将已记录的标量保存在内存中。 在极端情况下，它会炸毁您的 RAM。 Parameters main_tag (字符串）–标记的父名称 tag_scalar_dict (dict )–存储标签和对应值的键值对 global_step (python:int) – Global step value to record walltime (python：float )–可选的替代默认时间 Walltime(time.time(））秒 Examples: from torch.utils.tensorboard import SummaryWriter writer = SummaryWriter() r = 5 for i in range(100): writer.add_scalars('run_14h', {'xsinx':i*np.sin(i/r), 'xcosx':i*np.cos(i/r), 'tanx': np.tan(i/r)}, i) writer.close() # This call adds three values to the same scalar plot with the tag # 'run_14h' in TensorBoard's scalar section. Expected result: add_histogram(tag, values, global_step=None, bins='tensorflow', walltime=None, max_bins=None)¶ 将直方图添加到摘要中。 Parameters tag (string) – Data identifier 值 (torch张量 ， numpy.array 或 字符串/名称）–建立直方图的值 global_step (python:int) – Global step value to record 容器(字符串）– {'tensorflow'，'auto'，'fd'，…}中的一种。 这决定了垃圾桶的制作方式。 您可以在以下位置找到其他选项： https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html walltime (python:float) – Optional override default walltime (time.time()) seconds after epoch of event Examples: from torch.utils.tensorboard import SummaryWriter import numpy as np writer = SummaryWriter() for i in range(10): x = np.random.random(1000) writer.add_histogram('distribution centers', x + i, i) writer.close() Expected result: add_image(tag, img_tensor, global_step=None, walltime=None, dataformats='CHW')¶ 将图像数据添加到摘要。 注意，这需要pillow程序包。 Parameters tag (string) – Data identifier img_tensor (torch张量 ， numpy.array 或 字符串/名称）–图像数据 global_step (python:int) – Global step value to record walltime (python:float) – Optional override default walltime (time.time()) seconds after epoch of event Shape: img_tensor：默认为。 您可以使用torchvision.utils.make_grid()将一批张量转换为 3xHxW 格式，或者调用add_images让我们完成这项工作。 只要传递了相应的dataformats自变量，也可以使用带有，和的张量。 例如 CHW，HWC，HW。 Examples: from torch.utils.tensorboard import SummaryWriter import numpy as np img = np.zeros((3, 100, 100)) img[0] = np.arange(0, 10000).reshape(100, 100) / 10000 img[1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000 img_HWC = np.zeros((100, 100, 3)) img_HWC[:, :, 0] = np.arange(0, 10000).reshape(100, 100) / 10000 img_HWC[:, :, 1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000 writer = SummaryWriter() writer.add_image('my_image', img, 0) # If you have non-default dimension setting, set the dataformats argument. writer.add_image('my_image_HWC', img_HWC, 0, dataformats='HWC') writer.close() Expected result: add_images(tag, img_tensor, global_step=None, walltime=None, dataformats='NCHW')¶ 将批处理的图像数据添加到摘要中。 Note that this requires the pillow package. Parameters tag (string) – Data identifier img_tensor (torch.Tensor, numpy.array__, or string/blobname) – Image data global_step (python:int) – Global step value to record walltime (python:float) – Optional override default walltime (time.time()) seconds after epoch of event 数据格式(字符串）– NCHW，NHWC，CHW，HWC，HW，WH 等形式的图像数据格式规范 Shape: img_tensor：默认为。 如果指定dataformats，将接受其他形状。 例如 NCHW 或 NHWC。 Examples: from torch.utils.tensorboard import SummaryWriter import numpy as np img_batch = np.zeros((16, 3, 100, 100)) for i in range(16): img_batch[i, 0] = np.arange(0, 10000).reshape(100, 100) / 10000 / 16 * i img_batch[i, 1] = (1 - np.arange(0, 10000).reshape(100, 100) / 10000) / 16 * i writer = SummaryWriter() writer.add_images('my_image_batch', img_batch, 0) writer.close() Expected result: add_figure(tag, figure, global_step=None, close=True, walltime=None)¶ 将 matplotlib 图形渲染为图像，并将其添加到摘要中。 注意，这需要matplotlib程序包。 Parameters tag (string) – Data identifier 图形 (matplotlib.pyplot.figure )–图形或图形列表 global_step (python:int) – Global step value to record 关闭 (bool )–自动关闭图形的标志 walltime (python:float) – Optional override default walltime (time.time()) seconds after epoch of event add_video(tag, vid_tensor, global_step=None, fps=4, walltime=None)¶ 将视频数据添加到摘要。 注意，这需要moviepy程序包。 Parameters tag (string) – Data identifier vid_tensor (torch张量)–视频数据 global_step (python:int) – Global step value to record fps (python：float 或 python：int )–每秒帧数 walltime (python:float) – Optional override default walltime (time.time()) seconds after epoch of event Shape: vid_tensor：。 对于 uint8 类型，值应位于[0，255]中；对于 float 类型，值应位于[0，1]中。 add_audio(tag, snd_tensor, global_step=None, sample_rate=44100, walltime=None)¶ 将音频数据添加到摘要。 Parameters tag (string) – Data identifier snd_tensor (torch张量)–声音数据 global_step (python:int) – Global step value to record sample_rate (python：int )–以 Hz 为单位的采样率 walltime (python:float) – Optional override default walltime (time.time()) seconds after epoch of event Shape: snd_tensor：。 值应介于[-1，1]之间。 add_text(tag, text_string, global_step=None, walltime=None)¶ 将文本数据添加到摘要。 Parameters tag (string) – Data identifier text_string (字符串）–要保存的字符串 global_step (python:int) – Global step value to record walltime (python:float) – Optional override default walltime (time.time()) seconds after epoch of event Examples: writer.add_text('lstm', 'This is an lstm', 0) writer.add_text('rnn', 'This is an rnn', 10) add_graph(model, input_to_model=None, verbose=False)¶ add_embedding(mat, metadata=None, label_img=None, global_step=None, tag='default', metadata_header=None)¶ 将嵌入的投影仪数据添加到摘要中。 Parameters 垫 (torch张量 或 numpy.array )–矩阵，每行是特征向量 数据点 元数据(列表）–标签列表，每个元素将转换为字符串 label_img (炬管张紧器)–图像对应于每个数据点 global_step (python:int) – Global step value to record 标签(字符串）–嵌入的名称 Shape: 垫子：，其中 N 是数据数量，D 是特征尺寸 label_img： Examples: import keyword import torch meta = [] while len(meta) add_pr_curve(tag, labels, predictions, global_step=None, num_thresholds=127, weights=None, walltime=None)¶ 添加精度召回曲线。 绘制精确召回曲线可以让您了解模型在不同阈值设置下的性能。 使用此功能，您可以为每个目标提供地面真相标签(T / F）和预测置信度(通常是模型的输出）。 TensorBoard UI 将允许您交互选择阈值。 Parameters tag (string) – Data identifier 标签 (torch张量 ， numpy.array 或 字符串/名称）–基本事实数据。 每个元素的二进制标签。 预测 (torch张量 ， numpy.array 或 string / blobname )–元素归类为 true 的概率。 值应为[0，1] global_step (python:int) – Global step value to record num_thresholds (python：int )–用于绘制曲线的阈值数。 walltime (python:float) – Optional override default walltime (time.time()) seconds after epoch of event Examples: from torch.utils.tensorboard import SummaryWriter import numpy as np labels = np.random.randint(2, size=100) # binary label predictions = np.random.rand(100) writer = SummaryWriter() writer.add_pr_curve('pr_curve', labels, predictions, 0) writer.close() add_custom_scalars(layout)¶ 通过在“标量”中收集图表标签来创建特殊图表。 请注意，该函数只能为每个 SummaryWriter(）对象调用一次。 因为它仅向张量板提供元数据，所以可以在训练循环之前或之后调用该函数。 Parameters 布局 (dict )– {类别名称：图表}，其中图表也是字典{chartName： ListOfProperties ]}。 ListOfProperties 中的第一个元素是图表的类型(多线或保证金之一），第二个元素应是包含您在 add_scalar 中使用的标签的列表。 函数，它将被收集到新图表中。 Examples: layout = {'Taiwan':{'twse':['Multiline',['twse/0050', 'twse/2330']]}, 'USA':{ 'dow':['Margin', ['dow/aaa', 'dow/bbb', 'dow/ccc']], 'nasdaq':['Margin', ['nasdaq/aaa', 'nasdaq/bbb', 'nasdaq/ccc']]}} writer.add_custom_scalars(layout) add_mesh(tag, vertices, colors=None, faces=None, config_dict=None, global_step=None, walltime=None)¶ 将网格或 3D 点云添加到 TensorBoard。 可视化基于 Three.js，因此它允许用户与渲染的对象进行交互。 除了顶点，面部之类的基本定义外，用户还可以提供相机参数，光照条件等。请检查 https://threejs.org/docs/index.html#manual/en/introduction/Creating-a -scene 用于高级用法。 Parameters tag (string) – Data identifier 顶点 (torch张量)–顶点的 3D 坐标列表。 颜色 (torch张量)–每个顶点的颜色 面 (torch张量)–每个三角形内的顶点的索引。 (可选的） config_dict –具有 ThreeJS 类名称和配置的字典。 global_step (python:int) – Global step value to record walltime (python:float) – Optional override default walltime (time.time()) seconds after epoch of event Shape: 顶点：。 (批次，顶点数，渠道） 颜色：。 对于 uint8 类型，值应位于[0，255]中；对于 float 类型，值应位于[0，1]中。 面孔：。 对于 uint8 类型，这些值应位于[0，number_of_vertices]中。 Examples: from torch.utils.tensorboard import SummaryWriter vertices_tensor = torch.as_tensor([ [1, 1, 1], [-1, -1, 1], [1, -1, -1], [-1, 1, -1], ], dtype=torch.float).unsqueeze(0) colors_tensor = torch.as_tensor([ [255, 0, 0], [0, 255, 0], [0, 0, 255], [255, 0, 255], ], dtype=torch.int).unsqueeze(0) faces_tensor = torch.as_tensor([ [0, 2, 3], [0, 3, 1], [0, 1, 2], [1, 3, 2], ], dtype=torch.int).unsqueeze(0) writer = SummaryWriter() writer.add_mesh('my_mesh', vertices=vertices_tensor, colors=colors_tensor, faces=faces_tensor) writer.close() add_hparams(hparam_dict=None, metric_dict=None)¶ 添加一组要在 TensorBoard 中进行比较的超参数。 Parameters hparam_dict (dict )–字典中的每个键值对都是超参数的名称及其对应的值。 metric_dict (dict )–词典中的每个键值对都是指标的名称及其对应的值。 请注意，此处使用的密钥在张量板记录中应该是唯一的。 否则，由add_scalar添加的值将显示在 hparam 插件中。 在大多数情况下，这是不需要的。 Examples: from torch.utils.tensorboard import SummaryWriter with SummaryWriter() as w: for i in range(5): w.add_hparams({'lr': 0.1*i, 'bsize': i}, {'hparam/accuracy': 10*i, 'hparam/loss': 10*i}) Expected result: flush()¶ 将事件文件刷新到磁盘。 调用此方法以确保所有未决事件均已写入磁盘。 close()¶ 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:25:18 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"100.html":{"url":"100.html","title":"类型信息","keywords":"","body":"类型信息 原文： https://pytorch.org/docs/stable/type_info.html 可以通过 torch.finfo 或 torch.iinfo 访问 torch.dtype 的数值属性。 torch class torch.finfo¶ torch.finfo 是表示浮点 torch.dtype (即torch.float32，torch.float64和torch.float16）的数值属性的对象。 这类似于 numpy.finfo 。 torch.finfo 提供以下属性： | 名称 | 类型 | 描述 | | --- | --- | --- | | 位 | 整型 | 类型占用的位数。 | | eps | 浮动 | 最小可表示数字，例如1.0 + eps != 1.0。 | | 最大值 | float | 可表示的最大数字。 | | 分 | float | 最小的可表示数字(通常为-max）。 | | 小 | float | 可表示的最小正数。 | 注意 可以不带参数地调用 torch.finfo 的构造函数，在这种情况下，将为 pytorch 默认 dtype 创建类(由 torch.get_default_dtype() 返回）。 torch class torch.iinfo¶ torch.iinfo 是代表整数 torch.dtype (即torch.uint8，torch.int8，torch.int16，torch.int32和torch.int64）。 这类似于 numpy.iinfo 。 torch.iinfo 提供以下属性： | Name | Type | Description | | --- | --- | --- | | bits | int | The number of bits occupied by the type. | | max | int | The largest representable number. | | min | int | 可表示的最小数字。 | 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"101.html":{"url":"101.html","title":"命名张量","keywords":"","body":"命名张量 原文： https://pytorch.org/docs/stable/named_tensor.html 命名张量旨在通过允许用户将显式名称与张量维度相关联来使张量更易于使用。 在大多数情况下，采用尺寸参数的操作将接受尺寸名称，从而无需按位置跟踪尺寸。 此外，命名张量使用名称来自动检查运行时是否正确使用了 API，从而提供了额外的安全性。 名称也可以用于重新排列尺寸，例如，支持“按名称广播”而不是“按位置广播”。 警告 命名的张量 API 是实验性的，随时可能更改。 创建命名张量 现在，工厂函数采用新的names参数，该参数将名称与每个维度相关联。 >>> torch.zeros(2, 3, names=('N', 'C')) tensor([[0., 0., 0.], [0., 0., 0.]], names=('N', 'C')) 命名尺寸(与常规 Tensor 尺寸一样）已订购。 tensor.names[i]是tensor的尺寸i的名称。 以下工厂函数支持命名张量： torch.empty() torch.rand() torch.randn() torch.ones() torch.tensor() torch.zeros() 命名尺寸 有关张量名称的限制，请参见 names 。 使用 names 访问张量的尺寸名称，并使用 rename() 重命名命名尺寸。 >>> imgs = torch.randn(1, 2, 2, 3 , names=('N', 'C', 'H', 'W')) >>> imgs.names ('N', 'C', 'H', 'W') >>> renamed_imgs = imgs.rename(H='height', W='width') >>> renamed_imgs.names ('N', 'C', 'height', 'width) 命名张量可以与未命名张量共存； 命名张量是 torch.Tensor 的实例。 未命名的张量具有None命名的尺寸。 命名张量不需要命名所有尺寸。 >>> imgs = torch.randn(1, 2, 2, 3 , names=(None, 'C', 'H', 'W')) >>> imgs.names (None, 'C', 'H', 'W') 名称传播语义 命名张量使用名称来自动检查在运行时是否正确调用了 API。 这在称为名称推断的过程中发生。 更正式地说，名称推断包括以下两个步骤： 检查名称：操作员可以在运行时执行自动检查，以检查某些尺寸名称是否必须匹配。 传播名称：名称推断会将名称传播到输出张量。 所有支持命名张量的操作都会传播名称。 >>> x = torch.randn(3, 3, names=('N', 'C')) >>> x.abs().names ('N', 'C') 匹配语义 如果两个名称相等(字符串相等）或至少一个名称为None则匹配。 从本质上讲，没有一个是特殊的“通配符”名称。 unify(A, B)确定名称A和B中的哪个传播到输出。 如果两个名称匹配，它将返回更多特定的。 如果名称不匹配，则错误。 注意 在实践中，使用命名张量时，应避免使用未命名的维，因为它们的处理可能很复杂。 建议使用 refine_names() 将所有未命名的尺寸提升为已命名的尺寸。 基本名称推断规则 让我们看看在添加两个不广播的一维张量的情况下，如何在名称推断中使用match和unify。 x = torch.randn(3, names=('X',)) y = torch.randn(3) z = torch.randn(3, names=('Z',)) 检查名称：检查两个张量的名称是否与相匹配。 对于以下示例： >>> # x + y # match('X', None) is True >>> # x + z # match('X', 'Z') is False >>> # x + x # match('X', 'X') is True >>> x + z Error when attempting to broadcast dims ['X'] and dims ['Z']: dim 'X' and dim 'Z' are at the same position from the right but do not match. 传播名称：统一的名称以选择要传播的名称。 在x + y的情况下，unify('X', None) = 'X'因为'X'比None更特异性。 >>> (x + y).names ('X',) >>> (x + x).names ('X',) 有关名称推断规则的完整列表，请参见名为张量运算符的覆盖范围。 以下是两个可能有用的常见操作： 二进制算术运算：统一输入的名称 矩阵乘法操作：缩小暗淡 按名称明确对齐 使用 align_as() 或 align_to() 按名称将张量尺寸对齐到指定顺序。 这对于执行“按名称广播”很有用。 # This function is agnostic to the dimension ordering of `input`, # as long as it has a `C` dimension somewhere. def scale_channels(input, scale): scale = scale.refine_names('C') return input * scale.align_as(input) >>> num_channels = 3 >>> scale = torch.randn(num_channels, names=('C',)) >>> imgs = torch.rand(3, 3, 3, num_channels, names=('N', 'H', 'W', 'C')) >>> more_imgs = torch.rand(3, num_channels, 3, 3, names=('N', 'C', 'H', 'W')) >>> videos = torch.randn(3, num_channels, 3, 3, 3, names=('N', 'C', 'H', 'W', 'D') >>> scale_channels(imgs, scale) >>> scale_channels(more_imgs, scale) >>> scale_channels(videos, scale) 操纵尺寸 使用 align_to() 排列大量尺寸，而无需提及 permute() 要求的所有尺寸。 >>> tensor = torch.randn(2, 2, 2, 2, 2, 2) >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F') # Move the F (dim 5) and E dimension (dim 4) to the front while keeping # the rest in the same order >>> tensor.permute(5, 4, 0, 1, 2, 3) >>> named_tensor.align_to('F', 'E', ...) # Use '...' instead in Python 2 使用 flatten() 和 unflatten() 分别展平和展平尺寸。 这些方法比 view() 和 reshape() 更冗长，但对于阅读代码的人来说，语义更有意义。 >>> imgs = torch.randn(32, 3, 128, 128) >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W') >>> flat_imgs = imgs.view(32, -1) >>> named_flat_imgs = named_imgs.flatten(['C', 'H', 'W'], 'features') >>> named_flat_imgs.names ('N', 'features') >>> unflattened_imgs = imgs.view(32, 3, 128, 128) >>> unflattened_named_imgs = named_flat_imgs.unflatten( 'features', [('C', 3), ('H', 128), ('W', 128)]) Autograd 支持 Autograd 当前以有限的方式支持命名张量：autograd 忽略所有张量上的名称。 梯度计算仍然是正确的，但是我们失去了名称赋予我们的安全性。 >>> x = torch.randn(3, names=('D',)) >>> weight = torch.randn(3, names=('D',), requires_grad=True) >>> loss = (x - weight).abs() >>> grad_loss = torch.randn(3) >>> loss.backward(grad_loss) >>> weight.grad # Unnamed for now. Will be named in the future tensor([-1.8107, -0.6357, 0.0783]) >>> weight.grad.zero_() >>> grad_loss = grad_loss.refine_names('C') >>> loss = (x - weight).abs() # Ideally we'd check that the names of loss and grad_loss match but we don't yet. >>> loss.backward(grad_loss) >>> weight.grad tensor([-1.8107, -0.6357, 0.0783]) 当前支持的操作和子系统 经营者 有关受支持的torch和张量操作的完整列表，请参见命名为 Tensors 的操作员范围。 我们尚不支持以下链接未涵盖的内容： 索引，高级索引。 对于torch.nn.functional运算符，我们支持以下内容： torch.nn.functional.relu() torch.nn.functional.softmax() torch.nn.functional.log_softmax() torch.nn.functional.tanh() torch.nn.functional.sigmoid() torch.nn.functional.dropout() 子系统 支持 Autograd，请参见 Autograd support 。 由于当前未命名渐变，因此优化程序可能有效，但未经测试。 当前不支持 NN 模块。 调用具有命名张量输入的模块时，可能导致以下情况： NN 模块参数未命名，因此输出可以部分命名。 NN 模块正向传递的代码不支持命名张量，并且会适当地出错。 我们也不支持以下子系统，尽管有些子系统可能是开箱即用的： 分布 序列化 (torch.load() ， torch.save()) 并行处理 JIT Distributed ONNX 如果其中任何一个可以帮助您解决用例，请搜索是否已提交问题，否则，请提交一个。 命名张量 API 参考 在本节中，请找到特定于特定张量的 API 的文档。 有关如何通过其他 PyTorch 运算符传播名称的全面参考，请参见名为 Tensors 运算符的覆盖范围。 class torch.Tensor names¶ 存储每个张量维度的名称。 names[idx]对应于张量尺寸idx的名称。 如果名称为维，则名称为字符串；如果名称为未命名，则名称为None。 维度名称可以包含字符或下划线。 此外，维度名称必须是有效的 Python 变量名称(即，不能以下划线开头）。 张量可能没有两个具有相同名称的命名尺寸。 Warning The named tensor API is experimental and subject to change. rename(*names, **rename_map)¶ 重命名self的尺寸名称。 主要有两种用法： self.rename(**rename_map)返回张量的视图，该视图具有按映射rename_map中的指定重命名的暗角。 self.rename(*names)返回张量视图，并使用 names 重命名所有尺寸。 使用self.rename(None)在张量上放置名称。 不能同时指定位置 args names 和关键字 args rename_map。 例子： >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W')) >>> renamed_imgs = imgs.rename(N='batch', C='channels') >>> renamed_imgs.names ('batch', 'channels', 'H', 'W') >>> renamed_imgs = imgs.rename(None) >>> renamed_imgs.names (None,) >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width') >>> renamed_imgs.names ('batch', 'channel', 'height', 'width') Warning The named tensor API is experimental and subject to change. rename_(*names, **rename_map)¶ rename() 的就地版本。 refine_names(*names)¶ 根据 names 细化self的尺寸名称。 细化是重命名的特殊情况，可以“提升”未命名的尺寸。 可以将None暗号细化为任何名称； 命名的 dim 只能精简为具有相同的名称。 由于命名张量可以与未命名张量共存，因此优化名称提供了一种编写可处理命名张量和未命名张量的命名张量感知代码的好方法。 names 最多可以包含一个省略号(...）。 椭圆形贪婪地展开。 使用来自self.names的相应索引的名称，将其就地扩展为将 names 填充为与self.dim()相同的长度。 Python 2 不支持 Ellipsis，但是可以改用字符串文字('...'）。 参数 名称(str 的可迭代）–输出张量的所需名称。 最多可以包含一个省略号。 Examples: >>> imgs = torch.randn(32, 3, 128, 128) >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W') >>> named_imgs.names ('N', 'C', 'H', 'W') >>> tensor = torch.randn(2, 3, 5, 7, 11) >>> tensor = tensor.refine_names('A', ..., 'B', 'C') >>> tensor.names ('A', None, None, 'B', 'C') Warning The named tensor API is experimental and subject to change. align_as(other) → Tensor¶ 排列self张量的尺寸以匹配other张量中的尺寸顺序，为任何新名称添加大小为 1 的变暗。 此操作对于按名称进行显式广播很有用(请参见示例）。 为了使用此方法，必须命名self的所有暗色。 生成的张量是原始张量的视图。 self的所有尺寸名称必须存在于other.names中。 other可能包含不在self.names中的命名尺寸； 对于这些新名称中的每一个，输出张量都有一个一维的尺寸。 要将张量对齐到特定顺序，请使用 align_to() 。 Examples: # Example 1: Applying a mask >>> mask = torch.randint(2, [127, 128], dtype=torch.bool).refine_names('W', 'H') >>> imgs = torch.randn(32, 128, 127, 3, names=('N', 'H', 'W', 'C')) >>> imgs.masked_fill_(mask.align_as(imgs), 0) # Example 2: Applying a per-channel-scale def scale_channels(input, scale): scale = scale.refine_names('C') return input * scale.align_as(input) >>> num_channels = 3 >>> scale = torch.randn(num_channels, names=('C',)) >>> imgs = torch.rand(32, 128, 128, num_channels, names=('N', 'H', 'W', 'C')) >>> more_imgs = torch.rand(32, num_channels, 128, 128, names=('N', 'C', 'H', 'W')) >>> videos = torch.randn(3, num_channels, 128, 128, 128, names=('N', 'C', 'H', 'W', 'D')) # scale_channels is agnostic to the dimension order of the input >>> scale_channels(imgs, scale) >>> scale_channels(more_imgs, scale) >>> scale_channels(videos, scale) Warning The named tensor API is experimental and subject to change. align_to(*names)¶ 排列self张量的尺寸以匹配 names 中指定的顺序，为任何新名称添加大小为 1 的变暗。 All of the dims of self must be named in order to use this method. The resulting tensor is a view on the original tensor. self的所有尺寸名称必须出现在 names 中。 names 可能包含self.names中没有的其他名称； 对于这些新名称中的每一个，输出张量都有一个一维的尺寸。 names 最多可以包含一个省略号(...）。 省略号按在self中出现的顺序扩展为等于 names 中未提及的self的所有尺寸名称。 Python 2 does not support Ellipsis but one may use a string literal instead ('...'). Parameters 名称(可迭代的）–输出张量的所需尺寸顺序。 最多可以包含一个省略号，扩展为self的所有未提及的暗号。 Examples: >>> tensor = torch.randn(2, 2, 2, 2, 2, 2) >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F') # Move the F and E dims to the front while keeping the rest in order >>> named_tensor.align_to('F', 'E', ...) Warning The named tensor API is experimental and subject to change. unflatten(dim, namedshape)¶ 以namedshape指定的形状将命名尺寸 dim 展平。 Parameters 命名为形状 –(可复制(name, size)元组）。 Examples: >>> flat_imgs = torch.rand(32, 3 * 128 * 128, names=('N', 'features')) >>> imgs = flat_imgs.unflatten('features', (('C', 3), ('H', 128), ('W', 128))) >>> imgs.names, images.shape (('N', 'C', 'H', 'W'), torch.Size([32, 3, 128, 128])) Warning The named tensor API is experimental and subject to change. flatten(dims, out_dim) → Tensor 将dims展平为名称为out_dim的单个维度。 所有变暗必须在self张量中按顺序连续，但在内存中不必是连续的。 Examples: >>> imgs = torch.randn(32, 3, 128, 128, names=('N', 'C', 'H', 'W')) >>> flat_imgs = imgs.flatten(['C', 'H', 'W'], 'features') >>> flat_imgs.names, flat_imgs.shape (('N', 'features'), torch.Size([32, 49152])) Warning The named tensor API is experimental and subject to change. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:25:18 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"102.html":{"url":"102.html","title":"命名为 Tensors 操作员范围","keywords":"","body":"命名为 Tensors 操作员范围 原文： https://pytorch.org/docs/stable/name_inference.html 请首先阅读命名张量，以了解命名张量。 本文档是名称推断的参考，HTH1 是一个定义张量命名方式的过程： 使用名称提供其他自动运行时正确性检查 将名称从输入张量传播到输出张量 以下是命名张量及其关联的名称推断规则支持的所有操作的列表。 如果此处未列出操作，但对您的用例有帮助，请搜索问题是否已提交，否则请提交一个问题。 警告 命名的张量 API 是实验性的，随时可能更改。 Supported Operations API 名称推断规则 Tensor.abs() ， torch.abs() 保留输入名称 Tensor.abs_() Keeps input names Tensor.acos() ， torch.acos() Keeps input names Tensor.acos_() Keeps input names Tensor.add() ， torch.add() 统一输入的名称 Tensor.add_() Unifies names from inputs Tensor.addmm() ， torch.addmm() 缩小暗淡 Tensor.addmm_() Contracts away dims Tensor.addmv() ， torch.addmv() Contracts away dims Tensor.addmv_() Contracts away dims Tensor.align_as() 查看文件 Tensor.align_to() See documentation Tensor.all()，torch.all() 没有 Tensor.any()，torch.any() None Tensor.asin() ， torch.asin() Keeps input names Tensor.asin_() Keeps input names Tensor.atan() ， torch.atan() Keeps input names Tensor.atan2() ， torch.atan2() Unifies names from inputs Tensor.atan2_() Unifies names from inputs Tensor.atan_() Keeps input names Tensor.bernoulli() ， torch.bernoulli() Keeps input names Tensor.bernoulli_() None Tensor.bfloat16() Keeps input names Tensor.bitwise_not() ， torch.bitwise_not() Keeps input names Tensor.bitwise_not_() None Tensor.bmm() ， torch.bmm() Contracts away dims Tensor.bool() Keeps input names Tensor.byte() Keeps input names torch.cat() Unifies names from inputs Tensor.cauchy_() None Tensor.ceil() ， torch.ceil() Keeps input names Tensor.ceil_() None Tensor.char() Keeps input names Tensor.chunk() ， torch.chunk() Keeps input names Tensor.clamp() ， torch.clamp() Keeps input names Tensor.clamp_() None Tensor.copy_() 输出功能和就地变体 Tensor.cos() ， torch.cos() Keeps input names Tensor.cos_() None Tensor.cosh() ， torch.cosh() Keeps input names Tensor.cosh_() None Tensor.cpu() Keeps input names Tensor.cuda() Keeps input names Tensor.cumprod() ， torch.cumprod() Keeps input names Tensor.cumsum() ， torch.cumsum() Keeps input names Tensor.data_ptr() None Tensor.detach() ，torch.detach() Keeps input names Tensor.detach_() None Tensor.device ， torch.device() None Tensor.digamma() ， torch.digamma() Keeps input names Tensor.digamma_() None Tensor.dim() None Tensor.div() ， torch.div() Unifies names from inputs Tensor.div_() Unifies names from inputs Tensor.dot() ， torch.dot() None Tensor.double() Keeps input names Tensor.element_size() None torch.empty() 工厂功能 torch.empty_like() Factory functions Tensor.eq() ， torch.eq() Unifies names from inputs Tensor.erf() ， torch.erf() Keeps input names Tensor.erf_() None Tensor.erfc() ， torch.erfc() Keeps input names Tensor.erfc_() None Tensor.erfinv() ， torch.erfinv() Keeps input names Tensor.erfinv_() None Tensor.exp() ， torch.exp() Keeps input names Tensor.exp_() None Tensor.expand() Keeps input names Tensor.expm1() ， torch.expm1() Keeps input names Tensor.expm1_() None Tensor.exponential_() None Tensor.fill_() None Tensor.flatten() ， torch.flatten() See documentation Tensor.float() Keeps input names Tensor.floor() ， torch.floor() Keeps input names Tensor.floor_() None Tensor.frac() ， torch.frac() Keeps input names Tensor.frac_() None Tensor.ge() ， torch.ge() Unifies names from inputs Tensor.get_device() ，torch.get_device() None Tensor.grad None Tensor.gt() ， torch.gt() Unifies names from inputs Tensor.half() Keeps input names Tensor.has_names() See documentation Tensor.index_fill() ，torch.index_fill() Keeps input names Tensor.index_fill_() None Tensor.int() Keeps input names Tensor.is_contiguous() None Tensor.is_cuda None Tensor.is_floating_point() ， torch.is_floating_point() None Tensor.is_leaf None Tensor.is_pinned() None Tensor.is_shared() None Tensor.is_signed() ，torch.is_signed() None Tensor.is_sparse None torch.is_tensor() None Tensor.item() None Tensor.kthvalue() ， torch.kthvalue() 移除尺寸 Tensor.le() ， torch.le() Unifies names from inputs Tensor.log() ， torch.log() Keeps input names Tensor.log10() ， torch.log10() Keeps input names Tensor.log10_() None Tensor.log1p() ， torch.log1p() Keeps input names Tensor.log1p_() None Tensor.log2() ， torch.log2() Keeps input names Tensor.log2_() None Tensor.log_() None Tensor.log_normal_() None Tensor.logical_not() ， torch.logical_not() Keeps input names Tensor.logical_not_() None Tensor.logsumexp() ， torch.logsumexp() Removes dimensions Tensor.long() Keeps input names Tensor.lt() ， torch.lt() Unifies names from inputs torch.manual_seed() None Tensor.masked_fill() ，torch.masked_fill() Keeps input names Tensor.masked_fill_() None Tensor.masked_select() ， torch.masked_select() 将遮罩对齐到输入，然后 unified_names_from_input_tensors Tensor.matmul() ， torch.matmul() Contracts away dims Tensor.mean() ， torch.mean() Removes dimensions Tensor.median() ， torch.median() Removes dimensions Tensor.mm() ， torch.mm() Contracts away dims Tensor.mode() ， torch.mode() Removes dimensions Tensor.mul() ， torch.mul() Unifies names from inputs Tensor.mul_() Unifies names from inputs Tensor.mv() ， torch.mv() Contracts away dims Tensor.names See documentation Tensor.narrow() ， torch.narrow() Keeps input names Tensor.ndim None Tensor.ndimension() None Tensor.ne() ， torch.ne() Unifies names from inputs Tensor.neg() ， torch.neg() Keeps input names Tensor.neg_() None torch.normal() Keeps input names Tensor.normal_() None Tensor.numel() ， torch.numel() None torch.ones() Factory functions Tensor.pow() ， torch.pow() Unifies names from inputs Tensor.pow_() None Tensor.prod() ， torch.prod() Removes dimensions torch.rand() Factory functions torch.rand() Factory functions torch.randn() Factory functions torch.randn() Factory functions Tensor.random_() None Tensor.reciprocal() ， torch.reciprocal() Keeps input names Tensor.reciprocal_() None Tensor.refine_names() See documentation Tensor.register_hook() None Tensor.rename() See documentation Tensor.rename_() See documentation Tensor.requires_grad None Tensor.requires_grad_() None Tensor.resize_() 只允许不改变形状的调整大小 Tensor.resize_as_() Only allow resizes that do not change shape Tensor.round() ， torch.round() Keeps input names Tensor.round_() None Tensor.rsqrt() ， torch.rsqrt() Keeps input names Tensor.rsqrt_() None Tensor.select() ，torch.select() Removes dimensions Tensor.short() Keeps input names Tensor.sigmoid() ， torch.sigmoid() Keeps input names Tensor.sigmoid_() None Tensor.sign() ， torch.sign() Keeps input names Tensor.sign_() None Tensor.sin() ， torch.sin() Keeps input names Tensor.sin_() None Tensor.sinh() ， torch.sinh() Keeps input names Tensor.sinh_() None Tensor.size() None Tensor.split() ， torch.split() Keeps input names Tensor.sqrt() ， torch.sqrt() Keeps input names Tensor.sqrt_() None Tensor.squeeze() ， torch.squeeze() Removes dimensions Tensor.std() ， torch.std() Removes dimensions torch.std_mean() Removes dimensions Tensor.stride() None Tensor.sub() ，torch.sub() Unifies names from inputs Tensor.sub_() Unifies names from inputs Tensor.sum() ， torch.sum() Removes dimensions Tensor.tan() ， torch.tan() Keeps input names Tensor.tan_() None Tensor.tanh() ， torch.tanh() Keeps input names Tensor.tanh_() None torch.tensor() Factory functions Tensor.to() Keeps input names Tensor.topk() ， torch.topk() Removes dimensions Tensor.transpose() ， torch.transpose() 排列尺寸 Tensor.trunc() ， torch.trunc() Keeps input names Tensor.trunc_() None Tensor.type() None Tensor.type_as() Keeps input names Tensor.unbind() ， torch.unbind() Removes dimensions Tensor.unflatten() See documentation Tensor.uniform_() None Tensor.var() ， torch.var() Removes dimensions torch.var_mean() Removes dimensions Tensor.zero_() None torch.zeros() Factory functions 保留输入名称 所有逐点一元函数以及其他一些一元函数都遵循此规则。 检查姓名：无 传播名称：输入张量的名称会传播到输出。 >>> x = torch.randn(3, 3, names=('N', 'C')) >>> x.abs().names ('N', 'C') 移除尺寸 所有缩小操作，例如 sum() ，都会通过缩小所需尺寸来删除尺寸。 select() 和 squeeze() 等其他操作会删除尺寸。 只要有人可以将整数维度索引传递给运算符，就可以传递维度名称。 包含维索引列表的函数也可以包含维名称列表。 检查名称：如果dim或dims作为名称列表传入，请检查self中是否存在这些名称。 传播名称：如果在输出张量中不存在dim或dims指定的输入张量的尺寸，则这些尺寸的相应名称不会出现在output.names中。 >>> x = torch.randn(1, 3, 3, 3, names=('N', 'C', 'H', 'W')) >>> x.squeeze('N').names ('C', 'H', 'W') >>> x = torch.randn(3, 3, 3, 3, names=('N', 'C', 'H', 'W')) >>> x.sum(['N', 'C']).names ('H', 'W') # Reduction ops with keepdim=True don't actually remove dimensions. >>> x = torch.randn(3, 3, 3, 3, names=('N', 'C', 'H', 'W')) >>> x.sum(['N', 'C'], keepdim=True).names ('N', 'C', 'H', 'W') 统一输入中的名称 所有二进制算术运算都遵循此规则。 广播操作仍然从右侧进行位置广播，以保持与未命名张量的兼容性。 要通过名称执行显式广播，请使用 Tensor.align_as() 。 检查名称：所有名称都必须从右侧位置匹配。 即，在tensor + other中，对于(-min(tensor.dim(), other.dim()) + 1, -1]中的所有i，match(tensor.names[i], other.names[i])必须为 true。 检查名称：此外，所有命名的尺寸必须从右对齐。 在匹配期间，如果我们将命名尺寸A与未命名尺寸None匹配，则A不得出现在具有未命名尺寸的张量中。 传播名称：从两个张量的右边开始统一名称对，以产生输出名称。 例如， # tensor: Tensor[ N, None] # other: Tensor[None, C] >>> tensor = torch.randn(3, 3, names=('N', None)) >>> other = torch.randn(3, 3, names=(None, 'C')) >>> (tensor + other).names ('N', 'C') 检查姓名： match(tensor.names[-1], other.names[-1])是True match(tensor.names[-2], tensor.names[-2])是True 由于我们将 tensor 中的None与'C'匹配，因此请确保 tensor 中不存在'C'。 检查以确保other中不存在'N'(不存在）。 最后，使用[unify('N', None), unify(None, 'C')] = ['N', 'C']计算输出名称 更多示例： # Dimensions don't match from the right: # tensor: Tensor[N, C] # other: Tensor[ N] >>> tensor = torch.randn(3, 3, names=('N', 'C')) >>> other = torch.randn(3, names=('N',)) >>> (tensor + other).names RuntimeError: Error when attempting to broadcast dims ['N', 'C'] and dims ['N']: dim 'C' and dim 'N' are at the same position from the right but do not match. # Dimensions aren't aligned when matching tensor.names[-1] and other.names[-1]: # tensor: Tensor[N, None] # other: Tensor[ N] >>> tensor = torch.randn(3, 3, names=('N', None)) >>> other = torch.randn(3, names=('N',)) >>> (tensor + other).names RuntimeError: Misaligned dims when attempting to broadcast dims ['N'] and dims ['N', None]: dim 'N' appears in a different position from the right across both lists. 注意 在最后两个示例中，可以通过名称对齐张量，然后执行加法。 使用 Tensor.align_as() 按名称对齐张量，或使用 Tensor.align_to() 将张量对齐到自定义尺寸顺序。 排列尺寸 某些操作(例如 Tensor.t())会置换尺寸顺序。 维度名称附加到各个维度，因此也可以排列。 如果操作员输入位置索引dim，它也可以采用尺寸名称作为dim。 检查名称：如果将dim作为名称传递，请检查其是否在张量中存在。 传播名称：以与要排列的维相同的方式排列维名称。 >>> x = torch.randn(3, 3, names=('N', 'C')) >>> x.transpose('N', 'C').names ('C', 'N') 收缩消失 矩阵乘法函数遵循此方法的某些变体。 让我们先通过 torch.mm() ，然后概括一下批矩阵乘法的规则。 对于torch.mm(tensor, other)： Check names: None 传播名称：结果名称为(tensor.names[-2], other.names[-1])。 >>> x = torch.randn(3, 3, names=('N', 'D')) >>> y = torch.randn(3, 3, names=('in', 'out')) >>> x.mm(y).names ('N', 'out') 本质上，矩阵乘法在二维上执行点积运算，使它们折叠。 当两个张量矩阵相乘时，收缩尺寸消失，并且不出现在输出张量中。 torch.mv() ， torch.dot() 的工作方式类似：名称推断不会检查输入名称，并且会删除点积所涉及的尺寸： >>> x = torch.randn(3, 3, names=('N', 'D')) >>> y = torch.randn(3, names=('something',)) >>> x.mv(y).names ('N',) 现在，让我们看一下torch.matmul(tensor, other)。 假设tensor.dim() &gt;= 2和other.dim() &gt;= 2。 检查名称：检查输入的批次尺寸是否对齐并可以广播。 请参见统一输入的名称，以了解对齐输入的含义。 传播名称：结果名称是通过统一批次尺寸并删除合同规定的尺寸获得的：unify(tensor.names[:-2], other.names[:-2]) + (tensor.names[-2], other.names[-1])。 例子： # Batch matrix multiply of matrices Tensor['C', 'D'] and Tensor['E', 'F']. # 'A', 'B' are batch dimensions. >>> x = torch.randn(3, 3, 3, 3, names=('A', 'B', 'C', 'D)) >>> y = torch.randn(3, 3, 3, names=('B', 'E', 'F)) >>> torch.matmul(x, y).names ('A', 'B', 'C', 'F') 最后，还有许多功能的融合add版本。 即 addmm() 和 addmv() 。 这些被视为构成 mm() 的名称推断和 add() 的命名推断。 工厂功能 现在，工厂函数采用新的names参数，该参数将名称与每个维度相关联。 >>> torch.zeros(2, 3, names=('N', 'C')) tensor([[0., 0., 0.], [0., 0., 0.]], names=('N', 'C')) 输出功能和就地变型 指定为out=张量的张量具有以下行为： 如果没有命名维，则将从操作中计算出的名称传播到其中。 如果它具有任何命名维，则从该操作计算出的名称必须与现有名称完全相同。 否则，操作错误。 所有就地方法都会将输入修改为具有与根据名称推断计算出的名称相同的名称。 例如， >>> x = torch.randn(3, 3) >>> y = torch.randn(3, 3, names=('N', 'C')) >>> x.names (None, None) >>> x += y >>> x.names ('N', 'C') 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:39:43 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"103.html":{"url":"103.html","title":"糟糕！","keywords":"","body":"糟糕！ 原文： https://pytorch.org/docs/stable/config.html 你已经死胡同了。 如果您觉得应该在此处，则可以在 GitHub 上发布问题。 单击此处的返回主页。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-03 22:29:17 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"105.html":{"url":"105.html","title":"torchvision","keywords":"","body":"torchvision 原文： https://pytorch.org/docs/stable/torchvision/index.html torchvision 软件包包含用于计算机视觉的流行数据集，模型架构和常见图像转换。 包装参考 torchvision.datasets MNIST fashion MNIST KMNIST EMNIST QMNIST FakeData coco LSUN ImageFolder DatasetFolder ImageNet CIFAR STL10 SVHN PhotoTour SBU Flickr VOC 城市景观 SBD USPS Kinetics-400 HMDB51 UCF101 torchvision.io 视频 torchvision.models 分类 语义细分 对象检测，实例细分和人员关键点检测 视频分类 torchvision.ops torchvision.transforms 在 PIL 上转换图像 在torch上变换*张量 转换变换 通用转换 功能变换 torchvision.utils torchvision.get_image_backend()¶ 获取用于加载图像的包的名称 torchvision.set_image_backend(backend)¶ 指定用于加载图像的软件包。 参数 后端(字符串）–图像后端的名称。 {‘PIL’，‘accimage’}之一。 accimage程序包使用 Intel IPP 库。 它通常比 PIL 快，但不支持那么多操作。 torchvision.set_video_backend(backend)¶ 指定用于解码视频的包。 Parameters 后端(字符串）– 视频后端的名称。 {‘pyav’，‘video_reader’}之一。 pyav包使用第三方 PyAv 库。 这是 Pythonic FFmpeg 库的绑定。 The video_reader package includes a native c++ implementation on FFMPEG 库的顶部，以及 TorchScript 自定义运算符的 python API。 通常，它的解码速度比 pyav 快，但可能不够鲁棒。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:25:18 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"107.html":{"url":"107.html","title":"torchaudio","keywords":"","body":"torchaudio 原文： https://pytorch.org/audio torchaudio 程序包由 I / O，常用数据集和常见音频转换组成。 包装参考 torchaudio.sox_effects SoxEffect SoxEffectsChain torchaudio.datasets COMMONVOICE LIBRISPEECH VCTK 是 torchaudio.compliance.kaldi 功能 torchaudio.kaldi_io 矢量 矩阵 torchaudio.transforms 频谱图 AmplitudeToDB MelScale MelSpectrogram MFCC MuLawEncoding MuLawDecoding 重采样 ComplexNorm ComputeDeltas TimeStretch 频率屏蔽 时标 torchaudio.functional istft 频谱图 振幅 _ 至 _DB create_fb_matrix create_dct mu_law_encoding mu_law_decoding complex_norm 角度 相位 phase_vocoder lfilter biquad lowpass_biquad highpass_biquad equalizer_biquad mask_along_axis mask_along_axis_iid compute_deltas detect_pitch_frequency torchaudio.get_sox_bool(i=0)¶ 获取 sox_bool 枚举以获取 sox encodinginfo 选项。 参数 i (int ， 可选）–选择类型或获取具有所有可能选项的字典，请使用__members__查看未指定的所有选项。 (默认：sox_false或0） 退货 sox_bool 类型 返回类型 sox_bool torchaudio.get_sox_encoding_t(i=None)¶ 获取 sox 编码的 sox_encoding_t 枚举。 Parameters i (int ， 可选）–选择类型或获取具有所有可能选项的字典，请使用__members__查看未指定的所有选项。 (默认：None） Returns 用于输出编码的 sox_encoding_t 类型 Return type sox_encoding_t torchaudio.get_sox_option_t(i=2)¶ 获取 sox encodinginfo 选项的 sox_option_t 枚举。 Parameters i (int ， 可选）–选择类型或获取具有所有可能选项的字典，请使用__members__查看未指定的所有选项。 (默认：sox_option_default或2） Returns sox_option_t 类型 Return type sox_option_t torchaudio.info(filepath)¶ 从音频文件获取元数据，而不加载信号。 Parameters 文件路径 (str)–音频文件的路径 Returns si(sox_signalinfo_t）信号信息作为 python 对象。 EI(sox_encodinginfo_t）编码信息 Return type 元组[sox_signalinfo_t，sox_encodinginfo_t] Example >>> si, ei = torchaudio.info('foo.wav') >>> rate, channels, encoding = si.rate, si.channels, ei.encoding torchaudio.initialize_sox()¶ 初始化 sox 以与效果链一起使用。 对于简单加载，这不是必需的。 重要的是，只运行一次 initialize_sox ，并且不要在每个效果链之后都关闭，而是在完成所有效果链后才关闭。 torchaudio.load(filepath, out=None, normalization=True, channels_first=True, num_frames=0, offset=0, signalinfo=None, encodinginfo=None, filetype=None)¶ 将音频文件从磁盘加载到张量 Parameters 文件路径 (str 或 pathlib.Path)–音频文件的路径 输出 (torch张量 ， 可选）–使用一个输出张量来代替创建一个张量。 (默认：None） 规范化 (bool ， 编号 或 可调用 ， 可选）–如果布尔值为 True ，则输出除以 1 (假定带符号 32- 位音频），并标准化为 [-1，1] 。 如果数字，则输出除以该数字。如果可调用，则将输出作为参数传递给给定函数，然后将输出除以结果。 (默认：True） channels_first (bool)–首先设置通道，或先设置长度。 (默认：True） num_frames (int ， 可选）–要加载的帧数。 0 加载偏移量之后的所有内容。 (默认：0） 偏移量 (int ， 可选）–从文件开始到开始数据加载的帧数 。 (默认：0） signalinfo (sox_signalinfo_t ， 可选）– sox_signalinfo_t 类型，如果无法自动确定音频类型，则可能会有所帮助。 (默认：None） encodinginfo (sox_encodinginfo_t ， 可选）– sox_encodinginfo_t 类型，如果无法自动确定音频类型，则可以设置。 (默认：None） 文件类型 (str ， 可选）–如果 sox 无法自动确定文件类型或扩展名，请设置 。 (默认：None） Returns 大小为 [C x L] 或 [L x C] 的输出张量，其中 L 是音频帧数，C 是声道数。 一个整数，它是音频的采样率(如文件的元数据中所列） Return type 元组[torch.张量， int ] Example >>> data, sample_rate = torchaudio.load('foo.mp3') >>> print(data.size()) torch.Size([2, 278756]) >>> print(sample_rate) 44100 >>> data_vol_normalized, _ = torchaudio.load('foo.mp3', normalization=lambda x: torch.abs(x).max()) >>> print(data_vol_normalized.abs().max()) 1. torchaudio.load_wav(filepath, **kwargs)¶ 加载波形文件。 假定 wav 文件每个样本使用 16 位，需要通过将输入右移 16 位来进行归一化。 Parameters filepath (str or pathlib.Path) – Path to audio file Returns An output tensor of size [C x L] or [L x C] where L is the number of audio frames and C is the number of channels. An integer which is the sample rate of the audio (as listed in the metadata of the file) Return type Tuple[torch.Tensor, int] torchaudio.save(filepath, src, sample_rate, precision=16, channels_first=True)¶ save_encinfo 的便捷功能。 Parameters filepath (str) – Path to audio file src (torch张量)–形状为 [C x L] 或 [L x C]的输入 2D 张量 ] 其中 L 是音频帧数，C 是声道数 sample_rate (int)–整数，它是音频的采样率(如文件的元数据中列出） 精度 (int)–位精度(默认值：16） channels_first (bool)–首先设置通道，或先设置长度。 (默认：True） torchaudio.save_encinfo(filepath, src, channels_first=True, signalinfo=None, encodinginfo=None, filetype=None)¶ 将音频信号的张量以 mp3，wav 等标准格式保存到磁盘。 Parameters filepath (str) – Path to audio file src (torch.Tensor) – An input 2D tensor of shape [C x L] or [L x C] where L is the number of audio frames, C is the number of channels channels_first (bool) – Set channels first or length first in result. (Default: True) signalinfo (sox_signalinfo_t )– sox_signalinfo_t 类型，如果无法自动确定音频类型，这可能会有所帮助。 (默认：None） encodinginfo (soxencodinginfot, optional) – A sox_encodinginfo_t type, which could be set if the audio type cannot be automatically determined. (Default: None) filetype (str, optional) – A filetype or extension to be set if sox cannot determine it automatically. (Default: None) Example >>> data, sample_rate = torchaudio.load('foo.mp3') >>> torchaudio.save('foo.wav', data, sample_rate) torchaudio.shutdown_sox()¶ 摊牌袜效果链。 简单加载不需要。 重要的是，只能拨打一次。 尝试重新初始化 sox 将导致段错误。 torchaudio.sox_encodinginfo_t()¶ 创建一个 sox_encodinginfo_t 对象。 该对象可用于设置编码类型，位精度，压缩系数，反向字节，反向半字节，反向位和字节序。 可以在效果链中使用它来对最终输出进行编码或使用特定编码保存文件。 例如，可以使用 sox ulaw 编码进行 8 位 ulaw 编码。 请注意，在张量输出中，结果将是 32 位数字，但是唯一值的数量将由位精度确定。 Returns: sox_encodinginfo_t(object) 编码(sox_encoding_t），输出编码 bits_per_sample(int），位精度，与 sox_signalinfo_t 中的精度相同 压缩(浮动），有损格式的压缩，默认压缩为 0.0 reverse_bytes(sox_option_t），反向字节，使用 sox_option_default 反向半字节(sox_option_t），反向半字节，使用 sox_option_default reverse_bits(sox_option_t），反向字节，使用 sox_option_default 对立的字节序(sox_bool），更改字节序，使用 sox_false Example >>> ei = torchaudio.sox_encodinginfo_t() >>> ei.encoding = torchaudio.get_sox_encoding_t(1) >>> ei.bits_per_sample = 16 >>> ei.compression = 0 >>> ei.reverse_bytes = torchaudio.get_sox_option_t(2) >>> ei.reverse_nibbles = torchaudio.get_sox_option_t(2) >>> ei.reverse_bits = torchaudio.get_sox_option_t(2) >>> ei.opposite_endian = torchaudio.get_sox_bool(0) torchaudio.sox_signalinfo_t()¶ 创建一个 sox_signalinfo_t 对象。 该对象可用于设置效果的采样率，通道数，长度，位精度和净空倍数 Returns: sox_signalinfo_t(object) rate(float），采样率为 float，实际上可能是整数 float channel(int），音频通道数 精度(int），位精度 长度(int），样本中音频的长度*通道，0(未指定）和-1(未知） 多重(浮点型，可选），净空乘数用于效果，None无乘数 Example >>> si = torchaudio.sox_signalinfo_t() >>> si.channels = 1 >>> si.rate = 16000. >>> si.precision = 16 >>> si.length = 0 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 13:25:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"109.html":{"url":"109.html","title":"torchtext","keywords":"","body":"torchtext 原文： https://pytorch.org/text torchtext 程序包包含数据处理实用程序和流行的自然语言数据集。 包装参考 torchtext torchtext.data 数据集，批处理和示例 字段 迭代器 管道 功能 torchtext.data.utils get_tokenizer ngrams_iterator torchtext.data.functional generate_sp_model load_sp_model 句子数字编辑器 句子 _ 令牌 custom_replace simple_space_split numericize_tokens_from_iterator torchtext.data.metrics bleu_score torchtext.datasets 语言建模 情绪分析 文本分类 问题分类 需求 语言建模 机器翻译 序列标记 问答 无监督学习 torchtext.vocab 词汇 SubwordVocab 矢量 GloVe FastText CharNGram build_vocab_from_iterator torchtext.utils 报告钩子 download_from_url unicode_csv_reader extract_archive torchtext.experimental.datasets 情绪分析 语言建模 示例 指数和表格 索引 模块索引 搜索页 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:44:09 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"111.html":{"url":"111.html","title":"PyTorch 贡献指南","keywords":"","body":"PyTorch 贡献指南 原文： https://pytorch.org/docs/stable/community/contribution_guide.html PyTorch 是 GPU 加速的 Python 张量计算软件包，用于构建基于基于磁带的 autograd 系统构建的深度神经网络。 PyTorch 贡献过程 PyTorch 组织受 PyTorch 治理管辖。 PyTorch 开发过程涉及核心开发团队和社区之间的大量公开讨论。 PyTorch 的运行与 GitHub 上的大多数开源项目相似。 但是，如果您以前从未为开源项目做过贡献，那么这是基本过程。 弄清楚您要做什么。 大多数开源贡献来自于人们挠痒痒的人。 但是，如果您不知道要从事什么工作，或者只是想进一步了解该项目，请参考以下提示，以查找合适的任务： 浏览问题跟踪器，看看是否有任何已知的解决方法。 由其他贡献者确认的问题往往更易于调查。 我们还维护了一些可能对新人有益的标签，例如训练营和 1 小时，尽管这些标签维护得不太好。 加入我们的 Slack，让我们知道您有兴趣了解 PyTorch。 我们非常乐意帮助研究人员和合作伙伴加快使用代码库的速度。 找出更改的范围，并就 GitHub 问题(如果涉及的范围太大）寻求设计意见。 大多数拉取请求很小； 在这种情况下，无需让我们知道您想做什么，只需破解即可。 但是，如果变化很大，通常最好先获得一些设计意见。 如果您不知道更改会有多大，我们可以帮助您解决！ 只需发布有关问题或松弛的信息即可。 一些功能的添加非常标准化。 例如，许多人向 PyTorch 添加新的运算符或优化器。 在这些情况下，设计讨论主要归结为“我们是否需要此运算符/优化器？” 给出其实用性的证据，例如，在同行评审论文中的用法或在其他框架中的存在，在提出这种情况时会有所帮助。 通常不接受从最近发布的研究中添加运算符/算法，除非有大量证据表明这项新发表的研究成果具有开创性，并将最终成为该领域的标准。 如果不确定方法的用途，请在实施 PR 之前先打开问题。 核心变更和重构可能很难协调，因为 PyTorch master 的开发速度非常快。 绝对接触基本的或跨领域的变化； 我们通常可以提供有关如何将这些更改分成更容易检查的片段的指导。 编码！ 有关以技术形式使用 PyTorch 的建议，请参阅技术指南。 打开拉取请求。 如果您还没有准备好审查请求请求，请用[WIP]标记它。 审核通过时，我们将忽略它。 如果您要进行复杂的更改，最好先将其作为 WIP 进行，因为您将需要花费一些时间查看 CI 的结果以查看是否可行。 为您的更改找到合适的审阅者。 我们有一些人定期检查 PR 队列并尝试检查所有内容，但是如果您碰巧知道受补丁影响的给定子系统的维护者是谁，请随时将他们直接包含在请求请求中。 您可以在 PyTorch 子系统所有权上了解有关此结构的更多信息。 迭代拉取请求，直到接受为止！ 我们将尽最大努力减少审阅往返次数，并仅在出现重大问题时才阻止 PR。 对于请求请求中最常见的问题，请查看常见错误。 一旦请求请求被接受并且 CI 已通过，则您无需执行其他任何操作。 我们将为您合并 PR。 入门 提出新功能 最好在特定问题上讨论新功能的想法。 请提供尽可能多的信息，所有随附数据以及建议的解决方案。 PyTorch 团队和社区经常在他们认为有帮助的地方审查新问题和评论。 如果您对解决方案充满信心，请继续实施它。 报告问题 如果您发现了问题，请首先在存储库中搜索现有问题列表。 如果找不到类似的问题，请创建一个新的问题。 提供尽可能多的信息来重现有问题的行为。 此外，包括其他任何见解，例如您期望的行为。 实施功能或修复错误 如果您想解决特定的问题，最好有针对性地对单个问题发表评论。 但是，除非我们之前曾与开发人员合作，否则我们不会锁定或分配问题。 最好就此问题进行对话并讨论您建议的解决方案。 PyTorch 团队可以提供指导，以节省您的时间。 标为“新发行”，“低”或“中”优先级的问题是最好的切入点，是一个很好的起点。 添加教程 pytorch.org 上的大量教程都来自社区本身，我们欢迎您提供其他帮助。 要了解有关如何撰写新教程的更多信息，您可以在此处了解更多信息： Github 上的 PyTorch.org 教程贡献指南 改进文档&教程 我们旨在制作高质量的文档和教程。 在极少数情况下，内容包括错别字或错误。 如果您发现可以解决的问题，请向我们发送请求以供考虑。 请查看文档部分，以了解我们的系统如何工作。 参加在线讨论 您可以在 PyTorch 讨论论坛上找到活跃的讨论。 提交拉取请求以解决未解决的问题 您可以在此处查看所有未解决问题的列表。 对问题发表评论是引起团队关注的好方法。 在这里，您可以分享您的想法以及如何解决该问题。 对于更具挑战性的问题，团队将为如何最好地解决问题提供反馈和指导。 如果您无法自行解决问题，请评论并分享您是否可以重现该问题对于帮助团队确定问题区域很有用。 审查未完成的拉取请求 感谢您为审核请求提出评论的意见。 我们的团队努力将公开请求的数量保持在可管理的范围内，我们会在需要时迅速做出回应以提供更多信息，并且我们合并认为有用的 PR。 但是，由于人们的关注度很高，因此请多加关注拉取请求。 提高代码可读性 提高代码的可读性可以帮助所有人。 通常，提交少量触摸少量文件的请求，而不是提交大量触摸许多文件的请求。 在 PyTorch 论坛此处或与您的改进相关的问题上开始讨论是最好的入门方法。 添加测试用例以使代码库更健壮 附加测试覆盖范围表示赞赏。 推广 PyTorch 在项目，研究论文，文章，博客或互联网上的一般性讨论中使用 PyTorch 有助于提高对 PyTorch 和我们不断发展的社区的认识。 请联系 pytorch-marketing@fb.com 获取营销支持。 分类问题 如果您认为某个问题可以从特定的标记或复杂性级别中受益，请对该问题发表评论并分享您的观点。 如果您认为问题未正确归类，请发表评论并告知团队。 关于开源开发 如果这是您第一次为开放源代码项目做贡献，那么开发过程的某些方面对您来说似乎并不寻常。 无法“声明”问题。 人们通常希望在决定处理某个问题时“主张”该问题，以确保在其他人最终处理该问题时不会浪费工作。 在开放源代码中，这实际上并不是很好，因为有人可能会决定从事某项工作，最终没有时间去做。 随时以咨询的方式提供信息，但最终，我们将获得运行代码和粗略的共识。 添加了新功能的较高标准。 与公司环境不同，在公司环境中，编写代码的人隐式“拥有”该代码，并且可以期望在代码生命周期的开始就对其进行处理，一旦将合并请求合并到一个开源项目中，它就会立即 成为项目所有维护者的集体责任。 当我们合并代码时，我们是在说维护者能够查看随后的更改并对代码进行错误修正。 这自然会导致更高的贡献标准。 避免的常见错误 您是否添加了测试？ (或者如果很难测试更改，您是否描述了如何测试更改？） 对于为什么要进行测试，我们有一些动机： 来告诉我们以后是否要打破 帮助我们首先确定补丁程序是否正确(是的，我们确实对其进行了审核，但是正如 Knuth 所说，“请注意以下代码，因为我没有运行它，只是证明它是正确的”） 什么时候可以不添加测试？ 有时，更改无法方便地进行测试，或者更改显然很正确(并且不太可能被破坏），因此可以不进行测试。 相反，如果更改似乎有可能(或已知有可能）被意外破坏，那么花时间制定测试策略就很重要。 您的公关时间过长吗？ 对我们来说，审查和合并小型 PR 更加容易。 审查 PR 的难度与其规模成非线性关系。 什么时候可以提交大公关？ 如果在一个问题中进行了相应的设计讨论，并从将要检查您的差异的人员处签名，则很有帮助。 我们还可以帮助您提供建议，说明如何将较大的更改分成可单独装运的部分。 同样，如果对 PR 的内容有完整的描述，也会有所帮助：如果我们知道其中的内容，则更容易查看代码！ 对微妙的事物发表评论吗？ 如果您的代码行为有细微差别，请提供额外的注释和文档，以使我们更好地了解您的代码的意图。 您添加了 hack 吗？ 有时候，破解是正确的答案。 但是通常我们将不得不讨论它。 您想触摸一个非常核心的组件吗？ 为了防止出现重大衰退，涉及核心组件的拉取请求会受到额外的审查。 在进行重大更改之前，请确保您已与团队讨论过更改。 是否要添加新功能？ 如果要添加新功能，请对相关问题发表评论。 我们的团队尝试发表评论并向社区提供反馈。 在开发新功能之前，最好与团队和社区的其他成员进行公开讨论。 这可以帮助我们随时了解您的工作，并增加合并的可能性。 您是否触摸了与 PR 无关的代码？ 为帮助进行代码审查，请仅在请求请求中包括与您的更改直接相关的文件。 经常问的问题 我如何才能担任审稿人？ 如果社区开发人员重现问题，尝试新功能或以其他方式帮助我们确定问题或对其进行故障排除，则将具有很多价值。 使用您的环境详细信息对任务进行注释或请求将很有帮助并受到赞赏。 CI 测试失败，这是什么意思？ 也许您需要与 master 合并或以最新更改为基础。 推送更改应重新触发 CI 测试。 如果测试持续进行，您将需要查找错误消息并解决相关问题。 最高风险的更改是什么？ 涉及构建配置的任何内容都是有风险的领域。 除非事先与团队讨论，否则请避免更改这些内容。 嘿，我的分支上出现了一个提交，这是怎么回事？ 有时，另一个社区成员会为您的请求请求或分支提供补丁或修复。 为了使 CI 测试通过，通常需要这样做。 关于文档 Python 文档 PyTorch 文档是使用 Sphinx 从 python 源生成的。 生成的 HTML 复制到 pytorch.github.io 的 master 分支中的 docs 文件夹中，并通过 GitHub 页面提供。 网站： http://pytorch.org/docs GitHub： https://github.com/pytorch/pytorch/tree/master/docs 从以下服务器提供： https://github.com/pytorch/pytorch.github.io/tree/master/doc C ++文件 对于 C ++代码，我们使用 Doxygen 生成内容文件。 C ++文档建立在特殊的服务器上，并将生成的文件复制到 https://github.com/pytorch/cppdocs 存储库，并从 GitHub 页面提供。 网站： http://pytorch.org/cppdocs GitHub： https://github.com/pytorch/pytorch/tree/master/docs/cpp 从以下服务器提供： https://github.com/pytorch/cppdocs 讲解 PyTorch 教程是用于帮助理解使用 PyTorch 完成特定任务或了解更全面概念的文档。 教程是使用 Sphinx-Gallery 从可执行的 python 源文件或重组文本(rst）文件构建的。 网站： http://pytorch.org/tutorials GitHub： http://github.com/pytorch/tutorials 教程构建概述 对于教程，拉取请求使用 CircleCI 触发重建整个站点，以测试更改的效果。 该建筑被分割为 9 个工人建筑，总共耗时约 40 分钟。 同时，我们使用 make html-noplot 进行 Netlify 构建，该构建无需将笔记本输出呈现为页面即可快速浏览的站点。 接受 PR 后，可从 CircleCI 重建和部署站点。 撰写新教程 PyTorch.org 教程贡献指南 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:37:36 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"112.html":{"url":"112.html","title":"PyTorch 治理","keywords":"","body":"PyTorch 治理 原文： https://pytorch.org/docs/stable/community/governance.html 治理哲学与指导原则 PyTorch 采用治理结构，由一小组维护者推动整个项目方向，强烈偏向于 PyTorch 重视设计和代码贡献的设计理念。 除了核心维护者之外，还有一些稍微更广泛的核心开发人员，它们能够直接合并拉取请求并拥有核心代码库的各个部分。 除了维护者和核心开发人员之外，还鼓励社区做出贡献，提出问题，提出建议，审查拉动请求并出现在社区中。 有了贡献和投资意愿，就可以向任何人提供写访问权或部分代码库的所有权。 在此治理结构的基础上，该项目具有以下核心运营宗旨，通过这些宗旨进行决策并得出整体文化： 代码贡献的重要性远远超过公司赞助，并且独立开发人员也受到高度重视。 项目影响力是通过贡献获得的(无论是 PR，论坛答案，代码审查还是其他） 关键人物及其职能 项目维护者 项目维护者为 PyTorch 项目提供领导和指导。 具体包括： 为项目表达凝聚力的长期愿景 拥有对 PyTorch 代码库的深刻理解 以所有有关方面都可以接受的方式谈判和解决有争议的问题 PyTorch 维护人员： Adam Paszke (apaszke) Soumith Chintala (soumith) Edward Yang (ezyang) Greg Chanan (gchanan) Dmytro Dzhulgakov (dzhulgakov) (日落）Sam Gross(科尔斯伯里） 核心开发人员 PyTorch 项目由一组核心开发人员开发。 您可以在 PyTorch Governance |网站上找到核心开发人员列表。 感兴趣的人。 成员资格是由 GitHub 上“ PyTorch” 组织中“ PyTorch 核心”团队中的存在来决定的，但是贡献可以采取多种形式： 提交对存储库的更改； 审查其他人的拉取请求； 在问题跟踪器上分类错误报告； 在官方 PyTorch 交流渠道上讨论话题。 主持人 有一群人(其中有些不是核心开发人员）负责确保有关官方交流渠道的讨论符合《行为准则》。 他们针对违法行为采取行动，并帮助支持一个健康的社区。 您可以在中找到主持人列表。 做决定 毫无争议的变化 主要工作是通过错误跟踪程序问题以及在 GitHub 上的拉取请求来完成的。 核心开发人员应避免将其更改直接推送到 PyTorch 存储库，而应依赖于请求请求。 核心开发人员批准拉取请求后，无需进行进一步处理即可将其合并。 核心开发人员和项目维护人员最终会批准这些更改。 通知有关专家有关错误跟踪器问题或请求请求很重要。 强烈推荐给定兴趣领域的专家进行审核，尤其是在请求请求批准时。 否则，最终可能会导致相关专家撤消更改。 有争议的决策过程 给定关注领域的重大变化要求打开 GitHub 问题进行讨论。 这包括： 对框架的任何语义或语法更改。 向后不兼容的 Python 或 Cpp API 更改。 核心框架的补充，包括现有库中的实质性新功能。 删除核心功能 项目维护者最终会批准这些更改。 常问问题 问：如果我想拥有(或部分拥有）项目的一部分，例如域 api(即 Torch Vision）怎么办？ 这是绝对可能的。 第一步是开始为现有项目领域做出贡献，并为它的健康和成功做出贡献。 除此之外，您可以通过 GitHub 问题提出建议，以提供新功能或进行更改以改善项目范围。 问：如果我是一家希望内部使用 PyTorch 进行开发的公司，可以授予或购买董事会席位以驱动项目方向怎么办？ 不，PyTorch 项目严格由维护者驱动的项目理念来驱动，并且没有董事会或工具来获得与对技术方向的影响力相关的财务贡献。 问：PyTorch 项目是否支持赠款或方法来支持使用该项目或对该项目做出贡献的独立开发人员？ 否，目前不行。 但是，我们正在寻找方法，以更好地支持 PyTorch 周围的独立开发者社区。 如果您有建议或意见，请在 PyTorch 论坛上进行讨论。 问：如何为项目贡献代码？ 如果更改相对较小，则可以立即在 GitHub 上打开拉取请求，以供项目提交者进行审核和合并。 对于较大的更改，请打开问题以提出建议，以供事先讨论。 另请参阅 PyTorch 贡献者指南了解贡献准则。 问：我可以成为该项目的提交者吗？ 不幸的是，当前对 PyTorch 的提交过程涉及与 Facebook 基础结构的交互，该交互只能由 Facebook 员工触发。 但是，我们正在寻找将提交者基础扩展到 Facebook 以外的个人的方法，并将在存在允许此操作的工具时提供更新。 问：如果我想在会议上或其他场合提供 PyTorch 教程怎么办？ 我需要成为“官方”提交者吗？ 不，我们鼓励社区成员尽可能地展示他们的作品。 请联系 pytorch-marketing@fb.com 以获得营销支持。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:39:43 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"113.html":{"url":"113.html","title":"PyTorch 治理| 感兴趣的人","keywords":"","body":"PyTorch 治理| 感兴趣的人 原文： https://pytorch.org/docs/stable/community/persons_of_interest.html 一般维护者 Adam Paszke (apaszke) Soumith Chintala (soumith) Edward Yang (ezyang) Greg Chanan (gchanan) Dmytro Dzhulgakov (dzhulgakov) (日落）Sam Gross(科尔斯伯里） 模块级维护者 torch.* Greg Chanan (gchanan) Soumith Chintala (soumith) [线性代数] Vishwak Srinivasan (vishwakftw) torch 托马斯·维曼 (t-vi) Adam Paszke (apaszke) Greg Chanan (gchanan) Soumith Chintala (soumith) Sam Gross (colesbury) torch.optim Vincent Quenneville-Belair (vincentqb) Soumith Chintala (soumith) 万超良 (wanchaol) Autograd Engine Edward Yang (ezyang) Alban Desmaison (alband) Adam Paszke (apaszke) JIT Zach Devito (zdevito) 迈克尔·索 (suo) 发行 & RNG 弗里茨·奥伯梅耶 (fritzo) Neeraj Pradhan (neerajprad) Alican Bozkurt (alicanb) Vishwak Srinivasan (vishwakftw) Distributed Pieter Noordhuis (pietern) 神力 (mrshenli) (建议）Pritam Damania (pritamdamania87) 并行处理和数据加载器 Vitaly Fedyunin (VitalyFedyunin) Simon Wang (SsnL) Adam Paszke (apaszke) CPU 性能/ SIMD 郑小强 (zheng-xq) Vitaly Fedyunin (VitalyFedyunin) Sam Gross (colesbury) (日落）克里斯蒂安·普尔施 (cpuhrsch) [执行绪] Ilia Cherniavskii (ilia-cher) 卡达 Natalia Gimelshein (ngimel) Edward Yang (ezyang) Xiaoqiang Zheng (zheng-xq) MKLDNN 白俊杰 (bddppq) 英海路(英海） 移动 大卫·赖斯 (dreiss) 刘佳凯 (ljk53) 量化 Raghuraman Krishnamoorthi (dreiss) 张杰((jerryzh168 ) 刘玲怡 (lly-zero-one) 詹姆斯·里德 (jamesr66a) XLA 张爱玲 (ailzhang) Gregory Chanan (gchanan) Davide Libenzi (dlibenzi) Alex Suhan (asuhan) AMD / ROCm / HIP Junjie Bai (bddppq) 约翰内斯·迪特里里希 (iotamudelta) Build + CI 冯伟 (yf225) Edward Yang (ezyang) Soumith Chintala (soumith) 卡尔·奥斯特莫 (kostmo) 许洪 (xuhdev) 基准测试 李明哲 (mingzhe09088) C ++ API Will Feng (yf225) C10 实用程序和操作员派遣 塞巴斯蒂安·梅斯默 (smessmer) Dmytro Dzhulgakov (dzhulgakov) ONNX PyTorch 鲁芳(屋宇路） Lara Haidar (lara-hdr) Spandan Tiwari (spandantiwari) 鲍文宝(鲍文宝） 视窗 彼得·约翰逊 (peterjc123) PowerPC 阿尔弗雷多·门多萨 (avmgithub) 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2020-03-04 12:54:58 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"}}